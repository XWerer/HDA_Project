{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'python_speech_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2a8f272d156c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline  '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mextractMFCC\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcomputeFeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomputeFeatures1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0maddNoise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maddNoise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/HDA_Project/extractMFCC.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwavfile\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpython_speech_features\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0maddNoise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maddNoise2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'python_speech_features'"
     ]
    }
   ],
   "source": [
    "import Model\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import re\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "from extractMFCC import computeFeatures, computeFeatures1\n",
    "from addNoise import addNoise\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testWAVs = pd.read_csv('Dataset/testing_list.txt', sep=\" \", header=None)[0].tolist()\n",
    "valWAVs  = pd.read_csv('Dataset/validation_list.txt', sep=\" \", header=None)[0].tolist()\n",
    "\n",
    "for idx, item in enumerate(testWAVs):\n",
    "    testWAVs[idx] = \"Dataset/\" + testWAVs[idx]\n",
    "\n",
    "for idx, item in enumerate(valWAVs):\n",
    "    valWAVs[idx] = \"Dataset/\" + valWAVs[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DictCategs = {'nine' : 1, 'yes' : 2, \n",
    "                         'no' : 3, 'up' : 4, 'down' : 5, 'left' : 6, 'right' : 7, 'on' : 8, 'off' : 9, 'stop' : 10, 'go' : 11,\n",
    "                         'zero' : 12, 'one' : 13, 'two' : 14, 'three' : 15, 'four' : 16, 'five' : 17, 'six' : 18, \n",
    "                         'seven' : 19,  'eight' : 20, 'backward':0, 'bed':0, 'bird':0, 'cat':0, 'dog':0,\n",
    "                         'follow':0, 'forward':0, 'happy':0, 'house':0, 'learn':0, 'marvin':0, 'sheila':0, 'tree':0,\n",
    "                         'visual':0, 'wow':0}\n",
    "nCategs = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'valWAVs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0921a4231b98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"Dataset/_background_noise_\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mallWAVs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainWAVs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallWAVs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalWAVs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestWAVs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'valWAVs' is not defined"
     ]
    }
   ],
   "source": [
    "allWAVs  = []\n",
    "for root, dirs, files in os.walk('Dataset/'):\n",
    "    if root != \"Dataset/_background_noise_\":\n",
    "        allWAVs += [root+'/'+ f for f in files if f.endswith('.wav')]\n",
    "trainWAVs = list( set(allWAVs)-set(valWAVs)-set(testWAVs) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(trainWAVs))\n",
    "print(len(valWAVs))\n",
    "print(len(testWAVs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _getFileCategory(file, catDict):\n",
    "    \"\"\"\n",
    "    Receives a file with name Dataset/<cat>/<filename> and returns an integer that is catDict[cat]\n",
    "    \"\"\"\n",
    "    categ = os.path.basename(os.path.dirname(file))\n",
    "    return catDict.get(categ,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get categories\n",
    "testWAVlabels = [_getFileCategory(f, DictCategs) for f in testWAVs]\n",
    "valWAVlabels = [_getFileCategory(f, DictCategs) for f in valWAVs]\n",
    "trainWAVlabels = [_getFileCategory(f, DictCategs) for f in trainWAVs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(trainWAVlabels))\n",
    "print(len(valWAVlabels))\n",
    "print(len(testWAVlabels))\n",
    "#print(trainWAVs[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.io.wavfile import read\n",
    "import python_speech_features as sf\n",
    "import numpy as np\n",
    "from addNoise import addNoise2\n",
    "\n",
    "def cp(wav_signal_name, desiredLength = 16000, log = True, w_len = 0.025, w_step = 0.01, noise = \"dude_miaowing.wav\"):\n",
    "    # input:   a wav audio file (ours are all 1 second long, so 16000 sample long if Fc = 16000)\n",
    "    # the noise is the one to add to the signal if the signal is not full length\n",
    "    # output:  a 2D matrix of size (num_frames, 39), where 39 is the number of coefficients of the features vectors\n",
    "    # data are supposed to be single channel\n",
    "    # log = True: it means that we take the logarithm of the energies of delta and delta-delta\n",
    "    \n",
    "    # read audio sample\n",
    "    print(wav_signal_name)\n",
    "    input_signal = read(wav_signal_name)\n",
    "    # sampling rate\n",
    "    \n",
    "    Fc = input_signal[0]\n",
    "    # Nyquist critical frequency(highest freq. that can be represented)\n",
    "    nyqF = int(Fc/2)  #input in sf.base.mfcc() has to be an int\n",
    "    signal = input_signal[1] # this is the vector-signal we are interested in\n",
    "    if(signal.shape[0] < desiredLength):\n",
    "        noise = read(noise)[1]\n",
    "        signal = addNoise2(signal, noise, begin = True)\n",
    "    # appendEnergy = True means that the zeroth value of all the cepstral vectors is replaced  with the corresponding frame energy, E(s_i)\n",
    "    coeffs = sf.base.mfcc(signal, samplerate = Fc, nfft = nyqF, appendEnergy = True, winlen=w_len, winstep=w_step, winfunc=np.hamming)\n",
    "    useful_coeffs = coeffs[:,1:13] # (taking only the 1,2,...,12 MFCC's)\n",
    "    # energy(s)\n",
    "    E_s = coeffs[:,0]\n",
    "    # take the log10 to limit the dynamics\n",
    "    log_E_s = np.log10(E_s)\n",
    "    #print(\"shape of log energies of the frames: \" + str(log_E_s.shape))\n",
    "    #print(\"shape of useful coefficients: \" + str(useful_coeffs.shape))\n",
    "\n",
    "    # extracting deltas\n",
    "    deltas = sf.base.delta(useful_coeffs, 2)\n",
    "    #print(\"deltas = \" + str(deltas.shape))\n",
    "    \n",
    "    # extracting deltas of deltas\n",
    "    deltas_2 = sf.base.delta(deltas, 2)\n",
    "    #print(\"deltas_2 = \" + str(deltas_2.shape))\n",
    "    \n",
    "    # getting energies of deltas and of deltas_2\n",
    "    E_deltas = np.sum(np.power(deltas, 2), axis = 1)\n",
    "    log_E_deltas = np.log10(E_deltas)\n",
    "    #print(\"shape of log_E_deltas = \" + str(log_E_deltas.shape))\n",
    "    \n",
    "    # energy of delta of deltas: \n",
    "    E_deltas_2 = np.sum(np.power(deltas, 2), axis = 1)\n",
    "    log_E_deltas_2 = np.log10(E_deltas_2)\n",
    "    #print(\"shape of log_E_deltas_2 = \" + str(log_E_deltas_2.shape))\n",
    "\n",
    "    if(log):\n",
    "        E_d = log_E_deltas\n",
    "        E_d_d = log_E_deltas_2\n",
    "    else:\n",
    "        E_d = E_deltas    \n",
    "        E_d_d = E_deltas_2\n",
    "\n",
    "    # preallocating space:\n",
    "    num_frames = coeffs.shape[0]\n",
    "    #num_frames = 99\n",
    "    features = np.zeros((num_frames,39))\n",
    "\n",
    "    # putting everything inside the features 2D matrix:\n",
    "    features[0:coeffs.shape[0], 0:12] = useful_coeffs\n",
    "    features[0:coeffs.shape[0], 12:24] = deltas\n",
    "    features[0:coeffs.shape[0], 24:36] = deltas_2\n",
    "    features[0:coeffs.shape[0], 36] = log_E_s\n",
    "    features[0:coeffs.shape[0], 37] = E_d\n",
    "    features[0:coeffs.shape[0], 38] = E_d_d\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(file_name):\n",
    "    # Required by tensorflow (strings are passed as bytes)\n",
    "    file_name = tf.io.read_file(file_name)\n",
    "    file_name = file_name.eval()\n",
    "    #if type(file_name) is bytes:\n",
    "    #    file_name = file_name.decode()\n",
    "    print(file_name)\n",
    "    # Load data\n",
    "    feats = cp(file_name)\n",
    "    # Normalize\n",
    "    mean = np.mean(feats, axis = 0)\n",
    "    stv = np.std(feats, axis = 0)\n",
    "    diff = np.subtract(feats, mean)\n",
    "    feats = np.divide(diff, stv)\n",
    "\n",
    "    return feats.astype(np.float32)\n",
    "\"\"\"\n",
    "# example:\n",
    "feats = load_and_preprocess_data(trainWAVs[25])\n",
    "feats = np.transpose(feats)\n",
    "\n",
    "plt.figure(figsize=(17,6))\n",
    "plt.pcolormesh(feats)\n",
    "\n",
    "plt.title('Spectrogram visualization')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Time')\n",
    "\n",
    "plt.show()\n",
    "print(trainWAVlabels[25])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ds = tf.data.Dataset.from_tensor_slices(trainWAVs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ds = path_ds.map(load_and_preprocess_data, num_parallel_calls=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(file_names, labels, batch_size, shuffle, cache_file=None):\n",
    "    \n",
    "    # Create a Dataset object\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(file_names)\n",
    "    \n",
    "    # Map the load_and_preprocess_data function\n",
    "    #py_func = lambda file_name, label: (tf.py_function(load_and_preprocess_data, [file_name], tf.float32), label)\n",
    "    dataset = dataset.map(load_and_preprocess_data, num_parallel_calls=os.cpu_count())\n",
    "    \n",
    "    # Cache dataset\n",
    "    if cache_file:\n",
    "        dataset = dataset.cache(cache_file)\n",
    "    \n",
    "    # Shuffle    \n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(len(file_names))\n",
    "        \n",
    "    # Repeat the dataset indefinitely\n",
    "    dataset = dataset.repeat()\n",
    "    \n",
    "    # Correct input shape for the network\n",
    "    dataset = dataset.map(lambda data, label: (tf.expand_dims(data, 1), label))\n",
    "    \n",
    "    # Batch\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "    \n",
    "    # Prefetch\n",
    "    dataset = dataset.prefetch(buffer_size=1)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = tf.constant(trainWAVs)\n",
    "#train_labels = tf.constant(trainWAVlabels)\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset = create_dataset(trainWAVs, \n",
    "                               trainWAVlabels, \n",
    "                               batch_size=batch_size, \n",
    "                               shuffle=True,\n",
    "                               cache_file='train_cache')\n",
    "\n",
    "val_dataset = create_dataset(valWAVs, \n",
    "                             valWAVlabels,\n",
    "                             batch_size=batch_size, \n",
    "                             shuffle=False,\n",
    "                             cache_file='val_cache')\n",
    "\n",
    "train_steps = int(np.ceil(len(trainWAVs)/batch_size))\n",
    "val_steps = int(np.ceil(len(valWAVs)/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model.AttentionModel(21, 99, 39, use_GRU = True)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "history = model.fit(train_dataset, epochs=num_epochs, steps_per_epoch=train_steps, validation_data=val_dataset, validation_steps=val_steps)\n",
    "\n",
    "# Save the model\n",
    "model.save('my_model.h5')\n",
    "\n",
    "# Plot loss\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Train loss')\n",
    "plt.plot(history.history['val_loss'], label='Val loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "# Plot accuracy\n",
    "plt.figure()\n",
    "plt.plot(history.history['acc'], label='Train loss')\n",
    "plt.plot(history.history['val_acc'], label='Val loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
