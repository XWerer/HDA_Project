{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta0\n"
     ]
    }
   ],
   "source": [
    "import Model\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import re\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "from extractMFCC import computeFeatures, computeFeatures1\n",
    "from addNoise import addNoise\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "testWAVs = pd.read_csv('Dataset/testing_list.txt', sep=\" \", header=None)[0].tolist()\n",
    "valWAVs  = pd.read_csv('Dataset/validation_list.txt', sep=\" \", header=None)[0].tolist()\n",
    "\n",
    "for idx, item in enumerate(testWAVs):\n",
    "    testWAVs[idx] = \"Dataset/\" + testWAVs[idx]\n",
    "\n",
    "for idx, item in enumerate(valWAVs):\n",
    "    valWAVs[idx] = \"Dataset/\" + valWAVs[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "DictCategs = {'nine' : 1, 'yes' : 2, \n",
    "                         'no' : 3, 'up' : 4, 'down' : 5, 'left' : 6, 'right' : 7, 'on' : 8, 'off' : 9, 'stop' : 10, 'go' : 11,\n",
    "                         'zero' : 12, 'one' : 13, 'two' : 14, 'three' : 15, 'four' : 16, 'five' : 17, 'six' : 18, \n",
    "                         'seven' : 19,  'eight' : 20, 'backward':0, 'bed':0, 'bird':0, 'cat':0, 'dog':0,\n",
    "                         'follow':0, 'forward':0, 'happy':0, 'house':0, 'learn':0, 'marvin':0, 'sheila':0, 'tree':0,\n",
    "                         'visual':0, 'wow':0}\n",
    "nCategs = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "allWAVs  = []\n",
    "for root, dirs, files in os.walk('Dataset/'):\n",
    "    if root != \"Dataset/_background_noise_\":\n",
    "        allWAVs += [root+'/'+ f for f in files if f.endswith('.wav')]\n",
    "trainWAVs = list( set(allWAVs)-set(valWAVs)-set(testWAVs) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84843\n",
      "9981\n",
      "11005\n"
     ]
    }
   ],
   "source": [
    "print(len(trainWAVs))\n",
    "print(len(valWAVs))\n",
    "print(len(testWAVs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _getFileCategory(file, catDict):\n",
    "    \"\"\"\n",
    "    Receives a file with name Dataset/<cat>/<filename> and returns an integer that is catDict[cat]\n",
    "    \"\"\"\n",
    "    categ = os.path.basename(os.path.dirname(file))\n",
    "    return catDict.get(categ,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get categories\n",
    "testWAVlabels = [_getFileCategory(f, DictCategs) for f in testWAVs]\n",
    "valWAVlabels = [_getFileCategory(f, DictCategs) for f in valWAVs]\n",
    "trainWAVlabels = [_getFileCategory(f, DictCategs) for f in trainWAVs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84843\n",
      "9981\n",
      "11005\n"
     ]
    }
   ],
   "source": [
    "print(len(trainWAVlabels))\n",
    "print(len(valWAVlabels))\n",
    "print(len(testWAVlabels))\n",
    "#print(trainWAVs[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.io.wavfile import read\n",
    "import python_speech_features as sf\n",
    "import numpy as np\n",
    "from addNoise import addNoise2\n",
    "\n",
    "def cp(wav_signal_name, desiredLength = 16000, log = True, w_len = 0.025, w_step = 0.01, noise = \"dude_miaowing.wav\"):\n",
    "    # input:   a wav audio file (ours are all 1 second long, so 16000 sample long if Fc = 16000)\n",
    "    # the noise is the one to add to the signal if the signal is not full length\n",
    "    # output:  a 2D matrix of size (num_frames, 39), where 39 is the number of coefficients of the features vectors\n",
    "    # data are supposed to be single channel\n",
    "    # log = True: it means that we take the logarithm of the energies of delta and delta-delta\n",
    "    \n",
    "    # read audio sample\n",
    "    print(wav_signal_name)\n",
    "    input_signal = read(wav_signal_name)\n",
    "    # sampling rate\n",
    "    \n",
    "    Fc = input_signal[0]\n",
    "    # Nyquist critical frequency(highest freq. that can be represented)\n",
    "    nyqF = int(Fc/2)  #input in sf.base.mfcc() has to be an int\n",
    "    signal = input_signal[1] # this is the vector-signal we are interested in\n",
    "    if(signal.shape[0] < desiredLength):\n",
    "        noise = read(noise)[1]\n",
    "        signal = addNoise2(signal, noise, begin = True)\n",
    "    # appendEnergy = True means that the zeroth value of all the cepstral vectors is replaced  with the corresponding frame energy, E(s_i)\n",
    "    coeffs = sf.base.mfcc(signal, samplerate = Fc, nfft = nyqF, appendEnergy = True, winlen=w_len, winstep=w_step, winfunc=np.hamming)\n",
    "    useful_coeffs = coeffs[:,1:13] # (taking only the 1,2,...,12 MFCC's)\n",
    "    # energy(s)\n",
    "    E_s = coeffs[:,0]\n",
    "    # take the log10 to limit the dynamics\n",
    "    log_E_s = np.log10(E_s)\n",
    "    #print(\"shape of log energies of the frames: \" + str(log_E_s.shape))\n",
    "    #print(\"shape of useful coefficients: \" + str(useful_coeffs.shape))\n",
    "\n",
    "    # extracting deltas\n",
    "    deltas = sf.base.delta(useful_coeffs, 2)\n",
    "    #print(\"deltas = \" + str(deltas.shape))\n",
    "    \n",
    "    # extracting deltas of deltas\n",
    "    deltas_2 = sf.base.delta(deltas, 2)\n",
    "    #print(\"deltas_2 = \" + str(deltas_2.shape))\n",
    "    \n",
    "    # getting energies of deltas and of deltas_2\n",
    "    E_deltas = np.sum(np.power(deltas, 2), axis = 1)\n",
    "    log_E_deltas = np.log10(E_deltas)\n",
    "    #print(\"shape of log_E_deltas = \" + str(log_E_deltas.shape))\n",
    "    \n",
    "    # energy of delta of deltas: \n",
    "    E_deltas_2 = np.sum(np.power(deltas, 2), axis = 1)\n",
    "    log_E_deltas_2 = np.log10(E_deltas_2)\n",
    "    #print(\"shape of log_E_deltas_2 = \" + str(log_E_deltas_2.shape))\n",
    "\n",
    "    if(log):\n",
    "        E_d = log_E_deltas\n",
    "        E_d_d = log_E_deltas_2\n",
    "    else:\n",
    "        E_d = E_deltas    \n",
    "        E_d_d = E_deltas_2\n",
    "\n",
    "    # preallocating space:\n",
    "    num_frames = coeffs.shape[0]\n",
    "    #num_frames = 99\n",
    "    features = np.zeros((num_frames,39))\n",
    "\n",
    "    # putting everything inside the features 2D matrix:\n",
    "    features[0:coeffs.shape[0], 0:12] = useful_coeffs\n",
    "    features[0:coeffs.shape[0], 12:24] = deltas\n",
    "    features[0:coeffs.shape[0], 24:36] = deltas_2\n",
    "    features[0:coeffs.shape[0], 36] = log_E_s\n",
    "    features[0:coeffs.shape[0], 37] = E_d\n",
    "    features[0:coeffs.shape[0], 38] = E_d_d\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# example:\\nfeats = load_and_preprocess_data(trainWAVs[25])\\nfeats = np.transpose(feats)\\n\\nplt.figure(figsize=(17,6))\\nplt.pcolormesh(feats)\\n\\nplt.title('Spectrogram visualization')\\nplt.ylabel('Frequency')\\nplt.xlabel('Time')\\n\\nplt.show()\\nprint(trainWAVlabels[25])\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_and_preprocess_data(file_name):\n",
    "    # Required by tensorflow (strings are passed as bytes)\n",
    "    file_name = tf.io.read_file(file_name)\n",
    "    file_name = file_name.eval()\n",
    "    #if type(file_name) is bytes:\n",
    "    #    file_name = file_name.decode()\n",
    "    print(file_name)\n",
    "    # Load data\n",
    "    feats = cp(file_name)\n",
    "    # Normalize\n",
    "    mean = np.mean(feats, axis = 0)\n",
    "    stv = np.std(feats, axis = 0)\n",
    "    diff = np.subtract(feats, mean)\n",
    "    feats = np.divide(diff, stv)\n",
    "\n",
    "    return feats.astype(np.float32)\n",
    "\"\"\"\n",
    "# example:\n",
    "feats = load_and_preprocess_data(trainWAVs[25])\n",
    "feats = np.transpose(feats)\n",
    "\n",
    "plt.figure(figsize=(17,6))\n",
    "plt.pcolormesh(feats)\n",
    "\n",
    "plt.title('Spectrogram visualization')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Time')\n",
    "\n",
    "plt.show()\n",
    "print(trainWAVlabels[25])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ds = tf.data.Dataset.from_tensor_slices(trainWAVs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot evaluate tensor using `eval()`: No default session is registered. Use `with sess.as_default()` or pass an explicit session to `eval(session=sess)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-b39c3d5ed075>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_and_preprocess_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[1;32m   1143\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m       return ParallelMapDataset(\n\u001b[0;32m-> 1145\u001b[0;31m           self, map_func, num_parallel_calls, preserve_cardinality=True)\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3292\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     self._num_parallel_calls = ops.convert_to_tensor(\n\u001b[1;32m   3294\u001b[0m         num_parallel_calls, dtype=dtypes.int32, name=\"num_parallel_calls\")\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   2617\u001b[0m       \u001b[0mresource_tracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResourceTracker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2618\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2619\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2620\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2621\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;34m\"\"\"Bypasses error checking when getting a graph function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m     graph_function = self._get_concrete_function_internal_garbage_collected(\n\u001b[0;32m-> 1366\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   1367\u001b[0m     \u001b[0;31m# We're returning this concrete function to someone, and they may keep a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;31m# reference to the FuncGraph without keeping a reference to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1360\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1361\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1646\u001b[0m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1648\u001b[0;31m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1649\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   1539\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1541\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   1542\u001b[0m         self._function_attributes)\n\u001b[1;32m   1543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    714\u001b[0m                                           converted_func)\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   2611\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   2612\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2613\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2614\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2615\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   2551\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2553\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2554\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2555\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-41dafa3c4695>\u001b[0m in \u001b[0;36mload_and_preprocess_data\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Required by tensorflow (strings are passed as bytes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m#if type(file_name) is bytes:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#    file_name = file_name.decode()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m     \"\"\"\n\u001b[0;32m--> 739\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5243\u001b[0m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5244\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5245\u001b[0;31m       raise ValueError(\"Cannot evaluate tensor using `eval()`: No default \"\n\u001b[0m\u001b[1;32m   5246\u001b[0m                        \u001b[0;34m\"session is registered. Use `with \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5247\u001b[0m                        \u001b[0;34m\"sess.as_default()` or pass an explicit session to \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot evaluate tensor using `eval()`: No default session is registered. Use `with sess.as_default()` or pass an explicit session to `eval(session=sess)`"
     ]
    }
   ],
   "source": [
    "image_ds = path_ds.map(load_and_preprocess_data, num_parallel_calls=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(file_names, labels, batch_size, shuffle, cache_file=None):\n",
    "    \n",
    "    # Create a Dataset object\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(file_names)\n",
    "    \n",
    "    # Map the load_and_preprocess_data function\n",
    "    #py_func = lambda file_name, label: (tf.py_function(load_and_preprocess_data, [file_name], tf.float32), label)\n",
    "    dataset = dataset.map(load_and_preprocess_data, num_parallel_calls=os.cpu_count())\n",
    "    \n",
    "    # Cache dataset\n",
    "    if cache_file:\n",
    "        dataset = dataset.cache(cache_file)\n",
    "    \n",
    "    # Shuffle    \n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(len(file_names))\n",
    "        \n",
    "    # Repeat the dataset indefinitely\n",
    "    dataset = dataset.repeat()\n",
    "    \n",
    "    # Correct input shape for the network\n",
    "    dataset = dataset.map(lambda data, label: (tf.expand_dims(data, 1), label))\n",
    "    \n",
    "    # Batch\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "    \n",
    "    # Prefetch\n",
    "    dataset = dataset.prefetch(buffer_size=1)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ReadFile:0\", shape=(), dtype=string)\n",
      "Tensor(\"ReadFile:0\", shape=(), dtype=string)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "invalid file: <tf.Tensor 'ReadFile:0' shape=() dtype=string>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-93ab7c51d1cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                                cache_file='train_cache')\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m val_dataset = create_dataset(valWAVs, \n",
      "\u001b[0;32m<ipython-input-49-f50520d3db0a>\u001b[0m in \u001b[0;36mcreate_dataset\u001b[0;34m(file_names, labels, batch_size, shuffle, cache_file)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Map the load_and_preprocess_data function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#py_func = lambda file_name, label: (tf.py_function(load_and_preprocess_data, [file_name], tf.float32), label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_and_preprocess_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Cache dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[1;32m   1143\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m       return ParallelMapDataset(\n\u001b[0;32m-> 1145\u001b[0;31m           self, map_func, num_parallel_calls, preserve_cardinality=True)\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3292\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     self._num_parallel_calls = ops.convert_to_tensor(\n\u001b[1;32m   3294\u001b[0m         num_parallel_calls, dtype=dtypes.int32, name=\"num_parallel_calls\")\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   2617\u001b[0m       \u001b[0mresource_tracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResourceTracker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2618\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2619\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2620\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2621\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;34m\"\"\"Bypasses error checking when getting a graph function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m     graph_function = self._get_concrete_function_internal_garbage_collected(\n\u001b[0;32m-> 1366\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   1367\u001b[0m     \u001b[0;31m# We're returning this concrete function to someone, and they may keep a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;31m# reference to the FuncGraph without keeping a reference to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1360\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1361\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1646\u001b[0m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1648\u001b[0;31m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1649\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   1539\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1541\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   1542\u001b[0m         self._function_attributes)\n\u001b[1;32m   1543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    714\u001b[0m                                           converted_func)\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   2611\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   2612\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2613\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2614\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2615\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   2551\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2553\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2554\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2555\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-8c787bd43124>\u001b[0m in \u001b[0;36mload_and_preprocess_data\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Normalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-aced9627f1ba>\u001b[0m in \u001b[0;36mcp\u001b[0;34m(wav_signal_name, desiredLength, log, w_len, w_step, noise)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# read audio sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_signal_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0minput_signal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_signal_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;31m# sampling rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/scipy/io/wavfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(filename, mmap)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mmmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: invalid file: <tf.Tensor 'ReadFile:0' shape=() dtype=string>"
     ]
    }
   ],
   "source": [
    "#train = tf.constant(trainWAVs)\n",
    "#train_labels = tf.constant(trainWAVlabels)\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset = create_dataset(trainWAVs, \n",
    "                               trainWAVlabels, \n",
    "                               batch_size=batch_size, \n",
    "                               shuffle=True,\n",
    "                               cache_file='train_cache')\n",
    "\n",
    "val_dataset = create_dataset(valWAVs, \n",
    "                             valWAVlabels,\n",
    "                             batch_size=batch_size, \n",
    "                             shuffle=False,\n",
    "                             cache_file='val_cache')\n",
    "\n",
    "train_steps = int(np.ceil(len(trainWAVs)/batch_size))\n",
    "val_steps = int(np.ceil(len(valWAVs)/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model.AttentionModel(21, 99, 39, use_GRU = True)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "tf.Tensor(b'Dataset/wow/f15a354c_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/wow/f15a354c_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/five/cd7f8c1b_nohash_4.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/five/cd7f8c1b_nohash_4.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/go/4ec7d027_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/go/4ec7d027_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/zero/c38720cb_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/zero/c38720cb_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/left/3a3ee7ed_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/left/3a3ee7ed_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/zero/91ffb786_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/zero/91ffb786_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/nine/1dc86f91_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/nine/1dc86f91_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/stop/dea820ce_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/stop/dea820ce_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/zero/29fb33da_nohash_4.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/zero/29fb33da_nohash_4.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/marvin/2313e093_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/three/d278d8ef_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/three/d278d8ef_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/marvin/2313e093_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/down/22296dbe_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/down/22296dbe_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/two/d486fb84_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/two/d486fb84_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/yes/b8874962_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/yes/b8874962_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/three/106a6183_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/three/106a6183_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/one/dea820ce_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/one/dea820ce_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/five/ca4912b6_nohash_3.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/five/ca4912b6_nohash_3.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/go/39c13eed_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/go/39c13eed_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/happy/00970ce1_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/happy/00970ce1_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/one/b528edb3_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/one/b528edb3_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/five/d98dd124_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/stop/5c39594f_nohash_3.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/stop/5c39594f_nohash_3.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/five/d98dd124_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/one/51055bda_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/one/51055bda_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/four/57b68383_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/four/57b68383_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/two/28612180_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/two/28612180_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/right/40b60ae9_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/right/40b60ae9_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/tree/215699ff_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/tree/215699ff_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/yes/c53b335a_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/yes/c53b335a_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/bird/1626bc5a_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/bird/1626bc5a_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/eight/333d7ddb_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/eight/333d7ddb_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/go/365908bd_nohash_5.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/go/365908bd_nohash_5.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/zero/8b25410a_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/zero/8b25410a_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/off/eb3f7d82_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/off/eb3f7d82_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/visual/f19279c4_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/visual/f19279c4_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/no/0585b66d_nohash_3.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/no/0585b66d_nohash_3.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/happy/9c59dd28_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/happy/9c59dd28_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/go/f2f0d244_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/go/f2f0d244_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/six/5a5721f8_nohash_4.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/six/5a5721f8_nohash_4.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/go/0717b9f6_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/go/0717b9f6_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/five/815f0f03_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/five/815f0f03_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/left/9b8a7439_nohash_3.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/left/9b8a7439_nohash_3.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/no/de89e2ca_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/no/de89e2ca_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/no/e269bac0_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/no/e269bac0_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/left/62f05757_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/left/62f05757_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/right/eb3d8eb1_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/right/eb3d8eb1_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/cat/b9515bf3_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/cat/b9515bf3_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/nine/d8ee4734_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/nine/d8ee4734_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/on/bbb2eb5b_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/on/bbb2eb5b_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/six/a50a98d2_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/six/a50a98d2_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/five/9aa21fa9_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/five/9aa21fa9_nohash_1.wav', shape=(), dtype=string)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "TypeError: Can't convert 'tensorflow.python.framework.ops.EagerTensor' object to str implicitly\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/script_ops.py\", line 207, in __call__\n    return func(device, token, args)\n\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/script_ops.py\", line 109, in __call__\n    ret = self._func(*args)\n\n  File \"<ipython-input-125-2557e5fca52a>\", line 8, in load_and_preprocess_data\n    feats = cp(file_name)\n\n  File \"<ipython-input-84-aced9627f1ba>\", line 16, in cp\n    input_signal = read(wav_signal_name)\n\n  File \"/usr/local/lib/python3.5/site-packages/scipy/io/wavfile.py\", line 233, in read\n    fid = open(filename, 'rb')\n\nTypeError: Can't convert 'tensorflow.python.framework.ops.EagerTensor' object to str implicitly\n\n\n\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNextSync]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-5fa5f11861de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Save the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'my_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtarget_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m       \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36m_get_next_batch\u001b[0;34m(generator, mode)\u001b[0m\n\u001b[1;32m    360\u001b[0m   \u001b[0;34m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# For Python 3 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    621\u001b[0m     \"\"\"\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next_sync\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2118\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2120\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2121\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2122\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: TypeError: Can't convert 'tensorflow.python.framework.ops.EagerTensor' object to str implicitly\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/script_ops.py\", line 207, in __call__\n    return func(device, token, args)\n\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/script_ops.py\", line 109, in __call__\n    ret = self._func(*args)\n\n  File \"<ipython-input-125-2557e5fca52a>\", line 8, in load_and_preprocess_data\n    feats = cp(file_name)\n\n  File \"<ipython-input-84-aced9627f1ba>\", line 16, in cp\n    input_signal = read(wav_signal_name)\n\n  File \"/usr/local/lib/python3.5/site-packages/scipy/io/wavfile.py\", line 233, in read\n    fid = open(filename, 'rb')\n\nTypeError: Can't convert 'tensorflow.python.framework.ops.EagerTensor' object to str implicitly\n\n\n\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNextSync]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'Dataset/follow/cdee383b_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/follow/cdee383b_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/on/4422e51d_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/on/4422e51d_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/stop/e882abb2_nohash_3.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/stop/e882abb2_nohash_3.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/tree/c1eebc0b_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/tree/c1eebc0b_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/go/821b64cc_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/go/821b64cc_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/left/ccb1266b_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/left/ccb1266b_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/off/d430b3cc_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/off/d430b3cc_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/zero/e0315cf6_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/zero/e0315cf6_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/marvin/73af0c50_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/marvin/73af0c50_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/cat/9ce7a419_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/cat/9ce7a419_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/eight/cb62dbf1_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/eight/cb62dbf1_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/four/bfdb9801_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/four/bfdb9801_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/go/db7c95b0_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/go/db7c95b0_nohash_0.wav', shape=(), dtype=string)tf.Tensor(b'Dataset/bed/8c4854bc_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/bed/8c4854bc_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/nine/8b25410a_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/nine/8b25410a_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/left/f798ac78_nohash_3.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/left/f798ac78_nohash_3.wav', shape=(), dtype=string)\n",
      "\n",
      "tf.Tensor(b'Dataset/nine/e0315cf6_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/nine/e0315cf6_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/right/13dce503_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/right/13dce503_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/bed/a24582a0_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/bed/a24582a0_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/happy/35c8fa78_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/happy/35c8fa78_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/on/ea0cf37f_nohash_0.wav', shape=(), dtype=string)tf.Tensor(b'Dataset/six/c86d4fd4_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/six/c86d4fd4_nohash_0.wav', shape=(), dtype=string)\n",
      "\n",
      "tf.Tensor(b'Dataset/on/ea0cf37f_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/left/dcc012ec_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/left/dcc012ec_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/sheila/5b09db89_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/eight/042a8dde_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/eight/042a8dde_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/up/5b09db89_nohash_4.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/up/5b09db89_nohash_4.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/sheila/5b09db89_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/eight/845f8553_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/eight/845f8553_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/bed/34e8c726_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/bed/34e8c726_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/on/ef3367d9_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/on/ef3367d9_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/yes/3589bc72_nohash_3.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/yes/3589bc72_nohash_3.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/three/15c563d7_nohash_3.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/three/15c563d7_nohash_3.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/seven/6124b431_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/seven/6124b431_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/up/aff582a1_nohash_4.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/up/aff582a1_nohash_4.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/no/bbf38549_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/no/bbf38549_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/down/7e6bd776_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/down/7e6bd776_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/seven/e7ea8b76_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/seven/e7ea8b76_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/go/4c6944d6_nohash_4.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/go/4c6944d6_nohash_4.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/bird/0a5636ca_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/bird/0a5636ca_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/cat/43691f67_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/cat/43691f67_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/stop/ed3c2d05_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/stop/ed3c2d05_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/five/113b3fbc_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/two/c351e611_nohash_3.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/two/c351e611_nohash_3.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/five/113b3fbc_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/marvin/b06c19b0_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/marvin/b06c19b0_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/on/6a497f80_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/on/6a497f80_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/one/cc554de3_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/nine/365908bd_nohash_3.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/nine/365908bd_nohash_3.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/one/cc554de3_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/up/51055bda_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/up/51055bda_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/right/f00180d0_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/wow/571c044e_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/wow/571c044e_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/right/f00180d0_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/follow/ec989d6d_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/follow/ec989d6d_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/follow/96d8bb6f_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/house/3209ec42_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/house/3209ec42_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/follow/96d8bb6f_nohash_1.wav', shape=(), dtype=string)tf.Tensor(b'Dataset/follow/60402b64_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/follow/60402b64_nohash_0.wav', shape=(), dtype=string)\n",
      "\n",
      "tf.Tensor(b'Dataset/four/87d5e978_nohash_3.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/four/87d5e978_nohash_3.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/off/f88f97a7_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/off/f88f97a7_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/wow/6414258b_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/up/91ffb786_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/up/91ffb786_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/wow/6414258b_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/down/c661be6e_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/down/c661be6e_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/down/1e9b215e_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/one/28612180_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/one/28612180_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/down/1e9b215e_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/forward/b29f8b23_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/forward/b29f8b23_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/dog/bbbf4fbd_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/dog/bbbf4fbd_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/no/2ad772d6_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/no/2ad772d6_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/follow/0d85a428_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/follow/0d85a428_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/zero/bb6d4301_nohash_3.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/zero/bb6d4301_nohash_3.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/stop/1c1060b1_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/up/ee1d8d49_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/up/ee1d8d49_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/stop/1c1060b1_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/one/0f7dc557_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/one/0f7dc557_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/wow/e14d3db8_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/wow/e14d3db8_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/yes/363c6bad_nohash_4.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/yes/363c6bad_nohash_4.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/stop/f575faf3_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/no/9151f184_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/stop/f575faf3_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/no/9151f184_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/off/0d2bcf9d_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/off/0d2bcf9d_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/bed/46a153d8_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/bed/46a153d8_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/no/2f813234_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/happy/c7b4049e_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/happy/c7b4049e_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/go/742d6431_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/go/742d6431_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/no/2f813234_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/stop/b26343e9_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/right/eee5e541_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/stop/b26343e9_nohash_1.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/right/eee5e541_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/wow/30065f33_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/wow/30065f33_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/down/71d0ded4_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/down/71d0ded4_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/right/6c429c7b_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/right/6c429c7b_nohash_2.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/up/9fa86a74_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/up/9fa86a74_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/five/f575faf3_nohash_4.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/five/f575faf3_nohash_4.wav', shape=(), dtype=string)tf.Tensor(b'Dataset/right/ffd2ba2f_nohash_4.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/right/ffd2ba2f_nohash_4.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/four/211b928a_nohash_0.wav', shape=(), dtype=string)\n",
      "tf.Tensor(b'Dataset/four/211b928a_nohash_0.wav', shape=(), dtype=string)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "history = model.fit(train_dataset, epochs=num_epochs, steps_per_epoch=train_steps, validation_data=val_dataset, validation_steps=val_steps)\n",
    "\n",
    "# Save the model\n",
    "model.save('my_model.h5')\n",
    "\n",
    "# Plot loss\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Train loss')\n",
    "plt.plot(history.history['val_loss'], label='Val loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "# Plot accuracy\n",
    "plt.figure()\n",
    "plt.plot(history.history['acc'], label='Train loss')\n",
    "plt.plot(history.history['val_acc'], label='Val loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
