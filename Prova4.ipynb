{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1.14.0\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import Model\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "#from tensorflow.keras.models import Model\n",
    "from tqdm import tqdm \n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import SpeechGenerator\n",
    "import librosa\n",
    "#from keras import losses\n",
    "\n",
    "from extractMFCC import computeFeatures, computeFeatures1\n",
    "from addNoise import addNoise\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "print(tf.executing_eagerly())\n",
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root folder of the dataset\n",
    "dataset_dir = \"Dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File containing the path that identify the test and validation set\n",
    "testWAVs = pd.read_csv(dataset_dir + 'testing_list.txt', sep=\" \", header = None)[0].tolist()\n",
    "valWAVs  = pd.read_csv(dataset_dir + 'validation_list.txt', sep=\" \", header = None)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary containing the mapping between category name and label\n",
    "DictCategs = {'nine' : 1, 'yes' : 2, 'no' : 3, 'up' : 4, 'down' : 5, 'left' : 6, 'right' : 7, 'on' : 8, 'off' : 9, \n",
    "              'stop' : 10, 'go' : 11, 'zero' : 12, 'one' : 13, 'two' : 14, 'three' : 15, 'four' : 16, 'five' : 17, \n",
    "              'six' : 18, 'seven' : 19, 'eight' : 20, 'backward':0, 'bed':0, 'bird':0, 'cat':0, 'dog':0, 'follow':0, \n",
    "              'forward':0, 'happy':0, 'house':0, 'learn':0, 'marvin':0, 'sheila':0, 'tree':0, 'visual':0, 'wow':0 }\n",
    "nCategs = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the file in dataset\n",
    "allWAVs  = []\n",
    "for root, dirs, files in os.walk('Dataset/'):\n",
    "    for f in files:\n",
    "        if (root != dataset_dir + \"_background_noise_\") and (f.endswith('.wav')):\n",
    "            path = root + \"/\" + f\n",
    "            #print(path)\n",
    "            path = path[len(dataset_dir):]\n",
    "            #print(path)\n",
    "            allWAVs.append(path)\n",
    "\n",
    "# Remove from the training set the elements present in test and validation\n",
    "trainWAVs = list(set(allWAVs) - set(valWAVs) - set(testWAVs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set length: 84843\n",
      "Validation set length: 9981\n",
      "Test set length: 11005\n"
     ]
    }
   ],
   "source": [
    "# Size of sets\n",
    "print(\"Train set length: \" + str(len(trainWAVs)))\n",
    "print(\"Validation set length: \" + str(len(valWAVs)))\n",
    "print(\"Test set length: \" + str(len(testWAVs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the category from the path to the file\n",
    "def _getFileCategory(file, catDict):\n",
    "    # Receives a file with name <cat>/<filename> and returns an integer that is catDict[cat]\n",
    "    categ = os.path.basename(os.path.dirname(file))\n",
    "    return catDict.get(categ, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Labels set length: 84843\n",
      "Validation-Labels set length: 9981\n",
      "Test-Labels set length: 11005\n"
     ]
    }
   ],
   "source": [
    "# Get categories of each set\n",
    "testWAVlabels = [_getFileCategory(f, DictCategs) for f in testWAVs]\n",
    "valWAVlabels = [_getFileCategory(f, DictCategs) for f in valWAVs]\n",
    "trainWAVlabels = [_getFileCategory(f, DictCategs) for f in trainWAVs]\n",
    "\n",
    "# And test the size of the labels set\n",
    "print(\"Train-Labels set length: \" + str(len(trainWAVlabels)))\n",
    "print(\"Validation-Labels set length: \" + str(len(valWAVlabels)))\n",
    "print(\"Test-Labels set length: \" + str(len(testWAVlabels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading of the train set:\n",
      "0/84843\n",
      "5000/84843\n",
      "10000/84843\n",
      "15000/84843\n",
      "20000/84843\n",
      "25000/84843\n",
      "30000/84843\n",
      "35000/84843\n",
      "40000/84843\n",
      "45000/84843\n",
      "50000/84843\n",
      "55000/84843\n",
      "60000/84843\n",
      "65000/84843\n",
      "70000/84843\n",
      "75000/84843\n",
      "80000/84843\n",
      "84843/84843\n"
     ]
    }
   ],
   "source": [
    "# Transoform the train dataset in numpy array and load them \n",
    "train = np.array(trainWAVs, dtype = object)\n",
    "trainLabels = np.array(trainWAVlabels, dtype = '>i4') #stands for int32\n",
    "\n",
    "print(\"Loading of the train set:\")\n",
    "for i in range(len(trainWAVs)):\n",
    "    # Print the progress \n",
    "    if (i % 5000) == 0:\n",
    "        print(str(i) + '/' + str(len(trainWAVs)))\n",
    "    \n",
    "    # If the file is not already present, we create the numpy version \n",
    "    if (not os.path.isfile(dataset_dir + \"/\" + trainWAVs[i] + '.npy')):\n",
    "        y, sr = librosa.load(dataset_dir + \"/\" + trainWAVs[i], sr = 16000)\n",
    "        np.save(dataset_dir + \"/\" + trainWAVs[i] + '.npy', y)\n",
    "    \n",
    "    # We load the path to numpy array in a vector \n",
    "    train[i] = trainWAVs[i] + '.npy'\n",
    "    \n",
    "print(str(i+1) + '/' + str(len(trainWAVs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading of the validation set:\n",
      "0/9981\n",
      "5000/9981\n",
      "9981/9981\n",
      "Loading of the test set:\n",
      "0/11005\n",
      "5000/11005\n",
      "10000/11005\n",
      "11005/11005\n"
     ]
    }
   ],
   "source": [
    "# Do the same thing for the validation and the test set\n",
    "val = np.array(valWAVs, dtype = object)\n",
    "valLabels = np.array(valWAVlabels, dtype = '>i4') #stands for int32\n",
    "\n",
    "print(\"Loading of the validation set:\")\n",
    "for i in range(len(valWAVs)):\n",
    "    # Print the progress \n",
    "    if (i % 5000) == 0:\n",
    "        print(str(i) + '/' + str(len(valWAVs)))\n",
    "    \n",
    "    # If the file is not already present, we create the numpy version \n",
    "    if (not os.path.isfile(dataset_dir + \"/\" + valWAVs[i] + '.npy')):\n",
    "        y, sr = librosa.load(dataset_dir + \"/\" + valWAVs[i], sr = 16000)\n",
    "        np.save(dataset_dir + \"/\" + valWAVs[i] + '.npy', y)\n",
    "    \n",
    "    # We load the path to numpy array in a vector \n",
    "    val[i] = valWAVs[i] + '.npy'\n",
    "    \n",
    "print(str(i+1) + '/' + str(len(valWAVs)))\n",
    "\n",
    "test = np.array(testWAVs, dtype = object)\n",
    "\n",
    "print(\"Loading of the test set:\")\n",
    "for i in range(len(testWAVs)):\n",
    "    # Print the progress \n",
    "    if (i % 5000) == 0:\n",
    "        print(str(i) + '/' + str(len(testWAVs)))\n",
    "    \n",
    "    # If the file is not already present, we create the numpy version \n",
    "    if (not os.path.isfile(dataset_dir + \"/\" + testWAVs[i] + '.npy')):\n",
    "        y, sr = librosa.load(dataset_dir + \"/\" + testWAVs[i], sr = 16000)\n",
    "        np.save(dataset_dir + \"/\" + testWAVs[i] + '.npy', y)\n",
    "    \n",
    "    # We load the path to numpy array in a vector \n",
    "    test[i] = testWAVs[i] + '.npy' \n",
    "    \n",
    "print(str(i+1) + '/' + str(len(testWAVs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84843 = 84843\n",
      "9981 = 9981\n",
      "11005 = 11005\n",
      "file: two/9886d8bf_nohash_0.wav.npy - label: 14\n",
      "file: two/9886d8bf_nohash_0.wav - label: 14\n"
     ]
    }
   ],
   "source": [
    "#test on the length\n",
    "print(str(len(trainWAVs)) + \" = \" + str(len(train)))\n",
    "print(str(len(valWAVs)) + \" = \" + str(len(val)))\n",
    "print(str(len(testWAVs)) + \" = \" + str(len(test)))\n",
    "\n",
    "#test on labels \n",
    "for i in range(0, 1):\n",
    "    print(\"file: \" + train[i] + \" - label: \" + str(trainLabels[i]))\n",
    "    print(\"file: \" + trainWAVs[i] + \" - label: \" + str(trainLabels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'WAV signal')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to load numpy array\n",
    "def load_data(file_name, data_dir):\n",
    "    # Load the wav signal from the .npy file\n",
    "    data = np.load(data_dir + file_name)\n",
    "    return data\n",
    "\n",
    "# Plot a wav\n",
    "file_name = train[25]\n",
    "data = load_data(file_name, dataset_dir)\n",
    "plt.figure()\n",
    "plt.plot(data, color='b')\n",
    "plt.title('WAV signal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess the data \n",
    "def load_and_preprocess_data(file_name, data_dir):\n",
    "    # Required by tensorflow (strings are passed as bytes)\n",
    "    if type(file_name) is bytes:\n",
    "        file_name = file_name.decode()\n",
    "        data_dir = data_dir.decode()\n",
    "\n",
    "    # Load data\n",
    "    data = load_data(file_name, data_dir)\n",
    "    feats = computeFeatures1(data, 16000)\n",
    "    # Normalize\n",
    "    #feats -= np.mean(feats, axis=1)\n",
    "    #mean = np.mean(feats, axis = 0)\n",
    "    #print(feats)\n",
    "    #print(mean)\n",
    "    #std = np.std(feats, axis = 0) + 1e-8\n",
    "    #print(std)\n",
    "    #diff = np.subtract(feats, mean)\n",
    "    #print(diff[:, 36])\n",
    "    #feats = np.divide(diff, std)\n",
    "    #print(feats[:, 36])\n",
    "\n",
    "    return feats.astype(np.float32)\n",
    "\n",
    "# example:\n",
    "index = 12345\n",
    "feats = load_and_preprocess_data(train[index], dataset_dir)\n",
    "feats = np.transpose(feats)\n",
    "#plt.plot(feats, color='b')\n",
    "plt.figure(figsize=(17,6))\n",
    "plt.pcolormesh(feats)\n",
    "\n",
    "plt.title('Spectrogram visualization')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Time')\n",
    "\n",
    "plt.show()\n",
    "print(\"File: \" + train[index] + \" - Label: \" + str(trainLabels[index]))\n",
    "print(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data_dir, file_names, labels, batch_size = 32, shuffle = True, cache_file = None):\n",
    "    \n",
    "    # Create a Dataset object\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((file_names, labels))\n",
    "    \n",
    "    # Map the load_and_preprocess_data function\n",
    "    py_func = lambda file_name, label: (tf.numpy_function (load_and_preprocess_data, [file_name, data_dir], tf.float32), label)\n",
    "    dataset = dataset.map(py_func, num_parallel_calls = os.cpu_count())\n",
    "    \n",
    "    # Cache dataset\n",
    "    if cache_file:\n",
    "        dataset = dataset.cache(cache_file)\n",
    "    \n",
    "    # Shuffle    \n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(len(file_names))\n",
    "        \n",
    "    # Repeat the dataset indefinitely (capire bene anche questo repeat come funziona)\n",
    "    dataset = dataset.repeat()\n",
    "    \n",
    "    # Correct input shape for the network\n",
    "    dataset = dataset.map(lambda data, label: (tf.expand_dims(data, -1), label))\n",
    "    \n",
    "    # Batch\n",
    "    dataset = dataset.batch(batch_size = batch_size)\n",
    "    \n",
    "    # Prefetch (1 means that prefetch a batch at time)\n",
    "    dataset = dataset.prefetch(buffer_size = 1)\n",
    "    \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataset = create_dataset(dataset_dir, train, trainLabels, batch_size = batch_size, shuffle = True, cache_file = 'train_cache')\n",
    "\n",
    "val_dataset = create_dataset(dataset_dir, val, valLabels, batch_size = batch_size, shuffle = False, cache_file = 'val_cache')\n",
    "\n",
    "test_dataset = create_dataset(dataset_dir, test, testWAVlabels, batch_size = batch_size, shuffle = False, cache_file = 'test_cache')\n",
    "\n",
    "train_steps = int(np.ceil(len(train) / batch_size))\n",
    "val_steps = int(np.ceil(len(val) / batch_size))\n",
    "test_steps = int(np.ceil(len(test) / batch_size))\n",
    "\n",
    "print(\"steps to completa a train epoch: \" + str(train_steps))\n",
    "print(\"steps to completa a validation spoch: \" + str(val_steps))\n",
    "print(\"steps to completa a test epoch: \" + str(test_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model.AttentionModel(nCategs, 99, 39, 64, use_GRU = True, dropout = 0.15, activation = 'elu')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questa funzione sembra essere difficile da applicare ad un fit normale, si può provare ma intanto ho provato ad usare \n",
    "# l'exp_decay che si da in ingresso all'optimizer\n",
    "import math\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    drop = 0.4\n",
    "    epochs_drop = 3.0\n",
    "    lrate = initial_lrate * math.pow(drop,  \n",
    "            math.floor((1+epoch)/epochs_drop))\n",
    "    \n",
    "    if (lrate < 4e-5):\n",
    "        lrate = 4e-5\n",
    "      \n",
    "    print('Changing learning rate to {}'.format(lrate))\n",
    "    return lrate\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "\n",
    "earlystopper = EarlyStopping(monitor='val_sparse_categorical_accuracy', patience = 3, verbose = 1)\n",
    "checkpointer = ModelCheckpoint('Model/AttentionModel-checkpoint-1.h5', \n",
    "                               monitor = 'val_sparse_categorical_accuracy', \n",
    "                               verbose = 1, save_best_only = True, save_weights_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "global_step = tf.Variable(train_steps * 2, trainable = False)\n",
    "\n",
    "decayed_lr = tf.train.exponential_decay(learning_rate,\n",
    "                                        global_step, train_steps * 2,\n",
    "                                        0.4, staircase = True)\n",
    "\n",
    "adam = tf.train.AdamOptimizer(decayed_lr, \n",
    "                              beta1 = 0.9,\n",
    "                              beta2 = 0.999,\n",
    "                              epsilon = 1e-07,\n",
    "                              use_locking = False,\n",
    "                              name = 'Adam')\n",
    "\n",
    "model.compile(optimizer = adam,\n",
    "              loss = tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics = ['sparse_categorical_accuracy'])\n",
    "\n",
    "num_epochs = 6\n",
    "history = model.fit(train_dataset, \n",
    "                    epochs = num_epochs, \n",
    "                    steps_per_epoch = train_steps,\n",
    "                    validation_data = val_dataset, \n",
    "                    validation_steps = val_steps,\n",
    "                    callbacks = [checkpointer, earlystopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(history.history.keys())\n",
    "\n",
    "# Plot loss\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label = 'Train loss')\n",
    "plt.plot(history.history['val_loss'], label = 'Val loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "# Plot accuracy\n",
    "plt.figure()\n",
    "plt.plot(history.history['sparse_categorical_accuracy'], label = 'Train acc')\n",
    "plt.plot(history.history['val_sparse_categorical_accuracy'], label = 'Val acc')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "# Save the model\n",
    "model.save('Model/AttentionModel-1_00-0107-17.h5')\n",
    "\n",
    "testEval = model.evaluate(test_dataset,\n",
    "                          steps = test_steps,\n",
    "                          verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"left/94de6a6a_nohash_2.wav.npy\"\n",
    "x = load_and_preprocess_data(x, dataset_dir).reshape((1, 99, 39, 1))\n",
    "print(x.shape)\n",
    "res = model.predict(x) \n",
    "print(res.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
