{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1.14.0\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import Model\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "#from tensorflow.keras.models import Model\n",
    "from tqdm import tqdm \n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import SpeechGenerator\n",
    "import librosa\n",
    "#from keras import losses\n",
    "\n",
    "from extractMFCC import computeFeatures, computeFeatures1\n",
    "from addNoise import addNoise\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "print(tf.executing_eagerly())\n",
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root folder of the dataset\n",
    "dataset_dir = \"Dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File containing the path that identify the test and validation set\n",
    "testWAVs = pd.read_csv(dataset_dir + 'testing_list.txt', sep=\" \", header = None)[0].tolist()\n",
    "valWAVs  = pd.read_csv(dataset_dir + 'validation_list.txt', sep=\" \", header = None)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary containing the mapping between category name and label\n",
    "DictCategs = {'nine' : 1, 'yes' : 2, 'no' : 3, 'up' : 4, 'down' : 5, 'left' : 6, 'right' : 7, 'on' : 8, 'off' : 9, \n",
    "              'stop' : 10, 'go' : 11, 'zero' : 12, 'one' : 13, 'two' : 14, 'three' : 15, 'four' : 16, 'five' : 17, \n",
    "              'six' : 18, 'seven' : 19, 'eight' : 20, 'backward':0, 'bed':0, 'bird':0, 'cat':0, 'dog':0, 'follow':0, \n",
    "              'forward':0, 'happy':0, 'house':0, 'learn':0, 'marvin':0, 'sheila':0, 'tree':0, 'visual':0, 'wow':0 }\n",
    "nCategs = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the file in dataset\n",
    "allWAVs  = []\n",
    "for root, dirs, files in os.walk('Dataset/'):\n",
    "    for f in files:\n",
    "        if (root != dataset_dir + \"_background_noise_\") and (f.endswith('.wav')):\n",
    "            path = root + \"/\" + f\n",
    "            #print(path)\n",
    "            path = path[len(dataset_dir):]\n",
    "            #print(path)\n",
    "            allWAVs.append(path)\n",
    "\n",
    "# Remove from the training set the elements present in test and validation\n",
    "trainWAVs = list(set(allWAVs) - set(valWAVs) - set(testWAVs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set length: 84843\n",
      "Validation set length: 9981\n",
      "Test set length: 11005\n"
     ]
    }
   ],
   "source": [
    "# Size of sets\n",
    "print(\"Train set length: \" + str(len(trainWAVs)))\n",
    "print(\"Validation set length: \" + str(len(valWAVs)))\n",
    "print(\"Test set length: \" + str(len(testWAVs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the category from the path to the file\n",
    "def _getFileCategory(file, catDict):\n",
    "    # Receives a file with name <cat>/<filename> and returns an integer that is catDict[cat]\n",
    "    categ = os.path.basename(os.path.dirname(file))\n",
    "    return catDict.get(categ, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Labels set length: 84843\n",
      "Validation-Labels set length: 9981\n",
      "Test-Labels set length: 11005\n"
     ]
    }
   ],
   "source": [
    "# Get categories of each set\n",
    "testWAVlabels = [_getFileCategory(f, DictCategs) for f in testWAVs]\n",
    "valWAVlabels = [_getFileCategory(f, DictCategs) for f in valWAVs]\n",
    "trainWAVlabels = [_getFileCategory(f, DictCategs) for f in trainWAVs]\n",
    "\n",
    "# And test the size of the labels set\n",
    "print(\"Train-Labels set length: \" + str(len(trainWAVlabels)))\n",
    "print(\"Validation-Labels set length: \" + str(len(valWAVlabels)))\n",
    "print(\"Test-Labels set length: \" + str(len(testWAVlabels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading of the train set:\n",
      "0/84843\n",
      "5000/84843\n",
      "10000/84843\n",
      "15000/84843\n",
      "20000/84843\n",
      "25000/84843\n",
      "30000/84843\n",
      "35000/84843\n",
      "40000/84843\n",
      "45000/84843\n",
      "50000/84843\n",
      "55000/84843\n",
      "60000/84843\n",
      "65000/84843\n",
      "70000/84843\n",
      "75000/84843\n",
      "80000/84843\n",
      "84843/84843\n"
     ]
    }
   ],
   "source": [
    "# Transoform the train dataset in numpy array and load them \n",
    "train = np.array(trainWAVs, dtype = object)\n",
    "trainLabels = np.array(trainWAVlabels, dtype = '>i4') #stands for int32\n",
    "\n",
    "print(\"Loading of the train set:\")\n",
    "for i in range(len(trainWAVs)):\n",
    "    # Print the progress \n",
    "    if (i % 5000) == 0:\n",
    "        print(str(i) + '/' + str(len(trainWAVs)))\n",
    "    \n",
    "    # If the file is not already present, we create the numpy version \n",
    "    if (not os.path.isfile(dataset_dir + \"/\" + trainWAVs[i] + '.npy')):\n",
    "        y, sr = librosa.load(dataset_dir + \"/\" + trainWAVs[i], sr = 16000)\n",
    "        np.save(dataset_dir + \"/\" + trainWAVs[i] + '.npy', y)\n",
    "    \n",
    "    # We load the path to numpy array in a vector \n",
    "    train[i] = trainWAVs[i] + '.npy'\n",
    "    \n",
    "print(str(i+1) + '/' + str(len(trainWAVs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading of the validation set:\n",
      "0/9981\n",
      "5000/9981\n",
      "9981/9981\n",
      "Loading of the test set:\n",
      "0/11005\n",
      "5000/11005\n",
      "10000/11005\n",
      "11005/11005\n"
     ]
    }
   ],
   "source": [
    "# Do the same thing for the validation and the test set\n",
    "val = np.array(valWAVs, dtype = object)\n",
    "valLabels = np.array(valWAVlabels, dtype = '>i4') #stands for int32\n",
    "\n",
    "print(\"Loading of the validation set:\")\n",
    "for i in range(len(valWAVs)):\n",
    "    # Print the progress \n",
    "    if (i % 5000) == 0:\n",
    "        print(str(i) + '/' + str(len(valWAVs)))\n",
    "    \n",
    "    # If the file is not already present, we create the numpy version \n",
    "    if (not os.path.isfile(dataset_dir + \"/\" + valWAVs[i] + '.npy')):\n",
    "        y, sr = librosa.load(dataset_dir + \"/\" + valWAVs[i], sr = 16000)\n",
    "        np.save(dataset_dir + \"/\" + valWAVs[i] + '.npy', y)\n",
    "    \n",
    "    # We load the path to numpy array in a vector \n",
    "    val[i] = valWAVs[i] + '.npy'\n",
    "    \n",
    "print(str(i+1) + '/' + str(len(valWAVs)))\n",
    "\n",
    "test = np.array(testWAVs, dtype = object)\n",
    "\n",
    "print(\"Loading of the test set:\")\n",
    "for i in range(len(testWAVs)):\n",
    "    # Print the progress \n",
    "    if (i % 5000) == 0:\n",
    "        print(str(i) + '/' + str(len(testWAVs)))\n",
    "    \n",
    "    # If the file is not already present, we create the numpy version \n",
    "    if (not os.path.isfile(dataset_dir + \"/\" + testWAVs[i] + '.npy')):\n",
    "        y, sr = librosa.load(dataset_dir + \"/\" + testWAVs[i], sr = 16000)\n",
    "        np.save(dataset_dir + \"/\" + testWAVs[i] + '.npy', y)\n",
    "    \n",
    "    # We load the path to numpy array in a vector \n",
    "    test[i] = testWAVs[i] + '.npy' \n",
    "    \n",
    "print(str(i+1) + '/' + str(len(testWAVs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84843 = 84843\n",
      "9981 = 9981\n",
      "11005 = 11005\n",
      "file: bed/4c594e0f_nohash_0.wav.npy - label: 0\n",
      "file: bed/4c594e0f_nohash_0.wav - label: 0\n"
     ]
    }
   ],
   "source": [
    "#test on the length\n",
    "print(str(len(trainWAVs)) + \" = \" + str(len(train)))\n",
    "print(str(len(valWAVs)) + \" = \" + str(len(val)))\n",
    "print(str(len(testWAVs)) + \" = \" + str(len(test)))\n",
    "\n",
    "#test on labels \n",
    "for i in range(0, 1):\n",
    "    print(\"file: \" + train[i] + \" - label: \" + str(trainLabels[i]))\n",
    "    print(\"file: \" + trainWAVs[i] + \" - label: \" + str(trainLabels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'WAV signal')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to load numpy array\n",
    "def load_data(file_name, data_dir):\n",
    "    # Load the wav signal from the .npy file\n",
    "    data = np.load(data_dir + file_name)\n",
    "    return data\n",
    "\n",
    "# Plot a wav\n",
    "file_name = train[25]\n",
    "data = load_data(file_name, dataset_dir)\n",
    "plt.figure()\n",
    "plt.plot(data, color='b')\n",
    "plt.title('WAV signal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: forward/a55105d0_nohash_4.wav.npy - Label: 0\n"
     ]
    }
   ],
   "source": [
    "# Function to preprocess the data \n",
    "def load_and_preprocess_data(file_name, data_dir):\n",
    "    # Required by tensorflow (strings are passed as bytes)\n",
    "    if type(file_name) is bytes:\n",
    "        file_name = file_name.decode()\n",
    "        data_dir = data_dir.decode()\n",
    "\n",
    "    # Load data\n",
    "    data = load_data(file_name, data_dir)\n",
    "    feats = computeFeatures1(data, 16000)\n",
    "    # Normalize\n",
    "    #feats -= (np.mean(feats, axis=0) + 1e-8)\n",
    "    #mean = np.mean(feats, axis = 0)\n",
    "    #stv = np.std(feats, axis = 0)\n",
    "    #diff = np.subtract(feats, mean)\n",
    "    #feats = np.divide(diff, stv)\n",
    "\n",
    "    return feats.astype(np.float32)\n",
    "\n",
    "# example:\n",
    "index = 26257\n",
    "feats = load_and_preprocess_data(train[index], dataset_dir)\n",
    "feats = np.transpose(feats)\n",
    "#plt.plot(feats, color='b')\n",
    "plt.figure(figsize=(17,6))\n",
    "plt.pcolormesh(feats)\n",
    "\n",
    "plt.title('Spectrogram visualization')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Time')\n",
    "\n",
    "plt.show()\n",
    "print(\"File: \" + train[index] + \" - Label: \" + str(trainLabels[index]))\n",
    "#print(np.max(feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data_dir, file_names, labels, batch_size = 32, shuffle = True, cache_file = None):\n",
    "    \n",
    "    # Create a Dataset object\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((file_names, labels))\n",
    "    \n",
    "    # Map the load_and_preprocess_data function\n",
    "    py_func = lambda file_name, label: (tf.py_func(load_and_preprocess_data, [file_name, data_dir], tf.float32), label)\n",
    "    dataset = dataset.map(py_func, num_parallel_calls = os.cpu_count())\n",
    "    \n",
    "    # Cache dataset\n",
    "    if cache_file:\n",
    "        dataset = dataset.cache(cache_file)\n",
    "    \n",
    "    # Shuffle    \n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(len(file_names))\n",
    "        \n",
    "    # Repeat the dataset indefinitely (capire bene anche questo repeat come funziona)\n",
    "    #dataset = dataset.repeat()\n",
    "    \n",
    "    # Correct input shape for the network\n",
    "    dataset = dataset.map(lambda data, label: (tf.expand_dims(data, -1), label))\n",
    "    \n",
    "    # Batch\n",
    "    dataset = dataset.batch(batch_size = batch_size)\n",
    "    \n",
    "    # Prefetch (TODO: da cambiare questo e capire come funziona)\n",
    "    dataset = dataset.prefetch(buffer_size = 1)\n",
    "    \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0628 16:28:32.964558 139623002822400 deprecation.py:323] From <ipython-input-14-3369a57ef390>:7: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2652\n",
      "312\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataset = create_dataset(dataset_dir, train, trainLabels, batch_size = batch_size, shuffle = True, cache_file = 'train_cache')\n",
    "\n",
    "val_dataset = create_dataset(dataset_dir, val, valLabels, batch_size = batch_size, shuffle = False, cache_file = 'val_cache')\n",
    "\n",
    "train_steps = int(np.ceil(len(train) / batch_size))\n",
    "val_steps = int(np.ceil(len(val) / batch_size))\n",
    "print(\"steps per completare un epoca di train: \" + str(train_steps))\n",
    "print(\"steps per completare un epoca di validation: \" + str(val_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0628 16:28:43.916669 139623002822400 deprecation.py:323] From <ipython-input-17-8e4813be7eb7>:10: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The Session graph is empty.  Add operations to the graph before calling run().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8e4813be7eb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0;31m# Get the next batch of data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Print loading time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'EPOCH {} - Time to load the entire dataset [seconds]: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1096\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n\u001b[0m\u001b[1;32m   1099\u001b[0m                          'graph before calling run().')\n\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The Session graph is empty.  Add operations to the graph before calling run()."
     ]
    }
   ],
   "source": [
    "\"\"\" Questa parte con la eager execution attiva non va, ma non  un problema\n",
    "# Initialize a dataset for test\n",
    "small_dataset = create_dataset(dataset_dir,\n",
    "                               train[:100], \n",
    "                               trainLabels[:100], \n",
    "                               batch_size = batch_size, \n",
    "                               shuffle = True, \n",
    "                               cache_file = 'small_cache')\n",
    "\n",
    "# Define an iterator to get data\n",
    "iterator = small_dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "# Start a new session\n",
    "with tf.Session() as sess:\n",
    "    # Iterate for 3 epochs\n",
    "    for num_epoch in range(3):\n",
    "        # Time the loading time\n",
    "        it = time.time()\n",
    "        for step in tqdm(range(3)):\n",
    "                # Get the next batch of data\n",
    "                data, label = sess.run(next_element)\n",
    "        # Print loading time\n",
    "        print('EPOCH {} - Time to load the entire dataset [seconds]: {}'.format(num_epoch+1, time.time() - it))\n",
    "    \n",
    "# Remove the created cache\n",
    "os.remove('small_cache.data-00000-of-00001')\n",
    "os.remove('small_cache.index')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainGen = SpeechGenerator.SpeechGen(train, trainLabels, dataset_dir, batch_size = 64, shuffle = True)\n",
    "#valGen = SpeechGenerator.SpeechGen(val, valLabels, dataset_dir, batch_size = 16, shuffle = False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 99, 39, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 95, 35, 64)        1664      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 31, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 31, 11, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 29, 9, 32)         18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 9, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 9, 3, 32)          128       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 864)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 864)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               110720    \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 21)                2709      \n",
      "=================================================================\n",
      "Total params: 133,941\n",
      "Trainable params: 133,749\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#keras.backend.set_floatx('float32')\n",
    "\n",
    "#print(keras.backend.floatx())\n",
    "\n",
    "model = Model.SimpleModel(nCategs, 99, 39, use_GRU = True, dropout = 0.1, activation = 'relu')\n",
    "\"\"\"\n",
    "decayed_lr = tf.train.exponential_decay(0.0000001,\n",
    "                                        0.8, 50,\n",
    "                                        0.95, staircase=True)\n",
    "\n",
    "adam = tf.train.AdamOptimizer(learning_rate=decayed_lr,  \n",
    "                                beta1=0.9,\n",
    "                                beta2=0.999,\n",
    "                                epsilon=1e-07,\n",
    "                                use_locking=False,\n",
    "                                name='Adam')\n",
    "\"\"\"\n",
    "adam = tf.train.AdamOptimizer(learning_rate=0.001,  \n",
    "                                beta1=0.9,\n",
    "                                beta2=0.999,\n",
    "                                epsilon=1e-07,\n",
    "                                use_locking=False,\n",
    "                                name='Adam')\n",
    "\n",
    "#model.compile(optimizer=adam,\n",
    "#              loss= tf.losses.softmax_cross_entropy,\n",
    "#              metrics=[keras.metrics.sparse_categorical_accuracy, ])\n",
    "\n",
    "#model.compile(optimizer = adam,\n",
    "#              loss = tf.keras.losses.sparse_categorical_crossentropy,\n",
    "#              metrics = ['sparse_categorical_accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 0\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 0: 2.923954963684082\n",
      "Seen so far: 64 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1: 3.8171277046203613\n",
      "Seen so far: 128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2: 3.401384115219116\n",
      "Seen so far: 192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 3: 3.0038671493530273\n",
      "Seen so far: 256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 4: 2.8590378761291504\n",
      "Seen so far: 320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 5: 2.986589193344116\n",
      "Seen so far: 384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 6: 2.826308012008667\n",
      "Seen so far: 448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 7: 2.6467840671539307\n",
      "Seen so far: 512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 8: 2.9938552379608154\n",
      "Seen so far: 576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 9: 2.616656541824341\n",
      "Seen so far: 640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 10: 2.7189252376556396\n",
      "Seen so far: 704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 11: 2.7006659507751465\n",
      "Seen so far: 768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 12: 2.9740099906921387\n",
      "Seen so far: 832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 13: 2.844914436340332\n",
      "Seen so far: 896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 14: 3.2884316444396973\n",
      "Seen so far: 960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 15: 2.7145323753356934\n",
      "Seen so far: 1024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 16: 2.703619956970215\n",
      "Seen so far: 1088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 17: 2.670126438140869\n",
      "Seen so far: 1152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 18: 2.818565607070923\n",
      "Seen so far: 1216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 19: 2.7819271087646484\n",
      "Seen so far: 1280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 20: 2.8843774795532227\n",
      "Seen so far: 1344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 21: 2.754866361618042\n",
      "Seen so far: 1408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 22: 2.6423113346099854\n",
      "Seen so far: 1472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 23: 2.7977867126464844\n",
      "Seen so far: 1536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 24: 2.9872782230377197\n",
      "Seen so far: 1600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 25: 2.8519346714019775\n",
      "Seen so far: 1664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 26: 2.8830771446228027\n",
      "Seen so far: 1728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 27: 2.8683738708496094\n",
      "Seen so far: 1792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 28: 2.848870038986206\n",
      "Seen so far: 1856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 29: 2.6812572479248047\n",
      "Seen so far: 1920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 30: 3.0468215942382812\n",
      "Seen so far: 1984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 31: 2.6809589862823486\n",
      "Seen so far: 2048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 32: 2.7147955894470215\n",
      "Seen so far: 2112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 33: 2.903074026107788\n",
      "Seen so far: 2176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 34: 2.904222011566162\n",
      "Seen so far: 2240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 35: 2.9489102363586426\n",
      "Seen so far: 2304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 36: 3.0509960651397705\n",
      "Seen so far: 2368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 37: 2.8119211196899414\n",
      "Seen so far: 2432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 38: 2.7355997562408447\n",
      "Seen so far: 2496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 39: 2.809896945953369\n",
      "Seen so far: 2560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 40: 2.880728244781494\n",
      "Seen so far: 2624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 41: 3.079159736633301\n",
      "Seen so far: 2688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 42: 2.8490352630615234\n",
      "Seen so far: 2752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 43: 2.822741746902466\n",
      "Seen so far: 2816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 44: 2.7890079021453857\n",
      "Seen so far: 2880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 45: 2.6582512855529785\n",
      "Seen so far: 2944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 46: 2.7399911880493164\n",
      "Seen so far: 3008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 47: 2.389479637145996\n",
      "Seen so far: 3072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 48: 3.231964349746704\n",
      "Seen so far: 3136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 49: 2.8524203300476074\n",
      "Seen so far: 3200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 50: 2.7939858436584473\n",
      "Seen so far: 3264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 51: 2.8880367279052734\n",
      "Seen so far: 3328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 52: 2.8598885536193848\n",
      "Seen so far: 3392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 53: 2.682981014251709\n",
      "Seen so far: 3456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 54: 2.9315590858459473\n",
      "Seen so far: 3520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 55: 2.8042654991149902\n",
      "Seen so far: 3584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 56: 2.510446786880493\n",
      "Seen so far: 3648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 57: 2.7926788330078125\n",
      "Seen so far: 3712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 58: 2.7867653369903564\n",
      "Seen so far: 3776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 59: 2.8808507919311523\n",
      "Seen so far: 3840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 60: 2.635140895843506\n",
      "Seen so far: 3904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 61: 2.9998779296875\n",
      "Seen so far: 3968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 62: 2.7377943992614746\n",
      "Seen so far: 4032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 63: 2.7936697006225586\n",
      "Seen so far: 4096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 64: 2.7410478591918945\n",
      "Seen so far: 4160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 65: 2.730440378189087\n",
      "Seen so far: 4224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 66: 2.7454137802124023\n",
      "Seen so far: 4288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 67: 2.714139461517334\n",
      "Seen so far: 4352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 68: 2.5202879905700684\n",
      "Seen so far: 4416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 69: 2.8822579383850098\n",
      "Seen so far: 4480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 70: 2.15771222114563\n",
      "Seen so far: 4544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 71: 2.925168991088867\n",
      "Seen so far: 4608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 72: 2.7025132179260254\n",
      "Seen so far: 4672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 73: 2.461468458175659\n",
      "Seen so far: 4736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 74: 3.1314167976379395\n",
      "Seen so far: 4800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 75: 2.6043670177459717\n",
      "Seen so far: 4864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 76: 2.839961051940918\n",
      "Seen so far: 4928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 77: 2.6872687339782715\n",
      "Seen so far: 4992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 78: 2.881289482116699\n",
      "Seen so far: 5056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 79: 2.6713619232177734\n",
      "Seen so far: 5120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 80: 2.8274943828582764\n",
      "Seen so far: 5184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 81: 2.7811453342437744\n",
      "Seen so far: 5248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 82: 2.7738265991210938\n",
      "Seen so far: 5312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 83: 2.7849152088165283\n",
      "Seen so far: 5376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 84: 2.8630027770996094\n",
      "Seen so far: 5440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 85: 2.8575246334075928\n",
      "Seen so far: 5504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 86: 2.8457303047180176\n",
      "Seen so far: 5568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 87: 2.854391098022461\n",
      "Seen so far: 5632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 88: 2.7483763694763184\n",
      "Seen so far: 5696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 89: 2.536849021911621\n",
      "Seen so far: 5760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 90: 2.6731739044189453\n",
      "Seen so far: 5824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 91: 2.78117299079895\n",
      "Seen so far: 5888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 92: 2.909095287322998\n",
      "Seen so far: 5952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 93: 2.2585015296936035\n",
      "Seen so far: 6016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 94: 2.7996087074279785\n",
      "Seen so far: 6080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 95: 2.871983766555786\n",
      "Seen so far: 6144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 96: 2.841073513031006\n",
      "Seen so far: 6208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 97: 2.9695167541503906\n",
      "Seen so far: 6272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 98: 2.6575942039489746\n",
      "Seen so far: 6336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 99: 2.609590530395508\n",
      "Seen so far: 6400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 100: 2.8188352584838867\n",
      "Seen so far: 6464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 101: 2.3391406536102295\n",
      "Seen so far: 6528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 102: 2.65297532081604\n",
      "Seen so far: 6592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 103: 2.7628965377807617\n",
      "Seen so far: 6656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 104: 2.8872032165527344\n",
      "Seen so far: 6720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 105: 2.8649702072143555\n",
      "Seen so far: 6784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 106: 2.7037172317504883\n",
      "Seen so far: 6848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 107: 2.8044464588165283\n",
      "Seen so far: 6912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 108: 2.6328392028808594\n",
      "Seen so far: 6976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 109: 2.830536365509033\n",
      "Seen so far: 7040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 110: 2.9564690589904785\n",
      "Seen so far: 7104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 111: 2.6664202213287354\n",
      "Seen so far: 7168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 112: 2.8202433586120605\n",
      "Seen so far: 7232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 113: 2.86777925491333\n",
      "Seen so far: 7296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 114: 2.4585680961608887\n",
      "Seen so far: 7360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 115: 2.5699548721313477\n",
      "Seen so far: 7424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 116: 2.764606475830078\n",
      "Seen so far: 7488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 117: 2.899259567260742\n",
      "Seen so far: 7552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 118: 2.7973670959472656\n",
      "Seen so far: 7616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 119: 2.6630196571350098\n",
      "Seen so far: 7680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 120: 2.73583984375\n",
      "Seen so far: 7744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 121: 2.898069381713867\n",
      "Seen so far: 7808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 122: 2.6118593215942383\n",
      "Seen so far: 7872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 123: 2.667701482772827\n",
      "Seen so far: 7936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 124: 2.411937713623047\n",
      "Seen so far: 8000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 125: 2.838083267211914\n",
      "Seen so far: 8064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 126: 2.795187473297119\n",
      "Seen so far: 8128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 127: 2.3785805702209473\n",
      "Seen so far: 8192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 128: 2.7382025718688965\n",
      "Seen so far: 8256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 129: 2.941838264465332\n",
      "Seen so far: 8320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 130: 2.7027103900909424\n",
      "Seen so far: 8384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 131: 2.6831369400024414\n",
      "Seen so far: 8448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 132: 2.8379011154174805\n",
      "Seen so far: 8512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 133: 2.4304261207580566\n",
      "Seen so far: 8576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 134: 2.6966655254364014\n",
      "Seen so far: 8640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 135: 2.864084243774414\n",
      "Seen so far: 8704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 136: 2.6202611923217773\n",
      "Seen so far: 8768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 137: 2.87874698638916\n",
      "Seen so far: 8832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 138: 2.7366814613342285\n",
      "Seen so far: 8896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 139: 2.7418365478515625\n",
      "Seen so far: 8960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 140: 2.865464687347412\n",
      "Seen so far: 9024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 141: 2.8034017086029053\n",
      "Seen so far: 9088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 142: 2.6555943489074707\n",
      "Seen so far: 9152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 143: 2.907151699066162\n",
      "Seen so far: 9216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 144: 2.571485757827759\n",
      "Seen so far: 9280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 145: 2.650127410888672\n",
      "Seen so far: 9344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 146: 2.624586582183838\n",
      "Seen so far: 9408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 147: 2.8198018074035645\n",
      "Seen so far: 9472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 148: 2.683621406555176\n",
      "Seen so far: 9536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 149: 2.912484884262085\n",
      "Seen so far: 9600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 150: 2.9224648475646973\n",
      "Seen so far: 9664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 151: 2.589339256286621\n",
      "Seen so far: 9728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 152: 2.8877315521240234\n",
      "Seen so far: 9792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 153: 2.4294304847717285\n",
      "Seen so far: 9856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 154: 2.7515149116516113\n",
      "Seen so far: 9920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 155: 2.7247977256774902\n",
      "Seen so far: 9984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 156: 2.5733039379119873\n",
      "Seen so far: 10048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 157: 2.696383476257324\n",
      "Seen so far: 10112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 158: 2.654723644256592\n",
      "Seen so far: 10176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 159: 2.773886203765869\n",
      "Seen so far: 10240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 160: 2.8584628105163574\n",
      "Seen so far: 10304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 161: 2.629272222518921\n",
      "Seen so far: 10368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 162: 2.5805046558380127\n",
      "Seen so far: 10432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 163: 2.5240631103515625\n",
      "Seen so far: 10496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 164: 2.6391775608062744\n",
      "Seen so far: 10560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 165: 2.5175437927246094\n",
      "Seen so far: 10624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 166: 2.6584811210632324\n",
      "Seen so far: 10688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 167: 2.6327152252197266\n",
      "Seen so far: 10752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 168: 2.5349884033203125\n",
      "Seen so far: 10816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 169: 2.277778387069702\n",
      "Seen so far: 10880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 170: 2.5832061767578125\n",
      "Seen so far: 10944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 171: 2.676307439804077\n",
      "Seen so far: 11008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 172: 2.6510112285614014\n",
      "Seen so far: 11072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 173: 2.4342830181121826\n",
      "Seen so far: 11136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 174: 2.4407663345336914\n",
      "Seen so far: 11200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 175: 2.5047855377197266\n",
      "Seen so far: 11264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 176: 2.7370753288269043\n",
      "Seen so far: 11328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 177: 2.345628499984741\n",
      "Seen so far: 11392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 178: 2.441542148590088\n",
      "Seen so far: 11456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 179: 2.725677967071533\n",
      "Seen so far: 11520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 180: 2.355032444000244\n",
      "Seen so far: 11584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 181: 3.0200815200805664\n",
      "Seen so far: 11648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 182: 2.629702091217041\n",
      "Seen so far: 11712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 183: 2.524324655532837\n",
      "Seen so far: 11776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 184: 2.5281176567077637\n",
      "Seen so far: 11840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 185: 2.712570905685425\n",
      "Seen so far: 11904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 186: 2.744290351867676\n",
      "Seen so far: 11968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 187: 2.6835741996765137\n",
      "Seen so far: 12032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 188: 2.4627771377563477\n",
      "Seen so far: 12096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 189: 2.5863406658172607\n",
      "Seen so far: 12160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 190: 2.417994976043701\n",
      "Seen so far: 12224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 191: 2.0995335578918457\n",
      "Seen so far: 12288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 192: 2.5919291973114014\n",
      "Seen so far: 12352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 193: 2.7756283283233643\n",
      "Seen so far: 12416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 194: 2.797058582305908\n",
      "Seen so far: 12480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 195: 2.7822110652923584\n",
      "Seen so far: 12544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 196: 2.3901116847991943\n",
      "Seen so far: 12608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 197: 2.5611865520477295\n",
      "Seen so far: 12672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 198: 2.4982357025146484\n",
      "Seen so far: 12736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 199: 2.451857328414917\n",
      "Seen so far: 12800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 200: 2.652920722961426\n",
      "Seen so far: 12864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 201: 2.722853422164917\n",
      "Seen so far: 12928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 202: 2.4041390419006348\n",
      "Seen so far: 12992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 203: 2.692894458770752\n",
      "Seen so far: 13056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 204: 2.317610263824463\n",
      "Seen so far: 13120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 205: 2.2535011768341064\n",
      "Seen so far: 13184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 206: 2.518866539001465\n",
      "Seen so far: 13248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 207: 2.743577003479004\n",
      "Seen so far: 13312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 208: 2.607578754425049\n",
      "Seen so far: 13376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 209: 2.553117036819458\n",
      "Seen so far: 13440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 210: 2.6013412475585938\n",
      "Seen so far: 13504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 211: 2.74592924118042\n",
      "Seen so far: 13568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 212: 2.3959436416625977\n",
      "Seen so far: 13632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 213: 2.4460713863372803\n",
      "Seen so far: 13696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 214: 2.4902467727661133\n",
      "Seen so far: 13760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 215: 2.475480794906616\n",
      "Seen so far: 13824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 216: 2.3966140747070312\n",
      "Seen so far: 13888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 217: 2.487727642059326\n",
      "Seen so far: 13952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 218: 2.221525192260742\n",
      "Seen so far: 14016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 219: 2.5089733600616455\n",
      "Seen so far: 14080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 220: 2.486818790435791\n",
      "Seen so far: 14144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 221: 2.4736225605010986\n",
      "Seen so far: 14208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 222: 2.5527143478393555\n",
      "Seen so far: 14272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 223: 2.466317653656006\n",
      "Seen so far: 14336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 224: 2.4788246154785156\n",
      "Seen so far: 14400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 225: 2.362175464630127\n",
      "Seen so far: 14464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 226: 2.19234037399292\n",
      "Seen so far: 14528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 227: 2.737135410308838\n",
      "Seen so far: 14592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 228: 2.733649253845215\n",
      "Seen so far: 14656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 229: 2.542034149169922\n",
      "Seen so far: 14720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 230: 2.7128148078918457\n",
      "Seen so far: 14784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 231: 2.5953805446624756\n",
      "Seen so far: 14848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 232: 2.8229501247406006\n",
      "Seen so far: 14912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 233: 2.475050449371338\n",
      "Seen so far: 14976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 234: 2.4340500831604004\n",
      "Seen so far: 15040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 235: 2.6499314308166504\n",
      "Seen so far: 15104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 236: 2.6546125411987305\n",
      "Seen so far: 15168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 237: 2.655313491821289\n",
      "Seen so far: 15232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 238: 2.4865570068359375\n",
      "Seen so far: 15296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 239: 2.161986827850342\n",
      "Seen so far: 15360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 240: 2.677551507949829\n",
      "Seen so far: 15424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 241: 2.2957417964935303\n",
      "Seen so far: 15488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 242: 2.7685649394989014\n",
      "Seen so far: 15552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 243: 2.4591760635375977\n",
      "Seen so far: 15616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 244: 2.4113779067993164\n",
      "Seen so far: 15680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 245: 2.605567216873169\n",
      "Seen so far: 15744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 246: 2.8043947219848633\n",
      "Seen so far: 15808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 247: 2.4656238555908203\n",
      "Seen so far: 15872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 248: 2.7895188331604004\n",
      "Seen so far: 15936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 249: 2.6237733364105225\n",
      "Seen so far: 16000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 250: 2.30625581741333\n",
      "Seen so far: 16064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 251: 2.6746654510498047\n",
      "Seen so far: 16128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 252: 2.8243045806884766\n",
      "Seen so far: 16192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 253: 2.5925660133361816\n",
      "Seen so far: 16256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 254: 2.6595029830932617\n",
      "Seen so far: 16320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 255: 2.66752552986145\n",
      "Seen so far: 16384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 256: 2.5644893646240234\n",
      "Seen so far: 16448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 257: 2.7689037322998047\n",
      "Seen so far: 16512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 258: 2.694626808166504\n",
      "Seen so far: 16576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 259: 2.5350451469421387\n",
      "Seen so far: 16640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 260: 2.7261953353881836\n",
      "Seen so far: 16704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 261: 2.2364349365234375\n",
      "Seen so far: 16768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 262: 2.6213109493255615\n",
      "Seen so far: 16832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 263: 2.5613560676574707\n",
      "Seen so far: 16896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 264: 2.4162378311157227\n",
      "Seen so far: 16960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 265: 2.4886488914489746\n",
      "Seen so far: 17024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 266: 2.487513542175293\n",
      "Seen so far: 17088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 267: 2.184046506881714\n",
      "Seen so far: 17152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 268: 2.497323513031006\n",
      "Seen so far: 17216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 269: 2.432992935180664\n",
      "Seen so far: 17280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 270: 2.6414132118225098\n",
      "Seen so far: 17344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 271: 2.5030364990234375\n",
      "Seen so far: 17408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 272: 2.40203857421875\n",
      "Seen so far: 17472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 273: 2.4364140033721924\n",
      "Seen so far: 17536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 274: 2.8263494968414307\n",
      "Seen so far: 17600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 275: 2.3392531871795654\n",
      "Seen so far: 17664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 276: 2.5099470615386963\n",
      "Seen so far: 17728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 277: 2.6440725326538086\n",
      "Seen so far: 17792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 278: 2.752439498901367\n",
      "Seen so far: 17856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 279: 2.645010232925415\n",
      "Seen so far: 17920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 280: 1.9924968481063843\n",
      "Seen so far: 17984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 281: 2.245302677154541\n",
      "Seen so far: 18048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 282: 2.5995712280273438\n",
      "Seen so far: 18112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 283: 2.522881507873535\n",
      "Seen so far: 18176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 284: 2.4139509201049805\n",
      "Seen so far: 18240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 285: 2.4621944427490234\n",
      "Seen so far: 18304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 286: 2.105509042739868\n",
      "Seen so far: 18368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 287: 2.4447028636932373\n",
      "Seen so far: 18432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 288: 2.6395444869995117\n",
      "Seen so far: 18496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 289: 2.472656726837158\n",
      "Seen so far: 18560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 290: 2.421266794204712\n",
      "Seen so far: 18624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 291: 2.3409929275512695\n",
      "Seen so far: 18688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 292: 2.549804210662842\n",
      "Seen so far: 18752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 293: 2.5177268981933594\n",
      "Seen so far: 18816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 294: 1.9803451299667358\n",
      "Seen so far: 18880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 295: 2.57432222366333\n",
      "Seen so far: 18944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 296: 2.549515962600708\n",
      "Seen so far: 19008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 297: 2.2604994773864746\n",
      "Seen so far: 19072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 298: 2.581005334854126\n",
      "Seen so far: 19136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 299: 2.7082748413085938\n",
      "Seen so far: 19200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 300: 2.213693857192993\n",
      "Seen so far: 19264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 301: 2.5472452640533447\n",
      "Seen so far: 19328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 302: 2.4950318336486816\n",
      "Seen so far: 19392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 303: 2.8249735832214355\n",
      "Seen so far: 19456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 304: 2.521636962890625\n",
      "Seen so far: 19520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 305: 2.400092124938965\n",
      "Seen so far: 19584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 306: 2.679629325866699\n",
      "Seen so far: 19648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 307: 2.827650547027588\n",
      "Seen so far: 19712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 308: 2.4153544902801514\n",
      "Seen so far: 19776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 309: 2.674487590789795\n",
      "Seen so far: 19840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 310: 2.566277027130127\n",
      "Seen so far: 19904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 311: 2.4894773960113525\n",
      "Seen so far: 19968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 312: 2.5400075912475586\n",
      "Seen so far: 20032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 313: 2.3827450275421143\n",
      "Seen so far: 20096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 314: 2.4617257118225098\n",
      "Seen so far: 20160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 315: 2.6534359455108643\n",
      "Seen so far: 20224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 316: 2.5100109577178955\n",
      "Seen so far: 20288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 317: 2.6825129985809326\n",
      "Seen so far: 20352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 318: 2.764647960662842\n",
      "Seen so far: 20416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 319: 2.571380853652954\n",
      "Seen so far: 20480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 320: 2.2099578380584717\n",
      "Seen so far: 20544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 321: 2.543956756591797\n",
      "Seen so far: 20608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 322: 2.4276037216186523\n",
      "Seen so far: 20672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 323: 2.4496569633483887\n",
      "Seen so far: 20736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 324: 2.19881534576416\n",
      "Seen so far: 20800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 325: 2.3436975479125977\n",
      "Seen so far: 20864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 326: 2.523700475692749\n",
      "Seen so far: 20928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 327: 2.742018938064575\n",
      "Seen so far: 20992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 328: 2.6935877799987793\n",
      "Seen so far: 21056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 329: 2.4431209564208984\n",
      "Seen so far: 21120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 330: 2.1924548149108887\n",
      "Seen so far: 21184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 331: 2.4231760501861572\n",
      "Seen so far: 21248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 332: 2.3572325706481934\n",
      "Seen so far: 21312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 333: 2.279428243637085\n",
      "Seen so far: 21376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 334: 1.9753715991973877\n",
      "Seen so far: 21440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 335: 2.019766092300415\n",
      "Seen so far: 21504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 336: 2.4193787574768066\n",
      "Seen so far: 21568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 337: 2.308419704437256\n",
      "Seen so far: 21632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 338: 2.266820192337036\n",
      "Seen so far: 21696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 339: 2.01849365234375\n",
      "Seen so far: 21760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 340: 2.2609148025512695\n",
      "Seen so far: 21824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 341: 2.7129578590393066\n",
      "Seen so far: 21888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 342: 2.506427764892578\n",
      "Seen so far: 21952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 343: 2.6202924251556396\n",
      "Seen so far: 22016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 344: 2.345086097717285\n",
      "Seen so far: 22080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 345: 2.3863368034362793\n",
      "Seen so far: 22144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 346: 2.132979393005371\n",
      "Seen so far: 22208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 347: 2.878570795059204\n",
      "Seen so far: 22272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 348: 2.3038506507873535\n",
      "Seen so far: 22336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 349: 2.307936191558838\n",
      "Seen so far: 22400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 350: 2.344552516937256\n",
      "Seen so far: 22464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 351: 2.5060393810272217\n",
      "Seen so far: 22528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 352: 2.469681739807129\n",
      "Seen so far: 22592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 353: 2.5544824600219727\n",
      "Seen so far: 22656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 354: 2.3592276573181152\n",
      "Seen so far: 22720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 355: 2.5294418334960938\n",
      "Seen so far: 22784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 356: 2.327533006668091\n",
      "Seen so far: 22848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 357: 2.4546782970428467\n",
      "Seen so far: 22912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 358: 2.2808828353881836\n",
      "Seen so far: 22976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 359: 2.3823704719543457\n",
      "Seen so far: 23040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 360: 2.2325010299682617\n",
      "Seen so far: 23104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 361: 2.316816806793213\n",
      "Seen so far: 23168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 362: 2.3274943828582764\n",
      "Seen so far: 23232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 363: 2.365546941757202\n",
      "Seen so far: 23296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 364: 2.3829171657562256\n",
      "Seen so far: 23360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 365: 2.6874561309814453\n",
      "Seen so far: 23424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 366: 2.379312038421631\n",
      "Seen so far: 23488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 367: 2.327399253845215\n",
      "Seen so far: 23552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 368: 2.421083688735962\n",
      "Seen so far: 23616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 369: 2.7111284732818604\n",
      "Seen so far: 23680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 370: 2.3547024726867676\n",
      "Seen so far: 23744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 371: 2.1766443252563477\n",
      "Seen so far: 23808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 372: 1.9656982421875\n",
      "Seen so far: 23872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 373: 2.5614142417907715\n",
      "Seen so far: 23936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 374: 2.87324857711792\n",
      "Seen so far: 24000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 375: 2.627619504928589\n",
      "Seen so far: 24064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 376: 2.3154215812683105\n",
      "Seen so far: 24128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 377: 2.375539779663086\n",
      "Seen so far: 24192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 378: 2.35774827003479\n",
      "Seen so far: 24256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 379: 2.167975664138794\n",
      "Seen so far: 24320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 380: 2.5426108837127686\n",
      "Seen so far: 24384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 381: 2.538355588912964\n",
      "Seen so far: 24448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 382: 2.353062629699707\n",
      "Seen so far: 24512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 383: 2.3554999828338623\n",
      "Seen so far: 24576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 384: 2.4676098823547363\n",
      "Seen so far: 24640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 385: 2.635019302368164\n",
      "Seen so far: 24704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 386: 2.4902989864349365\n",
      "Seen so far: 24768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 387: 2.5474886894226074\n",
      "Seen so far: 24832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 388: 2.4486522674560547\n",
      "Seen so far: 24896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 389: 2.388969898223877\n",
      "Seen so far: 24960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 390: 2.2747440338134766\n",
      "Seen so far: 25024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 391: 2.664602279663086\n",
      "Seen so far: 25088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 392: 2.1766748428344727\n",
      "Seen so far: 25152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 393: 2.4474782943725586\n",
      "Seen so far: 25216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 394: 2.250535011291504\n",
      "Seen so far: 25280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 395: 2.3399887084960938\n",
      "Seen so far: 25344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 396: 2.4848175048828125\n",
      "Seen so far: 25408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 397: 2.2960338592529297\n",
      "Seen so far: 25472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 398: 2.103839874267578\n",
      "Seen so far: 25536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 399: 2.4225058555603027\n",
      "Seen so far: 25600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 400: 1.9780538082122803\n",
      "Seen so far: 25664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 401: 2.291943073272705\n",
      "Seen so far: 25728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 402: 2.484229564666748\n",
      "Seen so far: 25792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 403: 2.0248618125915527\n",
      "Seen so far: 25856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 404: 2.170316219329834\n",
      "Seen so far: 25920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 405: 2.4809181690216064\n",
      "Seen so far: 25984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 406: 2.5302934646606445\n",
      "Seen so far: 26048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 407: 2.54347562789917\n",
      "Seen so far: 26112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 408: 2.2332305908203125\n",
      "Seen so far: 26176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 409: 2.1071879863739014\n",
      "Seen so far: 26240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 410: 2.37039852142334\n",
      "Seen so far: 26304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 411: 2.543724775314331\n",
      "Seen so far: 26368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 412: 2.4641902446746826\n",
      "Seen so far: 26432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 413: 2.4254090785980225\n",
      "Seen so far: 26496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 414: 2.1490936279296875\n",
      "Seen so far: 26560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 415: 2.240225076675415\n",
      "Seen so far: 26624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 416: 2.653712034225464\n",
      "Seen so far: 26688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 417: 2.2488150596618652\n",
      "Seen so far: 26752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 418: 2.498642921447754\n",
      "Seen so far: 26816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 419: 2.7302746772766113\n",
      "Seen so far: 26880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 420: 2.3934528827667236\n",
      "Seen so far: 26944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 421: 2.308060884475708\n",
      "Seen so far: 27008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 422: 2.283501625061035\n",
      "Seen so far: 27072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 423: 2.512314796447754\n",
      "Seen so far: 27136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 424: 2.451963186264038\n",
      "Seen so far: 27200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 425: 2.508965492248535\n",
      "Seen so far: 27264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 426: 2.22800874710083\n",
      "Seen so far: 27328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 427: 2.240000009536743\n",
      "Seen so far: 27392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 428: 2.200253963470459\n",
      "Seen so far: 27456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 429: 2.5937132835388184\n",
      "Seen so far: 27520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 430: 2.2187931537628174\n",
      "Seen so far: 27584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 431: 2.3145947456359863\n",
      "Seen so far: 27648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 432: 2.6326651573181152\n",
      "Seen so far: 27712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 433: 2.191225528717041\n",
      "Seen so far: 27776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 434: 2.504640579223633\n",
      "Seen so far: 27840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 435: 2.6086792945861816\n",
      "Seen so far: 27904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 436: 2.494277000427246\n",
      "Seen so far: 27968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 437: 2.311917781829834\n",
      "Seen so far: 28032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 438: 2.244258403778076\n",
      "Seen so far: 28096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 439: 2.2804088592529297\n",
      "Seen so far: 28160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 440: 2.31234073638916\n",
      "Seen so far: 28224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 441: 2.5333118438720703\n",
      "Seen so far: 28288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 442: 2.4222075939178467\n",
      "Seen so far: 28352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 443: 2.151548147201538\n",
      "Seen so far: 28416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 444: 2.643627166748047\n",
      "Seen so far: 28480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 445: 2.6870779991149902\n",
      "Seen so far: 28544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 446: 2.376681089401245\n",
      "Seen so far: 28608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 447: 2.5307626724243164\n",
      "Seen so far: 28672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 448: 2.230931520462036\n",
      "Seen so far: 28736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 449: 2.4552927017211914\n",
      "Seen so far: 28800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 450: 2.5192489624023438\n",
      "Seen so far: 28864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 451: 2.2552475929260254\n",
      "Seen so far: 28928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 452: 2.591704845428467\n",
      "Seen so far: 28992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 453: 2.5043981075286865\n",
      "Seen so far: 29056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 454: 2.448659896850586\n",
      "Seen so far: 29120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 455: 2.2203736305236816\n",
      "Seen so far: 29184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 456: 2.3026609420776367\n",
      "Seen so far: 29248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 457: 2.3290631771087646\n",
      "Seen so far: 29312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 458: 2.2189583778381348\n",
      "Seen so far: 29376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 459: 2.3305671215057373\n",
      "Seen so far: 29440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 460: 2.4569525718688965\n",
      "Seen so far: 29504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 461: 2.4574928283691406\n",
      "Seen so far: 29568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 462: 2.092916488647461\n",
      "Seen so far: 29632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 463: 2.44323468208313\n",
      "Seen so far: 29696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 464: 2.261645555496216\n",
      "Seen so far: 29760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 465: 1.9678618907928467\n",
      "Seen so far: 29824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 466: 2.150780439376831\n",
      "Seen so far: 29888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 467: 2.5851430892944336\n",
      "Seen so far: 29952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 468: 2.2689061164855957\n",
      "Seen so far: 30016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 469: 2.111631393432617\n",
      "Seen so far: 30080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 470: 2.307194232940674\n",
      "Seen so far: 30144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 471: 2.2981159687042236\n",
      "Seen so far: 30208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 472: 2.407935619354248\n",
      "Seen so far: 30272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 473: 2.1698102951049805\n",
      "Seen so far: 30336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 474: 2.2051892280578613\n",
      "Seen so far: 30400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 475: 2.2694196701049805\n",
      "Seen so far: 30464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 476: 2.199984073638916\n",
      "Seen so far: 30528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 477: 2.5815134048461914\n",
      "Seen so far: 30592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 478: 2.2437009811401367\n",
      "Seen so far: 30656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 479: 2.4176721572875977\n",
      "Seen so far: 30720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 480: 2.1989293098449707\n",
      "Seen so far: 30784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 481: 2.086977481842041\n",
      "Seen so far: 30848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 482: 2.2406888008117676\n",
      "Seen so far: 30912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 483: 2.328711986541748\n",
      "Seen so far: 30976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 484: 2.318403720855713\n",
      "Seen so far: 31040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 485: 1.9973018169403076\n",
      "Seen so far: 31104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 486: 2.2753372192382812\n",
      "Seen so far: 31168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 487: 2.1981263160705566\n",
      "Seen so far: 31232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 488: 2.45993971824646\n",
      "Seen so far: 31296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 489: 2.363130569458008\n",
      "Seen so far: 31360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 490: 2.3432250022888184\n",
      "Seen so far: 31424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 491: 2.202515125274658\n",
      "Seen so far: 31488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 492: 2.533609390258789\n",
      "Seen so far: 31552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 493: 2.2228779792785645\n",
      "Seen so far: 31616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 494: 1.7492527961730957\n",
      "Seen so far: 31680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 495: 2.399606227874756\n",
      "Seen so far: 31744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 496: 2.23856258392334\n",
      "Seen so far: 31808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 497: 2.2437784671783447\n",
      "Seen so far: 31872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 498: 2.403398036956787\n",
      "Seen so far: 31936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 499: 2.644796848297119\n",
      "Seen so far: 32000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 500: 2.359144687652588\n",
      "Seen so far: 32064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 501: 2.5290420055389404\n",
      "Seen so far: 32128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 502: 2.331355333328247\n",
      "Seen so far: 32192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 503: 2.457469940185547\n",
      "Seen so far: 32256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 504: 2.2658329010009766\n",
      "Seen so far: 32320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 505: 2.22031307220459\n",
      "Seen so far: 32384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 506: 2.5721235275268555\n",
      "Seen so far: 32448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 507: 2.6674113273620605\n",
      "Seen so far: 32512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 508: 2.1885805130004883\n",
      "Seen so far: 32576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 509: 2.546123504638672\n",
      "Seen so far: 32640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 510: 2.6094632148742676\n",
      "Seen so far: 32704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 511: 2.113895893096924\n",
      "Seen so far: 32768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 512: 2.4573140144348145\n",
      "Seen so far: 32832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 513: 2.2388503551483154\n",
      "Seen so far: 32896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 514: 2.2383382320404053\n",
      "Seen so far: 32960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 515: 2.4551711082458496\n",
      "Seen so far: 33024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 516: 2.261348247528076\n",
      "Seen so far: 33088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 517: 2.142125129699707\n",
      "Seen so far: 33152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 518: 2.448289632797241\n",
      "Seen so far: 33216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 519: 2.8304591178894043\n",
      "Seen so far: 33280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 520: 2.5334994792938232\n",
      "Seen so far: 33344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 521: 2.4577715396881104\n",
      "Seen so far: 33408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 522: 2.2305006980895996\n",
      "Seen so far: 33472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 523: 2.268643379211426\n",
      "Seen so far: 33536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 524: 2.3337883949279785\n",
      "Seen so far: 33600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 525: 2.202716827392578\n",
      "Seen so far: 33664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 526: 2.866076946258545\n",
      "Seen so far: 33728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 527: 2.1703579425811768\n",
      "Seen so far: 33792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 528: 2.508814573287964\n",
      "Seen so far: 33856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 529: 1.7811557054519653\n",
      "Seen so far: 33920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 530: 2.5843772888183594\n",
      "Seen so far: 33984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 531: 2.2306885719299316\n",
      "Seen so far: 34048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 532: 2.332185745239258\n",
      "Seen so far: 34112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 533: 2.646705150604248\n",
      "Seen so far: 34176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 534: 2.3557987213134766\n",
      "Seen so far: 34240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 535: 2.6698689460754395\n",
      "Seen so far: 34304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 536: 2.1111650466918945\n",
      "Seen so far: 34368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 537: 2.0312862396240234\n",
      "Seen so far: 34432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 538: 2.3111515045166016\n",
      "Seen so far: 34496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 539: 1.6740753650665283\n",
      "Seen so far: 34560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 540: 2.1546454429626465\n",
      "Seen so far: 34624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 541: 2.351933479309082\n",
      "Seen so far: 34688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 542: 2.4763283729553223\n",
      "Seen so far: 34752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 543: 2.198298215866089\n",
      "Seen so far: 34816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 544: 2.211294651031494\n",
      "Seen so far: 34880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 545: 2.454620599746704\n",
      "Seen so far: 34944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 546: 2.508370876312256\n",
      "Seen so far: 35008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 547: 2.2639472484588623\n",
      "Seen so far: 35072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 548: 2.445498466491699\n",
      "Seen so far: 35136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 549: 2.224677085876465\n",
      "Seen so far: 35200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 550: 2.4567809104919434\n",
      "Seen so far: 35264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 551: 2.4303855895996094\n",
      "Seen so far: 35328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 552: 2.383263111114502\n",
      "Seen so far: 35392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 553: 2.2941999435424805\n",
      "Seen so far: 35456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 554: 2.301821231842041\n",
      "Seen so far: 35520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 555: 2.2797327041625977\n",
      "Seen so far: 35584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 556: 2.2589850425720215\n",
      "Seen so far: 35648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 557: 2.4459879398345947\n",
      "Seen so far: 35712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 558: 2.234931468963623\n",
      "Seen so far: 35776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 559: 2.1374380588531494\n",
      "Seen so far: 35840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 560: 2.4854297637939453\n",
      "Seen so far: 35904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 561: 2.3521153926849365\n",
      "Seen so far: 35968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 562: 2.2430052757263184\n",
      "Seen so far: 36032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 563: 2.2529830932617188\n",
      "Seen so far: 36096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 564: 2.2006287574768066\n",
      "Seen so far: 36160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 565: 2.1597869396209717\n",
      "Seen so far: 36224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 566: 2.442870616912842\n",
      "Seen so far: 36288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 567: 2.155329704284668\n",
      "Seen so far: 36352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 568: 2.2091407775878906\n",
      "Seen so far: 36416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 569: 2.15468168258667\n",
      "Seen so far: 36480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 570: 2.5160465240478516\n",
      "Seen so far: 36544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 571: 2.5157880783081055\n",
      "Seen so far: 36608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 572: 2.619934320449829\n",
      "Seen so far: 36672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 573: 2.35715651512146\n",
      "Seen so far: 36736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 574: 2.2591724395751953\n",
      "Seen so far: 36800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 575: 2.131908655166626\n",
      "Seen so far: 36864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 576: 2.596282958984375\n",
      "Seen so far: 36928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 577: 2.334254503250122\n",
      "Seen so far: 36992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 578: 2.0570831298828125\n",
      "Seen so far: 37056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 579: 2.1147570610046387\n",
      "Seen so far: 37120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 580: 2.106255292892456\n",
      "Seen so far: 37184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 581: 2.040411949157715\n",
      "Seen so far: 37248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 582: 2.957963466644287\n",
      "Seen so far: 37312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 583: 2.3414974212646484\n",
      "Seen so far: 37376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 584: 2.315217971801758\n",
      "Seen so far: 37440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 585: 2.0031871795654297\n",
      "Seen so far: 37504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 586: 2.277529239654541\n",
      "Seen so far: 37568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 587: 2.0172977447509766\n",
      "Seen so far: 37632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 588: 2.2551097869873047\n",
      "Seen so far: 37696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 589: 2.4068543910980225\n",
      "Seen so far: 37760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 590: 2.084660053253174\n",
      "Seen so far: 37824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 591: 2.158698797225952\n",
      "Seen so far: 37888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 592: 2.252525806427002\n",
      "Seen so far: 37952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 593: 2.6315011978149414\n",
      "Seen so far: 38016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 594: 1.5513249635696411\n",
      "Seen so far: 38080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 595: 2.280474901199341\n",
      "Seen so far: 38144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 596: 1.97212815284729\n",
      "Seen so far: 38208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 597: 2.3778624534606934\n",
      "Seen so far: 38272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 598: 1.956629753112793\n",
      "Seen so far: 38336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 599: 2.255511522293091\n",
      "Seen so far: 38400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 600: 1.944589614868164\n",
      "Seen so far: 38464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 601: 2.1328721046447754\n",
      "Seen so far: 38528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 602: 2.010465145111084\n",
      "Seen so far: 38592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 603: 2.5495424270629883\n",
      "Seen so far: 38656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 604: 1.96406888961792\n",
      "Seen so far: 38720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 605: 1.926934003829956\n",
      "Seen so far: 38784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 606: 2.5708069801330566\n",
      "Seen so far: 38848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 607: 2.1598715782165527\n",
      "Seen so far: 38912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 608: 2.0198657512664795\n",
      "Seen so far: 38976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 609: 2.058793067932129\n",
      "Seen so far: 39040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 610: 1.9167534112930298\n",
      "Seen so far: 39104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 611: 2.229896068572998\n",
      "Seen so far: 39168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 612: 1.7759792804718018\n",
      "Seen so far: 39232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 613: 2.2146499156951904\n",
      "Seen so far: 39296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 614: 2.0700182914733887\n",
      "Seen so far: 39360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 615: 1.9821853637695312\n",
      "Seen so far: 39424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 616: 2.4262256622314453\n",
      "Seen so far: 39488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 617: 2.239635467529297\n",
      "Seen so far: 39552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 618: 2.375755786895752\n",
      "Seen so far: 39616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 619: 2.113100528717041\n",
      "Seen so far: 39680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 620: 2.257786273956299\n",
      "Seen so far: 39744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 621: 2.1668996810913086\n",
      "Seen so far: 39808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 622: 2.120734214782715\n",
      "Seen so far: 39872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 623: 2.286832094192505\n",
      "Seen so far: 39936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 624: 1.9977257251739502\n",
      "Seen so far: 40000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 625: 2.2203991413116455\n",
      "Seen so far: 40064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 626: 2.1457359790802\n",
      "Seen so far: 40128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 627: 2.1508922576904297\n",
      "Seen so far: 40192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 628: 2.3452999591827393\n",
      "Seen so far: 40256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 629: 2.098147392272949\n",
      "Seen so far: 40320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 630: 2.24204683303833\n",
      "Seen so far: 40384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 631: 2.39676570892334\n",
      "Seen so far: 40448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 632: 2.2742879390716553\n",
      "Seen so far: 40512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 633: 2.5207881927490234\n",
      "Seen so far: 40576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 634: 1.9329564571380615\n",
      "Seen so far: 40640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 635: 2.0764341354370117\n",
      "Seen so far: 40704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 636: 2.391523599624634\n",
      "Seen so far: 40768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 637: 2.0486514568328857\n",
      "Seen so far: 40832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 638: 2.242791175842285\n",
      "Seen so far: 40896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 639: 1.8902835845947266\n",
      "Seen so far: 40960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 640: 2.159169912338257\n",
      "Seen so far: 41024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 641: 2.288209915161133\n",
      "Seen so far: 41088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 642: 2.2015504837036133\n",
      "Seen so far: 41152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 643: 2.0951409339904785\n",
      "Seen so far: 41216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 644: 2.279567241668701\n",
      "Seen so far: 41280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 645: 1.7589854001998901\n",
      "Seen so far: 41344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 646: 1.9636198282241821\n",
      "Seen so far: 41408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 647: 2.061001777648926\n",
      "Seen so far: 41472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 648: 2.3190536499023438\n",
      "Seen so far: 41536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 649: 2.0213422775268555\n",
      "Seen so far: 41600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 650: 2.37019681930542\n",
      "Seen so far: 41664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 651: 2.4232778549194336\n",
      "Seen so far: 41728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 652: 2.2385997772216797\n",
      "Seen so far: 41792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 653: 2.274531364440918\n",
      "Seen so far: 41856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 654: 2.3303027153015137\n",
      "Seen so far: 41920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 655: 2.2038419246673584\n",
      "Seen so far: 41984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 656: 2.4126627445220947\n",
      "Seen so far: 42048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 657: 2.224703311920166\n",
      "Seen so far: 42112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 658: 2.1539368629455566\n",
      "Seen so far: 42176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 659: 1.9167745113372803\n",
      "Seen so far: 42240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 660: 2.41636061668396\n",
      "Seen so far: 42304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 661: 2.0675230026245117\n",
      "Seen so far: 42368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 662: 2.2041373252868652\n",
      "Seen so far: 42432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 663: 1.804738163948059\n",
      "Seen so far: 42496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 664: 2.111982583999634\n",
      "Seen so far: 42560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 665: 2.5551583766937256\n",
      "Seen so far: 42624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 666: 1.8239156007766724\n",
      "Seen so far: 42688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 667: 2.0562081336975098\n",
      "Seen so far: 42752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 668: 2.3206920623779297\n",
      "Seen so far: 42816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 669: 2.0471181869506836\n",
      "Seen so far: 42880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 670: 1.9603629112243652\n",
      "Seen so far: 42944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 671: 2.151395320892334\n",
      "Seen so far: 43008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 672: 2.3314669132232666\n",
      "Seen so far: 43072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 673: 2.2943673133850098\n",
      "Seen so far: 43136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 674: 2.1933531761169434\n",
      "Seen so far: 43200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 675: 2.0071682929992676\n",
      "Seen so far: 43264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 676: 2.001960277557373\n",
      "Seen so far: 43328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 677: 2.263601303100586\n",
      "Seen so far: 43392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 678: 1.9038474559783936\n",
      "Seen so far: 43456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 679: 2.494992971420288\n",
      "Seen so far: 43520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 680: 1.8576171398162842\n",
      "Seen so far: 43584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 681: 2.2025461196899414\n",
      "Seen so far: 43648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 682: 2.2255234718322754\n",
      "Seen so far: 43712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 683: 1.709310531616211\n",
      "Seen so far: 43776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 684: 2.01566219329834\n",
      "Seen so far: 43840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 685: 2.1177968978881836\n",
      "Seen so far: 43904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 686: 2.001397132873535\n",
      "Seen so far: 43968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 687: 2.51303768157959\n",
      "Seen so far: 44032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 688: 1.9167317152023315\n",
      "Seen so far: 44096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 689: 2.007709503173828\n",
      "Seen so far: 44160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 690: 2.251899242401123\n",
      "Seen so far: 44224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 691: 2.1792941093444824\n",
      "Seen so far: 44288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 692: 2.2785799503326416\n",
      "Seen so far: 44352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 693: 2.0506527423858643\n",
      "Seen so far: 44416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 694: 2.391879081726074\n",
      "Seen so far: 44480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 695: 2.518291473388672\n",
      "Seen so far: 44544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 696: 2.0346622467041016\n",
      "Seen so far: 44608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 697: 1.8238921165466309\n",
      "Seen so far: 44672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 698: 1.9987415075302124\n",
      "Seen so far: 44736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 699: 1.8852710723876953\n",
      "Seen so far: 44800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 700: 2.3729050159454346\n",
      "Seen so far: 44864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 701: 1.9501776695251465\n",
      "Seen so far: 44928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 702: 1.982749581336975\n",
      "Seen so far: 44992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 703: 2.4104957580566406\n",
      "Seen so far: 45056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 704: 2.2193117141723633\n",
      "Seen so far: 45120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 705: 2.415379524230957\n",
      "Seen so far: 45184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 706: 2.1581196784973145\n",
      "Seen so far: 45248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 707: 2.0438780784606934\n",
      "Seen so far: 45312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 708: 1.6072825193405151\n",
      "Seen so far: 45376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 709: 2.3494725227355957\n",
      "Seen so far: 45440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 710: 2.1820881366729736\n",
      "Seen so far: 45504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 711: 2.277343988418579\n",
      "Seen so far: 45568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 712: 2.179668426513672\n",
      "Seen so far: 45632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 713: 2.134481430053711\n",
      "Seen so far: 45696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 714: 1.9732471704483032\n",
      "Seen so far: 45760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 715: 1.8939229249954224\n",
      "Seen so far: 45824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 716: 1.8803156614303589\n",
      "Seen so far: 45888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 717: 2.3883767127990723\n",
      "Seen so far: 45952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 718: 2.4990270137786865\n",
      "Seen so far: 46016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 719: 2.228992462158203\n",
      "Seen so far: 46080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 720: 2.0992794036865234\n",
      "Seen so far: 46144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 721: 1.9779653549194336\n",
      "Seen so far: 46208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 722: 1.7271122932434082\n",
      "Seen so far: 46272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 723: 2.085096836090088\n",
      "Seen so far: 46336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 724: 2.2809348106384277\n",
      "Seen so far: 46400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 725: 2.5638065338134766\n",
      "Seen so far: 46464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 726: 2.0644025802612305\n",
      "Seen so far: 46528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 727: 1.987516164779663\n",
      "Seen so far: 46592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 728: 2.205460786819458\n",
      "Seen so far: 46656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 729: 1.9637267589569092\n",
      "Seen so far: 46720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 730: 2.1425375938415527\n",
      "Seen so far: 46784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 731: 2.3239572048187256\n",
      "Seen so far: 46848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 732: 2.4150612354278564\n",
      "Seen so far: 46912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 733: 2.083585262298584\n",
      "Seen so far: 46976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 734: 2.2373805046081543\n",
      "Seen so far: 47040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 735: 2.02620530128479\n",
      "Seen so far: 47104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 736: 2.2572240829467773\n",
      "Seen so far: 47168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 737: 2.0500078201293945\n",
      "Seen so far: 47232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 738: 1.9767576456069946\n",
      "Seen so far: 47296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 739: 2.2202906608581543\n",
      "Seen so far: 47360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 740: 2.079592704772949\n",
      "Seen so far: 47424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 741: 1.895181655883789\n",
      "Seen so far: 47488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 742: 2.016961097717285\n",
      "Seen so far: 47552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 743: 1.9702975749969482\n",
      "Seen so far: 47616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 744: 1.7848637104034424\n",
      "Seen so far: 47680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 745: 1.9376096725463867\n",
      "Seen so far: 47744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 746: 2.108602285385132\n",
      "Seen so far: 47808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 747: 2.2794711589813232\n",
      "Seen so far: 47872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 748: 1.994864821434021\n",
      "Seen so far: 47936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 749: 2.0265450477600098\n",
      "Seen so far: 48000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 750: 1.769939661026001\n",
      "Seen so far: 48064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 751: 1.9939359426498413\n",
      "Seen so far: 48128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 752: 2.0280275344848633\n",
      "Seen so far: 48192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 753: 2.2669057846069336\n",
      "Seen so far: 48256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 754: 2.2097010612487793\n",
      "Seen so far: 48320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 755: 2.1944193840026855\n",
      "Seen so far: 48384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 756: 2.2246286869049072\n",
      "Seen so far: 48448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 757: 2.4096884727478027\n",
      "Seen so far: 48512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 758: 2.0541088581085205\n",
      "Seen so far: 48576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 759: 1.7505139112472534\n",
      "Seen so far: 48640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 760: 2.2765419483184814\n",
      "Seen so far: 48704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 761: 1.9823389053344727\n",
      "Seen so far: 48768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 762: 2.128117561340332\n",
      "Seen so far: 48832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 763: 2.0461957454681396\n",
      "Seen so far: 48896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 764: 2.656540632247925\n",
      "Seen so far: 48960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 765: 2.0099029541015625\n",
      "Seen so far: 49024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 766: 2.2178969383239746\n",
      "Seen so far: 49088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 767: 1.9587204456329346\n",
      "Seen so far: 49152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 768: 1.8994700908660889\n",
      "Seen so far: 49216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 769: 2.076375961303711\n",
      "Seen so far: 49280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 770: 1.9386262893676758\n",
      "Seen so far: 49344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 771: 2.1632769107818604\n",
      "Seen so far: 49408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 772: 2.348850965499878\n",
      "Seen so far: 49472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 773: 1.7325587272644043\n",
      "Seen so far: 49536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 774: 2.250237464904785\n",
      "Seen so far: 49600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 775: 1.8420535326004028\n",
      "Seen so far: 49664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 776: 2.154153823852539\n",
      "Seen so far: 49728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 777: 1.9583700895309448\n",
      "Seen so far: 49792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 778: 2.132932186126709\n",
      "Seen so far: 49856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 779: 1.645219087600708\n",
      "Seen so far: 49920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 780: 1.9584752321243286\n",
      "Seen so far: 49984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 781: 2.170506477355957\n",
      "Seen so far: 50048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 782: 2.0493578910827637\n",
      "Seen so far: 50112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 783: 1.7481350898742676\n",
      "Seen so far: 50176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 784: 2.3170671463012695\n",
      "Seen so far: 50240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 785: 2.619251251220703\n",
      "Seen so far: 50304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 786: 1.9324911832809448\n",
      "Seen so far: 50368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 787: 2.248227119445801\n",
      "Seen so far: 50432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 788: 1.6846199035644531\n",
      "Seen so far: 50496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 789: 2.0804238319396973\n",
      "Seen so far: 50560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 790: 2.3846824169158936\n",
      "Seen so far: 50624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 791: 2.297427177429199\n",
      "Seen so far: 50688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 792: 1.633392095565796\n",
      "Seen so far: 50752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 793: 1.855295181274414\n",
      "Seen so far: 50816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 794: 2.397111415863037\n",
      "Seen so far: 50880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 795: 2.2865853309631348\n",
      "Seen so far: 50944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 796: 2.3325562477111816\n",
      "Seen so far: 51008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 797: 2.222745895385742\n",
      "Seen so far: 51072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 798: 2.341765880584717\n",
      "Seen so far: 51136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 799: 2.1158275604248047\n",
      "Seen so far: 51200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 800: 2.172327995300293\n",
      "Seen so far: 51264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 801: 1.7671386003494263\n",
      "Seen so far: 51328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 802: 2.0655643939971924\n",
      "Seen so far: 51392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 803: 1.9649393558502197\n",
      "Seen so far: 51456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 804: 1.9509270191192627\n",
      "Seen so far: 51520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 805: 2.1781716346740723\n",
      "Seen so far: 51584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 806: 2.300950527191162\n",
      "Seen so far: 51648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 807: 1.8008599281311035\n",
      "Seen so far: 51712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 808: 2.166268825531006\n",
      "Seen so far: 51776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 809: 2.0998759269714355\n",
      "Seen so far: 51840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 810: 1.9954233169555664\n",
      "Seen so far: 51904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 811: 1.9305105209350586\n",
      "Seen so far: 51968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 812: 1.9821817874908447\n",
      "Seen so far: 52032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 813: 1.996631145477295\n",
      "Seen so far: 52096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 814: 1.6262956857681274\n",
      "Seen so far: 52160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 815: 2.2299163341522217\n",
      "Seen so far: 52224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 816: 2.0213358402252197\n",
      "Seen so far: 52288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 817: 2.179915428161621\n",
      "Seen so far: 52352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 818: 2.1090645790100098\n",
      "Seen so far: 52416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 819: 1.6211628913879395\n",
      "Seen so far: 52480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 820: 1.8458499908447266\n",
      "Seen so far: 52544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 821: 2.2322964668273926\n",
      "Seen so far: 52608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 822: 1.8692100048065186\n",
      "Seen so far: 52672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 823: 2.051119565963745\n",
      "Seen so far: 52736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 824: 2.2289464473724365\n",
      "Seen so far: 52800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 825: 2.1159799098968506\n",
      "Seen so far: 52864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 826: 2.0936460494995117\n",
      "Seen so far: 52928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 827: 2.199105739593506\n",
      "Seen so far: 52992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 828: 2.332944631576538\n",
      "Seen so far: 53056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 829: 1.9753291606903076\n",
      "Seen so far: 53120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 830: 1.7040574550628662\n",
      "Seen so far: 53184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 831: 1.981137990951538\n",
      "Seen so far: 53248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 832: 2.116415500640869\n",
      "Seen so far: 53312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 833: 2.3386030197143555\n",
      "Seen so far: 53376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 834: 2.165347099304199\n",
      "Seen so far: 53440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 835: 1.8704440593719482\n",
      "Seen so far: 53504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 836: 2.2239673137664795\n",
      "Seen so far: 53568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 837: 2.007014274597168\n",
      "Seen so far: 53632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 838: 2.117166042327881\n",
      "Seen so far: 53696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 839: 1.693827748298645\n",
      "Seen so far: 53760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 840: 1.8756492137908936\n",
      "Seen so far: 53824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 841: 2.1625375747680664\n",
      "Seen so far: 53888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 842: 2.1179609298706055\n",
      "Seen so far: 53952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 843: 1.6206061840057373\n",
      "Seen so far: 54016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 844: 2.3171944618225098\n",
      "Seen so far: 54080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 845: 1.977957844734192\n",
      "Seen so far: 54144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 846: 2.117278814315796\n",
      "Seen so far: 54208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 847: 2.6083824634552\n",
      "Seen so far: 54272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 848: 2.2988193035125732\n",
      "Seen so far: 54336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 849: 1.7539905309677124\n",
      "Seen so far: 54400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 850: 1.5760831832885742\n",
      "Seen so far: 54464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 851: 2.0190207958221436\n",
      "Seen so far: 54528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 852: 1.505147933959961\n",
      "Seen so far: 54592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 853: 1.6984994411468506\n",
      "Seen so far: 54656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 854: 1.983068585395813\n",
      "Seen so far: 54720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 855: 2.185053825378418\n",
      "Seen so far: 54784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 856: 2.1040351390838623\n",
      "Seen so far: 54848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 857: 1.9449129104614258\n",
      "Seen so far: 54912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 858: 2.239631414413452\n",
      "Seen so far: 54976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 859: 2.3776187896728516\n",
      "Seen so far: 55040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 860: 2.2789106369018555\n",
      "Seen so far: 55104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 861: 2.2561373710632324\n",
      "Seen so far: 55168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 862: 2.2515761852264404\n",
      "Seen so far: 55232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 863: 2.0909059047698975\n",
      "Seen so far: 55296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 864: 2.0608441829681396\n",
      "Seen so far: 55360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 865: 1.973442554473877\n",
      "Seen so far: 55424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 866: 1.85049569606781\n",
      "Seen so far: 55488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 867: 2.075049877166748\n",
      "Seen so far: 55552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 868: 2.0623342990875244\n",
      "Seen so far: 55616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 869: 2.237576961517334\n",
      "Seen so far: 55680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 870: 2.240936279296875\n",
      "Seen so far: 55744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 871: 2.1057825088500977\n",
      "Seen so far: 55808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 872: 2.2422423362731934\n",
      "Seen so far: 55872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 873: 2.1550004482269287\n",
      "Seen so far: 55936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 874: 2.179673671722412\n",
      "Seen so far: 56000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 875: 2.0315091609954834\n",
      "Seen so far: 56064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 876: 2.1628007888793945\n",
      "Seen so far: 56128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 877: 2.060321092605591\n",
      "Seen so far: 56192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 878: 2.2689061164855957\n",
      "Seen so far: 56256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 879: 2.107938766479492\n",
      "Seen so far: 56320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 880: 1.966232180595398\n",
      "Seen so far: 56384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 881: 2.5560860633850098\n",
      "Seen so far: 56448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 882: 2.3291449546813965\n",
      "Seen so far: 56512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 883: 1.87041437625885\n",
      "Seen so far: 56576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 884: 2.225827217102051\n",
      "Seen so far: 56640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 885: 2.1719894409179688\n",
      "Seen so far: 56704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 886: 2.20172119140625\n",
      "Seen so far: 56768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 887: 1.6305932998657227\n",
      "Seen so far: 56832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 888: 1.9479691982269287\n",
      "Seen so far: 56896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 889: 2.0539603233337402\n",
      "Seen so far: 56960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 890: 2.0278677940368652\n",
      "Seen so far: 57024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 891: 2.6419193744659424\n",
      "Seen so far: 57088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 892: 2.027942180633545\n",
      "Seen so far: 57152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 893: 1.838998556137085\n",
      "Seen so far: 57216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 894: 2.144336700439453\n",
      "Seen so far: 57280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 895: 1.915635108947754\n",
      "Seen so far: 57344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 896: 2.6295695304870605\n",
      "Seen so far: 57408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 897: 2.2634406089782715\n",
      "Seen so far: 57472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 898: 2.1877856254577637\n",
      "Seen so far: 57536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 899: 1.5018763542175293\n",
      "Seen so far: 57600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 900: 2.2836761474609375\n",
      "Seen so far: 57664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 901: 2.3254899978637695\n",
      "Seen so far: 57728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 902: 1.9025849103927612\n",
      "Seen so far: 57792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 903: 1.825011968612671\n",
      "Seen so far: 57856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 904: 2.117358922958374\n",
      "Seen so far: 57920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 905: 1.8645780086517334\n",
      "Seen so far: 57984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 906: 2.398855209350586\n",
      "Seen so far: 58048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 907: 1.9845654964447021\n",
      "Seen so far: 58112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 908: 1.7380516529083252\n",
      "Seen so far: 58176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 909: 1.824276089668274\n",
      "Seen so far: 58240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 910: 1.9754447937011719\n",
      "Seen so far: 58304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 911: 2.0327553749084473\n",
      "Seen so far: 58368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 912: 1.643882155418396\n",
      "Seen so far: 58432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 913: 1.8427562713623047\n",
      "Seen so far: 58496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 914: 1.895514965057373\n",
      "Seen so far: 58560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 915: 2.197394371032715\n",
      "Seen so far: 58624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 916: 1.9844027757644653\n",
      "Seen so far: 58688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 917: 1.862485408782959\n",
      "Seen so far: 58752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 918: 1.9558486938476562\n",
      "Seen so far: 58816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 919: 1.7314863204956055\n",
      "Seen so far: 58880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 920: 2.047672986984253\n",
      "Seen so far: 58944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 921: 1.9000334739685059\n",
      "Seen so far: 59008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 922: 2.0106136798858643\n",
      "Seen so far: 59072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 923: 1.8384108543395996\n",
      "Seen so far: 59136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 924: 1.9157555103302002\n",
      "Seen so far: 59200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 925: 2.066897392272949\n",
      "Seen so far: 59264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 926: 2.107271671295166\n",
      "Seen so far: 59328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 927: 2.1958816051483154\n",
      "Seen so far: 59392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 928: 2.164637565612793\n",
      "Seen so far: 59456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 929: 2.0798327922821045\n",
      "Seen so far: 59520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 930: 1.8202134370803833\n",
      "Seen so far: 59584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 931: 2.257371425628662\n",
      "Seen so far: 59648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 932: 1.9003820419311523\n",
      "Seen so far: 59712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 933: 1.7156800031661987\n",
      "Seen so far: 59776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 934: 1.6979866027832031\n",
      "Seen so far: 59840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 935: 2.060452699661255\n",
      "Seen so far: 59904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 936: 1.694326400756836\n",
      "Seen so far: 59968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 937: 1.7770068645477295\n",
      "Seen so far: 60032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 938: 2.1068594455718994\n",
      "Seen so far: 60096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 939: 1.707910180091858\n",
      "Seen so far: 60160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 940: 1.8729490041732788\n",
      "Seen so far: 60224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 941: 1.6962881088256836\n",
      "Seen so far: 60288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 942: 1.974371075630188\n",
      "Seen so far: 60352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 943: 1.8300251960754395\n",
      "Seen so far: 60416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 944: 2.017463207244873\n",
      "Seen so far: 60480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 945: 1.9922311305999756\n",
      "Seen so far: 60544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 946: 2.092613935470581\n",
      "Seen so far: 60608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 947: 2.343355417251587\n",
      "Seen so far: 60672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 948: 1.7630738019943237\n",
      "Seen so far: 60736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 949: 2.0064568519592285\n",
      "Seen so far: 60800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 950: 2.2297611236572266\n",
      "Seen so far: 60864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 951: 1.8794913291931152\n",
      "Seen so far: 60928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 952: 2.0656003952026367\n",
      "Seen so far: 60992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 953: 2.3980698585510254\n",
      "Seen so far: 61056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 954: 1.8974339962005615\n",
      "Seen so far: 61120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 955: 1.8766911029815674\n",
      "Seen so far: 61184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 956: 2.140714645385742\n",
      "Seen so far: 61248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 957: 1.8057172298431396\n",
      "Seen so far: 61312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 958: 2.0963735580444336\n",
      "Seen so far: 61376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 959: 1.9423140287399292\n",
      "Seen so far: 61440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 960: 2.033051013946533\n",
      "Seen so far: 61504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 961: 2.0053441524505615\n",
      "Seen so far: 61568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 962: 1.8801119327545166\n",
      "Seen so far: 61632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 963: 1.8254499435424805\n",
      "Seen so far: 61696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 964: 1.8056435585021973\n",
      "Seen so far: 61760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 965: 2.0720787048339844\n",
      "Seen so far: 61824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 966: 1.657012701034546\n",
      "Seen so far: 61888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 967: 1.672540545463562\n",
      "Seen so far: 61952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 968: 1.7874770164489746\n",
      "Seen so far: 62016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 969: 1.9497771263122559\n",
      "Seen so far: 62080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 970: 1.9285184144973755\n",
      "Seen so far: 62144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 971: 1.868725299835205\n",
      "Seen so far: 62208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 972: 1.8882319927215576\n",
      "Seen so far: 62272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 973: 1.878174901008606\n",
      "Seen so far: 62336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 974: 1.6437668800354004\n",
      "Seen so far: 62400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 975: 2.0096077919006348\n",
      "Seen so far: 62464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 976: 1.9257503747940063\n",
      "Seen so far: 62528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 977: 1.8462481498718262\n",
      "Seen so far: 62592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 978: 1.5635682344436646\n",
      "Seen so far: 62656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 979: 1.8169149160385132\n",
      "Seen so far: 62720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 980: 2.115403652191162\n",
      "Seen so far: 62784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 981: 1.7944865226745605\n",
      "Seen so far: 62848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 982: 1.6767200231552124\n",
      "Seen so far: 62912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 983: 1.710606336593628\n",
      "Seen so far: 62976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 984: 1.7462363243103027\n",
      "Seen so far: 63040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 985: 1.8378493785858154\n",
      "Seen so far: 63104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 986: 1.888354778289795\n",
      "Seen so far: 63168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 987: 2.1082568168640137\n",
      "Seen so far: 63232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 988: 1.8409137725830078\n",
      "Seen so far: 63296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 989: 1.8124003410339355\n",
      "Seen so far: 63360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 990: 1.7421135902404785\n",
      "Seen so far: 63424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 991: 1.9941173791885376\n",
      "Seen so far: 63488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 992: 1.7229292392730713\n",
      "Seen so far: 63552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 993: 1.8623511791229248\n",
      "Seen so far: 63616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 994: 1.8218061923980713\n",
      "Seen so far: 63680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 995: 1.693141222000122\n",
      "Seen so far: 63744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 996: 2.1736021041870117\n",
      "Seen so far: 63808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 997: 1.7076847553253174\n",
      "Seen so far: 63872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 998: 1.7634406089782715\n",
      "Seen so far: 63936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 999: 2.1009163856506348\n",
      "Seen so far: 64000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1000: 1.6797879934310913\n",
      "Seen so far: 64064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1001: 1.5331486463546753\n",
      "Seen so far: 64128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1002: 1.7673993110656738\n",
      "Seen so far: 64192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1003: 2.0069053173065186\n",
      "Seen so far: 64256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1004: 2.031399726867676\n",
      "Seen so far: 64320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1005: 1.7545604705810547\n",
      "Seen so far: 64384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1006: 2.3383727073669434\n",
      "Seen so far: 64448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1007: 1.8928852081298828\n",
      "Seen so far: 64512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1008: 1.8136482238769531\n",
      "Seen so far: 64576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1009: 1.5950229167938232\n",
      "Seen so far: 64640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1010: 1.2443116903305054\n",
      "Seen so far: 64704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1011: 1.3954834938049316\n",
      "Seen so far: 64768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1012: 2.0378623008728027\n",
      "Seen so far: 64832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1013: 1.8503952026367188\n",
      "Seen so far: 64896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1014: 1.9905366897583008\n",
      "Seen so far: 64960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1015: 1.5932526588439941\n",
      "Seen so far: 65024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1016: 1.7528505325317383\n",
      "Seen so far: 65088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1017: 1.9402762651443481\n",
      "Seen so far: 65152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1018: 1.6989414691925049\n",
      "Seen so far: 65216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1019: 2.0162744522094727\n",
      "Seen so far: 65280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1020: 1.6310887336730957\n",
      "Seen so far: 65344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1021: 1.8327358961105347\n",
      "Seen so far: 65408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1022: 1.8154845237731934\n",
      "Seen so far: 65472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1023: 2.5367703437805176\n",
      "Seen so far: 65536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1024: 1.546928882598877\n",
      "Seen so far: 65600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1025: 1.9857511520385742\n",
      "Seen so far: 65664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1026: 1.5868839025497437\n",
      "Seen so far: 65728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1027: 1.869140863418579\n",
      "Seen so far: 65792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1028: 1.5131279230117798\n",
      "Seen so far: 65856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1029: 2.0265209674835205\n",
      "Seen so far: 65920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1030: 2.0939955711364746\n",
      "Seen so far: 65984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1031: 2.0305042266845703\n",
      "Seen so far: 66048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1032: 1.7668735980987549\n",
      "Seen so far: 66112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1033: 1.945427417755127\n",
      "Seen so far: 66176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1034: 2.102464199066162\n",
      "Seen so far: 66240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1035: 1.9126251935958862\n",
      "Seen so far: 66304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1036: 1.5007412433624268\n",
      "Seen so far: 66368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1037: 2.1214208602905273\n",
      "Seen so far: 66432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1038: 1.763420820236206\n",
      "Seen so far: 66496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1039: 1.6278399229049683\n",
      "Seen so far: 66560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1040: 1.9889953136444092\n",
      "Seen so far: 66624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1041: 1.9466968774795532\n",
      "Seen so far: 66688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1042: 1.9021236896514893\n",
      "Seen so far: 66752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1043: 1.8626599311828613\n",
      "Seen so far: 66816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1044: 1.5697884559631348\n",
      "Seen so far: 66880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1045: 1.5092189311981201\n",
      "Seen so far: 66944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1046: 1.9096695184707642\n",
      "Seen so far: 67008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1047: 1.8345917463302612\n",
      "Seen so far: 67072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1048: 1.6962759494781494\n",
      "Seen so far: 67136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1049: 1.642888069152832\n",
      "Seen so far: 67200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1050: 2.1549158096313477\n",
      "Seen so far: 67264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1051: 1.786224365234375\n",
      "Seen so far: 67328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1052: 1.5849305391311646\n",
      "Seen so far: 67392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1053: 1.7358462810516357\n",
      "Seen so far: 67456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1054: 2.0856077671051025\n",
      "Seen so far: 67520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1055: 2.1475746631622314\n",
      "Seen so far: 67584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1056: 1.7443569898605347\n",
      "Seen so far: 67648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1057: 2.135991096496582\n",
      "Seen so far: 67712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1058: 1.7502825260162354\n",
      "Seen so far: 67776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1059: 1.647961139678955\n",
      "Seen so far: 67840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1060: 1.546039342880249\n",
      "Seen so far: 67904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1061: 1.7398550510406494\n",
      "Seen so far: 67968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1062: 1.6168103218078613\n",
      "Seen so far: 68032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1063: 1.3768134117126465\n",
      "Seen so far: 68096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1064: 1.6641300916671753\n",
      "Seen so far: 68160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1065: 2.16827392578125\n",
      "Seen so far: 68224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1066: 1.8944730758666992\n",
      "Seen so far: 68288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1067: 1.7600246667861938\n",
      "Seen so far: 68352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1068: 1.901550054550171\n",
      "Seen so far: 68416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1069: 1.60756516456604\n",
      "Seen so far: 68480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1070: 1.7148516178131104\n",
      "Seen so far: 68544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1071: 1.6111302375793457\n",
      "Seen so far: 68608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1072: 2.002429962158203\n",
      "Seen so far: 68672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1073: 1.7234268188476562\n",
      "Seen so far: 68736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1074: 1.3868722915649414\n",
      "Seen so far: 68800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1075: 1.9799590110778809\n",
      "Seen so far: 68864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1076: 1.5479016304016113\n",
      "Seen so far: 68928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1077: 2.17360782623291\n",
      "Seen so far: 68992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1078: 1.801137924194336\n",
      "Seen so far: 69056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1079: 1.9668298959732056\n",
      "Seen so far: 69120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1080: 1.65816330909729\n",
      "Seen so far: 69184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1081: 2.0571305751800537\n",
      "Seen so far: 69248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1082: 2.2649927139282227\n",
      "Seen so far: 69312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1083: 2.19088077545166\n",
      "Seen so far: 69376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1084: 2.3393285274505615\n",
      "Seen so far: 69440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1085: 2.015350818634033\n",
      "Seen so far: 69504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1086: 1.9121747016906738\n",
      "Seen so far: 69568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1087: 2.090785026550293\n",
      "Seen so far: 69632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1088: 1.8218367099761963\n",
      "Seen so far: 69696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1089: 1.9119380712509155\n",
      "Seen so far: 69760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1090: 2.170212745666504\n",
      "Seen so far: 69824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1091: 2.07914662361145\n",
      "Seen so far: 69888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1092: 2.022210121154785\n",
      "Seen so far: 69952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1093: 2.2326676845550537\n",
      "Seen so far: 70016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1094: 2.3203125\n",
      "Seen so far: 70080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1095: 1.7859219312667847\n",
      "Seen so far: 70144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1096: 2.0211548805236816\n",
      "Seen so far: 70208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1097: 2.0273232460021973\n",
      "Seen so far: 70272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1098: 1.9564425945281982\n",
      "Seen so far: 70336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1099: 1.9631105661392212\n",
      "Seen so far: 70400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1100: 1.7854232788085938\n",
      "Seen so far: 70464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1101: 2.125746965408325\n",
      "Seen so far: 70528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1102: 1.7357511520385742\n",
      "Seen so far: 70592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1103: 2.098468780517578\n",
      "Seen so far: 70656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1104: 1.5406466722488403\n",
      "Seen so far: 70720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1105: 1.725618600845337\n",
      "Seen so far: 70784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1106: 1.9662976264953613\n",
      "Seen so far: 70848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1107: 1.4822590351104736\n",
      "Seen so far: 70912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1108: 1.4928054809570312\n",
      "Seen so far: 70976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1109: 1.4015116691589355\n",
      "Seen so far: 71040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1110: 1.6611621379852295\n",
      "Seen so far: 71104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1111: 2.0373709201812744\n",
      "Seen so far: 71168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1112: 2.1301493644714355\n",
      "Seen so far: 71232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1113: 2.1152706146240234\n",
      "Seen so far: 71296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1114: 1.9047234058380127\n",
      "Seen so far: 71360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1115: 2.2499783039093018\n",
      "Seen so far: 71424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1116: 1.7699525356292725\n",
      "Seen so far: 71488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1117: 1.4984016418457031\n",
      "Seen so far: 71552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1118: 1.6829736232757568\n",
      "Seen so far: 71616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1119: 1.6703197956085205\n",
      "Seen so far: 71680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1120: 1.6539613008499146\n",
      "Seen so far: 71744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1121: 1.5190237760543823\n",
      "Seen so far: 71808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1122: 1.5360627174377441\n",
      "Seen so far: 71872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1123: 2.1371800899505615\n",
      "Seen so far: 71936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1124: 1.7805895805358887\n",
      "Seen so far: 72000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1125: 1.8885512351989746\n",
      "Seen so far: 72064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1126: 1.5771315097808838\n",
      "Seen so far: 72128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1127: 2.2342889308929443\n",
      "Seen so far: 72192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1128: 2.0054996013641357\n",
      "Seen so far: 72256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1129: 1.9612798690795898\n",
      "Seen so far: 72320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1130: 1.5427402257919312\n",
      "Seen so far: 72384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1131: 1.9719252586364746\n",
      "Seen so far: 72448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1132: 1.703244686126709\n",
      "Seen so far: 72512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1133: 1.5887415409088135\n",
      "Seen so far: 72576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1134: 2.020033836364746\n",
      "Seen so far: 72640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1135: 2.0487096309661865\n",
      "Seen so far: 72704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1136: 1.8022651672363281\n",
      "Seen so far: 72768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1137: 1.6892626285552979\n",
      "Seen so far: 72832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1138: 1.9648748636245728\n",
      "Seen so far: 72896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1139: 1.680328607559204\n",
      "Seen so far: 72960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1140: 1.3350367546081543\n",
      "Seen so far: 73024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1141: 1.6298102140426636\n",
      "Seen so far: 73088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1142: 1.6032240390777588\n",
      "Seen so far: 73152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1143: 1.6622964143753052\n",
      "Seen so far: 73216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1144: 1.6366101503372192\n",
      "Seen so far: 73280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1145: 1.9560770988464355\n",
      "Seen so far: 73344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1146: 2.194807767868042\n",
      "Seen so far: 73408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1147: 2.035858154296875\n",
      "Seen so far: 73472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1148: 2.066664218902588\n",
      "Seen so far: 73536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1149: 2.002077579498291\n",
      "Seen so far: 73600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1150: 2.1380398273468018\n",
      "Seen so far: 73664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1151: 2.3390862941741943\n",
      "Seen so far: 73728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1152: 2.0405540466308594\n",
      "Seen so far: 73792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1153: 1.7329521179199219\n",
      "Seen so far: 73856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1154: 1.7320700883865356\n",
      "Seen so far: 73920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1155: 2.119788408279419\n",
      "Seen so far: 73984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1156: 2.052701950073242\n",
      "Seen so far: 74048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1157: 1.828900694847107\n",
      "Seen so far: 74112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1158: 1.46506667137146\n",
      "Seen so far: 74176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1159: 1.7759287357330322\n",
      "Seen so far: 74240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1160: 1.720395803451538\n",
      "Seen so far: 74304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1161: 1.9295930862426758\n",
      "Seen so far: 74368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1162: 1.625186562538147\n",
      "Seen so far: 74432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1163: 1.6524914503097534\n",
      "Seen so far: 74496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1164: 2.071242332458496\n",
      "Seen so far: 74560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1165: 1.8033777475357056\n",
      "Seen so far: 74624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1166: 1.6673890352249146\n",
      "Seen so far: 74688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1167: 1.8519567251205444\n",
      "Seen so far: 74752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1168: 1.5525155067443848\n",
      "Seen so far: 74816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1169: 1.9929347038269043\n",
      "Seen so far: 74880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1170: 1.719192624092102\n",
      "Seen so far: 74944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1171: 1.9347106218338013\n",
      "Seen so far: 75008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1172: 2.1048548221588135\n",
      "Seen so far: 75072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1173: 1.8343303203582764\n",
      "Seen so far: 75136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1174: 1.7392876148223877\n",
      "Seen so far: 75200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1175: 2.013651132583618\n",
      "Seen so far: 75264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1176: 1.9213547706604004\n",
      "Seen so far: 75328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1177: 1.8331429958343506\n",
      "Seen so far: 75392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1178: 2.2082157135009766\n",
      "Seen so far: 75456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1179: 1.4645981788635254\n",
      "Seen so far: 75520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1180: 1.7399226427078247\n",
      "Seen so far: 75584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1181: 1.6991286277770996\n",
      "Seen so far: 75648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1182: 1.8852936029434204\n",
      "Seen so far: 75712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1183: 2.1604831218719482\n",
      "Seen so far: 75776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1184: 1.7674109935760498\n",
      "Seen so far: 75840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1185: 1.9399683475494385\n",
      "Seen so far: 75904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1186: 1.792163610458374\n",
      "Seen so far: 75968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1187: 1.7889901399612427\n",
      "Seen so far: 76032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1188: 2.0289111137390137\n",
      "Seen so far: 76096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1189: 1.6184303760528564\n",
      "Seen so far: 76160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1190: 1.4783780574798584\n",
      "Seen so far: 76224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1191: 1.5113604068756104\n",
      "Seen so far: 76288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1192: 1.9216097593307495\n",
      "Seen so far: 76352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1193: 1.4534313678741455\n",
      "Seen so far: 76416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1194: 2.058527946472168\n",
      "Seen so far: 76480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1195: 1.5657938718795776\n",
      "Seen so far: 76544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1196: 1.5331518650054932\n",
      "Seen so far: 76608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1197: 1.8551808595657349\n",
      "Seen so far: 76672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1198: 2.133517265319824\n",
      "Seen so far: 76736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1199: 1.8087553977966309\n",
      "Seen so far: 76800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1200: 1.9417455196380615\n",
      "Seen so far: 76864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1201: 1.831656575202942\n",
      "Seen so far: 76928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1202: 1.662079095840454\n",
      "Seen so far: 76992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1203: 1.7683185338974\n",
      "Seen so far: 77056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1204: 2.27712345123291\n",
      "Seen so far: 77120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1205: 1.5108203887939453\n",
      "Seen so far: 77184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1206: 1.8662467002868652\n",
      "Seen so far: 77248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1207: 1.902508020401001\n",
      "Seen so far: 77312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1208: 1.8846174478530884\n",
      "Seen so far: 77376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1209: 1.7502915859222412\n",
      "Seen so far: 77440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1210: 1.8982659578323364\n",
      "Seen so far: 77504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1211: 1.6980814933776855\n",
      "Seen so far: 77568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1212: 1.404340386390686\n",
      "Seen so far: 77632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1213: 1.7437677383422852\n",
      "Seen so far: 77696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1214: 2.011430025100708\n",
      "Seen so far: 77760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1215: 1.5667150020599365\n",
      "Seen so far: 77824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1216: 1.728341817855835\n",
      "Seen so far: 77888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1217: 1.7988438606262207\n",
      "Seen so far: 77952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1218: 1.653833270072937\n",
      "Seen so far: 78016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1219: 1.8517258167266846\n",
      "Seen so far: 78080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1220: 2.171895980834961\n",
      "Seen so far: 78144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1221: 1.9228219985961914\n",
      "Seen so far: 78208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1222: 1.6654181480407715\n",
      "Seen so far: 78272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1223: 1.4855064153671265\n",
      "Seen so far: 78336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1224: 1.8352593183517456\n",
      "Seen so far: 78400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1225: 1.820844054222107\n",
      "Seen so far: 78464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1226: 1.9711863994598389\n",
      "Seen so far: 78528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1227: 1.744452953338623\n",
      "Seen so far: 78592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1228: 1.5691108703613281\n",
      "Seen so far: 78656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1229: 1.6429747343063354\n",
      "Seen so far: 78720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1230: 1.7790381908416748\n",
      "Seen so far: 78784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1231: 1.580946445465088\n",
      "Seen so far: 78848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1232: 1.9868218898773193\n",
      "Seen so far: 78912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1233: 1.8984898328781128\n",
      "Seen so far: 78976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1234: 2.017286777496338\n",
      "Seen so far: 79040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1235: 1.974737286567688\n",
      "Seen so far: 79104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1236: 1.9857304096221924\n",
      "Seen so far: 79168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1237: 2.058609962463379\n",
      "Seen so far: 79232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1238: 2.346104621887207\n",
      "Seen so far: 79296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1239: 1.597242832183838\n",
      "Seen so far: 79360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1240: 1.5942498445510864\n",
      "Seen so far: 79424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1241: 1.9740928411483765\n",
      "Seen so far: 79488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1242: 1.844761610031128\n",
      "Seen so far: 79552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1243: 1.9697997570037842\n",
      "Seen so far: 79616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1244: 1.802121877670288\n",
      "Seen so far: 79680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1245: 1.7243573665618896\n",
      "Seen so far: 79744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1246: 1.419847011566162\n",
      "Seen so far: 79808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1247: 1.3466600179672241\n",
      "Seen so far: 79872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1248: 1.490433931350708\n",
      "Seen so far: 79936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1249: 1.7954318523406982\n",
      "Seen so far: 80000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1250: 1.544524908065796\n",
      "Seen so far: 80064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1251: 1.5661201477050781\n",
      "Seen so far: 80128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1252: 1.9598861932754517\n",
      "Seen so far: 80192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1253: 1.5538508892059326\n",
      "Seen so far: 80256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1254: 1.640854835510254\n",
      "Seen so far: 80320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1255: 1.511889100074768\n",
      "Seen so far: 80384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1256: 2.0699002742767334\n",
      "Seen so far: 80448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1257: 1.9166306257247925\n",
      "Seen so far: 80512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1258: 1.5068345069885254\n",
      "Seen so far: 80576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1259: 1.7916784286499023\n",
      "Seen so far: 80640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1260: 1.6817278861999512\n",
      "Seen so far: 80704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1261: 1.4683326482772827\n",
      "Seen so far: 80768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1262: 1.4383718967437744\n",
      "Seen so far: 80832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1263: 1.3916807174682617\n",
      "Seen so far: 80896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1264: 1.4913506507873535\n",
      "Seen so far: 80960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1265: 1.5415921211242676\n",
      "Seen so far: 81024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1266: 1.915690541267395\n",
      "Seen so far: 81088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1267: 2.181781768798828\n",
      "Seen so far: 81152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1268: 1.7184151411056519\n",
      "Seen so far: 81216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1269: 1.988997220993042\n",
      "Seen so far: 81280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1270: 1.6357671022415161\n",
      "Seen so far: 81344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1271: 1.5591015815734863\n",
      "Seen so far: 81408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1272: 1.9762651920318604\n",
      "Seen so far: 81472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1273: 1.533847451210022\n",
      "Seen so far: 81536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1274: 1.6002349853515625\n",
      "Seen so far: 81600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1275: 1.4628764390945435\n",
      "Seen so far: 81664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1276: 1.5175524950027466\n",
      "Seen so far: 81728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1277: 1.4520670175552368\n",
      "Seen so far: 81792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1278: 1.7657325267791748\n",
      "Seen so far: 81856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1279: 2.07598876953125\n",
      "Seen so far: 81920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1280: 1.5961031913757324\n",
      "Seen so far: 81984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1281: 1.2157680988311768\n",
      "Seen so far: 82048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1282: 1.6914165019989014\n",
      "Seen so far: 82112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1283: 1.8546966314315796\n",
      "Seen so far: 82176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1284: 1.8950530290603638\n",
      "Seen so far: 82240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1285: 1.6819323301315308\n",
      "Seen so far: 82304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1286: 1.6402181386947632\n",
      "Seen so far: 82368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1287: 1.7687917947769165\n",
      "Seen so far: 82432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1288: 1.5434656143188477\n",
      "Seen so far: 82496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1289: 1.7758543491363525\n",
      "Seen so far: 82560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1290: 1.6779835224151611\n",
      "Seen so far: 82624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1291: 1.5196926593780518\n",
      "Seen so far: 82688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1292: 1.3367996215820312\n",
      "Seen so far: 82752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1293: 1.9052945375442505\n",
      "Seen so far: 82816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1294: 1.7944425344467163\n",
      "Seen so far: 82880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1295: 1.5719187259674072\n",
      "Seen so far: 82944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1296: 1.3680016994476318\n",
      "Seen so far: 83008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1297: 1.8522765636444092\n",
      "Seen so far: 83072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1298: 1.5828216075897217\n",
      "Seen so far: 83136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1299: 1.7676188945770264\n",
      "Seen so far: 83200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1300: 1.7514848709106445\n",
      "Seen so far: 83264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1301: 1.6055874824523926\n",
      "Seen so far: 83328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1302: 2.0317585468292236\n",
      "Seen so far: 83392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1303: 1.8168960809707642\n",
      "Seen so far: 83456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1304: 1.356806755065918\n",
      "Seen so far: 83520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1305: 1.568637490272522\n",
      "Seen so far: 83584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1306: 1.8347225189208984\n",
      "Seen so far: 83648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1307: 1.6050488948822021\n",
      "Seen so far: 83712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1308: 1.872745394706726\n",
      "Seen so far: 83776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1309: 1.6592841148376465\n",
      "Seen so far: 83840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1310: 1.7286016941070557\n",
      "Seen so far: 83904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1311: 1.9046598672866821\n",
      "Seen so far: 83968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1312: 1.9026739597320557\n",
      "Seen so far: 84032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1313: 1.7877012491226196\n",
      "Seen so far: 84096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1314: 1.7539230585098267\n",
      "Seen so far: 84160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1315: 2.0938897132873535\n",
      "Seen so far: 84224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1316: 2.4227426052093506\n",
      "Seen so far: 84288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1317: 1.953084945678711\n",
      "Seen so far: 84352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1318: 1.7774577140808105\n",
      "Seen so far: 84416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1319: 1.7329583168029785\n",
      "Seen so far: 84480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1320: 1.7399046421051025\n",
      "Seen so far: 84544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1321: 1.951230525970459\n",
      "Seen so far: 84608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1322: 1.698035717010498\n",
      "Seen so far: 84672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1323: 2.000919818878174\n",
      "Seen so far: 84736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1324: 1.8122031688690186\n",
      "Seen so far: 84800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1325: 2.1913061141967773\n",
      "Seen so far: 84864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1326: 1.8398892879486084\n",
      "Seen so far: 84928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1327: 1.7715901136398315\n",
      "Seen so far: 84992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1328: 1.7582253217697144\n",
      "Seen so far: 85056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1329: 1.864585518836975\n",
      "Seen so far: 85120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1330: 1.6504731178283691\n",
      "Seen so far: 85184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1331: 2.2324295043945312\n",
      "Seen so far: 85248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1332: 1.9773460626602173\n",
      "Seen so far: 85312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1333: 1.8950004577636719\n",
      "Seen so far: 85376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1334: 1.976209282875061\n",
      "Seen so far: 85440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1335: 1.6204365491867065\n",
      "Seen so far: 85504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1336: 1.6304107904434204\n",
      "Seen so far: 85568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1337: 2.1584970951080322\n",
      "Seen so far: 85632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1338: 2.0421009063720703\n",
      "Seen so far: 85696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1339: 1.7126741409301758\n",
      "Seen so far: 85760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1340: 1.762770414352417\n",
      "Seen so far: 85824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1341: 1.623854398727417\n",
      "Seen so far: 85888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1342: 1.7486904859542847\n",
      "Seen so far: 85952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1343: 2.022500991821289\n",
      "Seen so far: 86016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1344: 2.055492877960205\n",
      "Seen so far: 86080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1345: 1.8576180934906006\n",
      "Seen so far: 86144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1346: 1.8060225248336792\n",
      "Seen so far: 86208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1347: 1.5507471561431885\n",
      "Seen so far: 86272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1348: 1.836483359336853\n",
      "Seen so far: 86336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1349: 1.9251880645751953\n",
      "Seen so far: 86400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1350: 2.384913444519043\n",
      "Seen so far: 86464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1351: 1.6947537660598755\n",
      "Seen so far: 86528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1352: 1.7187668085098267\n",
      "Seen so far: 86592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1353: 1.856966257095337\n",
      "Seen so far: 86656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1354: 2.309311866760254\n",
      "Seen so far: 86720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1355: 1.7537513971328735\n",
      "Seen so far: 86784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1356: 1.8757319450378418\n",
      "Seen so far: 86848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1357: 1.5195218324661255\n",
      "Seen so far: 86912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1358: 1.5787544250488281\n",
      "Seen so far: 86976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1359: 1.9767565727233887\n",
      "Seen so far: 87040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1360: 1.8998881578445435\n",
      "Seen so far: 87104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1361: 2.025026321411133\n",
      "Seen so far: 87168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1362: 1.7483735084533691\n",
      "Seen so far: 87232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1363: 1.7059919834136963\n",
      "Seen so far: 87296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1364: 1.9237687587738037\n",
      "Seen so far: 87360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1365: 1.924511432647705\n",
      "Seen so far: 87424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1366: 1.5041395425796509\n",
      "Seen so far: 87488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1367: 1.855139970779419\n",
      "Seen so far: 87552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1368: 1.8381255865097046\n",
      "Seen so far: 87616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1369: 1.6429615020751953\n",
      "Seen so far: 87680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1370: 1.5968823432922363\n",
      "Seen so far: 87744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1371: 1.4317816495895386\n",
      "Seen so far: 87808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1372: 2.246753215789795\n",
      "Seen so far: 87872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1373: 1.546392798423767\n",
      "Seen so far: 87936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1374: 1.7036020755767822\n",
      "Seen so far: 88000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1375: 1.5467352867126465\n",
      "Seen so far: 88064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1376: 1.9949214458465576\n",
      "Seen so far: 88128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1377: 1.913543701171875\n",
      "Seen so far: 88192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1378: 1.5643963813781738\n",
      "Seen so far: 88256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1379: 1.804842233657837\n",
      "Seen so far: 88320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1380: 1.629990816116333\n",
      "Seen so far: 88384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1381: 1.9895811080932617\n",
      "Seen so far: 88448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1382: 1.6753103733062744\n",
      "Seen so far: 88512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1383: 2.1609883308410645\n",
      "Seen so far: 88576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1384: 1.5606440305709839\n",
      "Seen so far: 88640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1385: 1.290282130241394\n",
      "Seen so far: 88704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1386: 1.6450741291046143\n",
      "Seen so far: 88768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1387: 1.6629433631896973\n",
      "Seen so far: 88832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1388: 1.6578738689422607\n",
      "Seen so far: 88896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1389: 1.4696171283721924\n",
      "Seen so far: 88960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1390: 1.6614878177642822\n",
      "Seen so far: 89024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1391: 1.9194411039352417\n",
      "Seen so far: 89088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1392: 1.7872073650360107\n",
      "Seen so far: 89152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1393: 1.5229822397232056\n",
      "Seen so far: 89216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1394: 1.6183381080627441\n",
      "Seen so far: 89280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1395: 1.946703553199768\n",
      "Seen so far: 89344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1396: 1.4617384672164917\n",
      "Seen so far: 89408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1397: 1.6621387004852295\n",
      "Seen so far: 89472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1398: 1.6648578643798828\n",
      "Seen so far: 89536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1399: 1.6910185813903809\n",
      "Seen so far: 89600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1400: 1.965867042541504\n",
      "Seen so far: 89664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1401: 1.8317539691925049\n",
      "Seen so far: 89728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1402: 1.9082599878311157\n",
      "Seen so far: 89792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1403: 1.9634284973144531\n",
      "Seen so far: 89856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1404: 1.4919145107269287\n",
      "Seen so far: 89920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1405: 1.655339241027832\n",
      "Seen so far: 89984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1406: 1.822506308555603\n",
      "Seen so far: 90048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1407: 1.5461252927780151\n",
      "Seen so far: 90112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1408: 1.7144287824630737\n",
      "Seen so far: 90176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1409: 1.7594914436340332\n",
      "Seen so far: 90240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1410: 1.4532297849655151\n",
      "Seen so far: 90304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1411: 1.2748457193374634\n",
      "Seen so far: 90368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1412: 1.547348141670227\n",
      "Seen so far: 90432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1413: 1.692752480506897\n",
      "Seen so far: 90496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1414: 1.6123566627502441\n",
      "Seen so far: 90560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1415: 1.6797605752944946\n",
      "Seen so far: 90624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1416: 1.8415923118591309\n",
      "Seen so far: 90688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1417: 1.7507779598236084\n",
      "Seen so far: 90752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1418: 1.7233117818832397\n",
      "Seen so far: 90816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1419: 1.9651148319244385\n",
      "Seen so far: 90880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1420: 1.5092058181762695\n",
      "Seen so far: 90944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1421: 1.6857812404632568\n",
      "Seen so far: 91008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1422: 1.389559268951416\n",
      "Seen so far: 91072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1423: 1.4632055759429932\n",
      "Seen so far: 91136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1424: 1.7616603374481201\n",
      "Seen so far: 91200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1425: 1.4583635330200195\n",
      "Seen so far: 91264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1426: 1.6630325317382812\n",
      "Seen so far: 91328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1427: 1.5218762159347534\n",
      "Seen so far: 91392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1428: 1.8179324865341187\n",
      "Seen so far: 91456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1429: 1.5950878858566284\n",
      "Seen so far: 91520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1430: 1.9841290712356567\n",
      "Seen so far: 91584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1431: 1.5727729797363281\n",
      "Seen so far: 91648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1432: 1.4934430122375488\n",
      "Seen so far: 91712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1433: 1.8126897811889648\n",
      "Seen so far: 91776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1434: 1.6449356079101562\n",
      "Seen so far: 91840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1435: 1.8078796863555908\n",
      "Seen so far: 91904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1436: 1.5595602989196777\n",
      "Seen so far: 91968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1437: 1.722020149230957\n",
      "Seen so far: 92032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1438: 1.9653977155685425\n",
      "Seen so far: 92096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1439: 1.5135074853897095\n",
      "Seen so far: 92160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1440: 1.5198957920074463\n",
      "Seen so far: 92224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1441: 1.74784517288208\n",
      "Seen so far: 92288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1442: 1.6613664627075195\n",
      "Seen so far: 92352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1443: 1.588883399963379\n",
      "Seen so far: 92416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1444: 1.8560014963150024\n",
      "Seen so far: 92480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1445: 1.9775359630584717\n",
      "Seen so far: 92544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1446: 1.8639127016067505\n",
      "Seen so far: 92608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1447: 1.617867350578308\n",
      "Seen so far: 92672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1448: 1.3828186988830566\n",
      "Seen so far: 92736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1449: 1.7885942459106445\n",
      "Seen so far: 92800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1450: 1.45489501953125\n",
      "Seen so far: 92864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1451: 1.864640712738037\n",
      "Seen so far: 92928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1452: 1.2534130811691284\n",
      "Seen so far: 92992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1453: 1.801979899406433\n",
      "Seen so far: 93056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1454: 1.6131373643875122\n",
      "Seen so far: 93120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1455: 1.9012870788574219\n",
      "Seen so far: 93184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1456: 1.5258898735046387\n",
      "Seen so far: 93248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1457: 1.977785348892212\n",
      "Seen so far: 93312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1458: 1.9321752786636353\n",
      "Seen so far: 93376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1459: 1.8525855541229248\n",
      "Seen so far: 93440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1460: 1.6254100799560547\n",
      "Seen so far: 93504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1461: 1.8438167572021484\n",
      "Seen so far: 93568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1462: 1.6881561279296875\n",
      "Seen so far: 93632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1463: 1.8618342876434326\n",
      "Seen so far: 93696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1464: 1.4778106212615967\n",
      "Seen so far: 93760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1465: 1.6605687141418457\n",
      "Seen so far: 93824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1466: 1.6762497425079346\n",
      "Seen so far: 93888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1467: 1.5152151584625244\n",
      "Seen so far: 93952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1468: 1.6654562950134277\n",
      "Seen so far: 94016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1469: 1.3876872062683105\n",
      "Seen so far: 94080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1470: 1.6739039421081543\n",
      "Seen so far: 94144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1471: 1.4088594913482666\n",
      "Seen so far: 94208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1472: 1.9393547773361206\n",
      "Seen so far: 94272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1473: 1.9626437425613403\n",
      "Seen so far: 94336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1474: 1.5969699621200562\n",
      "Seen so far: 94400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1475: 1.7944031953811646\n",
      "Seen so far: 94464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1476: 1.480035424232483\n",
      "Seen so far: 94528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1477: 1.804886817932129\n",
      "Seen so far: 94592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1478: 1.8391937017440796\n",
      "Seen so far: 94656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1479: 1.7558337450027466\n",
      "Seen so far: 94720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1480: 1.705116629600525\n",
      "Seen so far: 94784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1481: 1.5741243362426758\n",
      "Seen so far: 94848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1482: 1.6230769157409668\n",
      "Seen so far: 94912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1483: 1.5809440612792969\n",
      "Seen so far: 94976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1484: 1.5255125761032104\n",
      "Seen so far: 95040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1485: 1.566495656967163\n",
      "Seen so far: 95104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1486: 1.5577073097229004\n",
      "Seen so far: 95168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1487: 1.5276343822479248\n",
      "Seen so far: 95232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1488: 1.9472846984863281\n",
      "Seen so far: 95296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1489: 1.4757171869277954\n",
      "Seen so far: 95360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1490: 1.7965830564498901\n",
      "Seen so far: 95424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1491: 1.6032191514968872\n",
      "Seen so far: 95488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1492: 1.591186285018921\n",
      "Seen so far: 95552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1493: 1.2531934976577759\n",
      "Seen so far: 95616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1494: 1.5717977285385132\n",
      "Seen so far: 95680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1495: 2.1225507259368896\n",
      "Seen so far: 95744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1496: 1.3733679056167603\n",
      "Seen so far: 95808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1497: 1.8495261669158936\n",
      "Seen so far: 95872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1498: 1.4310517311096191\n",
      "Seen so far: 95936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1499: 1.7651785612106323\n",
      "Seen so far: 96000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1500: 1.3348578214645386\n",
      "Seen so far: 96064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1501: 1.9034181833267212\n",
      "Seen so far: 96128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1502: 1.4735826253890991\n",
      "Seen so far: 96192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1503: 1.1187036037445068\n",
      "Seen so far: 96256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1504: 1.696077823638916\n",
      "Seen so far: 96320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1505: 2.119128465652466\n",
      "Seen so far: 96384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1506: 1.4934718608856201\n",
      "Seen so far: 96448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1507: 1.8747775554656982\n",
      "Seen so far: 96512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1508: 1.1763147115707397\n",
      "Seen so far: 96576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1509: 1.6903270483016968\n",
      "Seen so far: 96640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1510: 2.402602434158325\n",
      "Seen so far: 96704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1511: 1.6876211166381836\n",
      "Seen so far: 96768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1512: 1.7053711414337158\n",
      "Seen so far: 96832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1513: 1.5588393211364746\n",
      "Seen so far: 96896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1514: 1.5945730209350586\n",
      "Seen so far: 96960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1515: 1.9204797744750977\n",
      "Seen so far: 97024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1516: 2.06868314743042\n",
      "Seen so far: 97088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1517: 2.0628013610839844\n",
      "Seen so far: 97152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1518: 1.9138615131378174\n",
      "Seen so far: 97216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1519: 1.9404070377349854\n",
      "Seen so far: 97280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1520: 1.7557917833328247\n",
      "Seen so far: 97344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1521: 1.5641616582870483\n",
      "Seen so far: 97408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1522: 1.7945696115493774\n",
      "Seen so far: 97472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1523: 1.9378000497817993\n",
      "Seen so far: 97536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1524: 1.6828221082687378\n",
      "Seen so far: 97600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1525: 1.9009207487106323\n",
      "Seen so far: 97664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1526: 1.70859956741333\n",
      "Seen so far: 97728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1527: 1.4393752813339233\n",
      "Seen so far: 97792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1528: 1.538102626800537\n",
      "Seen so far: 97856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1529: 1.9292739629745483\n",
      "Seen so far: 97920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1530: 1.835829257965088\n",
      "Seen so far: 97984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1531: 1.2290477752685547\n",
      "Seen so far: 98048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1532: 1.6960879564285278\n",
      "Seen so far: 98112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1533: 1.7920033931732178\n",
      "Seen so far: 98176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1534: 1.8720519542694092\n",
      "Seen so far: 98240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1535: 1.5088844299316406\n",
      "Seen so far: 98304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1536: 1.7131240367889404\n",
      "Seen so far: 98368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1537: 1.730033278465271\n",
      "Seen so far: 98432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1538: 1.662660837173462\n",
      "Seen so far: 98496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1539: 1.5268352031707764\n",
      "Seen so far: 98560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1540: 1.5744578838348389\n",
      "Seen so far: 98624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1541: 1.5045832395553589\n",
      "Seen so far: 98688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1542: 1.6223703622817993\n",
      "Seen so far: 98752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1543: 1.8566954135894775\n",
      "Seen so far: 98816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1544: 1.4960250854492188\n",
      "Seen so far: 98880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1545: 1.3764046430587769\n",
      "Seen so far: 98944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1546: 1.329400897026062\n",
      "Seen so far: 99008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1547: 1.6016972064971924\n",
      "Seen so far: 99072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1548: 1.383984923362732\n",
      "Seen so far: 99136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1549: 1.5201892852783203\n",
      "Seen so far: 99200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1550: 1.8576209545135498\n",
      "Seen so far: 99264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1551: 1.573939561843872\n",
      "Seen so far: 99328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1552: 1.2570714950561523\n",
      "Seen so far: 99392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1553: 1.5490951538085938\n",
      "Seen so far: 99456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1554: 1.6415839195251465\n",
      "Seen so far: 99520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1555: 1.4839448928833008\n",
      "Seen so far: 99584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1556: 1.6410603523254395\n",
      "Seen so far: 99648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1557: 1.7582132816314697\n",
      "Seen so far: 99712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1558: 1.5335462093353271\n",
      "Seen so far: 99776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1559: 1.3786741495132446\n",
      "Seen so far: 99840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1560: 1.9403926134109497\n",
      "Seen so far: 99904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1561: 1.6715724468231201\n",
      "Seen so far: 99968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1562: 2.039421319961548\n",
      "Seen so far: 100032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1563: 1.5683443546295166\n",
      "Seen so far: 100096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1564: 1.9232878684997559\n",
      "Seen so far: 100160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1565: 1.7654328346252441\n",
      "Seen so far: 100224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1566: 1.6214168071746826\n",
      "Seen so far: 100288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1567: 1.2745611667633057\n",
      "Seen so far: 100352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1568: 1.4333069324493408\n",
      "Seen so far: 100416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1569: 1.7953770160675049\n",
      "Seen so far: 100480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1570: 2.040952205657959\n",
      "Seen so far: 100544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1571: 1.92594575881958\n",
      "Seen so far: 100608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1572: 1.5861587524414062\n",
      "Seen so far: 100672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1573: 1.632308006286621\n",
      "Seen so far: 100736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1574: 1.7269296646118164\n",
      "Seen so far: 100800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1575: 1.9095256328582764\n",
      "Seen so far: 100864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1576: 1.483117699623108\n",
      "Seen so far: 100928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1577: 2.0501458644866943\n",
      "Seen so far: 100992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1578: 1.610406517982483\n",
      "Seen so far: 101056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1579: 1.3312695026397705\n",
      "Seen so far: 101120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1580: 1.5561470985412598\n",
      "Seen so far: 101184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1581: 1.2379298210144043\n",
      "Seen so far: 101248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1582: 1.7844654321670532\n",
      "Seen so far: 101312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1583: 1.6209204196929932\n",
      "Seen so far: 101376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1584: 1.5692133903503418\n",
      "Seen so far: 101440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1585: 1.9614639282226562\n",
      "Seen so far: 101504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1586: 1.776902198791504\n",
      "Seen so far: 101568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1587: 1.1475815773010254\n",
      "Seen so far: 101632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1588: 1.6107105016708374\n",
      "Seen so far: 101696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1589: 1.4223803281784058\n",
      "Seen so far: 101760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1590: 1.7258646488189697\n",
      "Seen so far: 101824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1591: 1.5247422456741333\n",
      "Seen so far: 101888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1592: 1.5192723274230957\n",
      "Seen so far: 101952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1593: 1.6137988567352295\n",
      "Seen so far: 102016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1594: 1.3757269382476807\n",
      "Seen so far: 102080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1595: 1.6883665323257446\n",
      "Seen so far: 102144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1596: 1.6250081062316895\n",
      "Seen so far: 102208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1597: 1.640604019165039\n",
      "Seen so far: 102272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1598: 1.459018349647522\n",
      "Seen so far: 102336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1599: 1.3879716396331787\n",
      "Seen so far: 102400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1600: 1.7849018573760986\n",
      "Seen so far: 102464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1601: 1.8737783432006836\n",
      "Seen so far: 102528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1602: 1.3789976835250854\n",
      "Seen so far: 102592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1603: 1.973465919494629\n",
      "Seen so far: 102656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1604: 1.54313063621521\n",
      "Seen so far: 102720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1605: 1.7190687656402588\n",
      "Seen so far: 102784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1606: 1.6332815885543823\n",
      "Seen so far: 102848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1607: 1.6980462074279785\n",
      "Seen so far: 102912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1608: 1.3410634994506836\n",
      "Seen so far: 102976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1609: 1.7058250904083252\n",
      "Seen so far: 103040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1610: 1.7342841625213623\n",
      "Seen so far: 103104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1611: 1.622617483139038\n",
      "Seen so far: 103168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1612: 1.573835849761963\n",
      "Seen so far: 103232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1613: 1.9096574783325195\n",
      "Seen so far: 103296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1614: 1.2510786056518555\n",
      "Seen so far: 103360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1615: 1.5089938640594482\n",
      "Seen so far: 103424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1616: 1.449538230895996\n",
      "Seen so far: 103488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1617: 1.8606433868408203\n",
      "Seen so far: 103552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1618: 1.4050713777542114\n",
      "Seen so far: 103616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1619: 1.70162034034729\n",
      "Seen so far: 103680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1620: 1.4378583431243896\n",
      "Seen so far: 103744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1621: 1.4001739025115967\n",
      "Seen so far: 103808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1622: 1.5823088884353638\n",
      "Seen so far: 103872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1623: 1.3135254383087158\n",
      "Seen so far: 103936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1624: 1.8008501529693604\n",
      "Seen so far: 104000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1625: 1.8234186172485352\n",
      "Seen so far: 104064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1626: 2.0074055194854736\n",
      "Seen so far: 104128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1627: 1.666121006011963\n",
      "Seen so far: 104192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1628: 1.3707396984100342\n",
      "Seen so far: 104256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1629: 1.6490521430969238\n",
      "Seen so far: 104320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1630: 1.6422275304794312\n",
      "Seen so far: 104384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1631: 1.454628586769104\n",
      "Seen so far: 104448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1632: 1.755079746246338\n",
      "Seen so far: 104512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1633: 1.8937060832977295\n",
      "Seen so far: 104576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1634: 1.5937986373901367\n",
      "Seen so far: 104640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1635: 1.3588443994522095\n",
      "Seen so far: 104704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1636: 1.7431831359863281\n",
      "Seen so far: 104768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1637: 1.072275996208191\n",
      "Seen so far: 104832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1638: 1.5033299922943115\n",
      "Seen so far: 104896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1639: 1.453011393547058\n",
      "Seen so far: 104960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1640: 1.5958306789398193\n",
      "Seen so far: 105024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1641: 1.2395639419555664\n",
      "Seen so far: 105088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1642: 1.5441513061523438\n",
      "Seen so far: 105152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1643: 2.224140167236328\n",
      "Seen so far: 105216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1644: 1.7246744632720947\n",
      "Seen so far: 105280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1645: 1.73516845703125\n",
      "Seen so far: 105344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1646: 1.4994711875915527\n",
      "Seen so far: 105408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1647: 1.312983512878418\n",
      "Seen so far: 105472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1648: 1.574587106704712\n",
      "Seen so far: 105536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1649: 2.1831421852111816\n",
      "Seen so far: 105600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1650: 1.6396996974945068\n",
      "Seen so far: 105664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1651: 1.6067488193511963\n",
      "Seen so far: 105728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1652: 1.5729238986968994\n",
      "Seen so far: 105792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1653: 1.372004508972168\n",
      "Seen so far: 105856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1654: 1.37071692943573\n",
      "Seen so far: 105920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1655: 1.6351079940795898\n",
      "Seen so far: 105984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1656: 2.0378565788269043\n",
      "Seen so far: 106048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1657: 1.5360617637634277\n",
      "Seen so far: 106112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1658: 1.6656873226165771\n",
      "Seen so far: 106176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1659: 1.3722751140594482\n",
      "Seen so far: 106240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1660: 1.6110999584197998\n",
      "Seen so far: 106304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1661: 1.4004459381103516\n",
      "Seen so far: 106368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1662: 1.4183251857757568\n",
      "Seen so far: 106432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1663: 1.8987998962402344\n",
      "Seen so far: 106496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1664: 1.772752046585083\n",
      "Seen so far: 106560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1665: 1.4695377349853516\n",
      "Seen so far: 106624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1666: 1.6501647233963013\n",
      "Seen so far: 106688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1667: 1.2556941509246826\n",
      "Seen so far: 106752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1668: 1.9234596490859985\n",
      "Seen so far: 106816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1669: 1.8255600929260254\n",
      "Seen so far: 106880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1670: 1.8954999446868896\n",
      "Seen so far: 106944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1671: 1.5326894521713257\n",
      "Seen so far: 107008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1672: 1.8798772096633911\n",
      "Seen so far: 107072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1673: 1.3125555515289307\n",
      "Seen so far: 107136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1674: 1.0586183071136475\n",
      "Seen so far: 107200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1675: 1.6728405952453613\n",
      "Seen so far: 107264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1676: 1.621090054512024\n",
      "Seen so far: 107328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1677: 1.384911060333252\n",
      "Seen so far: 107392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1678: 1.5148277282714844\n",
      "Seen so far: 107456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1679: 1.484591007232666\n",
      "Seen so far: 107520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1680: 1.371220588684082\n",
      "Seen so far: 107584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1681: 1.9699068069458008\n",
      "Seen so far: 107648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1682: 1.8143519163131714\n",
      "Seen so far: 107712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1683: 1.8398654460906982\n",
      "Seen so far: 107776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1684: 1.7561557292938232\n",
      "Seen so far: 107840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1685: 1.480670690536499\n",
      "Seen so far: 107904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1686: 1.3817598819732666\n",
      "Seen so far: 107968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1687: 1.6724520921707153\n",
      "Seen so far: 108032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1688: 2.1197333335876465\n",
      "Seen so far: 108096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1689: 1.2844586372375488\n",
      "Seen so far: 108160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1690: 1.7533860206604004\n",
      "Seen so far: 108224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1691: 1.1746045351028442\n",
      "Seen so far: 108288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1692: 1.297144889831543\n",
      "Seen so far: 108352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1693: 1.7989224195480347\n",
      "Seen so far: 108416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1694: 1.9350000619888306\n",
      "Seen so far: 108480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1695: 1.6029868125915527\n",
      "Seen so far: 108544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1696: 1.885704755783081\n",
      "Seen so far: 108608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1697: 1.706790804862976\n",
      "Seen so far: 108672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1698: 1.434923529624939\n",
      "Seen so far: 108736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1699: 1.1419509649276733\n",
      "Seen so far: 108800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1700: 1.4780445098876953\n",
      "Seen so far: 108864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1701: 1.583088755607605\n",
      "Seen so far: 108928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1702: 1.8328006267547607\n",
      "Seen so far: 108992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1703: 1.4595520496368408\n",
      "Seen so far: 109056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1704: 1.8053773641586304\n",
      "Seen so far: 109120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1705: 1.6723332405090332\n",
      "Seen so far: 109184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1706: 1.716299057006836\n",
      "Seen so far: 109248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1707: 1.914004921913147\n",
      "Seen so far: 109312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1708: 1.3936352729797363\n",
      "Seen so far: 109376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1709: 1.772743582725525\n",
      "Seen so far: 109440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1710: 1.4149816036224365\n",
      "Seen so far: 109504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1711: 1.5051312446594238\n",
      "Seen so far: 109568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1712: 1.132084846496582\n",
      "Seen so far: 109632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1713: 1.1253159046173096\n",
      "Seen so far: 109696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1714: 1.4419612884521484\n",
      "Seen so far: 109760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1715: 1.4101223945617676\n",
      "Seen so far: 109824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1716: 1.9914724826812744\n",
      "Seen so far: 109888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1717: 1.276789665222168\n",
      "Seen so far: 109952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1718: 1.446582555770874\n",
      "Seen so far: 110016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1719: 1.5473856925964355\n",
      "Seen so far: 110080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1720: 1.7141211032867432\n",
      "Seen so far: 110144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1721: 1.6878985166549683\n",
      "Seen so far: 110208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1722: 1.164691686630249\n",
      "Seen so far: 110272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1723: 1.2884153127670288\n",
      "Seen so far: 110336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1724: 1.901179313659668\n",
      "Seen so far: 110400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1725: 1.7719000577926636\n",
      "Seen so far: 110464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1726: 1.7651376724243164\n",
      "Seen so far: 110528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1727: 1.1785823106765747\n",
      "Seen so far: 110592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1728: 1.5643590688705444\n",
      "Seen so far: 110656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1729: 1.4602289199829102\n",
      "Seen so far: 110720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1730: 1.6236152648925781\n",
      "Seen so far: 110784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1731: 1.2114585638046265\n",
      "Seen so far: 110848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1732: 1.6248723268508911\n",
      "Seen so far: 110912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1733: 1.829879641532898\n",
      "Seen so far: 110976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1734: 1.6358991861343384\n",
      "Seen so far: 111040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1735: 1.501743197441101\n",
      "Seen so far: 111104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1736: 1.4637099504470825\n",
      "Seen so far: 111168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1737: 1.976461410522461\n",
      "Seen so far: 111232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1738: 1.2911601066589355\n",
      "Seen so far: 111296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1739: 1.5556092262268066\n",
      "Seen so far: 111360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1740: 1.7289475202560425\n",
      "Seen so far: 111424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1741: 1.5171730518341064\n",
      "Seen so far: 111488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1742: 1.458050012588501\n",
      "Seen so far: 111552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1743: 1.4830337762832642\n",
      "Seen so far: 111616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1744: 1.535567045211792\n",
      "Seen so far: 111680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1745: 1.6042083501815796\n",
      "Seen so far: 111744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1746: 1.429301381111145\n",
      "Seen so far: 111808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1747: 2.3510828018188477\n",
      "Seen so far: 111872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1748: 1.3723137378692627\n",
      "Seen so far: 111936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1749: 1.5053963661193848\n",
      "Seen so far: 112000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1750: 1.585140347480774\n",
      "Seen so far: 112064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1751: 1.458719253540039\n",
      "Seen so far: 112128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1752: 1.6983007192611694\n",
      "Seen so far: 112192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1753: 1.6997971534729004\n",
      "Seen so far: 112256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1754: 1.9313786029815674\n",
      "Seen so far: 112320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1755: 1.5929925441741943\n",
      "Seen so far: 112384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1756: 1.780863881111145\n",
      "Seen so far: 112448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1757: 1.5708067417144775\n",
      "Seen so far: 112512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1758: 1.7300434112548828\n",
      "Seen so far: 112576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1759: 1.7300007343292236\n",
      "Seen so far: 112640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1760: 1.9753412008285522\n",
      "Seen so far: 112704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1761: 1.3049311637878418\n",
      "Seen so far: 112768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1762: 1.3864004611968994\n",
      "Seen so far: 112832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1763: 1.7682154178619385\n",
      "Seen so far: 112896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1764: 1.5180821418762207\n",
      "Seen so far: 112960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1765: 1.418139934539795\n",
      "Seen so far: 113024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1766: 1.807763695716858\n",
      "Seen so far: 113088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1767: 1.4532270431518555\n",
      "Seen so far: 113152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1768: 1.692643165588379\n",
      "Seen so far: 113216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1769: 1.5158412456512451\n",
      "Seen so far: 113280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1770: 1.4484002590179443\n",
      "Seen so far: 113344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1771: 1.4256012439727783\n",
      "Seen so far: 113408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1772: 1.8360488414764404\n",
      "Seen so far: 113472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1773: 1.405122995376587\n",
      "Seen so far: 113536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1774: 1.8337533473968506\n",
      "Seen so far: 113600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1775: 1.310370922088623\n",
      "Seen so far: 113664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1776: 1.8380143642425537\n",
      "Seen so far: 113728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1777: 1.735654354095459\n",
      "Seen so far: 113792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1778: 1.4351863861083984\n",
      "Seen so far: 113856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1779: 1.785214900970459\n",
      "Seen so far: 113920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1780: 1.6385498046875\n",
      "Seen so far: 113984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1781: 1.866844654083252\n",
      "Seen so far: 114048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1782: 1.3916234970092773\n",
      "Seen so far: 114112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1783: 1.6668384075164795\n",
      "Seen so far: 114176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1784: 1.4113900661468506\n",
      "Seen so far: 114240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1785: 1.6047053337097168\n",
      "Seen so far: 114304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1786: 1.4421026706695557\n",
      "Seen so far: 114368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1787: 1.9064613580703735\n",
      "Seen so far: 114432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1788: 1.3410589694976807\n",
      "Seen so far: 114496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1789: 1.5681289434432983\n",
      "Seen so far: 114560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1790: 1.5533909797668457\n",
      "Seen so far: 114624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1791: 1.3509836196899414\n",
      "Seen so far: 114688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1792: 1.3746094703674316\n",
      "Seen so far: 114752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1793: 1.9087013006210327\n",
      "Seen so far: 114816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1794: 1.36855149269104\n",
      "Seen so far: 114880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1795: 1.468790888786316\n",
      "Seen so far: 114944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1796: 1.464583158493042\n",
      "Seen so far: 115008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1797: 1.8672363758087158\n",
      "Seen so far: 115072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1798: 1.2135483026504517\n",
      "Seen so far: 115136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1799: 1.7238502502441406\n",
      "Seen so far: 115200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1800: 1.66970694065094\n",
      "Seen so far: 115264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1801: 1.3435273170471191\n",
      "Seen so far: 115328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1802: 1.333677053451538\n",
      "Seen so far: 115392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1803: 1.4336435794830322\n",
      "Seen so far: 115456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1804: 1.7462193965911865\n",
      "Seen so far: 115520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1805: 1.1359130144119263\n",
      "Seen so far: 115584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1806: 1.22251558303833\n",
      "Seen so far: 115648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1807: 1.9412305355072021\n",
      "Seen so far: 115712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1808: 1.5579941272735596\n",
      "Seen so far: 115776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1809: 1.9806349277496338\n",
      "Seen so far: 115840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1810: 1.5733718872070312\n",
      "Seen so far: 115904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1811: 1.415346384048462\n",
      "Seen so far: 115968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1812: 1.1597552299499512\n",
      "Seen so far: 116032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1813: 1.7561917304992676\n",
      "Seen so far: 116096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1814: 1.535203218460083\n",
      "Seen so far: 116160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1815: 1.9246083498001099\n",
      "Seen so far: 116224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1816: 1.629044532775879\n",
      "Seen so far: 116288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1817: 1.7373052835464478\n",
      "Seen so far: 116352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1818: 1.3794255256652832\n",
      "Seen so far: 116416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1819: 1.8496737480163574\n",
      "Seen so far: 116480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1820: 1.2855188846588135\n",
      "Seen so far: 116544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1821: 1.994413137435913\n",
      "Seen so far: 116608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1822: 1.5527722835540771\n",
      "Seen so far: 116672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1823: 1.7143456935882568\n",
      "Seen so far: 116736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1824: 1.2722558975219727\n",
      "Seen so far: 116800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1825: 1.855797529220581\n",
      "Seen so far: 116864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1826: 1.599290132522583\n",
      "Seen so far: 116928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1827: 1.862274169921875\n",
      "Seen so far: 116992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1828: 1.610600233078003\n",
      "Seen so far: 117056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1829: 1.3505620956420898\n",
      "Seen so far: 117120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1830: 1.628138780593872\n",
      "Seen so far: 117184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1831: 1.7307020425796509\n",
      "Seen so far: 117248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1832: 1.9745502471923828\n",
      "Seen so far: 117312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1833: 1.486281394958496\n",
      "Seen so far: 117376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1834: 1.976556658744812\n",
      "Seen so far: 117440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1835: 1.4796113967895508\n",
      "Seen so far: 117504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1836: 1.6411253213882446\n",
      "Seen so far: 117568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1837: 1.3647540807724\n",
      "Seen so far: 117632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1838: 1.7032582759857178\n",
      "Seen so far: 117696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1839: 1.5452275276184082\n",
      "Seen so far: 117760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1840: 1.6324965953826904\n",
      "Seen so far: 117824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1841: 1.3935739994049072\n",
      "Seen so far: 117888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1842: 1.268492341041565\n",
      "Seen so far: 117952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1843: 1.8758907318115234\n",
      "Seen so far: 118016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1844: 1.5387072563171387\n",
      "Seen so far: 118080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1845: 1.7214275598526\n",
      "Seen so far: 118144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1846: 1.9527513980865479\n",
      "Seen so far: 118208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1847: 1.7955683469772339\n",
      "Seen so far: 118272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1848: 1.5196889638900757\n",
      "Seen so far: 118336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1849: 1.7136881351470947\n",
      "Seen so far: 118400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1850: 1.2405505180358887\n",
      "Seen so far: 118464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1851: 1.931586742401123\n",
      "Seen so far: 118528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1852: 1.735776424407959\n",
      "Seen so far: 118592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1853: 1.5655778646469116\n",
      "Seen so far: 118656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1854: 1.7945356369018555\n",
      "Seen so far: 118720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1855: 1.9785716533660889\n",
      "Seen so far: 118784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1856: 1.5451083183288574\n",
      "Seen so far: 118848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1857: 1.134854793548584\n",
      "Seen so far: 118912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1858: 1.5722216367721558\n",
      "Seen so far: 118976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1859: 1.3933117389678955\n",
      "Seen so far: 119040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1860: 1.5034253597259521\n",
      "Seen so far: 119104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1861: 1.2139167785644531\n",
      "Seen so far: 119168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1862: 1.4295384883880615\n",
      "Seen so far: 119232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1863: 1.5747435092926025\n",
      "Seen so far: 119296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1864: 1.445013403892517\n",
      "Seen so far: 119360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1865: 1.6850643157958984\n",
      "Seen so far: 119424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1866: 1.3581035137176514\n",
      "Seen so far: 119488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1867: 2.0833828449249268\n",
      "Seen so far: 119552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1868: 1.481189250946045\n",
      "Seen so far: 119616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1869: 1.3643999099731445\n",
      "Seen so far: 119680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1870: 1.4340202808380127\n",
      "Seen so far: 119744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1871: 1.358145833015442\n",
      "Seen so far: 119808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1872: 1.4566864967346191\n",
      "Seen so far: 119872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1873: 1.691009759902954\n",
      "Seen so far: 119936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1874: 1.408089518547058\n",
      "Seen so far: 120000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1875: 1.4303030967712402\n",
      "Seen so far: 120064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1876: 1.2392613887786865\n",
      "Seen so far: 120128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1877: 1.488885521888733\n",
      "Seen so far: 120192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1878: 1.6765100955963135\n",
      "Seen so far: 120256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1879: 1.6597920656204224\n",
      "Seen so far: 120320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1880: 1.5676230192184448\n",
      "Seen so far: 120384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1881: 1.1011468172073364\n",
      "Seen so far: 120448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1882: 1.4902303218841553\n",
      "Seen so far: 120512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1883: 1.0983141660690308\n",
      "Seen so far: 120576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1884: 1.6037812232971191\n",
      "Seen so far: 120640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1885: 1.4473004341125488\n",
      "Seen so far: 120704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1886: 1.4289048910140991\n",
      "Seen so far: 120768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1887: 1.4943591356277466\n",
      "Seen so far: 120832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1888: 1.397591233253479\n",
      "Seen so far: 120896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1889: 1.7209770679473877\n",
      "Seen so far: 120960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1890: 1.7721136808395386\n",
      "Seen so far: 121024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1891: 1.7661813497543335\n",
      "Seen so far: 121088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1892: 1.3252081871032715\n",
      "Seen so far: 121152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1893: 1.3484188318252563\n",
      "Seen so far: 121216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1894: 1.7563159465789795\n",
      "Seen so far: 121280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1895: 1.522134780883789\n",
      "Seen so far: 121344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1896: 1.142467975616455\n",
      "Seen so far: 121408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1897: 1.988297462463379\n",
      "Seen so far: 121472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1898: 1.5540850162506104\n",
      "Seen so far: 121536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1899: 1.557448387145996\n",
      "Seen so far: 121600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1900: 1.6635717153549194\n",
      "Seen so far: 121664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1901: 1.3359620571136475\n",
      "Seen so far: 121728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1902: 2.108936309814453\n",
      "Seen so far: 121792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1903: 1.6189861297607422\n",
      "Seen so far: 121856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1904: 1.6207176446914673\n",
      "Seen so far: 121920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1905: 1.5365502834320068\n",
      "Seen so far: 121984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1906: 1.4914360046386719\n",
      "Seen so far: 122048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1907: 1.7523324489593506\n",
      "Seen so far: 122112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1908: 1.5366923809051514\n",
      "Seen so far: 122176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1909: 1.5546849966049194\n",
      "Seen so far: 122240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1910: 1.4020015001296997\n",
      "Seen so far: 122304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1911: 1.3655452728271484\n",
      "Seen so far: 122368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1912: 1.720924973487854\n",
      "Seen so far: 122432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1913: 1.2824485301971436\n",
      "Seen so far: 122496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1914: 1.4233124256134033\n",
      "Seen so far: 122560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1915: 1.3682235479354858\n",
      "Seen so far: 122624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1916: 1.3380134105682373\n",
      "Seen so far: 122688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1917: 1.425820231437683\n",
      "Seen so far: 122752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1918: 1.9096869230270386\n",
      "Seen so far: 122816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1919: 1.5531986951828003\n",
      "Seen so far: 122880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1920: 1.3327323198318481\n",
      "Seen so far: 122944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1921: 1.5384562015533447\n",
      "Seen so far: 123008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1922: 1.7226381301879883\n",
      "Seen so far: 123072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1923: 1.689035415649414\n",
      "Seen so far: 123136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1924: 1.8949217796325684\n",
      "Seen so far: 123200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1925: 1.5360312461853027\n",
      "Seen so far: 123264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1926: 1.4511840343475342\n",
      "Seen so far: 123328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1927: 1.4363389015197754\n",
      "Seen so far: 123392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1928: 1.2818491458892822\n",
      "Seen so far: 123456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1929: 1.540826439857483\n",
      "Seen so far: 123520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1930: 1.6785255670547485\n",
      "Seen so far: 123584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1931: 1.4511640071868896\n",
      "Seen so far: 123648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1932: 1.6087555885314941\n",
      "Seen so far: 123712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1933: 1.3337308168411255\n",
      "Seen so far: 123776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1934: 1.7519218921661377\n",
      "Seen so far: 123840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1935: 1.4744640588760376\n",
      "Seen so far: 123904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1936: 2.1095314025878906\n",
      "Seen so far: 123968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1937: 1.5617139339447021\n",
      "Seen so far: 124032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1938: 1.76600980758667\n",
      "Seen so far: 124096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1939: 1.827978253364563\n",
      "Seen so far: 124160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1940: 1.8109910488128662\n",
      "Seen so far: 124224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1941: 1.4643410444259644\n",
      "Seen so far: 124288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1942: 1.7697596549987793\n",
      "Seen so far: 124352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1943: 1.2031769752502441\n",
      "Seen so far: 124416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1944: 1.4883899688720703\n",
      "Seen so far: 124480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1945: 1.498037338256836\n",
      "Seen so far: 124544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1946: 1.4160315990447998\n",
      "Seen so far: 124608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1947: 1.7573072910308838\n",
      "Seen so far: 124672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1948: 1.7141389846801758\n",
      "Seen so far: 124736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1949: 1.6800103187561035\n",
      "Seen so far: 124800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1950: 2.0383424758911133\n",
      "Seen so far: 124864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1951: 1.2461433410644531\n",
      "Seen so far: 124928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1952: 0.7877206206321716\n",
      "Seen so far: 124992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1953: 1.2242367267608643\n",
      "Seen so far: 125056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1954: 1.5333528518676758\n",
      "Seen so far: 125120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1955: 1.5992157459259033\n",
      "Seen so far: 125184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1956: 1.3883607387542725\n",
      "Seen so far: 125248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1957: 1.6911380290985107\n",
      "Seen so far: 125312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1958: 1.5121617317199707\n",
      "Seen so far: 125376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1959: 1.4161489009857178\n",
      "Seen so far: 125440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1960: 1.7850439548492432\n",
      "Seen so far: 125504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1961: 1.7245683670043945\n",
      "Seen so far: 125568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1962: 1.3653206825256348\n",
      "Seen so far: 125632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1963: 1.523537039756775\n",
      "Seen so far: 125696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1964: 1.253049373626709\n",
      "Seen so far: 125760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1965: 1.7450374364852905\n",
      "Seen so far: 125824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1966: 1.3064852952957153\n",
      "Seen so far: 125888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1967: 1.184462547302246\n",
      "Seen so far: 125952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1968: 1.1263659000396729\n",
      "Seen so far: 126016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1969: 1.5584092140197754\n",
      "Seen so far: 126080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1970: 1.4634861946105957\n",
      "Seen so far: 126144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1971: 1.0784547328948975\n",
      "Seen so far: 126208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1972: 1.5735595226287842\n",
      "Seen so far: 126272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1973: 1.4692316055297852\n",
      "Seen so far: 126336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1974: 1.3839340209960938\n",
      "Seen so far: 126400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1975: 1.4385855197906494\n",
      "Seen so far: 126464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1976: 1.6970499753952026\n",
      "Seen so far: 126528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1977: 1.3058817386627197\n",
      "Seen so far: 126592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1978: 1.6674315929412842\n",
      "Seen so far: 126656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1979: 1.015710473060608\n",
      "Seen so far: 126720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1980: 1.407365083694458\n",
      "Seen so far: 126784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1981: 1.4699337482452393\n",
      "Seen so far: 126848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1982: 1.2920538187026978\n",
      "Seen so far: 126912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1983: 2.1604559421539307\n",
      "Seen so far: 126976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1984: 1.3956775665283203\n",
      "Seen so far: 127040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1985: 1.5262172222137451\n",
      "Seen so far: 127104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1986: 1.2124438285827637\n",
      "Seen so far: 127168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1987: 1.7826308012008667\n",
      "Seen so far: 127232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1988: 1.6886396408081055\n",
      "Seen so far: 127296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1989: 1.747148036956787\n",
      "Seen so far: 127360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1990: 1.5915319919586182\n",
      "Seen so far: 127424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1991: 1.6284456253051758\n",
      "Seen so far: 127488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1992: 1.6271336078643799\n",
      "Seen so far: 127552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1993: 1.3107481002807617\n",
      "Seen so far: 127616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1994: 1.51824152469635\n",
      "Seen so far: 127680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1995: 1.4039644002914429\n",
      "Seen so far: 127744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1996: 1.626907467842102\n",
      "Seen so far: 127808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1997: 1.3117715120315552\n",
      "Seen so far: 127872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1998: 1.412681221961975\n",
      "Seen so far: 127936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1999: 1.4732348918914795\n",
      "Seen so far: 128000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2000: 1.467529296875\n",
      "Seen so far: 128064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2001: 1.4355287551879883\n",
      "Seen so far: 128128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2002: 1.824463129043579\n",
      "Seen so far: 128192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2003: 1.3415778875350952\n",
      "Seen so far: 128256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2004: 1.3678371906280518\n",
      "Seen so far: 128320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2005: 1.5487086772918701\n",
      "Seen so far: 128384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2006: 1.754838228225708\n",
      "Seen so far: 128448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2007: 1.1689690351486206\n",
      "Seen so far: 128512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2008: 1.6418870687484741\n",
      "Seen so far: 128576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2009: 1.6264724731445312\n",
      "Seen so far: 128640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2010: 1.7055659294128418\n",
      "Seen so far: 128704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2011: 1.3603647947311401\n",
      "Seen so far: 128768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2012: 1.4438470602035522\n",
      "Seen so far: 128832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2013: 1.559977650642395\n",
      "Seen so far: 128896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2014: 1.3347039222717285\n",
      "Seen so far: 128960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2015: 1.289079189300537\n",
      "Seen so far: 129024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2016: 1.5544145107269287\n",
      "Seen so far: 129088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2017: 1.9347116947174072\n",
      "Seen so far: 129152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2018: 1.2388715744018555\n",
      "Seen so far: 129216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2019: 1.7410309314727783\n",
      "Seen so far: 129280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2020: 1.3625106811523438\n",
      "Seen so far: 129344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2021: 1.828589916229248\n",
      "Seen so far: 129408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2022: 2.2723705768585205\n",
      "Seen so far: 129472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2023: 1.5529589653015137\n",
      "Seen so far: 129536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2024: 1.4405581951141357\n",
      "Seen so far: 129600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2025: 1.4762907028198242\n",
      "Seen so far: 129664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2026: 1.466184377670288\n",
      "Seen so far: 129728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2027: 1.6624150276184082\n",
      "Seen so far: 129792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2028: 1.3042902946472168\n",
      "Seen so far: 129856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2029: 1.531712532043457\n",
      "Seen so far: 129920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2030: 2.1487088203430176\n",
      "Seen so far: 129984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2031: 1.9258003234863281\n",
      "Seen so far: 130048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2032: 1.3828542232513428\n",
      "Seen so far: 130112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2033: 1.5646767616271973\n",
      "Seen so far: 130176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2034: 1.8028138875961304\n",
      "Seen so far: 130240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2035: 1.2530162334442139\n",
      "Seen so far: 130304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2036: 1.5822694301605225\n",
      "Seen so far: 130368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2037: 1.1913940906524658\n",
      "Seen so far: 130432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2038: 1.5046125650405884\n",
      "Seen so far: 130496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2039: 1.7625789642333984\n",
      "Seen so far: 130560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2040: 1.3437614440917969\n",
      "Seen so far: 130624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2041: 1.571454644203186\n",
      "Seen so far: 130688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2042: 1.4971121549606323\n",
      "Seen so far: 130752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2043: 1.4793057441711426\n",
      "Seen so far: 130816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2044: 1.538848876953125\n",
      "Seen so far: 130880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2045: 1.3651506900787354\n",
      "Seen so far: 130944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2046: 1.528383731842041\n",
      "Seen so far: 131008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2047: 1.7027738094329834\n",
      "Seen so far: 131072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2048: 1.543346643447876\n",
      "Seen so far: 131136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2049: 1.3597393035888672\n",
      "Seen so far: 131200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2050: 1.3864201307296753\n",
      "Seen so far: 131264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2051: 1.8385294675827026\n",
      "Seen so far: 131328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2052: 1.310280442237854\n",
      "Seen so far: 131392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2053: 1.6319185495376587\n",
      "Seen so far: 131456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2054: 1.3746548891067505\n",
      "Seen so far: 131520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2055: 1.0191264152526855\n",
      "Seen so far: 131584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2056: 1.1505206823349\n",
      "Seen so far: 131648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2057: 1.4947885274887085\n",
      "Seen so far: 131712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2058: 1.2773323059082031\n",
      "Seen so far: 131776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2059: 1.2723499536514282\n",
      "Seen so far: 131840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2060: 1.2762609720230103\n",
      "Seen so far: 131904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2061: 1.937501311302185\n",
      "Seen so far: 131968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2062: 1.2976590394973755\n",
      "Seen so far: 132032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2063: 1.4636603593826294\n",
      "Seen so far: 132096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2064: 1.4658598899841309\n",
      "Seen so far: 132160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2065: 1.425379991531372\n",
      "Seen so far: 132224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2066: 1.6128443479537964\n",
      "Seen so far: 132288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2067: 1.424905776977539\n",
      "Seen so far: 132352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2068: 1.56514573097229\n",
      "Seen so far: 132416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2069: 1.8710922002792358\n",
      "Seen so far: 132480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2070: 1.5406384468078613\n",
      "Seen so far: 132544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2071: 1.350109338760376\n",
      "Seen so far: 132608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2072: 1.4403362274169922\n",
      "Seen so far: 132672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2073: 1.4462462663650513\n",
      "Seen so far: 132736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2074: 1.3876986503601074\n",
      "Seen so far: 132800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2075: 1.611070156097412\n",
      "Seen so far: 132864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2076: 1.0913245677947998\n",
      "Seen so far: 132928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2077: 1.135892391204834\n",
      "Seen so far: 132992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2078: 1.508152961730957\n",
      "Seen so far: 133056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2079: 1.5295226573944092\n",
      "Seen so far: 133120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2080: 1.4517364501953125\n",
      "Seen so far: 133184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2081: 1.484870195388794\n",
      "Seen so far: 133248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2082: 1.4022736549377441\n",
      "Seen so far: 133312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2083: 1.5674018859863281\n",
      "Seen so far: 133376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2084: 1.4843767881393433\n",
      "Seen so far: 133440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2085: 1.0776424407958984\n",
      "Seen so far: 133504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2086: 1.604736089706421\n",
      "Seen so far: 133568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2087: 1.8597513437271118\n",
      "Seen so far: 133632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2088: 1.0922331809997559\n",
      "Seen so far: 133696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2089: 1.5947325229644775\n",
      "Seen so far: 133760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2090: 1.354593276977539\n",
      "Seen so far: 133824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2091: 1.6855459213256836\n",
      "Seen so far: 133888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2092: 1.5978258848190308\n",
      "Seen so far: 133952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2093: 1.1530628204345703\n",
      "Seen so far: 134016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2094: 1.3259612321853638\n",
      "Seen so far: 134080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2095: 1.5203516483306885\n",
      "Seen so far: 134144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2096: 2.0957417488098145\n",
      "Seen so far: 134208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2097: 1.357582688331604\n",
      "Seen so far: 134272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2098: 1.3572807312011719\n",
      "Seen so far: 134336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2099: 1.221205472946167\n",
      "Seen so far: 134400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2100: 1.3044546842575073\n",
      "Seen so far: 134464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2101: 1.3057411909103394\n",
      "Seen so far: 134528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2102: 1.535844087600708\n",
      "Seen so far: 134592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2103: 1.4748525619506836\n",
      "Seen so far: 134656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2104: 1.3909947872161865\n",
      "Seen so far: 134720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2105: 1.4930696487426758\n",
      "Seen so far: 134784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2106: 1.2543257474899292\n",
      "Seen so far: 134848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2107: 1.4516417980194092\n",
      "Seen so far: 134912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2108: 1.1186496019363403\n",
      "Seen so far: 134976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2109: 1.658467411994934\n",
      "Seen so far: 135040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2110: 1.6463141441345215\n",
      "Seen so far: 135104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2111: 1.3241844177246094\n",
      "Seen so far: 135168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2112: 1.2334587574005127\n",
      "Seen so far: 135232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2113: 1.546677589416504\n",
      "Seen so far: 135296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2114: 1.6530835628509521\n",
      "Seen so far: 135360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2115: 1.832714319229126\n",
      "Seen so far: 135424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2116: 1.3274853229522705\n",
      "Seen so far: 135488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2117: 1.1653728485107422\n",
      "Seen so far: 135552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2118: 1.717113971710205\n",
      "Seen so far: 135616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2119: 1.6865077018737793\n",
      "Seen so far: 135680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2120: 1.3480329513549805\n",
      "Seen so far: 135744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2121: 1.5275518894195557\n",
      "Seen so far: 135808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2122: 1.4948904514312744\n",
      "Seen so far: 135872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2123: 1.2000372409820557\n",
      "Seen so far: 135936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2124: 1.3915176391601562\n",
      "Seen so far: 136000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2125: 1.831226110458374\n",
      "Seen so far: 136064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2126: 1.4149091243743896\n",
      "Seen so far: 136128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2127: 1.5803965330123901\n",
      "Seen so far: 136192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2128: 1.9163552522659302\n",
      "Seen so far: 136256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2129: 1.7453725337982178\n",
      "Seen so far: 136320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2130: 1.0852015018463135\n",
      "Seen so far: 136384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2131: 1.8760825395584106\n",
      "Seen so far: 136448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2132: 1.5514862537384033\n",
      "Seen so far: 136512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2133: 1.3908286094665527\n",
      "Seen so far: 136576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2134: 1.2081108093261719\n",
      "Seen so far: 136640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2135: 1.1995775699615479\n",
      "Seen so far: 136704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2136: 1.4576767683029175\n",
      "Seen so far: 136768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2137: 1.5254130363464355\n",
      "Seen so far: 136832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2138: 1.7403253316879272\n",
      "Seen so far: 136896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2139: 1.4540988206863403\n",
      "Seen so far: 136960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2140: 1.7589236497879028\n",
      "Seen so far: 137024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2141: 1.9545682668685913\n",
      "Seen so far: 137088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2142: 1.3570836782455444\n",
      "Seen so far: 137152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2143: 1.2945575714111328\n",
      "Seen so far: 137216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2144: 1.318832278251648\n",
      "Seen so far: 137280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2145: 1.5630683898925781\n",
      "Seen so far: 137344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2146: 1.7222886085510254\n",
      "Seen so far: 137408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2147: 1.2610301971435547\n",
      "Seen so far: 137472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2148: 1.9152984619140625\n",
      "Seen so far: 137536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2149: 1.733176589012146\n",
      "Seen so far: 137600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2150: 1.399395227432251\n",
      "Seen so far: 137664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2151: 1.5327894687652588\n",
      "Seen so far: 137728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2152: 1.2779521942138672\n",
      "Seen so far: 137792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2153: 1.4234899282455444\n",
      "Seen so far: 137856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2154: 1.8679747581481934\n",
      "Seen so far: 137920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2155: 1.5500298738479614\n",
      "Seen so far: 137984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2156: 1.5796456336975098\n",
      "Seen so far: 138048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2157: 1.2140841484069824\n",
      "Seen so far: 138112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2158: 1.4679622650146484\n",
      "Seen so far: 138176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2159: 1.3773692846298218\n",
      "Seen so far: 138240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2160: 1.4201107025146484\n",
      "Seen so far: 138304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2161: 1.4170458316802979\n",
      "Seen so far: 138368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2162: 1.4923062324523926\n",
      "Seen so far: 138432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2163: 1.1515616178512573\n",
      "Seen so far: 138496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2164: 1.7343273162841797\n",
      "Seen so far: 138560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2165: 1.577921986579895\n",
      "Seen so far: 138624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2166: 1.3109936714172363\n",
      "Seen so far: 138688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2167: 1.6913001537322998\n",
      "Seen so far: 138752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2168: 1.376571536064148\n",
      "Seen so far: 138816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2169: 1.4287018775939941\n",
      "Seen so far: 138880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2170: 1.4086042642593384\n",
      "Seen so far: 138944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2171: 1.6454246044158936\n",
      "Seen so far: 139008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2172: 1.6270947456359863\n",
      "Seen so far: 139072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2173: 1.4242666959762573\n",
      "Seen so far: 139136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2174: 1.6660609245300293\n",
      "Seen so far: 139200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2175: 1.40066659450531\n",
      "Seen so far: 139264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2176: 1.365354061126709\n",
      "Seen so far: 139328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2177: 1.4421684741973877\n",
      "Seen so far: 139392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2178: 1.2310714721679688\n",
      "Seen so far: 139456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2179: 1.0846766233444214\n",
      "Seen so far: 139520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2180: 1.3648076057434082\n",
      "Seen so far: 139584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2181: 1.6326090097427368\n",
      "Seen so far: 139648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2182: 1.5829424858093262\n",
      "Seen so far: 139712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2183: 1.1707572937011719\n",
      "Seen so far: 139776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2184: 1.5961220264434814\n",
      "Seen so far: 139840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2185: 1.7898261547088623\n",
      "Seen so far: 139904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2186: 1.2904605865478516\n",
      "Seen so far: 139968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2187: 1.4903247356414795\n",
      "Seen so far: 140032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2188: 1.418116569519043\n",
      "Seen so far: 140096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2189: 1.9396967887878418\n",
      "Seen so far: 140160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2190: 1.4728341102600098\n",
      "Seen so far: 140224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2191: 1.2971551418304443\n",
      "Seen so far: 140288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2192: 1.7994773387908936\n",
      "Seen so far: 140352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2193: 1.710734486579895\n",
      "Seen so far: 140416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2194: 1.2577927112579346\n",
      "Seen so far: 140480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2195: 1.4947149753570557\n",
      "Seen so far: 140544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2196: 1.3991718292236328\n",
      "Seen so far: 140608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2197: 1.2892062664031982\n",
      "Seen so far: 140672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2198: 1.6312155723571777\n",
      "Seen so far: 140736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2199: 1.3813855648040771\n",
      "Seen so far: 140800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2200: 1.9163358211517334\n",
      "Seen so far: 140864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2201: 1.340865135192871\n",
      "Seen so far: 140928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2202: 1.459017276763916\n",
      "Seen so far: 140992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2203: 1.772019863128662\n",
      "Seen so far: 141056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2204: 1.627723217010498\n",
      "Seen so far: 141120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2205: 1.3606008291244507\n",
      "Seen so far: 141184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2206: 1.5892882347106934\n",
      "Seen so far: 141248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2207: 1.3315868377685547\n",
      "Seen so far: 141312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2208: 2.0190048217773438\n",
      "Seen so far: 141376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2209: 1.474604606628418\n",
      "Seen so far: 141440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2210: 0.8512948751449585\n",
      "Seen so far: 141504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2211: 1.6839630603790283\n",
      "Seen so far: 141568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2212: 1.2141480445861816\n",
      "Seen so far: 141632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2213: 1.7309935092926025\n",
      "Seen so far: 141696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2214: 1.5528802871704102\n",
      "Seen so far: 141760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2215: 1.6257811784744263\n",
      "Seen so far: 141824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2216: 1.2380611896514893\n",
      "Seen so far: 141888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2217: 1.5280543565750122\n",
      "Seen so far: 141952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2218: 1.4200918674468994\n",
      "Seen so far: 142016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2219: 1.546386480331421\n",
      "Seen so far: 142080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2220: 1.5084304809570312\n",
      "Seen so far: 142144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2221: 1.780981421470642\n",
      "Seen so far: 142208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2222: 1.9601693153381348\n",
      "Seen so far: 142272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2223: 1.2590970993041992\n",
      "Seen so far: 142336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2224: 1.7844539880752563\n",
      "Seen so far: 142400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2225: 1.32948899269104\n",
      "Seen so far: 142464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2226: 1.5752055644989014\n",
      "Seen so far: 142528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2227: 1.1856735944747925\n",
      "Seen so far: 142592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2228: 2.006101608276367\n",
      "Seen so far: 142656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2229: 1.3171966075897217\n",
      "Seen so far: 142720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2230: 1.5315704345703125\n",
      "Seen so far: 142784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2231: 1.4247031211853027\n",
      "Seen so far: 142848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2232: 1.4384812116622925\n",
      "Seen so far: 142912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2233: 1.3711318969726562\n",
      "Seen so far: 142976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2234: 1.1704660654067993\n",
      "Seen so far: 143040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2235: 1.7253403663635254\n",
      "Seen so far: 143104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2236: 1.5659096240997314\n",
      "Seen so far: 143168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2237: 1.7326655387878418\n",
      "Seen so far: 143232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2238: 1.495868444442749\n",
      "Seen so far: 143296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2239: 1.442018747329712\n",
      "Seen so far: 143360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2240: 1.303070306777954\n",
      "Seen so far: 143424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2241: 1.6744095087051392\n",
      "Seen so far: 143488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2242: 1.483938217163086\n",
      "Seen so far: 143552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2243: 2.0332870483398438\n",
      "Seen so far: 143616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2244: 1.5858757495880127\n",
      "Seen so far: 143680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2245: 1.395280361175537\n",
      "Seen so far: 143744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2246: 1.3335075378417969\n",
      "Seen so far: 143808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2247: 1.8718347549438477\n",
      "Seen so far: 143872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2248: 1.1887871026992798\n",
      "Seen so far: 143936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2249: 1.3909776210784912\n",
      "Seen so far: 144000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2250: 1.3423672914505005\n",
      "Seen so far: 144064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2251: 1.4460238218307495\n",
      "Seen so far: 144128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2252: 1.1409165859222412\n",
      "Seen so far: 144192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2253: 1.8301122188568115\n",
      "Seen so far: 144256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2254: 1.2010343074798584\n",
      "Seen so far: 144320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2255: 1.0540169477462769\n",
      "Seen so far: 144384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2256: 1.2867028713226318\n",
      "Seen so far: 144448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2257: 1.5544464588165283\n",
      "Seen so far: 144512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2258: 1.8801254034042358\n",
      "Seen so far: 144576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2259: 1.167445182800293\n",
      "Seen so far: 144640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2260: 1.4464962482452393\n",
      "Seen so far: 144704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2261: 1.7877482175827026\n",
      "Seen so far: 144768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2262: 1.3836898803710938\n",
      "Seen so far: 144832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2263: 1.3021820783615112\n",
      "Seen so far: 144896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2264: 1.41856050491333\n",
      "Seen so far: 144960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2265: 1.5175052881240845\n",
      "Seen so far: 145024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2266: 1.2927032709121704\n",
      "Seen so far: 145088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2267: 1.2743796110153198\n",
      "Seen so far: 145152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2268: 1.3595821857452393\n",
      "Seen so far: 145216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2269: 1.4284306764602661\n",
      "Seen so far: 145280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2270: 1.3493680953979492\n",
      "Seen so far: 145344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2271: 1.4065635204315186\n",
      "Seen so far: 145408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2272: 1.3746676445007324\n",
      "Seen so far: 145472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2273: 1.6714768409729004\n",
      "Seen so far: 145536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2274: 1.6562541723251343\n",
      "Seen so far: 145600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2275: 1.5524442195892334\n",
      "Seen so far: 145664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2276: 1.2059276103973389\n",
      "Seen so far: 145728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2277: 1.591485619544983\n",
      "Seen so far: 145792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2278: 1.7256412506103516\n",
      "Seen so far: 145856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2279: 1.3953845500946045\n",
      "Seen so far: 145920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2280: 1.5910181999206543\n",
      "Seen so far: 145984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2281: 1.2545572519302368\n",
      "Seen so far: 146048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2282: 1.7353156805038452\n",
      "Seen so far: 146112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2283: 1.7491778135299683\n",
      "Seen so far: 146176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2284: 1.409468173980713\n",
      "Seen so far: 146240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2285: 1.8494014739990234\n",
      "Seen so far: 146304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2286: 1.4754807949066162\n",
      "Seen so far: 146368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2287: 1.5574376583099365\n",
      "Seen so far: 146432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2288: 1.1917091608047485\n",
      "Seen so far: 146496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2289: 1.6102460622787476\n",
      "Seen so far: 146560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2290: 1.6296498775482178\n",
      "Seen so far: 146624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2291: 1.0847281217575073\n",
      "Seen so far: 146688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2292: 1.4777051210403442\n",
      "Seen so far: 146752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2293: 1.6913930177688599\n",
      "Seen so far: 146816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2294: 1.920008897781372\n",
      "Seen so far: 146880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2295: 1.4626708030700684\n",
      "Seen so far: 146944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2296: 1.4523634910583496\n",
      "Seen so far: 147008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2297: 1.6823821067810059\n",
      "Seen so far: 147072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2298: 1.6888787746429443\n",
      "Seen so far: 147136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2299: 1.1297416687011719\n",
      "Seen so far: 147200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2300: 1.46096670627594\n",
      "Seen so far: 147264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2301: 1.5055941343307495\n",
      "Seen so far: 147328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2302: 1.4038182497024536\n",
      "Seen so far: 147392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2303: 1.5493788719177246\n",
      "Seen so far: 147456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2304: 1.195873498916626\n",
      "Seen so far: 147520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2305: 1.3129594326019287\n",
      "Seen so far: 147584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2306: 1.5365008115768433\n",
      "Seen so far: 147648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2307: 1.4509443044662476\n",
      "Seen so far: 147712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2308: 1.402327537536621\n",
      "Seen so far: 147776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2309: 1.3580933809280396\n",
      "Seen so far: 147840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2310: 1.2496659755706787\n",
      "Seen so far: 147904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2311: 1.1174722909927368\n",
      "Seen so far: 147968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2312: 1.2554705142974854\n",
      "Seen so far: 148032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2313: 1.4009708166122437\n",
      "Seen so far: 148096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2314: 1.2719743251800537\n",
      "Seen so far: 148160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2315: 1.5458441972732544\n",
      "Seen so far: 148224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2316: 1.4281076192855835\n",
      "Seen so far: 148288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2317: 1.1973929405212402\n",
      "Seen so far: 148352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2318: 1.0221760272979736\n",
      "Seen so far: 148416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2319: 1.2409347295761108\n",
      "Seen so far: 148480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2320: 1.194450855255127\n",
      "Seen so far: 148544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2321: 1.0671063661575317\n",
      "Seen so far: 148608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2322: 1.0382827520370483\n",
      "Seen so far: 148672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2323: 1.193838119506836\n",
      "Seen so far: 148736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2324: 1.5612608194351196\n",
      "Seen so far: 148800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2325: 1.4765326976776123\n",
      "Seen so far: 148864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2326: 1.3731086254119873\n",
      "Seen so far: 148928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2327: 1.4300360679626465\n",
      "Seen so far: 148992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2328: 1.3225306272506714\n",
      "Seen so far: 149056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2329: 1.3604397773742676\n",
      "Seen so far: 149120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2330: 1.383336067199707\n",
      "Seen so far: 149184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2331: 1.7073262929916382\n",
      "Seen so far: 149248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2332: 1.1905796527862549\n",
      "Seen so far: 149312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2333: 1.5220279693603516\n",
      "Seen so far: 149376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2334: 1.1825754642486572\n",
      "Seen so far: 149440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2335: 1.4807257652282715\n",
      "Seen so far: 149504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2336: 1.5079007148742676\n",
      "Seen so far: 149568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2337: 1.2957839965820312\n",
      "Seen so far: 149632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2338: 0.9756277203559875\n",
      "Seen so far: 149696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2339: 1.5119621753692627\n",
      "Seen so far: 149760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2340: 1.828580617904663\n",
      "Seen so far: 149824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2341: 1.6789060831069946\n",
      "Seen so far: 149888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2342: 0.8686205744743347\n",
      "Seen so far: 149952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2343: 1.063272476196289\n",
      "Seen so far: 150016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2344: 1.534730076789856\n",
      "Seen so far: 150080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2345: 1.5620667934417725\n",
      "Seen so far: 150144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2346: 1.361203908920288\n",
      "Seen so far: 150208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2347: 1.21049165725708\n",
      "Seen so far: 150272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2348: 1.582277774810791\n",
      "Seen so far: 150336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2349: 1.2980375289916992\n",
      "Seen so far: 150400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2350: 1.2539786100387573\n",
      "Seen so far: 150464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2351: 1.70087468624115\n",
      "Seen so far: 150528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2352: 1.5847806930541992\n",
      "Seen so far: 150592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2353: 1.478234052658081\n",
      "Seen so far: 150656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2354: 1.347736120223999\n",
      "Seen so far: 150720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2355: 1.193495750427246\n",
      "Seen so far: 150784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2356: 1.3111597299575806\n",
      "Seen so far: 150848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2357: 1.2475335597991943\n",
      "Seen so far: 150912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2358: 1.872610092163086\n",
      "Seen so far: 150976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2359: 1.295974612236023\n",
      "Seen so far: 151040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2360: 1.6268402338027954\n",
      "Seen so far: 151104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2361: 1.466505527496338\n",
      "Seen so far: 151168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2362: 1.826127290725708\n",
      "Seen so far: 151232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2363: 1.5393059253692627\n",
      "Seen so far: 151296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2364: 1.2613813877105713\n",
      "Seen so far: 151360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2365: 2.211977243423462\n",
      "Seen so far: 151424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2366: 1.620722770690918\n",
      "Seen so far: 151488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2367: 1.229555606842041\n",
      "Seen so far: 151552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2368: 1.3351842164993286\n",
      "Seen so far: 151616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2369: 1.7114143371582031\n",
      "Seen so far: 151680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2370: 1.4041502475738525\n",
      "Seen so far: 151744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2371: 1.4344470500946045\n",
      "Seen so far: 151808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2372: 1.2909928560256958\n",
      "Seen so far: 151872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2373: 1.433823823928833\n",
      "Seen so far: 151936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2374: 1.3677823543548584\n",
      "Seen so far: 152000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2375: 1.6090302467346191\n",
      "Seen so far: 152064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2376: 1.690726399421692\n",
      "Seen so far: 152128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2377: 1.574389934539795\n",
      "Seen so far: 152192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2378: 1.4040143489837646\n",
      "Seen so far: 152256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2379: 1.4576129913330078\n",
      "Seen so far: 152320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2380: 1.388885736465454\n",
      "Seen so far: 152384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2381: 1.1475629806518555\n",
      "Seen so far: 152448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2382: 0.9600132703781128\n",
      "Seen so far: 152512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2383: 1.49434232711792\n",
      "Seen so far: 152576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2384: 1.6017630100250244\n",
      "Seen so far: 152640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2385: 1.4024980068206787\n",
      "Seen so far: 152704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2386: 1.158653974533081\n",
      "Seen so far: 152768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2387: 1.3345143795013428\n",
      "Seen so far: 152832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2388: 1.157174825668335\n",
      "Seen so far: 152896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2389: 1.5390472412109375\n",
      "Seen so far: 152960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2390: 1.3567452430725098\n",
      "Seen so far: 153024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2391: 1.4623042345046997\n",
      "Seen so far: 153088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2392: 1.4544901847839355\n",
      "Seen so far: 153152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2393: 1.6021592617034912\n",
      "Seen so far: 153216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2394: 1.2178456783294678\n",
      "Seen so far: 153280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2395: 1.6840472221374512\n",
      "Seen so far: 153344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2396: 1.4114940166473389\n",
      "Seen so far: 153408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2397: 1.442995309829712\n",
      "Seen so far: 153472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2398: 1.5167561769485474\n",
      "Seen so far: 153536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2399: 1.28997004032135\n",
      "Seen so far: 153600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2400: 1.2987122535705566\n",
      "Seen so far: 153664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2401: 1.38631272315979\n",
      "Seen so far: 153728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2402: 1.3985836505889893\n",
      "Seen so far: 153792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2403: 1.5370075702667236\n",
      "Seen so far: 153856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2404: 1.373613715171814\n",
      "Seen so far: 153920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2405: 1.4821338653564453\n",
      "Seen so far: 153984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2406: 1.3645778894424438\n",
      "Seen so far: 154048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2407: 2.2814321517944336\n",
      "Seen so far: 154112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2408: 1.2364957332611084\n",
      "Seen so far: 154176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2409: 1.5961436033248901\n",
      "Seen so far: 154240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2410: 1.477501392364502\n",
      "Seen so far: 154304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2411: 1.3031213283538818\n",
      "Seen so far: 154368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2412: 1.8049211502075195\n",
      "Seen so far: 154432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2413: 1.7206776142120361\n",
      "Seen so far: 154496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2414: 1.4633965492248535\n",
      "Seen so far: 154560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2415: 1.3341996669769287\n",
      "Seen so far: 154624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2416: 1.4167563915252686\n",
      "Seen so far: 154688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2417: 1.9022023677825928\n",
      "Seen so far: 154752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2418: 1.4863479137420654\n",
      "Seen so far: 154816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2419: 1.3628592491149902\n",
      "Seen so far: 154880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2420: 1.5543001890182495\n",
      "Seen so far: 154944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2421: 1.1809877157211304\n",
      "Seen so far: 155008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2422: 1.4119224548339844\n",
      "Seen so far: 155072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2423: 1.6328535079956055\n",
      "Seen so far: 155136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2424: 1.2515196800231934\n",
      "Seen so far: 155200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2425: 2.069878578186035\n",
      "Seen so far: 155264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2426: 1.4680626392364502\n",
      "Seen so far: 155328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2427: 1.5063979625701904\n",
      "Seen so far: 155392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2428: 1.5169742107391357\n",
      "Seen so far: 155456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2429: 0.9876168370246887\n",
      "Seen so far: 155520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2430: 1.4814836978912354\n",
      "Seen so far: 155584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2431: 1.5768592357635498\n",
      "Seen so far: 155648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2432: 1.3133232593536377\n",
      "Seen so far: 155712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2433: 1.4277489185333252\n",
      "Seen so far: 155776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2434: 1.1872317790985107\n",
      "Seen so far: 155840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2435: 1.530039668083191\n",
      "Seen so far: 155904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2436: 1.5136804580688477\n",
      "Seen so far: 155968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2437: 1.0291036367416382\n",
      "Seen so far: 156032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2438: 1.3018126487731934\n",
      "Seen so far: 156096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2439: 1.5681407451629639\n",
      "Seen so far: 156160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2440: 1.4599881172180176\n",
      "Seen so far: 156224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2441: 1.145737648010254\n",
      "Seen so far: 156288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2442: 1.6367443799972534\n",
      "Seen so far: 156352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2443: 1.5637757778167725\n",
      "Seen so far: 156416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2444: 1.2593926191329956\n",
      "Seen so far: 156480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2445: 1.4088985919952393\n",
      "Seen so far: 156544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2446: 1.210160255432129\n",
      "Seen so far: 156608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2447: 1.0574593544006348\n",
      "Seen so far: 156672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2448: 1.6617040634155273\n",
      "Seen so far: 156736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2449: 1.2024729251861572\n",
      "Seen so far: 156800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2450: 1.4302222728729248\n",
      "Seen so far: 156864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2451: 1.6579773426055908\n",
      "Seen so far: 156928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2452: 1.3634803295135498\n",
      "Seen so far: 156992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2453: 1.3502429723739624\n",
      "Seen so far: 157056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2454: 1.5504120588302612\n",
      "Seen so far: 157120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2455: 1.394711971282959\n",
      "Seen so far: 157184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2456: 1.4337317943572998\n",
      "Seen so far: 157248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2457: 1.9398651123046875\n",
      "Seen so far: 157312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2458: 1.5193485021591187\n",
      "Seen so far: 157376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2459: 1.4166512489318848\n",
      "Seen so far: 157440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2460: 1.2737061977386475\n",
      "Seen so far: 157504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2461: 1.6027474403381348\n",
      "Seen so far: 157568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2462: 1.3726701736450195\n",
      "Seen so far: 157632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2463: 1.4579334259033203\n",
      "Seen so far: 157696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2464: 1.1862611770629883\n",
      "Seen so far: 157760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2465: 1.336491346359253\n",
      "Seen so far: 157824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2466: 2.224743366241455\n",
      "Seen so far: 157888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2467: 1.8409578800201416\n",
      "Seen so far: 157952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2468: 1.596144676208496\n",
      "Seen so far: 158016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2469: 1.365135908126831\n",
      "Seen so far: 158080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2470: 1.4184489250183105\n",
      "Seen so far: 158144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2471: 1.8457257747650146\n",
      "Seen so far: 158208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2472: 1.4345788955688477\n",
      "Seen so far: 158272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2473: 1.478097677230835\n",
      "Seen so far: 158336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2474: 1.7991451025009155\n",
      "Seen so far: 158400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2475: 1.5305018424987793\n",
      "Seen so far: 158464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2476: 1.409864902496338\n",
      "Seen so far: 158528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2477: 1.331502914428711\n",
      "Seen so far: 158592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2478: 1.4380090236663818\n",
      "Seen so far: 158656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2479: 1.998100996017456\n",
      "Seen so far: 158720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2480: 1.3293697834014893\n",
      "Seen so far: 158784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2481: 1.5016913414001465\n",
      "Seen so far: 158848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2482: 1.6738008260726929\n",
      "Seen so far: 158912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2483: 1.5006541013717651\n",
      "Seen so far: 158976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2484: 1.174942970275879\n",
      "Seen so far: 159040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2485: 1.189274549484253\n",
      "Seen so far: 159104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2486: 1.6772899627685547\n",
      "Seen so far: 159168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2487: 1.4689223766326904\n",
      "Seen so far: 159232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2488: 1.4334468841552734\n",
      "Seen so far: 159296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2489: 1.3156635761260986\n",
      "Seen so far: 159360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2490: 1.4304053783416748\n",
      "Seen so far: 159424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2491: 1.3915860652923584\n",
      "Seen so far: 159488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2492: 1.3155393600463867\n",
      "Seen so far: 159552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2493: 1.152258038520813\n",
      "Seen so far: 159616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2494: 1.279139757156372\n",
      "Seen so far: 159680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2495: 1.288472056388855\n",
      "Seen so far: 159744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2496: 1.3780004978179932\n",
      "Seen so far: 159808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2497: 1.4297454357147217\n",
      "Seen so far: 159872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2498: 1.0630748271942139\n",
      "Seen so far: 159936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2499: 1.5205152034759521\n",
      "Seen so far: 160000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2500: 1.8245103359222412\n",
      "Seen so far: 160064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2501: 1.5552842617034912\n",
      "Seen so far: 160128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2502: 0.9247773289680481\n",
      "Seen so far: 160192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2503: 1.4363350868225098\n",
      "Seen so far: 160256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2504: 1.514481544494629\n",
      "Seen so far: 160320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2505: 1.6090725660324097\n",
      "Seen so far: 160384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2506: 1.3765907287597656\n",
      "Seen so far: 160448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2507: 1.641834020614624\n",
      "Seen so far: 160512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2508: 1.2958474159240723\n",
      "Seen so far: 160576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2509: 1.5307183265686035\n",
      "Seen so far: 160640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2510: 1.59088933467865\n",
      "Seen so far: 160704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2511: 1.4421600103378296\n",
      "Seen so far: 160768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2512: 0.8585378527641296\n",
      "Seen so far: 160832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2513: 1.469916582107544\n",
      "Seen so far: 160896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2514: 1.3113352060317993\n",
      "Seen so far: 160960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2515: 1.289656639099121\n",
      "Seen so far: 161024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2516: 1.5247403383255005\n",
      "Seen so far: 161088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2517: 1.3911261558532715\n",
      "Seen so far: 161152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2518: 1.6588789224624634\n",
      "Seen so far: 161216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2519: 1.247614860534668\n",
      "Seen so far: 161280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2520: 1.2255098819732666\n",
      "Seen so far: 161344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2521: 1.1415541172027588\n",
      "Seen so far: 161408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2522: 1.288431167602539\n",
      "Seen so far: 161472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2523: 1.4921650886535645\n",
      "Seen so far: 161536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2524: 1.4459049701690674\n",
      "Seen so far: 161600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2525: 1.4419028759002686\n",
      "Seen so far: 161664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2526: 1.1581306457519531\n",
      "Seen so far: 161728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2527: 1.3191428184509277\n",
      "Seen so far: 161792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2528: 1.9426801204681396\n",
      "Seen so far: 161856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2529: 1.9189623594284058\n",
      "Seen so far: 161920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2530: 0.9080613255500793\n",
      "Seen so far: 161984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2531: 1.362410545349121\n",
      "Seen so far: 162048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2532: 1.1348191499710083\n",
      "Seen so far: 162112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2533: 1.6135475635528564\n",
      "Seen so far: 162176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2534: 1.9107038974761963\n",
      "Seen so far: 162240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2535: 1.1556594371795654\n",
      "Seen so far: 162304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2536: 1.2711460590362549\n",
      "Seen so far: 162368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2537: 1.8385655879974365\n",
      "Seen so far: 162432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2538: 1.1884316205978394\n",
      "Seen so far: 162496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2539: 1.4555389881134033\n",
      "Seen so far: 162560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2540: 1.362292766571045\n",
      "Seen so far: 162624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2541: 1.5889426469802856\n",
      "Seen so far: 162688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2542: 1.255944013595581\n",
      "Seen so far: 162752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2543: 1.5594494342803955\n",
      "Seen so far: 162816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2544: 1.378868818283081\n",
      "Seen so far: 162880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2545: 1.7926392555236816\n",
      "Seen so far: 162944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2546: 1.2195196151733398\n",
      "Seen so far: 163008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2547: 1.458783745765686\n",
      "Seen so far: 163072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2548: 1.8052886724472046\n",
      "Seen so far: 163136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2549: 1.7862401008605957\n",
      "Seen so far: 163200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2550: 1.2425813674926758\n",
      "Seen so far: 163264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2551: 1.1944680213928223\n",
      "Seen so far: 163328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2552: 1.1950962543487549\n",
      "Seen so far: 163392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2553: 1.802091360092163\n",
      "Seen so far: 163456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2554: 1.1672585010528564\n",
      "Seen so far: 163520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2555: 1.2552868127822876\n",
      "Seen so far: 163584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2556: 1.6856410503387451\n",
      "Seen so far: 163648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2557: 1.0384807586669922\n",
      "Seen so far: 163712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2558: 1.3020330667495728\n",
      "Seen so far: 163776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2559: 1.3596264123916626\n",
      "Seen so far: 163840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2560: 1.6669905185699463\n",
      "Seen so far: 163904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2561: 1.4283006191253662\n",
      "Seen so far: 163968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2562: 1.4901797771453857\n",
      "Seen so far: 164032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2563: 1.3476507663726807\n",
      "Seen so far: 164096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2564: 1.444000482559204\n",
      "Seen so far: 164160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2565: 1.366517424583435\n",
      "Seen so far: 164224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2566: 1.2942723035812378\n",
      "Seen so far: 164288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2567: 1.4907023906707764\n",
      "Seen so far: 164352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2568: 1.4286707639694214\n",
      "Seen so far: 164416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2569: 1.210972547531128\n",
      "Seen so far: 164480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2570: 1.2618818283081055\n",
      "Seen so far: 164544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2571: 1.1090247631072998\n",
      "Seen so far: 164608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2572: 1.3159513473510742\n",
      "Seen so far: 164672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2573: 1.0759258270263672\n",
      "Seen so far: 164736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2574: 1.4291024208068848\n",
      "Seen so far: 164800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2575: 1.0861406326293945\n",
      "Seen so far: 164864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2576: 1.6122312545776367\n",
      "Seen so far: 164928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2577: 1.4453516006469727\n",
      "Seen so far: 164992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2578: 1.1475344896316528\n",
      "Seen so far: 165056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2579: 1.1440365314483643\n",
      "Seen so far: 165120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2580: 1.5768853425979614\n",
      "Seen so far: 165184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2581: 1.1335524320602417\n",
      "Seen so far: 165248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2582: 1.6982795000076294\n",
      "Seen so far: 165312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2583: 1.4130816459655762\n",
      "Seen so far: 165376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2584: 0.7673945426940918\n",
      "Seen so far: 165440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2585: 1.0877093076705933\n",
      "Seen so far: 165504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2586: 0.9895158410072327\n",
      "Seen so far: 165568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2587: 1.2383143901824951\n",
      "Seen so far: 165632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2588: 1.4136297702789307\n",
      "Seen so far: 165696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2589: 1.3222495317459106\n",
      "Seen so far: 165760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2590: 1.482679843902588\n",
      "Seen so far: 165824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2591: 1.1009820699691772\n",
      "Seen so far: 165888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2592: 1.2324727773666382\n",
      "Seen so far: 165952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2593: 1.3365750312805176\n",
      "Seen so far: 166016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2594: 1.5189921855926514\n",
      "Seen so far: 166080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2595: 1.6832510232925415\n",
      "Seen so far: 166144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2596: 1.352952003479004\n",
      "Seen so far: 166208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2597: 1.8415820598602295\n",
      "Seen so far: 166272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2598: 1.951784372329712\n",
      "Seen so far: 166336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2599: 1.4329631328582764\n",
      "Seen so far: 166400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2600: 1.230156421661377\n",
      "Seen so far: 166464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2601: 1.4833049774169922\n",
      "Seen so far: 166528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2602: 1.1531469821929932\n",
      "Seen so far: 166592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2603: 1.1021790504455566\n",
      "Seen so far: 166656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2604: 1.6652196645736694\n",
      "Seen so far: 166720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2605: 1.7987960577011108\n",
      "Seen so far: 166784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2606: 1.8765507936477661\n",
      "Seen so far: 166848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2607: 1.9094518423080444\n",
      "Seen so far: 166912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2608: 1.4375\n",
      "Seen so far: 166976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2609: 1.2925004959106445\n",
      "Seen so far: 167040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2610: 1.0751383304595947\n",
      "Seen so far: 167104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2611: 1.543177843093872\n",
      "Seen so far: 167168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2612: 1.7324953079223633\n",
      "Seen so far: 167232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2613: 1.3411884307861328\n",
      "Seen so far: 167296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2614: 1.3840659856796265\n",
      "Seen so far: 167360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2615: 1.2637810707092285\n",
      "Seen so far: 167424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2616: 1.1899077892303467\n",
      "Seen so far: 167488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2617: 1.6560618877410889\n",
      "Seen so far: 167552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2618: 1.6583589315414429\n",
      "Seen so far: 167616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2619: 1.8329349756240845\n",
      "Seen so far: 167680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2620: 1.1573784351348877\n",
      "Seen so far: 167744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2621: 1.4539551734924316\n",
      "Seen so far: 167808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2622: 1.6636048555374146\n",
      "Seen so far: 167872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2623: 1.400238275527954\n",
      "Seen so far: 167936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2624: 1.313023328781128\n",
      "Seen so far: 168000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2625: 1.1794559955596924\n",
      "Seen so far: 168064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2626: 1.2663369178771973\n",
      "Seen so far: 168128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2627: 1.2978038787841797\n",
      "Seen so far: 168192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2628: 0.9376627206802368\n",
      "Seen so far: 168256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2629: 1.2128374576568604\n",
      "Seen so far: 168320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2630: 1.4924473762512207\n",
      "Seen so far: 168384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2631: 1.558424472808838\n",
      "Seen so far: 168448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2632: 1.1458395719528198\n",
      "Seen so far: 168512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2633: 1.3090400695800781\n",
      "Seen so far: 168576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2634: 1.4349948167800903\n",
      "Seen so far: 168640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2635: 1.4617621898651123\n",
      "Seen so far: 168704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2636: 1.6233426332473755\n",
      "Seen so far: 168768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2637: 1.22969651222229\n",
      "Seen so far: 168832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2638: 1.8047521114349365\n",
      "Seen so far: 168896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2639: 1.425016164779663\n",
      "Seen so far: 168960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2640: 1.4192380905151367\n",
      "Seen so far: 169024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2641: 1.2332868576049805\n",
      "Seen so far: 169088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2642: 1.4029579162597656\n",
      "Seen so far: 169152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2643: 1.3378076553344727\n",
      "Seen so far: 169216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2644: 1.2596988677978516\n",
      "Seen so far: 169280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2645: 1.3223322629928589\n",
      "Seen so far: 169344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2646: 1.3629698753356934\n",
      "Seen so far: 169408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2647: 1.4331016540527344\n",
      "Seen so far: 169472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2648: 1.2525827884674072\n",
      "Seen so far: 169536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2649: 1.527980089187622\n",
      "Seen so far: 169600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2650: 1.4308037757873535\n",
      "Seen so far: 169664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2651: 1.760678768157959\n",
      "Seen so far: 169728 samples\n",
      "Training acc over epoch: 0.41969284415245056\n",
      "Start of epoch 1\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 0: 0.9605872631072998\n",
      "Seen so far: 64 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1: 1.3544485569000244\n",
      "Seen so far: 128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2: 1.0481116771697998\n",
      "Seen so far: 192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 3: 1.2367281913757324\n",
      "Seen so far: 256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 4: 1.022662878036499\n",
      "Seen so far: 320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 5: 1.705700397491455\n",
      "Seen so far: 384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 6: 1.5612766742706299\n",
      "Seen so far: 448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 7: 1.5394024848937988\n",
      "Seen so far: 512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 8: 1.5608651638031006\n",
      "Seen so far: 576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 9: 1.4583210945129395\n",
      "Seen so far: 640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 10: 1.2297781705856323\n",
      "Seen so far: 704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 11: 1.0963739156723022\n",
      "Seen so far: 768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 12: 1.2069830894470215\n",
      "Seen so far: 832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 13: 1.204674482345581\n",
      "Seen so far: 896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 14: 1.8181331157684326\n",
      "Seen so far: 960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 15: 1.433034896850586\n",
      "Seen so far: 1024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 16: 1.719413161277771\n",
      "Seen so far: 1088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 17: 1.8360559940338135\n",
      "Seen so far: 1152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 18: 1.3898859024047852\n",
      "Seen so far: 1216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 19: 1.9520281553268433\n",
      "Seen so far: 1280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 20: 0.9472126960754395\n",
      "Seen so far: 1344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 21: 1.679398536682129\n",
      "Seen so far: 1408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 22: 1.4656174182891846\n",
      "Seen so far: 1472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 23: 1.969163179397583\n",
      "Seen so far: 1536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 24: 1.1027789115905762\n",
      "Seen so far: 1600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 25: 1.2761846780776978\n",
      "Seen so far: 1664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 26: 1.5305848121643066\n",
      "Seen so far: 1728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 27: 1.6484200954437256\n",
      "Seen so far: 1792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 28: 1.3047218322753906\n",
      "Seen so far: 1856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 29: 1.671545147895813\n",
      "Seen so far: 1920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 30: 1.233762264251709\n",
      "Seen so far: 1984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 31: 1.4112248420715332\n",
      "Seen so far: 2048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 32: 1.6553874015808105\n",
      "Seen so far: 2112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 33: 1.5014464855194092\n",
      "Seen so far: 2176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 34: 1.38741934299469\n",
      "Seen so far: 2240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 35: 1.8444095849990845\n",
      "Seen so far: 2304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 36: 1.1857895851135254\n",
      "Seen so far: 2368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 37: 1.5193488597869873\n",
      "Seen so far: 2432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 38: 1.3383076190948486\n",
      "Seen so far: 2496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 39: 1.7059599161148071\n",
      "Seen so far: 2560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 40: 1.2473630905151367\n",
      "Seen so far: 2624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 41: 2.0956499576568604\n",
      "Seen so far: 2688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 42: 1.4491088390350342\n",
      "Seen so far: 2752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 43: 1.3239045143127441\n",
      "Seen so far: 2816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 44: 1.4026119709014893\n",
      "Seen so far: 2880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 45: 1.721163272857666\n",
      "Seen so far: 2944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 46: 1.3445394039154053\n",
      "Seen so far: 3008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 47: 1.0291422605514526\n",
      "Seen so far: 3072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 48: 1.350770354270935\n",
      "Seen so far: 3136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 49: 1.394620656967163\n",
      "Seen so far: 3200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 50: 1.4900548458099365\n",
      "Seen so far: 3264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 51: 1.7042970657348633\n",
      "Seen so far: 3328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 52: 1.378645420074463\n",
      "Seen so far: 3392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 53: 1.3387000560760498\n",
      "Seen so far: 3456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 54: 1.3728474378585815\n",
      "Seen so far: 3520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 55: 1.80136239528656\n",
      "Seen so far: 3584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 56: 1.7116905450820923\n",
      "Seen so far: 3648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 57: 1.7266502380371094\n",
      "Seen so far: 3712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 58: 1.1589975357055664\n",
      "Seen so far: 3776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 59: 1.4538809061050415\n",
      "Seen so far: 3840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 60: 0.8344707489013672\n",
      "Seen so far: 3904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 61: 1.226416826248169\n",
      "Seen so far: 3968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 62: 1.4062579870224\n",
      "Seen so far: 4032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 63: 1.1861120462417603\n",
      "Seen so far: 4096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 64: 1.5273100137710571\n",
      "Seen so far: 4160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 65: 1.0786340236663818\n",
      "Seen so far: 4224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 66: 1.658247470855713\n",
      "Seen so far: 4288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 67: 1.5695030689239502\n",
      "Seen so far: 4352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 68: 1.3780670166015625\n",
      "Seen so far: 4416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 69: 1.186232328414917\n",
      "Seen so far: 4480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 70: 1.1905441284179688\n",
      "Seen so far: 4544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 71: 1.6031711101531982\n",
      "Seen so far: 4608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 72: 1.2787494659423828\n",
      "Seen so far: 4672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 73: 1.1455895900726318\n",
      "Seen so far: 4736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 74: 1.2076530456542969\n",
      "Seen so far: 4800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 75: 1.3240216970443726\n",
      "Seen so far: 4864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 76: 1.6514393091201782\n",
      "Seen so far: 4928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 77: 1.234372854232788\n",
      "Seen so far: 4992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 78: 1.5112053155899048\n",
      "Seen so far: 5056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 79: 1.7072062492370605\n",
      "Seen so far: 5120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 80: 1.1523998975753784\n",
      "Seen so far: 5184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 81: 1.4743223190307617\n",
      "Seen so far: 5248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 82: 1.1497888565063477\n",
      "Seen so far: 5312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 83: 1.3733835220336914\n",
      "Seen so far: 5376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 84: 1.2402050495147705\n",
      "Seen so far: 5440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 85: 1.4525768756866455\n",
      "Seen so far: 5504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 86: 1.2726253271102905\n",
      "Seen so far: 5568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 87: 1.5658290386199951\n",
      "Seen so far: 5632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 88: 1.2739877700805664\n",
      "Seen so far: 5696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 89: 1.4500181674957275\n",
      "Seen so far: 5760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 90: 1.5021600723266602\n",
      "Seen so far: 5824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 91: 1.5871186256408691\n",
      "Seen so far: 5888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 92: 1.0848275423049927\n",
      "Seen so far: 5952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 93: 1.7080557346343994\n",
      "Seen so far: 6016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 94: 1.6048028469085693\n",
      "Seen so far: 6080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 95: 1.2592817544937134\n",
      "Seen so far: 6144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 96: 1.7785930633544922\n",
      "Seen so far: 6208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 97: 1.7319046258926392\n",
      "Seen so far: 6272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 98: 1.4321367740631104\n",
      "Seen so far: 6336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 99: 1.282313585281372\n",
      "Seen so far: 6400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 100: 1.3956310749053955\n",
      "Seen so far: 6464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 101: 0.9213790893554688\n",
      "Seen so far: 6528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 102: 1.0597403049468994\n",
      "Seen so far: 6592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 103: 1.0768120288848877\n",
      "Seen so far: 6656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 104: 1.4422365427017212\n",
      "Seen so far: 6720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 105: 1.5776339769363403\n",
      "Seen so far: 6784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 106: 1.323790431022644\n",
      "Seen so far: 6848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 107: 1.8169435262680054\n",
      "Seen so far: 6912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 108: 1.2788820266723633\n",
      "Seen so far: 6976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 109: 1.3646072149276733\n",
      "Seen so far: 7040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 110: 1.1922204494476318\n",
      "Seen so far: 7104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 111: 1.3549911975860596\n",
      "Seen so far: 7168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 112: 0.940261721611023\n",
      "Seen so far: 7232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 113: 1.358612298965454\n",
      "Seen so far: 7296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 114: 1.4927594661712646\n",
      "Seen so far: 7360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 115: 1.3399322032928467\n",
      "Seen so far: 7424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 116: 1.4436943531036377\n",
      "Seen so far: 7488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 117: 1.580151915550232\n",
      "Seen so far: 7552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 118: 1.7182068824768066\n",
      "Seen so far: 7616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 119: 1.3745601177215576\n",
      "Seen so far: 7680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 120: 1.3797566890716553\n",
      "Seen so far: 7744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 121: 1.5070703029632568\n",
      "Seen so far: 7808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 122: 1.7275290489196777\n",
      "Seen so far: 7872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 123: 1.0256168842315674\n",
      "Seen so far: 7936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 124: 1.4006247520446777\n",
      "Seen so far: 8000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 125: 1.4321718215942383\n",
      "Seen so far: 8064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 126: 1.1945075988769531\n",
      "Seen so far: 8128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 127: 1.644012212753296\n",
      "Seen so far: 8192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 128: 1.019627332687378\n",
      "Seen so far: 8256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 129: 1.3490042686462402\n",
      "Seen so far: 8320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 130: 1.4023891687393188\n",
      "Seen so far: 8384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 131: 1.5568976402282715\n",
      "Seen so far: 8448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 132: 1.5805250406265259\n",
      "Seen so far: 8512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 133: 1.2170350551605225\n",
      "Seen so far: 8576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 134: 1.427451491355896\n",
      "Seen so far: 8640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 135: 1.532721996307373\n",
      "Seen so far: 8704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 136: 1.5582170486450195\n",
      "Seen so far: 8768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 137: 1.523958444595337\n",
      "Seen so far: 8832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 138: 1.2488510608673096\n",
      "Seen so far: 8896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 139: 1.2326939105987549\n",
      "Seen so far: 8960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 140: 1.2175707817077637\n",
      "Seen so far: 9024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 141: 1.570917010307312\n",
      "Seen so far: 9088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 142: 1.308978796005249\n",
      "Seen so far: 9152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 143: 1.4191491603851318\n",
      "Seen so far: 9216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 144: 1.647384762763977\n",
      "Seen so far: 9280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 145: 1.1672916412353516\n",
      "Seen so far: 9344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 146: 1.4536457061767578\n",
      "Seen so far: 9408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 147: 1.377551555633545\n",
      "Seen so far: 9472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 148: 1.744903564453125\n",
      "Seen so far: 9536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 149: 1.4690098762512207\n",
      "Seen so far: 9600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 150: 1.1861505508422852\n",
      "Seen so far: 9664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 151: 1.5075702667236328\n",
      "Seen so far: 9728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 152: 1.769170880317688\n",
      "Seen so far: 9792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 153: 1.6978442668914795\n",
      "Seen so far: 9856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 154: 1.8888812065124512\n",
      "Seen so far: 9920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 155: 1.2592363357543945\n",
      "Seen so far: 9984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 156: 1.4274842739105225\n",
      "Seen so far: 10048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 157: 1.1189556121826172\n",
      "Seen so far: 10112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 158: 1.9635412693023682\n",
      "Seen so far: 10176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 159: 1.634556770324707\n",
      "Seen so far: 10240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 160: 1.3904145956039429\n",
      "Seen so far: 10304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 161: 1.3926130533218384\n",
      "Seen so far: 10368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 162: 1.7549182176589966\n",
      "Seen so far: 10432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 163: 1.2473247051239014\n",
      "Seen so far: 10496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 164: 1.488067626953125\n",
      "Seen so far: 10560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 165: 1.2238264083862305\n",
      "Seen so far: 10624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 166: 0.9696829319000244\n",
      "Seen so far: 10688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 167: 1.0900624990463257\n",
      "Seen so far: 10752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 168: 1.3939251899719238\n",
      "Seen so far: 10816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 169: 1.2155604362487793\n",
      "Seen so far: 10880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 170: 1.4046169519424438\n",
      "Seen so far: 10944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 171: 1.6227856874465942\n",
      "Seen so far: 11008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 172: 1.4426710605621338\n",
      "Seen so far: 11072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 173: 1.4562218189239502\n",
      "Seen so far: 11136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 174: 1.4542677402496338\n",
      "Seen so far: 11200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 175: 1.3457112312316895\n",
      "Seen so far: 11264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 176: 1.5143795013427734\n",
      "Seen so far: 11328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 177: 1.3379724025726318\n",
      "Seen so far: 11392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 178: 1.2998640537261963\n",
      "Seen so far: 11456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 179: 1.258345127105713\n",
      "Seen so far: 11520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 180: 1.3406879901885986\n",
      "Seen so far: 11584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 181: 1.544313907623291\n",
      "Seen so far: 11648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 182: 1.4660807847976685\n",
      "Seen so far: 11712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 183: 1.5672756433486938\n",
      "Seen so far: 11776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 184: 1.4659178256988525\n",
      "Seen so far: 11840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 185: 1.5777137279510498\n",
      "Seen so far: 11904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 186: 1.389669418334961\n",
      "Seen so far: 11968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 187: 1.5067285299301147\n",
      "Seen so far: 12032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 188: 1.3273571729660034\n",
      "Seen so far: 12096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 189: 1.338369369506836\n",
      "Seen so far: 12160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 190: 1.5564719438552856\n",
      "Seen so far: 12224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 191: 1.1089303493499756\n",
      "Seen so far: 12288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 192: 1.3800511360168457\n",
      "Seen so far: 12352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 193: 1.514027714729309\n",
      "Seen so far: 12416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 194: 1.6954163312911987\n",
      "Seen so far: 12480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 195: 1.3049721717834473\n",
      "Seen so far: 12544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 196: 1.1817734241485596\n",
      "Seen so far: 12608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 197: 1.0204468965530396\n",
      "Seen so far: 12672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 198: 1.8735153675079346\n",
      "Seen so far: 12736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 199: 1.4288008213043213\n",
      "Seen so far: 12800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 200: 1.3787420988082886\n",
      "Seen so far: 12864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 201: 1.114151954650879\n",
      "Seen so far: 12928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 202: 1.490445613861084\n",
      "Seen so far: 12992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 203: 1.6722922325134277\n",
      "Seen so far: 13056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 204: 1.2124958038330078\n",
      "Seen so far: 13120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 205: 1.214264988899231\n",
      "Seen so far: 13184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 206: 1.6359100341796875\n",
      "Seen so far: 13248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 207: 1.4300892353057861\n",
      "Seen so far: 13312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 208: 1.4420713186264038\n",
      "Seen so far: 13376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 209: 1.4309947490692139\n",
      "Seen so far: 13440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 210: 1.46978759765625\n",
      "Seen so far: 13504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 211: 1.3335225582122803\n",
      "Seen so far: 13568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 212: 1.5969702005386353\n",
      "Seen so far: 13632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 213: 1.689063310623169\n",
      "Seen so far: 13696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 214: 1.4362221956253052\n",
      "Seen so far: 13760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 215: 1.4605578184127808\n",
      "Seen so far: 13824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 216: 1.2544687986373901\n",
      "Seen so far: 13888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 217: 1.3304541110992432\n",
      "Seen so far: 13952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 218: 1.1469128131866455\n",
      "Seen so far: 14016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 219: 1.3515962362289429\n",
      "Seen so far: 14080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 220: 1.4108076095581055\n",
      "Seen so far: 14144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 221: 1.2457902431488037\n",
      "Seen so far: 14208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 222: 1.5030953884124756\n",
      "Seen so far: 14272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 223: 1.4155309200286865\n",
      "Seen so far: 14336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 224: 1.3253282308578491\n",
      "Seen so far: 14400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 225: 1.675674319267273\n",
      "Seen so far: 14464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 226: 1.143951654434204\n",
      "Seen so far: 14528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 227: 1.3779842853546143\n",
      "Seen so far: 14592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 228: 1.4550459384918213\n",
      "Seen so far: 14656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 229: 1.5905964374542236\n",
      "Seen so far: 14720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 230: 1.194153070449829\n",
      "Seen so far: 14784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 231: 1.4097838401794434\n",
      "Seen so far: 14848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 232: 1.4179142713546753\n",
      "Seen so far: 14912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 233: 1.4824228286743164\n",
      "Seen so far: 14976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 234: 1.2443336248397827\n",
      "Seen so far: 15040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 235: 1.3405325412750244\n",
      "Seen so far: 15104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 236: 1.47538161277771\n",
      "Seen so far: 15168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 237: 1.5767369270324707\n",
      "Seen so far: 15232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 238: 1.8401380777359009\n",
      "Seen so far: 15296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 239: 1.4420359134674072\n",
      "Seen so far: 15360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 240: 1.4551520347595215\n",
      "Seen so far: 15424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 241: 1.4149876832962036\n",
      "Seen so far: 15488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 242: 1.479453682899475\n",
      "Seen so far: 15552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 243: 1.2355438470840454\n",
      "Seen so far: 15616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 244: 1.437779426574707\n",
      "Seen so far: 15680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 245: 1.4685547351837158\n",
      "Seen so far: 15744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 246: 1.6485862731933594\n",
      "Seen so far: 15808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 247: 1.413214921951294\n",
      "Seen so far: 15872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 248: 1.3067269325256348\n",
      "Seen so far: 15936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 249: 1.3046705722808838\n",
      "Seen so far: 16000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 250: 1.5004962682724\n",
      "Seen so far: 16064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 251: 1.3874472379684448\n",
      "Seen so far: 16128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 252: 1.6642885208129883\n",
      "Seen so far: 16192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 253: 1.4596774578094482\n",
      "Seen so far: 16256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 254: 1.318593978881836\n",
      "Seen so far: 16320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 255: 1.3469882011413574\n",
      "Seen so far: 16384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 256: 1.3819334506988525\n",
      "Seen so far: 16448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 257: 1.8242231607437134\n",
      "Seen so far: 16512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 258: 1.3912500143051147\n",
      "Seen so far: 16576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 259: 1.4824271202087402\n",
      "Seen so far: 16640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 260: 0.9416320323944092\n",
      "Seen so far: 16704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 261: 1.286301612854004\n",
      "Seen so far: 16768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 262: 1.8905264139175415\n",
      "Seen so far: 16832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 263: 1.481630802154541\n",
      "Seen so far: 16896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 264: 1.0736387968063354\n",
      "Seen so far: 16960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 265: 1.4703561067581177\n",
      "Seen so far: 17024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 266: 0.9540882110595703\n",
      "Seen so far: 17088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 267: 1.2270081043243408\n",
      "Seen so far: 17152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 268: 1.136361837387085\n",
      "Seen so far: 17216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 269: 1.3836371898651123\n",
      "Seen so far: 17280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 270: 1.1424169540405273\n",
      "Seen so far: 17344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 271: 1.2828428745269775\n",
      "Seen so far: 17408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 272: 1.0845011472702026\n",
      "Seen so far: 17472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 273: 1.7437124252319336\n",
      "Seen so far: 17536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 274: 1.3274580240249634\n",
      "Seen so far: 17600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 275: 1.0817949771881104\n",
      "Seen so far: 17664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 276: 1.8153923749923706\n",
      "Seen so far: 17728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 277: 1.8303865194320679\n",
      "Seen so far: 17792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 278: 1.4639437198638916\n",
      "Seen so far: 17856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 279: 1.718531847000122\n",
      "Seen so far: 17920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 280: 1.192395567893982\n",
      "Seen so far: 17984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 281: 1.3483649492263794\n",
      "Seen so far: 18048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 282: 1.2678157091140747\n",
      "Seen so far: 18112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 283: 0.9701173901557922\n",
      "Seen so far: 18176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 284: 1.1650217771530151\n",
      "Seen so far: 18240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 285: 1.0431681871414185\n",
      "Seen so far: 18304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 286: 1.2075930833816528\n",
      "Seen so far: 18368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 287: 1.2132608890533447\n",
      "Seen so far: 18432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 288: 1.4317433834075928\n",
      "Seen so far: 18496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 289: 1.1067372560501099\n",
      "Seen so far: 18560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 290: 1.526185393333435\n",
      "Seen so far: 18624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 291: 0.8631417155265808\n",
      "Seen so far: 18688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 292: 1.6542812585830688\n",
      "Seen so far: 18752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 293: 1.3561594486236572\n",
      "Seen so far: 18816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 294: 1.132943868637085\n",
      "Seen so far: 18880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 295: 1.2970788478851318\n",
      "Seen so far: 18944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 296: 1.4914556741714478\n",
      "Seen so far: 19008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 297: 1.2961795330047607\n",
      "Seen so far: 19072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 298: 1.1865299940109253\n",
      "Seen so far: 19136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 299: 1.76102614402771\n",
      "Seen so far: 19200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 300: 0.8326023817062378\n",
      "Seen so far: 19264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 301: 1.226822853088379\n",
      "Seen so far: 19328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 302: 1.2634525299072266\n",
      "Seen so far: 19392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 303: 1.292720913887024\n",
      "Seen so far: 19456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 304: 1.5263031721115112\n",
      "Seen so far: 19520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 305: 1.5858092308044434\n",
      "Seen so far: 19584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 306: 1.632716178894043\n",
      "Seen so far: 19648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 307: 1.6135032176971436\n",
      "Seen so far: 19712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 308: 1.620263695716858\n",
      "Seen so far: 19776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 309: 1.027292013168335\n",
      "Seen so far: 19840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 310: 1.6985361576080322\n",
      "Seen so far: 19904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 311: 1.2487030029296875\n",
      "Seen so far: 19968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 312: 1.5277929306030273\n",
      "Seen so far: 20032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 313: 1.1581300497055054\n",
      "Seen so far: 20096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 314: 1.3760335445404053\n",
      "Seen so far: 20160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 315: 1.3156179189682007\n",
      "Seen so far: 20224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 316: 1.3450284004211426\n",
      "Seen so far: 20288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 317: 1.3485677242279053\n",
      "Seen so far: 20352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 318: 1.1735273599624634\n",
      "Seen so far: 20416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 319: 1.3469667434692383\n",
      "Seen so far: 20480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 320: 1.3489327430725098\n",
      "Seen so far: 20544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 321: 1.1496317386627197\n",
      "Seen so far: 20608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 322: 1.2822449207305908\n",
      "Seen so far: 20672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 323: 1.5456362962722778\n",
      "Seen so far: 20736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 324: 1.7039785385131836\n",
      "Seen so far: 20800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 325: 0.9880648255348206\n",
      "Seen so far: 20864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 326: 1.0181941986083984\n",
      "Seen so far: 20928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 327: 1.3982839584350586\n",
      "Seen so far: 20992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 328: 1.2971007823944092\n",
      "Seen so far: 21056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 329: 1.4225391149520874\n",
      "Seen so far: 21120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 330: 1.5098761320114136\n",
      "Seen so far: 21184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 331: 1.262568473815918\n",
      "Seen so far: 21248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 332: 1.3151395320892334\n",
      "Seen so far: 21312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 333: 1.3338117599487305\n",
      "Seen so far: 21376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 334: 1.157851219177246\n",
      "Seen so far: 21440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 335: 1.3875101804733276\n",
      "Seen so far: 21504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 336: 1.5371341705322266\n",
      "Seen so far: 21568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 337: 1.1213496923446655\n",
      "Seen so far: 21632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 338: 1.3296349048614502\n",
      "Seen so far: 21696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 339: 1.1062228679656982\n",
      "Seen so far: 21760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 340: 1.422364354133606\n",
      "Seen so far: 21824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 341: 1.7694804668426514\n",
      "Seen so far: 21888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 342: 1.488041877746582\n",
      "Seen so far: 21952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 343: 1.422212839126587\n",
      "Seen so far: 22016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 344: 1.3045763969421387\n",
      "Seen so far: 22080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 345: 1.446007251739502\n",
      "Seen so far: 22144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 346: 1.282822608947754\n",
      "Seen so far: 22208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 347: 1.5766310691833496\n",
      "Seen so far: 22272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 348: 1.1290452480316162\n",
      "Seen so far: 22336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 349: 1.4171745777130127\n",
      "Seen so far: 22400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 350: 1.4299070835113525\n",
      "Seen so far: 22464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 351: 1.2949354648590088\n",
      "Seen so far: 22528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 352: 1.5841789245605469\n",
      "Seen so far: 22592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 353: 1.4607818126678467\n",
      "Seen so far: 22656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 354: 1.4608501195907593\n",
      "Seen so far: 22720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 355: 1.5173941850662231\n",
      "Seen so far: 22784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 356: 0.9164336323738098\n",
      "Seen so far: 22848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 357: 1.5208275318145752\n",
      "Seen so far: 22912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 358: 1.5895109176635742\n",
      "Seen so far: 22976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 359: 1.676500916481018\n",
      "Seen so far: 23040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 360: 1.4640369415283203\n",
      "Seen so far: 23104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 361: 1.3672893047332764\n",
      "Seen so far: 23168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 362: 1.4619985818862915\n",
      "Seen so far: 23232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 363: 1.1660656929016113\n",
      "Seen so far: 23296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 364: 1.331454873085022\n",
      "Seen so far: 23360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 365: 1.7291555404663086\n",
      "Seen so far: 23424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 366: 1.3384946584701538\n",
      "Seen so far: 23488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 367: 1.4234575033187866\n",
      "Seen so far: 23552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 368: 1.7182999849319458\n",
      "Seen so far: 23616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 369: 1.7919436693191528\n",
      "Seen so far: 23680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 370: 1.0925625562667847\n",
      "Seen so far: 23744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 371: 1.4333995580673218\n",
      "Seen so far: 23808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 372: 1.1833863258361816\n",
      "Seen so far: 23872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 373: 1.4605860710144043\n",
      "Seen so far: 23936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 374: 1.4721479415893555\n",
      "Seen so far: 24000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 375: 1.2352044582366943\n",
      "Seen so far: 24064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 376: 1.1457830667495728\n",
      "Seen so far: 24128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 377: 1.396396279335022\n",
      "Seen so far: 24192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 378: 1.2287365198135376\n",
      "Seen so far: 24256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 379: 1.082416296005249\n",
      "Seen so far: 24320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 380: 1.5354928970336914\n",
      "Seen so far: 24384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 381: 1.2949503660202026\n",
      "Seen so far: 24448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 382: 1.3223533630371094\n",
      "Seen so far: 24512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 383: 1.7791928052902222\n",
      "Seen so far: 24576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 384: 1.200028419494629\n",
      "Seen so far: 24640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 385: 1.5380322933197021\n",
      "Seen so far: 24704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 386: 1.9791709184646606\n",
      "Seen so far: 24768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 387: 1.3696753978729248\n",
      "Seen so far: 24832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 388: 1.5003283023834229\n",
      "Seen so far: 24896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 389: 1.2680635452270508\n",
      "Seen so far: 24960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 390: 1.4042079448699951\n",
      "Seen so far: 25024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 391: 1.245818853378296\n",
      "Seen so far: 25088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 392: 1.2197364568710327\n",
      "Seen so far: 25152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 393: 1.3949651718139648\n",
      "Seen so far: 25216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 394: 1.0326035022735596\n",
      "Seen so far: 25280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 395: 1.4714728593826294\n",
      "Seen so far: 25344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 396: 1.4374969005584717\n",
      "Seen so far: 25408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 397: 1.4582293033599854\n",
      "Seen so far: 25472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 398: 1.0337340831756592\n",
      "Seen so far: 25536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 399: 1.4002013206481934\n",
      "Seen so far: 25600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 400: 0.9610662460327148\n",
      "Seen so far: 25664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 401: 1.2095321416854858\n",
      "Seen so far: 25728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 402: 1.538827657699585\n",
      "Seen so far: 25792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 403: 1.2088451385498047\n",
      "Seen so far: 25856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 404: 1.0991606712341309\n",
      "Seen so far: 25920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 405: 1.1095325946807861\n",
      "Seen so far: 25984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 406: 1.6050472259521484\n",
      "Seen so far: 26048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 407: 1.513025164604187\n",
      "Seen so far: 26112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 408: 1.3157479763031006\n",
      "Seen so far: 26176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 409: 1.2725839614868164\n",
      "Seen so far: 26240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 410: 1.146936058998108\n",
      "Seen so far: 26304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 411: 1.7507497072219849\n",
      "Seen so far: 26368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 412: 1.466221809387207\n",
      "Seen so far: 26432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 413: 1.2931411266326904\n",
      "Seen so far: 26496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 414: 0.8903499841690063\n",
      "Seen so far: 26560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 415: 1.3520711660385132\n",
      "Seen so far: 26624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 416: 1.4604994058609009\n",
      "Seen so far: 26688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 417: 1.5987138748168945\n",
      "Seen so far: 26752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 418: 1.698999285697937\n",
      "Seen so far: 26816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 419: 1.8153736591339111\n",
      "Seen so far: 26880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 420: 1.2713288068771362\n",
      "Seen so far: 26944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 421: 1.7084131240844727\n",
      "Seen so far: 27008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 422: 1.099684238433838\n",
      "Seen so far: 27072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 423: 1.4844995737075806\n",
      "Seen so far: 27136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 424: 1.5690300464630127\n",
      "Seen so far: 27200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 425: 1.407820224761963\n",
      "Seen so far: 27264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 426: 1.111886739730835\n",
      "Seen so far: 27328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 427: 1.4554026126861572\n",
      "Seen so far: 27392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 428: 1.1349780559539795\n",
      "Seen so far: 27456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 429: 1.3953609466552734\n",
      "Seen so far: 27520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 430: 1.1478040218353271\n",
      "Seen so far: 27584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 431: 1.4153332710266113\n",
      "Seen so far: 27648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 432: 1.6022045612335205\n",
      "Seen so far: 27712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 433: 1.1646450757980347\n",
      "Seen so far: 27776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 434: 1.1743214130401611\n",
      "Seen so far: 27840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 435: 1.6257410049438477\n",
      "Seen so far: 27904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 436: 1.339412808418274\n",
      "Seen so far: 27968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 437: 1.3766517639160156\n",
      "Seen so far: 28032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 438: 1.6674084663391113\n",
      "Seen so far: 28096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 439: 1.3938289880752563\n",
      "Seen so far: 28160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 440: 1.6030511856079102\n",
      "Seen so far: 28224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 441: 1.4470181465148926\n",
      "Seen so far: 28288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 442: 1.3816337585449219\n",
      "Seen so far: 28352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 443: 0.8642531633377075\n",
      "Seen so far: 28416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 444: 1.5796000957489014\n",
      "Seen so far: 28480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 445: 1.3440879583358765\n",
      "Seen so far: 28544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 446: 1.3176608085632324\n",
      "Seen so far: 28608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 447: 1.2053751945495605\n",
      "Seen so far: 28672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 448: 1.498497724533081\n",
      "Seen so far: 28736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 449: 1.5623594522476196\n",
      "Seen so far: 28800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 450: 1.8183059692382812\n",
      "Seen so far: 28864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 451: 1.437077283859253\n",
      "Seen so far: 28928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 452: 1.3526512384414673\n",
      "Seen so far: 28992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 453: 1.4557301998138428\n",
      "Seen so far: 29056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 454: 1.5056512355804443\n",
      "Seen so far: 29120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 455: 1.1781997680664062\n",
      "Seen so far: 29184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 456: 1.305633783340454\n",
      "Seen so far: 29248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 457: 1.0584475994110107\n",
      "Seen so far: 29312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 458: 1.3748399019241333\n",
      "Seen so far: 29376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 459: 1.334057331085205\n",
      "Seen so far: 29440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 460: 1.4145493507385254\n",
      "Seen so far: 29504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 461: 1.3687942028045654\n",
      "Seen so far: 29568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 462: 1.2784135341644287\n",
      "Seen so far: 29632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 463: 1.420699119567871\n",
      "Seen so far: 29696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 464: 1.3195154666900635\n",
      "Seen so far: 29760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 465: 1.0264179706573486\n",
      "Seen so far: 29824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 466: 1.3722361326217651\n",
      "Seen so far: 29888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 467: 1.2321252822875977\n",
      "Seen so far: 29952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 468: 1.3266487121582031\n",
      "Seen so far: 30016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 469: 1.2452701330184937\n",
      "Seen so far: 30080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 470: 1.6760592460632324\n",
      "Seen so far: 30144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 471: 1.2299929857254028\n",
      "Seen so far: 30208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 472: 1.1018826961517334\n",
      "Seen so far: 30272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 473: 1.2765895128250122\n",
      "Seen so far: 30336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 474: 1.6885863542556763\n",
      "Seen so far: 30400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 475: 1.521010398864746\n",
      "Seen so far: 30464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 476: 1.2121645212173462\n",
      "Seen so far: 30528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 477: 1.7419798374176025\n",
      "Seen so far: 30592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 478: 1.2167649269104004\n",
      "Seen so far: 30656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 479: 1.484735131263733\n",
      "Seen so far: 30720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 480: 1.0952918529510498\n",
      "Seen so far: 30784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 481: 1.158928394317627\n",
      "Seen so far: 30848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 482: 1.5164437294006348\n",
      "Seen so far: 30912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 483: 1.5000818967819214\n",
      "Seen so far: 30976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 484: 1.252368688583374\n",
      "Seen so far: 31040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 485: 1.0701103210449219\n",
      "Seen so far: 31104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 486: 1.6540048122406006\n",
      "Seen so far: 31168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 487: 1.2757939100265503\n",
      "Seen so far: 31232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 488: 1.2858067750930786\n",
      "Seen so far: 31296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 489: 1.531630039215088\n",
      "Seen so far: 31360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 490: 1.2204545736312866\n",
      "Seen so far: 31424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 491: 1.255537986755371\n",
      "Seen so far: 31488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 492: 1.3380911350250244\n",
      "Seen so far: 31552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 493: 1.2439558506011963\n",
      "Seen so far: 31616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 494: 0.9774755239486694\n",
      "Seen so far: 31680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 495: 1.458315134048462\n",
      "Seen so far: 31744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 496: 1.2656912803649902\n",
      "Seen so far: 31808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 497: 1.3001244068145752\n",
      "Seen so far: 31872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 498: 1.2076703310012817\n",
      "Seen so far: 31936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 499: 1.7375235557556152\n",
      "Seen so far: 32000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 500: 1.2078077793121338\n",
      "Seen so far: 32064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 501: 1.0732693672180176\n",
      "Seen so far: 32128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 502: 1.418041706085205\n",
      "Seen so far: 32192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 503: 1.3798470497131348\n",
      "Seen so far: 32256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 504: 1.4934018850326538\n",
      "Seen so far: 32320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 505: 1.503584623336792\n",
      "Seen so far: 32384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 506: 1.614820122718811\n",
      "Seen so far: 32448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 507: 1.846225619316101\n",
      "Seen so far: 32512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 508: 1.1311824321746826\n",
      "Seen so far: 32576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 509: 1.4534045457839966\n",
      "Seen so far: 32640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 510: 1.4334166049957275\n",
      "Seen so far: 32704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 511: 1.3535773754119873\n",
      "Seen so far: 32768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 512: 1.4849591255187988\n",
      "Seen so far: 32832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 513: 1.4632923603057861\n",
      "Seen so far: 32896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 514: 1.340925931930542\n",
      "Seen so far: 32960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 515: 1.6113353967666626\n",
      "Seen so far: 33024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 516: 0.9936433434486389\n",
      "Seen so far: 33088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 517: 1.4657785892486572\n",
      "Seen so far: 33152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 518: 1.233760118484497\n",
      "Seen so far: 33216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 519: 1.3871256113052368\n",
      "Seen so far: 33280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 520: 1.138861894607544\n",
      "Seen so far: 33344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 521: 1.2218949794769287\n",
      "Seen so far: 33408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 522: 1.4413738250732422\n",
      "Seen so far: 33472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 523: 1.2851378917694092\n",
      "Seen so far: 33536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 524: 1.385930061340332\n",
      "Seen so far: 33600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 525: 1.194250226020813\n",
      "Seen so far: 33664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 526: 1.6707119941711426\n",
      "Seen so far: 33728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 527: 1.3617517948150635\n",
      "Seen so far: 33792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 528: 1.4053995609283447\n",
      "Seen so far: 33856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 529: 0.8095758557319641\n",
      "Seen so far: 33920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 530: 1.2665979862213135\n",
      "Seen so far: 33984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 531: 0.9285390377044678\n",
      "Seen so far: 34048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 532: 1.1852271556854248\n",
      "Seen so far: 34112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 533: 1.7051570415496826\n",
      "Seen so far: 34176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 534: 1.0554816722869873\n",
      "Seen so far: 34240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 535: 1.5480300188064575\n",
      "Seen so far: 34304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 536: 1.2921422719955444\n",
      "Seen so far: 34368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 537: 1.093019962310791\n",
      "Seen so far: 34432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 538: 1.167586088180542\n",
      "Seen so far: 34496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 539: 1.019853115081787\n",
      "Seen so far: 34560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 540: 1.491713285446167\n",
      "Seen so far: 34624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 541: 1.3699281215667725\n",
      "Seen so far: 34688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 542: 1.3289251327514648\n",
      "Seen so far: 34752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 543: 1.2311969995498657\n",
      "Seen so far: 34816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 544: 0.9380398988723755\n",
      "Seen so far: 34880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 545: 1.4068211317062378\n",
      "Seen so far: 34944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 546: 1.3773820400238037\n",
      "Seen so far: 35008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 547: 1.310115098953247\n",
      "Seen so far: 35072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 548: 1.570078730583191\n",
      "Seen so far: 35136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 549: 1.242483139038086\n",
      "Seen so far: 35200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 550: 1.3210179805755615\n",
      "Seen so far: 35264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 551: 1.1158332824707031\n",
      "Seen so far: 35328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 552: 0.9531673789024353\n",
      "Seen so far: 35392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 553: 1.4048585891723633\n",
      "Seen so far: 35456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 554: 1.5528922080993652\n",
      "Seen so far: 35520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 555: 1.5915358066558838\n",
      "Seen so far: 35584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 556: 1.2314733266830444\n",
      "Seen so far: 35648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 557: 1.3010121583938599\n",
      "Seen so far: 35712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 558: 1.1674861907958984\n",
      "Seen so far: 35776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 559: 1.3224447965621948\n",
      "Seen so far: 35840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 560: 1.4131821393966675\n",
      "Seen so far: 35904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 561: 1.180213212966919\n",
      "Seen so far: 35968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 562: 1.3123762607574463\n",
      "Seen so far: 36032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 563: 1.5412182807922363\n",
      "Seen so far: 36096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 564: 1.234682321548462\n",
      "Seen so far: 36160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 565: 1.107045292854309\n",
      "Seen so far: 36224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 566: 1.2983696460723877\n",
      "Seen so far: 36288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 567: 1.3570678234100342\n",
      "Seen so far: 36352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 568: 1.3624770641326904\n",
      "Seen so far: 36416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 569: 1.0200990438461304\n",
      "Seen so far: 36480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 570: 1.4344978332519531\n",
      "Seen so far: 36544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 571: 1.3613529205322266\n",
      "Seen so far: 36608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 572: 1.61904776096344\n",
      "Seen so far: 36672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 573: 1.480541706085205\n",
      "Seen so far: 36736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 574: 1.2236266136169434\n",
      "Seen so far: 36800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 575: 1.5888535976409912\n",
      "Seen so far: 36864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 576: 1.0610511302947998\n",
      "Seen so far: 36928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 577: 1.513320803642273\n",
      "Seen so far: 36992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 578: 1.1416490077972412\n",
      "Seen so far: 37056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 579: 1.3970236778259277\n",
      "Seen so far: 37120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 580: 1.1674323081970215\n",
      "Seen so far: 37184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 581: 1.2003910541534424\n",
      "Seen so far: 37248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 582: 2.007314443588257\n",
      "Seen so far: 37312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 583: 1.1731536388397217\n",
      "Seen so far: 37376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 584: 1.588310956954956\n",
      "Seen so far: 37440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 585: 1.152714729309082\n",
      "Seen so far: 37504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 586: 1.0451444387435913\n",
      "Seen so far: 37568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 587: 0.9854104518890381\n",
      "Seen so far: 37632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 588: 1.1092655658721924\n",
      "Seen so far: 37696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 589: 1.2633872032165527\n",
      "Seen so far: 37760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 590: 1.0698922872543335\n",
      "Seen so far: 37824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 591: 1.3257107734680176\n",
      "Seen so far: 37888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 592: 1.4096060991287231\n",
      "Seen so far: 37952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 593: 1.4459102153778076\n",
      "Seen so far: 38016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 594: 0.911081075668335\n",
      "Seen so far: 38080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 595: 1.00261390209198\n",
      "Seen so far: 38144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 596: 1.1740586757659912\n",
      "Seen so far: 38208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 597: 1.3303258419036865\n",
      "Seen so far: 38272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 598: 1.0974092483520508\n",
      "Seen so far: 38336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 599: 1.0617425441741943\n",
      "Seen so far: 38400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 600: 0.9450784921646118\n",
      "Seen so far: 38464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 601: 0.9444993138313293\n",
      "Seen so far: 38528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 602: 1.1802557706832886\n",
      "Seen so far: 38592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 603: 1.8414125442504883\n",
      "Seen so far: 38656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 604: 1.3109782934188843\n",
      "Seen so far: 38720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 605: 1.0849584341049194\n",
      "Seen so far: 38784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 606: 2.2042040824890137\n",
      "Seen so far: 38848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 607: 1.4897823333740234\n",
      "Seen so far: 38912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 608: 1.2229423522949219\n",
      "Seen so far: 38976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 609: 1.2325468063354492\n",
      "Seen so far: 39040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 610: 0.9307351112365723\n",
      "Seen so far: 39104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 611: 1.1680290699005127\n",
      "Seen so far: 39168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 612: 1.2216753959655762\n",
      "Seen so far: 39232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 613: 1.1400184631347656\n",
      "Seen so far: 39296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 614: 0.9641393423080444\n",
      "Seen so far: 39360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 615: 1.234494686126709\n",
      "Seen so far: 39424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 616: 1.0930373668670654\n",
      "Seen so far: 39488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 617: 1.7406425476074219\n",
      "Seen so far: 39552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 618: 1.3565807342529297\n",
      "Seen so far: 39616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 619: 1.2232924699783325\n",
      "Seen so far: 39680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 620: 1.185976266860962\n",
      "Seen so far: 39744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 621: 1.575139045715332\n",
      "Seen so far: 39808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 622: 1.2813048362731934\n",
      "Seen so far: 39872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 623: 1.3129220008850098\n",
      "Seen so far: 39936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 624: 1.2875807285308838\n",
      "Seen so far: 40000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 625: 1.320136547088623\n",
      "Seen so far: 40064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 626: 1.3217828273773193\n",
      "Seen so far: 40128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 627: 0.9193999171257019\n",
      "Seen so far: 40192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 628: 1.227020025253296\n",
      "Seen so far: 40256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 629: 1.409102201461792\n",
      "Seen so far: 40320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 630: 1.4430084228515625\n",
      "Seen so far: 40384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 631: 1.4762732982635498\n",
      "Seen so far: 40448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 632: 1.3212296962738037\n",
      "Seen so far: 40512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 633: 1.3210115432739258\n",
      "Seen so far: 40576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 634: 0.9446549415588379\n",
      "Seen so far: 40640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 635: 1.0315030813217163\n",
      "Seen so far: 40704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 636: 1.3703367710113525\n",
      "Seen so far: 40768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 637: 0.8814352750778198\n",
      "Seen so far: 40832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 638: 1.2477701902389526\n",
      "Seen so far: 40896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 639: 1.274956226348877\n",
      "Seen so far: 40960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 640: 0.9171210527420044\n",
      "Seen so far: 41024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 641: 0.6656627655029297\n",
      "Seen so far: 41088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 642: 1.1328169107437134\n",
      "Seen so far: 41152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 643: 1.3046283721923828\n",
      "Seen so far: 41216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 644: 1.4339184761047363\n",
      "Seen so far: 41280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 645: 1.2337162494659424\n",
      "Seen so far: 41344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 646: 1.1375706195831299\n",
      "Seen so far: 41408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 647: 1.1074661016464233\n",
      "Seen so far: 41472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 648: 1.394831895828247\n",
      "Seen so far: 41536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 649: 1.3458832502365112\n",
      "Seen so far: 41600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 650: 1.4946155548095703\n",
      "Seen so far: 41664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 651: 1.5939908027648926\n",
      "Seen so far: 41728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 652: 1.1918383836746216\n",
      "Seen so far: 41792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 653: 1.3257001638412476\n",
      "Seen so far: 41856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 654: 1.0276172161102295\n",
      "Seen so far: 41920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 655: 1.355290412902832\n",
      "Seen so far: 41984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 656: 1.4108052253723145\n",
      "Seen so far: 42048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 657: 1.4896292686462402\n",
      "Seen so far: 42112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 658: 1.0417227745056152\n",
      "Seen so far: 42176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 659: 1.1229259967803955\n",
      "Seen so far: 42240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 660: 1.4721108675003052\n",
      "Seen so far: 42304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 661: 1.0544253587722778\n",
      "Seen so far: 42368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 662: 1.445951223373413\n",
      "Seen so far: 42432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 663: 1.439706802368164\n",
      "Seen so far: 42496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 664: 1.2648743391036987\n",
      "Seen so far: 42560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 665: 1.472529411315918\n",
      "Seen so far: 42624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 666: 0.9927436113357544\n",
      "Seen so far: 42688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 667: 1.3036561012268066\n",
      "Seen so far: 42752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 668: 1.477243185043335\n",
      "Seen so far: 42816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 669: 1.3482325077056885\n",
      "Seen so far: 42880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 670: 1.4175297021865845\n",
      "Seen so far: 42944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 671: 1.6627490520477295\n",
      "Seen so far: 43008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 672: 1.4515748023986816\n",
      "Seen so far: 43072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 673: 1.5051777362823486\n",
      "Seen so far: 43136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 674: 1.3624835014343262\n",
      "Seen so far: 43200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 675: 1.243584394454956\n",
      "Seen so far: 43264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 676: 1.262237787246704\n",
      "Seen so far: 43328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 677: 1.4618165493011475\n",
      "Seen so far: 43392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 678: 1.1700838804244995\n",
      "Seen so far: 43456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 679: 1.5968091487884521\n",
      "Seen so far: 43520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 680: 0.7655670642852783\n",
      "Seen so far: 43584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 681: 1.4824044704437256\n",
      "Seen so far: 43648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 682: 1.168386697769165\n",
      "Seen so far: 43712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 683: 0.9028105735778809\n",
      "Seen so far: 43776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 684: 1.2273986339569092\n",
      "Seen so far: 43840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 685: 1.052211880683899\n",
      "Seen so far: 43904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 686: 1.3580825328826904\n",
      "Seen so far: 43968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 687: 1.7364081144332886\n",
      "Seen so far: 44032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 688: 1.3704618215560913\n",
      "Seen so far: 44096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 689: 1.00888991355896\n",
      "Seen so far: 44160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 690: 1.1793956756591797\n",
      "Seen so far: 44224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 691: 1.2703042030334473\n",
      "Seen so far: 44288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 692: 1.4201765060424805\n",
      "Seen so far: 44352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 693: 1.5031851530075073\n",
      "Seen so far: 44416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 694: 1.2731428146362305\n",
      "Seen so far: 44480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 695: 1.1762213706970215\n",
      "Seen so far: 44544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 696: 1.2412946224212646\n",
      "Seen so far: 44608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 697: 1.2057249546051025\n",
      "Seen so far: 44672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 698: 1.0328032970428467\n",
      "Seen so far: 44736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 699: 1.082573413848877\n",
      "Seen so far: 44800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 700: 1.987294316291809\n",
      "Seen so far: 44864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 701: 1.3050028085708618\n",
      "Seen so far: 44928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 702: 1.2450199127197266\n",
      "Seen so far: 44992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 703: 1.2517964839935303\n",
      "Seen so far: 45056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 704: 1.0380924940109253\n",
      "Seen so far: 45120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 705: 1.2005658149719238\n",
      "Seen so far: 45184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 706: 1.1170566082000732\n",
      "Seen so far: 45248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 707: 1.1880545616149902\n",
      "Seen so far: 45312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 708: 0.9288276433944702\n",
      "Seen so far: 45376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 709: 1.5121901035308838\n",
      "Seen so far: 45440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 710: 1.4139893054962158\n",
      "Seen so far: 45504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 711: 1.2159433364868164\n",
      "Seen so far: 45568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 712: 1.2362403869628906\n",
      "Seen so far: 45632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 713: 1.390375018119812\n",
      "Seen so far: 45696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 714: 1.5859577655792236\n",
      "Seen so far: 45760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 715: 1.7540287971496582\n",
      "Seen so far: 45824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 716: 0.7552074193954468\n",
      "Seen so far: 45888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 717: 1.366090178489685\n",
      "Seen so far: 45952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 718: 1.7627111673355103\n",
      "Seen so far: 46016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 719: 1.3158299922943115\n",
      "Seen so far: 46080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 720: 1.1829347610473633\n",
      "Seen so far: 46144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 721: 1.4302023649215698\n",
      "Seen so far: 46208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 722: 0.9162255525588989\n",
      "Seen so far: 46272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 723: 1.0608232021331787\n",
      "Seen so far: 46336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 724: 1.2686896324157715\n",
      "Seen so far: 46400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 725: 1.6395403146743774\n",
      "Seen so far: 46464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 726: 1.2397457361221313\n",
      "Seen so far: 46528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 727: 1.0271189212799072\n",
      "Seen so far: 46592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 728: 1.3246958255767822\n",
      "Seen so far: 46656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 729: 1.2724378108978271\n",
      "Seen so far: 46720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 730: 1.6069798469543457\n",
      "Seen so far: 46784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 731: 1.5135588645935059\n",
      "Seen so far: 46848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 732: 1.7109603881835938\n",
      "Seen so far: 46912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 733: 1.3383936882019043\n",
      "Seen so far: 46976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 734: 0.9844896197319031\n",
      "Seen so far: 47040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 735: 1.13687264919281\n",
      "Seen so far: 47104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 736: 1.0989065170288086\n",
      "Seen so far: 47168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 737: 1.2021878957748413\n",
      "Seen so far: 47232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 738: 1.2200946807861328\n",
      "Seen so far: 47296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 739: 1.7087364196777344\n",
      "Seen so far: 47360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 740: 1.2783018350601196\n",
      "Seen so far: 47424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 741: 1.1070013046264648\n",
      "Seen so far: 47488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 742: 1.0756909847259521\n",
      "Seen so far: 47552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 743: 1.5064657926559448\n",
      "Seen so far: 47616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 744: 1.0986278057098389\n",
      "Seen so far: 47680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 745: 1.199864387512207\n",
      "Seen so far: 47744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 746: 1.5246001482009888\n",
      "Seen so far: 47808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 747: 1.449873685836792\n",
      "Seen so far: 47872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 748: 0.9526578187942505\n",
      "Seen so far: 47936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 749: 1.924445390701294\n",
      "Seen so far: 48000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 750: 1.3200619220733643\n",
      "Seen so far: 48064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 751: 1.148812174797058\n",
      "Seen so far: 48128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 752: 1.350285530090332\n",
      "Seen so far: 48192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 753: 1.704688549041748\n",
      "Seen so far: 48256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 754: 1.1793053150177002\n",
      "Seen so far: 48320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 755: 1.2396183013916016\n",
      "Seen so far: 48384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 756: 1.3663039207458496\n",
      "Seen so far: 48448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 757: 1.547163486480713\n",
      "Seen so far: 48512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 758: 1.1241973638534546\n",
      "Seen so far: 48576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 759: 1.318448543548584\n",
      "Seen so far: 48640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 760: 1.557940125465393\n",
      "Seen so far: 48704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 761: 1.3648223876953125\n",
      "Seen so far: 48768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 762: 1.4260575771331787\n",
      "Seen so far: 48832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 763: 1.2102327346801758\n",
      "Seen so far: 48896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 764: 1.4055016040802002\n",
      "Seen so far: 48960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 765: 1.3464603424072266\n",
      "Seen so far: 49024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 766: 1.615409016609192\n",
      "Seen so far: 49088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 767: 1.62119460105896\n",
      "Seen so far: 49152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 768: 1.3046962022781372\n",
      "Seen so far: 49216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 769: 1.0650535821914673\n",
      "Seen so far: 49280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 770: 1.1954946517944336\n",
      "Seen so far: 49344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 771: 1.0793625116348267\n",
      "Seen so far: 49408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 772: 1.244278907775879\n",
      "Seen so far: 49472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 773: 1.2903192043304443\n",
      "Seen so far: 49536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 774: 1.5206068754196167\n",
      "Seen so far: 49600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 775: 1.5705927610397339\n",
      "Seen so far: 49664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 776: 1.4062459468841553\n",
      "Seen so far: 49728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 777: 1.626181960105896\n",
      "Seen so far: 49792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 778: 1.3758480548858643\n",
      "Seen so far: 49856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 779: 0.8917511105537415\n",
      "Seen so far: 49920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 780: 1.512503743171692\n",
      "Seen so far: 49984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 781: 1.4678624868392944\n",
      "Seen so far: 50048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 782: 1.398115634918213\n",
      "Seen so far: 50112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 783: 1.4527583122253418\n",
      "Seen so far: 50176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 784: 1.3379331827163696\n",
      "Seen so far: 50240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 785: 1.4421770572662354\n",
      "Seen so far: 50304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 786: 1.371882438659668\n",
      "Seen so far: 50368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 787: 1.674570918083191\n",
      "Seen so far: 50432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 788: 1.0287235975265503\n",
      "Seen so far: 50496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 789: 2.026719570159912\n",
      "Seen so far: 50560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 790: 1.6117663383483887\n",
      "Seen so far: 50624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 791: 1.173024296760559\n",
      "Seen so far: 50688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 792: 1.0150198936462402\n",
      "Seen so far: 50752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 793: 1.0874238014221191\n",
      "Seen so far: 50816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 794: 1.5723603963851929\n",
      "Seen so far: 50880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 795: 1.1455833911895752\n",
      "Seen so far: 50944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 796: 1.4272525310516357\n",
      "Seen so far: 51008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 797: 1.4904412031173706\n",
      "Seen so far: 51072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 798: 1.7082383632659912\n",
      "Seen so far: 51136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 799: 1.4668669700622559\n",
      "Seen so far: 51200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 800: 1.0686311721801758\n",
      "Seen so far: 51264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 801: 1.3939480781555176\n",
      "Seen so far: 51328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 802: 1.579281210899353\n",
      "Seen so far: 51392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 803: 1.2317132949829102\n",
      "Seen so far: 51456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 804: 1.135457992553711\n",
      "Seen so far: 51520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 805: 1.7764837741851807\n",
      "Seen so far: 51584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 806: 1.3649194240570068\n",
      "Seen so far: 51648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 807: 0.9325759410858154\n",
      "Seen so far: 51712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 808: 1.2523618936538696\n",
      "Seen so far: 51776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 809: 1.0632541179656982\n",
      "Seen so far: 51840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 810: 1.0347731113433838\n",
      "Seen so far: 51904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 811: 1.3732020854949951\n",
      "Seen so far: 51968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 812: 1.643223524093628\n",
      "Seen so far: 52032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 813: 1.2489666938781738\n",
      "Seen so far: 52096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 814: 0.7253652811050415\n",
      "Seen so far: 52160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 815: 1.698160171508789\n",
      "Seen so far: 52224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 816: 1.171639323234558\n",
      "Seen so far: 52288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 817: 1.1167562007904053\n",
      "Seen so far: 52352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 818: 1.766268253326416\n",
      "Seen so far: 52416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 819: 0.7793635725975037\n",
      "Seen so far: 52480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 820: 1.4416601657867432\n",
      "Seen so far: 52544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 821: 1.6873414516448975\n",
      "Seen so far: 52608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 822: 1.2319004535675049\n",
      "Seen so far: 52672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 823: 1.6163932085037231\n",
      "Seen so far: 52736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 824: 1.2924234867095947\n",
      "Seen so far: 52800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 825: 1.2978357076644897\n",
      "Seen so far: 52864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 826: 1.3437178134918213\n",
      "Seen so far: 52928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 827: 1.4596784114837646\n",
      "Seen so far: 52992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 828: 1.6844568252563477\n",
      "Seen so far: 53056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 829: 1.3068304061889648\n",
      "Seen so far: 53120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 830: 1.211273431777954\n",
      "Seen so far: 53184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 831: 1.5856692790985107\n",
      "Seen so far: 53248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 832: 1.3807651996612549\n",
      "Seen so far: 53312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 833: 1.6108338832855225\n",
      "Seen so far: 53376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 834: 1.2302203178405762\n",
      "Seen so far: 53440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 835: 0.8527592420578003\n",
      "Seen so far: 53504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 836: 1.1988093852996826\n",
      "Seen so far: 53568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 837: 1.1835987567901611\n",
      "Seen so far: 53632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 838: 0.8931105136871338\n",
      "Seen so far: 53696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 839: 0.98051518201828\n",
      "Seen so far: 53760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 840: 1.122638463973999\n",
      "Seen so far: 53824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 841: 1.5498642921447754\n",
      "Seen so far: 53888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 842: 0.9755551815032959\n",
      "Seen so far: 53952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 843: 1.33791983127594\n",
      "Seen so far: 54016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 844: 1.3238861560821533\n",
      "Seen so far: 54080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 845: 1.405126929283142\n",
      "Seen so far: 54144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 846: 1.4789819717407227\n",
      "Seen so far: 54208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 847: 1.393134593963623\n",
      "Seen so far: 54272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 848: 1.656147837638855\n",
      "Seen so far: 54336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 849: 0.8726710081100464\n",
      "Seen so far: 54400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 850: 0.886228621006012\n",
      "Seen so far: 54464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 851: 1.3383232355117798\n",
      "Seen so far: 54528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 852: 0.765774130821228\n",
      "Seen so far: 54592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 853: 0.8837828636169434\n",
      "Seen so far: 54656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 854: 1.1945865154266357\n",
      "Seen so far: 54720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 855: 0.8929675817489624\n",
      "Seen so far: 54784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 856: 1.2525038719177246\n",
      "Seen so far: 54848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 857: 0.8358866572380066\n",
      "Seen so far: 54912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 858: 1.164903163909912\n",
      "Seen so far: 54976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 859: 1.681485652923584\n",
      "Seen so far: 55040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 860: 1.009908676147461\n",
      "Seen so far: 55104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 861: 1.327500820159912\n",
      "Seen so far: 55168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 862: 1.0255415439605713\n",
      "Seen so far: 55232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 863: 1.4960825443267822\n",
      "Seen so far: 55296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 864: 1.3710190057754517\n",
      "Seen so far: 55360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 865: 1.0265145301818848\n",
      "Seen so far: 55424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 866: 1.0233900547027588\n",
      "Seen so far: 55488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 867: 1.1385397911071777\n",
      "Seen so far: 55552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 868: 1.213643193244934\n",
      "Seen so far: 55616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 869: 1.3771097660064697\n",
      "Seen so far: 55680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 870: 1.511551856994629\n",
      "Seen so far: 55744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 871: 1.5394303798675537\n",
      "Seen so far: 55808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 872: 1.0607562065124512\n",
      "Seen so far: 55872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 873: 1.3683040142059326\n",
      "Seen so far: 55936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 874: 1.657029628753662\n",
      "Seen so far: 56000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 875: 1.4551068544387817\n",
      "Seen so far: 56064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 876: 1.335569143295288\n",
      "Seen so far: 56128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 877: 1.3349570035934448\n",
      "Seen so far: 56192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 878: 1.7080507278442383\n",
      "Seen so far: 56256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 879: 1.0312182903289795\n",
      "Seen so far: 56320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 880: 1.2163398265838623\n",
      "Seen so far: 56384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 881: 1.8207013607025146\n",
      "Seen so far: 56448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 882: 1.3201208114624023\n",
      "Seen so far: 56512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 883: 1.214233160018921\n",
      "Seen so far: 56576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 884: 1.0437488555908203\n",
      "Seen so far: 56640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 885: 1.2657480239868164\n",
      "Seen so far: 56704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 886: 1.6635138988494873\n",
      "Seen so far: 56768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 887: 0.9918466806411743\n",
      "Seen so far: 56832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 888: 1.390555739402771\n",
      "Seen so far: 56896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 889: 1.7540936470031738\n",
      "Seen so far: 56960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 890: 1.1386289596557617\n",
      "Seen so far: 57024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 891: 1.4799553155899048\n",
      "Seen so far: 57088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 892: 1.1881542205810547\n",
      "Seen so far: 57152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 893: 1.3888132572174072\n",
      "Seen so far: 57216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 894: 1.4657456874847412\n",
      "Seen so far: 57280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 895: 1.115281343460083\n",
      "Seen so far: 57344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 896: 1.9213428497314453\n",
      "Seen so far: 57408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 897: 1.5467007160186768\n",
      "Seen so far: 57472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 898: 1.5169737339019775\n",
      "Seen so far: 57536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 899: 1.0659894943237305\n",
      "Seen so far: 57600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 900: 1.6286325454711914\n",
      "Seen so far: 57664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 901: 1.635016918182373\n",
      "Seen so far: 57728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 902: 1.3740414381027222\n",
      "Seen so far: 57792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 903: 1.147780179977417\n",
      "Seen so far: 57856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 904: 1.555387258529663\n",
      "Seen so far: 57920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 905: 1.378016471862793\n",
      "Seen so far: 57984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 906: 1.636315941810608\n",
      "Seen so far: 58048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 907: 1.4515061378479004\n",
      "Seen so far: 58112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 908: 1.154064416885376\n",
      "Seen so far: 58176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 909: 1.1401495933532715\n",
      "Seen so far: 58240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 910: 1.0165785551071167\n",
      "Seen so far: 58304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 911: 1.5866063833236694\n",
      "Seen so far: 58368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 912: 1.237025260925293\n",
      "Seen so far: 58432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 913: 1.3875319957733154\n",
      "Seen so far: 58496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 914: 0.9798676371574402\n",
      "Seen so far: 58560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 915: 1.2832762002944946\n",
      "Seen so far: 58624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 916: 1.4861444234848022\n",
      "Seen so far: 58688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 917: 1.0955698490142822\n",
      "Seen so far: 58752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 918: 1.4180474281311035\n",
      "Seen so far: 58816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 919: 1.061450481414795\n",
      "Seen so far: 58880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 920: 1.342936635017395\n",
      "Seen so far: 58944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 921: 1.0442379713058472\n",
      "Seen so far: 59008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 922: 1.372883677482605\n",
      "Seen so far: 59072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 923: 1.282881259918213\n",
      "Seen so far: 59136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 924: 1.373023271560669\n",
      "Seen so far: 59200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 925: 1.202417016029358\n",
      "Seen so far: 59264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 926: 1.6572281122207642\n",
      "Seen so far: 59328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 927: 1.4384047985076904\n",
      "Seen so far: 59392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 928: 1.5225287675857544\n",
      "Seen so far: 59456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 929: 1.3731727600097656\n",
      "Seen so far: 59520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 930: 0.9717824459075928\n",
      "Seen so far: 59584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 931: 1.6022069454193115\n",
      "Seen so far: 59648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 932: 1.4242432117462158\n",
      "Seen so far: 59712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 933: 1.03699791431427\n",
      "Seen so far: 59776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 934: 1.437835931777954\n",
      "Seen so far: 59840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 935: 1.034459114074707\n",
      "Seen so far: 59904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 936: 1.3717422485351562\n",
      "Seen so far: 59968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 937: 1.1828341484069824\n",
      "Seen so far: 60032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 938: 1.432258129119873\n",
      "Seen so far: 60096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 939: 1.243952989578247\n",
      "Seen so far: 60160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 940: 1.0166726112365723\n",
      "Seen so far: 60224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 941: 1.3553524017333984\n",
      "Seen so far: 60288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 942: 1.316867709159851\n",
      "Seen so far: 60352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 943: 1.143846869468689\n",
      "Seen so far: 60416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 944: 1.1385290622711182\n",
      "Seen so far: 60480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 945: 1.4273508787155151\n",
      "Seen so far: 60544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 946: 1.369612693786621\n",
      "Seen so far: 60608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 947: 1.5862104892730713\n",
      "Seen so far: 60672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 948: 0.9521660804748535\n",
      "Seen so far: 60736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 949: 1.256675124168396\n",
      "Seen so far: 60800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 950: 1.3831782341003418\n",
      "Seen so far: 60864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 951: 1.21367609500885\n",
      "Seen so far: 60928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 952: 1.4040555953979492\n",
      "Seen so far: 60992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 953: 1.5819355249404907\n",
      "Seen so far: 61056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 954: 1.4020999670028687\n",
      "Seen so far: 61120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 955: 1.2832190990447998\n",
      "Seen so far: 61184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 956: 1.7271074056625366\n",
      "Seen so far: 61248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 957: 1.2459094524383545\n",
      "Seen so far: 61312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 958: 1.1949372291564941\n",
      "Seen so far: 61376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 959: 1.1818580627441406\n",
      "Seen so far: 61440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 960: 1.3650949001312256\n",
      "Seen so far: 61504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 961: 1.5273995399475098\n",
      "Seen so far: 61568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 962: 1.1690950393676758\n",
      "Seen so far: 61632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 963: 1.0985779762268066\n",
      "Seen so far: 61696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 964: 1.3334496021270752\n",
      "Seen so far: 61760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 965: 1.0140557289123535\n",
      "Seen so far: 61824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 966: 1.107210397720337\n",
      "Seen so far: 61888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 967: 1.3460545539855957\n",
      "Seen so far: 61952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 968: 1.10093092918396\n",
      "Seen so far: 62016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 969: 1.4096524715423584\n",
      "Seen so far: 62080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 970: 1.3086997270584106\n",
      "Seen so far: 62144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 971: 1.2369624376296997\n",
      "Seen so far: 62208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 972: 1.4529744386672974\n",
      "Seen so far: 62272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 973: 1.563352346420288\n",
      "Seen so far: 62336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 974: 0.9555915594100952\n",
      "Seen so far: 62400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 975: 1.0537428855895996\n",
      "Seen so far: 62464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 976: 1.2299129962921143\n",
      "Seen so far: 62528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 977: 1.2271335124969482\n",
      "Seen so far: 62592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 978: 1.2971410751342773\n",
      "Seen so far: 62656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 979: 1.3636411428451538\n",
      "Seen so far: 62720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 980: 1.5515639781951904\n",
      "Seen so far: 62784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 981: 1.323934555053711\n",
      "Seen so far: 62848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 982: 1.033296823501587\n",
      "Seen so far: 62912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 983: 0.9146151542663574\n",
      "Seen so far: 62976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 984: 1.0840306282043457\n",
      "Seen so far: 63040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 985: 1.255321979522705\n",
      "Seen so far: 63104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 986: 1.1420376300811768\n",
      "Seen so far: 63168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 987: 1.5505526065826416\n",
      "Seen so far: 63232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 988: 1.2795500755310059\n",
      "Seen so far: 63296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 989: 1.1327072381973267\n",
      "Seen so far: 63360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 990: 1.212064504623413\n",
      "Seen so far: 63424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 991: 1.3740653991699219\n",
      "Seen so far: 63488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 992: 1.112593650817871\n",
      "Seen so far: 63552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 993: 1.0002014636993408\n",
      "Seen so far: 63616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 994: 1.1443599462509155\n",
      "Seen so far: 63680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 995: 1.2707655429840088\n",
      "Seen so far: 63744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 996: 1.2003003358840942\n",
      "Seen so far: 63808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 997: 0.9579346179962158\n",
      "Seen so far: 63872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 998: 1.515732765197754\n",
      "Seen so far: 63936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 999: 1.1405115127563477\n",
      "Seen so far: 64000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1000: 1.1846004724502563\n",
      "Seen so far: 64064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1001: 1.143210530281067\n",
      "Seen so far: 64128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1002: 0.8791064620018005\n",
      "Seen so far: 64192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1003: 1.237099289894104\n",
      "Seen so far: 64256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1004: 1.0522609949111938\n",
      "Seen so far: 64320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1005: 1.1874518394470215\n",
      "Seen so far: 64384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1006: 1.2501493692398071\n",
      "Seen so far: 64448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1007: 1.328209400177002\n",
      "Seen so far: 64512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1008: 1.4900922775268555\n",
      "Seen so far: 64576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1009: 1.165991187095642\n",
      "Seen so far: 64640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1010: 0.9778658747673035\n",
      "Seen so far: 64704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1011: 0.9045869708061218\n",
      "Seen so far: 64768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1012: 1.2484006881713867\n",
      "Seen so far: 64832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1013: 1.1879215240478516\n",
      "Seen so far: 64896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1014: 1.3771461248397827\n",
      "Seen so far: 64960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1015: 0.8618578314781189\n",
      "Seen so far: 65024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1016: 1.3251944780349731\n",
      "Seen so far: 65088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1017: 1.4720298051834106\n",
      "Seen so far: 65152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1018: 0.9024986028671265\n",
      "Seen so far: 65216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1019: 1.7283648252487183\n",
      "Seen so far: 65280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1020: 0.8274214863777161\n",
      "Seen so far: 65344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1021: 0.7681928873062134\n",
      "Seen so far: 65408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1022: 0.9690647721290588\n",
      "Seen so far: 65472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1023: 1.7417904138565063\n",
      "Seen so far: 65536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1024: 0.9894534349441528\n",
      "Seen so far: 65600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1025: 1.2448899745941162\n",
      "Seen so far: 65664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1026: 1.0693862438201904\n",
      "Seen so far: 65728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1027: 1.2045694589614868\n",
      "Seen so far: 65792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1028: 1.113034725189209\n",
      "Seen so far: 65856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1029: 1.3588722944259644\n",
      "Seen so far: 65920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1030: 1.6265060901641846\n",
      "Seen so far: 65984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1031: 1.1351666450500488\n",
      "Seen so far: 66048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1032: 1.067913293838501\n",
      "Seen so far: 66112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1033: 1.5663247108459473\n",
      "Seen so far: 66176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1034: 1.5310711860656738\n",
      "Seen so far: 66240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1035: 1.4206745624542236\n",
      "Seen so far: 66304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1036: 0.9965044260025024\n",
      "Seen so far: 66368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1037: 1.233245611190796\n",
      "Seen so far: 66432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1038: 1.2664508819580078\n",
      "Seen so far: 66496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1039: 1.0064375400543213\n",
      "Seen so far: 66560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1040: 1.5502727031707764\n",
      "Seen so far: 66624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1041: 1.4698073863983154\n",
      "Seen so far: 66688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1042: 0.9247692823410034\n",
      "Seen so far: 66752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1043: 1.1851081848144531\n",
      "Seen so far: 66816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1044: 0.7968354225158691\n",
      "Seen so far: 66880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1045: 1.0805755853652954\n",
      "Seen so far: 66944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1046: 1.3113603591918945\n",
      "Seen so far: 67008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1047: 0.9768117070198059\n",
      "Seen so far: 67072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1048: 1.2776496410369873\n",
      "Seen so far: 67136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1049: 0.7871756553649902\n",
      "Seen so far: 67200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1050: 1.5428522825241089\n",
      "Seen so far: 67264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1051: 1.1326560974121094\n",
      "Seen so far: 67328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1052: 0.7963241338729858\n",
      "Seen so far: 67392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1053: 1.5598524808883667\n",
      "Seen so far: 67456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1054: 1.3310939073562622\n",
      "Seen so far: 67520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1055: 1.589341163635254\n",
      "Seen so far: 67584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1056: 1.066894292831421\n",
      "Seen so far: 67648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1057: 1.2584726810455322\n",
      "Seen so far: 67712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1058: 1.0378247499465942\n",
      "Seen so far: 67776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1059: 0.8801518678665161\n",
      "Seen so far: 67840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1060: 1.0845255851745605\n",
      "Seen so far: 67904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1061: 1.3350452184677124\n",
      "Seen so far: 67968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1062: 1.5722596645355225\n",
      "Seen so far: 68032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1063: 0.6501747369766235\n",
      "Seen so far: 68096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1064: 1.4362390041351318\n",
      "Seen so far: 68160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1065: 1.6962623596191406\n",
      "Seen so far: 68224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1066: 1.3736495971679688\n",
      "Seen so far: 68288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1067: 1.182784080505371\n",
      "Seen so far: 68352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1068: 1.1212878227233887\n",
      "Seen so far: 68416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1069: 1.1322963237762451\n",
      "Seen so far: 68480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1070: 0.9024488925933838\n",
      "Seen so far: 68544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1071: 1.040428876876831\n",
      "Seen so far: 68608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1072: 1.536467432975769\n",
      "Seen so far: 68672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1073: 1.056790828704834\n",
      "Seen so far: 68736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1074: 1.0473544597625732\n",
      "Seen so far: 68800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1075: 1.322024941444397\n",
      "Seen so far: 68864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1076: 0.8035029768943787\n",
      "Seen so far: 68928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1077: 1.548081398010254\n",
      "Seen so far: 68992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1078: 1.4800130128860474\n",
      "Seen so far: 69056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1079: 1.3619885444641113\n",
      "Seen so far: 69120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1080: 1.258312463760376\n",
      "Seen so far: 69184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1081: 1.306553602218628\n",
      "Seen so far: 69248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1082: 1.6370561122894287\n",
      "Seen so far: 69312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1083: 1.527302861213684\n",
      "Seen so far: 69376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1084: 1.740123987197876\n",
      "Seen so far: 69440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1085: 1.0904464721679688\n",
      "Seen so far: 69504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1086: 1.412407398223877\n",
      "Seen so far: 69568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1087: 1.5855746269226074\n",
      "Seen so far: 69632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1088: 1.5239875316619873\n",
      "Seen so far: 69696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1089: 1.1063908338546753\n",
      "Seen so far: 69760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1090: 1.3617628812789917\n",
      "Seen so far: 69824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1091: 1.5199110507965088\n",
      "Seen so far: 69888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1092: 1.3174540996551514\n",
      "Seen so far: 69952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1093: 1.1779800653457642\n",
      "Seen so far: 70016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1094: 1.3061625957489014\n",
      "Seen so far: 70080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1095: 1.4232038259506226\n",
      "Seen so far: 70144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1096: 1.0613794326782227\n",
      "Seen so far: 70208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1097: 1.027982234954834\n",
      "Seen so far: 70272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1098: 1.7820734977722168\n",
      "Seen so far: 70336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1099: 1.3363893032073975\n",
      "Seen so far: 70400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1100: 1.6730726957321167\n",
      "Seen so far: 70464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1101: 1.5067813396453857\n",
      "Seen so far: 70528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1102: 1.336409330368042\n",
      "Seen so far: 70592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1103: 1.5837912559509277\n",
      "Seen so far: 70656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1104: 1.154052734375\n",
      "Seen so far: 70720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1105: 0.873683750629425\n",
      "Seen so far: 70784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1106: 1.563172459602356\n",
      "Seen so far: 70848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1107: 0.9681117534637451\n",
      "Seen so far: 70912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1108: 1.0518840551376343\n",
      "Seen so far: 70976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1109: 0.9443687200546265\n",
      "Seen so far: 71040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1110: 1.0188122987747192\n",
      "Seen so far: 71104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1111: 1.3363996744155884\n",
      "Seen so far: 71168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1112: 1.4006292819976807\n",
      "Seen so far: 71232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1113: 1.4152240753173828\n",
      "Seen so far: 71296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1114: 1.2995281219482422\n",
      "Seen so far: 71360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1115: 1.5786473751068115\n",
      "Seen so far: 71424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1116: 1.2342393398284912\n",
      "Seen so far: 71488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1117: 1.0941532850265503\n",
      "Seen so far: 71552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1118: 0.8407135605812073\n",
      "Seen so far: 71616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1119: 1.2506593465805054\n",
      "Seen so far: 71680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1120: 1.137571930885315\n",
      "Seen so far: 71744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1121: 1.3263721466064453\n",
      "Seen so far: 71808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1122: 0.8876724243164062\n",
      "Seen so far: 71872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1123: 0.9926470518112183\n",
      "Seen so far: 71936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1124: 1.0396087169647217\n",
      "Seen so far: 72000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1125: 1.4633111953735352\n",
      "Seen so far: 72064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1126: 0.9268361330032349\n",
      "Seen so far: 72128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1127: 1.19566011428833\n",
      "Seen so far: 72192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1128: 1.551961898803711\n",
      "Seen so far: 72256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1129: 1.3819853067398071\n",
      "Seen so far: 72320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1130: 0.8643823266029358\n",
      "Seen so far: 72384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1131: 1.3651318550109863\n",
      "Seen so far: 72448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1132: 1.0055150985717773\n",
      "Seen so far: 72512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1133: 1.0967316627502441\n",
      "Seen so far: 72576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1134: 1.5551633834838867\n",
      "Seen so far: 72640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1135: 1.2530606985092163\n",
      "Seen so far: 72704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1136: 1.4358108043670654\n",
      "Seen so far: 72768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1137: 1.2819041013717651\n",
      "Seen so far: 72832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1138: 1.3547701835632324\n",
      "Seen so far: 72896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1139: 1.3008794784545898\n",
      "Seen so far: 72960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1140: 1.0181488990783691\n",
      "Seen so far: 73024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1141: 1.0063152313232422\n",
      "Seen so far: 73088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1142: 1.0948363542556763\n",
      "Seen so far: 73152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1143: 1.3351550102233887\n",
      "Seen so far: 73216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1144: 1.1764661073684692\n",
      "Seen so far: 73280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1145: 1.5809922218322754\n",
      "Seen so far: 73344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1146: 1.4066230058670044\n",
      "Seen so far: 73408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1147: 1.2390546798706055\n",
      "Seen so far: 73472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1148: 1.3923003673553467\n",
      "Seen so far: 73536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1149: 1.1450754404067993\n",
      "Seen so far: 73600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1150: 1.272153377532959\n",
      "Seen so far: 73664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1151: 1.274230718612671\n",
      "Seen so far: 73728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1152: 1.2936079502105713\n",
      "Seen so far: 73792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1153: 1.1391949653625488\n",
      "Seen so far: 73856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1154: 1.0425746440887451\n",
      "Seen so far: 73920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1155: 1.3204766511917114\n",
      "Seen so far: 73984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1156: 1.4524400234222412\n",
      "Seen so far: 74048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1157: 1.0998554229736328\n",
      "Seen so far: 74112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1158: 1.2313449382781982\n",
      "Seen so far: 74176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1159: 1.1524486541748047\n",
      "Seen so far: 74240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1160: 1.2533307075500488\n",
      "Seen so far: 74304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1161: 1.1648964881896973\n",
      "Seen so far: 74368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1162: 0.9901688694953918\n",
      "Seen so far: 74432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1163: 1.1659636497497559\n",
      "Seen so far: 74496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1164: 1.182302474975586\n",
      "Seen so far: 74560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1165: 1.135784387588501\n",
      "Seen so far: 74624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1166: 1.2485378980636597\n",
      "Seen so far: 74688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1167: 1.0048857927322388\n",
      "Seen so far: 74752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1168: 1.0172220468521118\n",
      "Seen so far: 74816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1169: 1.3544871807098389\n",
      "Seen so far: 74880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1170: 1.3295178413391113\n",
      "Seen so far: 74944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1171: 1.2566553354263306\n",
      "Seen so far: 75008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1172: 1.840596318244934\n",
      "Seen so far: 75072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1173: 1.3176019191741943\n",
      "Seen so far: 75136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1174: 1.3358867168426514\n",
      "Seen so far: 75200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1175: 1.56428861618042\n",
      "Seen so far: 75264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1176: 1.2694027423858643\n",
      "Seen so far: 75328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1177: 1.3230466842651367\n",
      "Seen so far: 75392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1178: 2.0553605556488037\n",
      "Seen so far: 75456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1179: 0.9083487391471863\n",
      "Seen so far: 75520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1180: 1.2910795211791992\n",
      "Seen so far: 75584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1181: 1.1751139163970947\n",
      "Seen so far: 75648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1182: 1.4535043239593506\n",
      "Seen so far: 75712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1183: 1.4449779987335205\n",
      "Seen so far: 75776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1184: 1.3578057289123535\n",
      "Seen so far: 75840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1185: 1.2908389568328857\n",
      "Seen so far: 75904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1186: 1.2310442924499512\n",
      "Seen so far: 75968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1187: 1.2942378520965576\n",
      "Seen so far: 76032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1188: 1.2283799648284912\n",
      "Seen so far: 76096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1189: 1.1108633279800415\n",
      "Seen so far: 76160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1190: 1.0393908023834229\n",
      "Seen so far: 76224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1191: 0.9161285161972046\n",
      "Seen so far: 76288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1192: 1.3132046461105347\n",
      "Seen so far: 76352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1193: 1.2686071395874023\n",
      "Seen so far: 76416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1194: 1.768894910812378\n",
      "Seen so far: 76480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1195: 1.2279248237609863\n",
      "Seen so far: 76544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1196: 1.1164441108703613\n",
      "Seen so far: 76608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1197: 1.4773350954055786\n",
      "Seen so far: 76672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1198: 1.5435153245925903\n",
      "Seen so far: 76736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1199: 1.3341586589813232\n",
      "Seen so far: 76800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1200: 1.332015037536621\n",
      "Seen so far: 76864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1201: 1.072988510131836\n",
      "Seen so far: 76928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1202: 1.301730990409851\n",
      "Seen so far: 76992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1203: 1.1834694147109985\n",
      "Seen so far: 77056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1204: 1.3809115886688232\n",
      "Seen so far: 77120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1205: 1.055393934249878\n",
      "Seen so far: 77184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1206: 1.2983219623565674\n",
      "Seen so far: 77248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1207: 1.295124888420105\n",
      "Seen so far: 77312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1208: 1.4107487201690674\n",
      "Seen so far: 77376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1209: 1.0869126319885254\n",
      "Seen so far: 77440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1210: 1.167048454284668\n",
      "Seen so far: 77504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1211: 1.1431881189346313\n",
      "Seen so far: 77568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1212: 0.8319998383522034\n",
      "Seen so far: 77632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1213: 1.1049304008483887\n",
      "Seen so far: 77696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1214: 1.904021143913269\n",
      "Seen so far: 77760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1215: 0.8248834013938904\n",
      "Seen so far: 77824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1216: 1.1161837577819824\n",
      "Seen so far: 77888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1217: 1.2773962020874023\n",
      "Seen so far: 77952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1218: 1.1258766651153564\n",
      "Seen so far: 78016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1219: 1.3797318935394287\n",
      "Seen so far: 78080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1220: 1.2221791744232178\n",
      "Seen so far: 78144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1221: 1.3790874481201172\n",
      "Seen so far: 78208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1222: 1.2226762771606445\n",
      "Seen so far: 78272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1223: 1.1647199392318726\n",
      "Seen so far: 78336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1224: 1.1348565816879272\n",
      "Seen so far: 78400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1225: 1.2569265365600586\n",
      "Seen so far: 78464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1226: 1.4086284637451172\n",
      "Seen so far: 78528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1227: 1.3436471223831177\n",
      "Seen so far: 78592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1228: 1.2696290016174316\n",
      "Seen so far: 78656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1229: 1.3100868463516235\n",
      "Seen so far: 78720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1230: 1.143271565437317\n",
      "Seen so far: 78784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1231: 1.1961910724639893\n",
      "Seen so far: 78848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1232: 1.3490216732025146\n",
      "Seen so far: 78912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1233: 1.406661033630371\n",
      "Seen so far: 78976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1234: 1.5641629695892334\n",
      "Seen so far: 79040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1235: 1.377057671546936\n",
      "Seen so far: 79104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1236: 1.1435883045196533\n",
      "Seen so far: 79168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1237: 1.3774100542068481\n",
      "Seen so far: 79232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1238: 1.5007184743881226\n",
      "Seen so far: 79296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1239: 1.1316336393356323\n",
      "Seen so far: 79360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1240: 1.439980387687683\n",
      "Seen so far: 79424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1241: 1.3638405799865723\n",
      "Seen so far: 79488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1242: 1.2253878116607666\n",
      "Seen so far: 79552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1243: 1.6548833847045898\n",
      "Seen so far: 79616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1244: 1.0748133659362793\n",
      "Seen so far: 79680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1245: 1.2635307312011719\n",
      "Seen so far: 79744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1246: 1.0994683504104614\n",
      "Seen so far: 79808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1247: 0.9627000093460083\n",
      "Seen so far: 79872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1248: 0.9798852205276489\n",
      "Seen so far: 79936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1249: 1.4498999118804932\n",
      "Seen so far: 80000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1250: 1.1273515224456787\n",
      "Seen so far: 80064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1251: 0.7867059707641602\n",
      "Seen so far: 80128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1252: 1.5493896007537842\n",
      "Seen so far: 80192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1253: 0.9042458534240723\n",
      "Seen so far: 80256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1254: 1.1514338254928589\n",
      "Seen so far: 80320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1255: 0.9686482548713684\n",
      "Seen so far: 80384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1256: 1.5791913270950317\n",
      "Seen so far: 80448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1257: 1.33054780960083\n",
      "Seen so far: 80512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1258: 0.9990051984786987\n",
      "Seen so far: 80576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1259: 0.9263642430305481\n",
      "Seen so far: 80640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1260: 1.2397663593292236\n",
      "Seen so far: 80704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1261: 0.8255752325057983\n",
      "Seen so far: 80768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1262: 0.9589521288871765\n",
      "Seen so far: 80832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1263: 1.0699247121810913\n",
      "Seen so far: 80896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1264: 1.0998014211654663\n",
      "Seen so far: 80960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1265: 1.2339210510253906\n",
      "Seen so far: 81024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1266: 1.0163136720657349\n",
      "Seen so far: 81088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1267: 1.3689115047454834\n",
      "Seen so far: 81152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1268: 0.991502046585083\n",
      "Seen so far: 81216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1269: 1.2708855867385864\n",
      "Seen so far: 81280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1270: 1.474238395690918\n",
      "Seen so far: 81344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1271: 0.9928573966026306\n",
      "Seen so far: 81408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1272: 1.3080837726593018\n",
      "Seen so far: 81472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1273: 1.1127926111221313\n",
      "Seen so far: 81536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1274: 1.2090892791748047\n",
      "Seen so far: 81600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1275: 1.0709463357925415\n",
      "Seen so far: 81664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1276: 1.128000259399414\n",
      "Seen so far: 81728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1277: 1.0585383176803589\n",
      "Seen so far: 81792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1278: 1.3353770971298218\n",
      "Seen so far: 81856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1279: 1.383387804031372\n",
      "Seen so far: 81920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1280: 1.2927436828613281\n",
      "Seen so far: 81984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1281: 1.0024302005767822\n",
      "Seen so far: 82048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1282: 1.1108778715133667\n",
      "Seen so far: 82112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1283: 1.204455852508545\n",
      "Seen so far: 82176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1284: 1.479355812072754\n",
      "Seen so far: 82240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1285: 1.1282751560211182\n",
      "Seen so far: 82304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1286: 1.3218417167663574\n",
      "Seen so far: 82368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1287: 1.1952035427093506\n",
      "Seen so far: 82432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1288: 0.8470937013626099\n",
      "Seen so far: 82496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1289: 1.5456385612487793\n",
      "Seen so far: 82560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1290: 1.1024870872497559\n",
      "Seen so far: 82624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1291: 0.9847899675369263\n",
      "Seen so far: 82688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1292: 0.6045109033584595\n",
      "Seen so far: 82752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1293: 1.3849632740020752\n",
      "Seen so far: 82816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1294: 1.2909133434295654\n",
      "Seen so far: 82880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1295: 1.1438041925430298\n",
      "Seen so far: 82944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1296: 0.9420964121818542\n",
      "Seen so far: 83008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1297: 1.2278516292572021\n",
      "Seen so far: 83072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1298: 0.8371008038520813\n",
      "Seen so far: 83136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1299: 1.0281014442443848\n",
      "Seen so far: 83200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1300: 1.5349948406219482\n",
      "Seen so far: 83264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1301: 1.3122706413269043\n",
      "Seen so far: 83328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1302: 1.3307061195373535\n",
      "Seen so far: 83392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1303: 1.5181221961975098\n",
      "Seen so far: 83456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1304: 0.7258020043373108\n",
      "Seen so far: 83520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1305: 0.9546369910240173\n",
      "Seen so far: 83584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1306: 1.4293138980865479\n",
      "Seen so far: 83648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1307: 1.1756510734558105\n",
      "Seen so far: 83712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1308: 1.2675445079803467\n",
      "Seen so far: 83776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1309: 1.063230037689209\n",
      "Seen so far: 83840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1310: 1.2963676452636719\n",
      "Seen so far: 83904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1311: 1.277834415435791\n",
      "Seen so far: 83968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1312: 1.2483294010162354\n",
      "Seen so far: 84032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1313: 1.331329345703125\n",
      "Seen so far: 84096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1314: 1.207826018333435\n",
      "Seen so far: 84160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1315: 1.6630158424377441\n",
      "Seen so far: 84224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1316: 1.6050482988357544\n",
      "Seen so far: 84288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1317: 1.3560460805892944\n",
      "Seen so far: 84352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1318: 1.3363914489746094\n",
      "Seen so far: 84416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1319: 1.3974857330322266\n",
      "Seen so far: 84480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1320: 1.372103214263916\n",
      "Seen so far: 84544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1321: 1.8843610286712646\n",
      "Seen so far: 84608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1322: 1.2914336919784546\n",
      "Seen so far: 84672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1323: 0.9039994478225708\n",
      "Seen so far: 84736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1324: 1.1500334739685059\n",
      "Seen so far: 84800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1325: 1.347564935684204\n",
      "Seen so far: 84864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1326: 1.219700813293457\n",
      "Seen so far: 84928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1327: 1.1307623386383057\n",
      "Seen so far: 84992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1328: 1.4200201034545898\n",
      "Seen so far: 85056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1329: 1.235227346420288\n",
      "Seen so far: 85120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1330: 1.1696242094039917\n",
      "Seen so far: 85184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1331: 1.4506988525390625\n",
      "Seen so far: 85248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1332: 1.2830212116241455\n",
      "Seen so far: 85312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1333: 1.2751351594924927\n",
      "Seen so far: 85376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1334: 1.455855131149292\n",
      "Seen so far: 85440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1335: 1.164522409439087\n",
      "Seen so far: 85504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1336: 1.3078007698059082\n",
      "Seen so far: 85568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1337: 1.4275919198989868\n",
      "Seen so far: 85632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1338: 1.1577706336975098\n",
      "Seen so far: 85696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1339: 1.2982829809188843\n",
      "Seen so far: 85760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1340: 1.4702696800231934\n",
      "Seen so far: 85824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1341: 1.44308602809906\n",
      "Seen so far: 85888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1342: 1.0354864597320557\n",
      "Seen so far: 85952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1343: 1.6578373908996582\n",
      "Seen so far: 86016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1344: 1.4641084671020508\n",
      "Seen so far: 86080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1345: 1.1003096103668213\n",
      "Seen so far: 86144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1346: 1.2119940519332886\n",
      "Seen so far: 86208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1347: 1.1043142080307007\n",
      "Seen so far: 86272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1348: 1.5715389251708984\n",
      "Seen so far: 86336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1349: 1.43741774559021\n",
      "Seen so far: 86400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1350: 1.3088886737823486\n",
      "Seen so far: 86464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1351: 0.8479939699172974\n",
      "Seen so far: 86528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1352: 1.346655011177063\n",
      "Seen so far: 86592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1353: 0.9806557893753052\n",
      "Seen so far: 86656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1354: 1.8108277320861816\n",
      "Seen so far: 86720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1355: 1.249324083328247\n",
      "Seen so far: 86784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1356: 1.0919634103775024\n",
      "Seen so far: 86848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1357: 1.096472978591919\n",
      "Seen so far: 86912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1358: 0.9490782022476196\n",
      "Seen so far: 86976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1359: 1.2847635746002197\n",
      "Seen so far: 87040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1360: 1.4399549961090088\n",
      "Seen so far: 87104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1361: 0.9373353719711304\n",
      "Seen so far: 87168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1362: 1.2867989540100098\n",
      "Seen so far: 87232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1363: 1.2436479330062866\n",
      "Seen so far: 87296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1364: 1.3227643966674805\n",
      "Seen so far: 87360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1365: 1.148007869720459\n",
      "Seen so far: 87424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1366: 1.1045523881912231\n",
      "Seen so far: 87488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1367: 1.620274305343628\n",
      "Seen so far: 87552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1368: 1.5361067056655884\n",
      "Seen so far: 87616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1369: 0.732530951499939\n",
      "Seen so far: 87680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1370: 1.028077244758606\n",
      "Seen so far: 87744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1371: 0.9737443923950195\n",
      "Seen so far: 87808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1372: 1.577509880065918\n",
      "Seen so far: 87872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1373: 1.2219483852386475\n",
      "Seen so far: 87936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1374: 1.2921667098999023\n",
      "Seen so far: 88000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1375: 1.016144037246704\n",
      "Seen so far: 88064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1376: 1.2658687829971313\n",
      "Seen so far: 88128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1377: 1.3591868877410889\n",
      "Seen so far: 88192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1378: 1.4023807048797607\n",
      "Seen so far: 88256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1379: 1.4973180294036865\n",
      "Seen so far: 88320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1380: 1.2044587135314941\n",
      "Seen so far: 88384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1381: 1.2092139720916748\n",
      "Seen so far: 88448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1382: 1.0851843357086182\n",
      "Seen so far: 88512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1383: 1.7390350103378296\n",
      "Seen so far: 88576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1384: 0.7610728740692139\n",
      "Seen so far: 88640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1385: 1.2440898418426514\n",
      "Seen so far: 88704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1386: 1.2364304065704346\n",
      "Seen so far: 88768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1387: 1.2210835218429565\n",
      "Seen so far: 88832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1388: 1.4100056886672974\n",
      "Seen so far: 88896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1389: 0.8948861360549927\n",
      "Seen so far: 88960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1390: 0.9313924908638\n",
      "Seen so far: 89024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1391: 1.2935289144515991\n",
      "Seen so far: 89088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1392: 1.658008337020874\n",
      "Seen so far: 89152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1393: 1.4709666967391968\n",
      "Seen so far: 89216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1394: 1.1199922561645508\n",
      "Seen so far: 89280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1395: 1.5888922214508057\n",
      "Seen so far: 89344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1396: 1.177579402923584\n",
      "Seen so far: 89408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1397: 1.327044129371643\n",
      "Seen so far: 89472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1398: 1.0038399696350098\n",
      "Seen so far: 89536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1399: 1.510909080505371\n",
      "Seen so far: 89600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1400: 1.3807064294815063\n",
      "Seen so far: 89664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1401: 1.2049567699432373\n",
      "Seen so far: 89728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1402: 1.2243905067443848\n",
      "Seen so far: 89792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1403: 1.2824304103851318\n",
      "Seen so far: 89856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1404: 0.9396435618400574\n",
      "Seen so far: 89920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1405: 1.0744388103485107\n",
      "Seen so far: 89984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1406: 1.6529333591461182\n",
      "Seen so far: 90048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1407: 1.0517661571502686\n",
      "Seen so far: 90112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1408: 1.074660301208496\n",
      "Seen so far: 90176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1409: 1.1996790170669556\n",
      "Seen so far: 90240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1410: 1.0317294597625732\n",
      "Seen so far: 90304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1411: 0.7579751014709473\n",
      "Seen so far: 90368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1412: 1.1618523597717285\n",
      "Seen so far: 90432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1413: 1.227378010749817\n",
      "Seen so far: 90496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1414: 1.0997939109802246\n",
      "Seen so far: 90560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1415: 1.2013514041900635\n",
      "Seen so far: 90624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1416: 0.9981327056884766\n",
      "Seen so far: 90688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1417: 1.401296615600586\n",
      "Seen so far: 90752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1418: 1.2662583589553833\n",
      "Seen so far: 90816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1419: 1.1170357465744019\n",
      "Seen so far: 90880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1420: 1.0747003555297852\n",
      "Seen so far: 90944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1421: 0.9933871030807495\n",
      "Seen so far: 91008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1422: 1.117914080619812\n",
      "Seen so far: 91072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1423: 0.8275569677352905\n",
      "Seen so far: 91136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1424: 1.28985595703125\n",
      "Seen so far: 91200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1425: 1.1853073835372925\n",
      "Seen so far: 91264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1426: 1.2790824174880981\n",
      "Seen so far: 91328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1427: 1.1474733352661133\n",
      "Seen so far: 91392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1428: 1.4472416639328003\n",
      "Seen so far: 91456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1429: 1.2311439514160156\n",
      "Seen so far: 91520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1430: 0.9836254715919495\n",
      "Seen so far: 91584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1431: 1.3104913234710693\n",
      "Seen so far: 91648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1432: 0.9716777801513672\n",
      "Seen so far: 91712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1433: 1.2866928577423096\n",
      "Seen so far: 91776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1434: 1.0040093660354614\n",
      "Seen so far: 91840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1435: 1.2884907722473145\n",
      "Seen so far: 91904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1436: 1.1716505289077759\n",
      "Seen so far: 91968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1437: 1.3507301807403564\n",
      "Seen so far: 92032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1438: 1.5005630254745483\n",
      "Seen so far: 92096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1439: 1.3765093088150024\n",
      "Seen so far: 92160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1440: 1.4184010028839111\n",
      "Seen so far: 92224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1441: 1.061414361000061\n",
      "Seen so far: 92288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1442: 1.5788134336471558\n",
      "Seen so far: 92352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1443: 1.398656964302063\n",
      "Seen so far: 92416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1444: 1.2778868675231934\n",
      "Seen so far: 92480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1445: 1.4559967517852783\n",
      "Seen so far: 92544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1446: 1.5909628868103027\n",
      "Seen so far: 92608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1447: 1.0926251411437988\n",
      "Seen so far: 92672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1448: 1.018122911453247\n",
      "Seen so far: 92736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1449: 1.5242449045181274\n",
      "Seen so far: 92800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1450: 1.2649095058441162\n",
      "Seen so far: 92864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1451: 1.4562073945999146\n",
      "Seen so far: 92928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1452: 0.8902179002761841\n",
      "Seen so far: 92992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1453: 1.340989351272583\n",
      "Seen so far: 93056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1454: 0.9631810188293457\n",
      "Seen so far: 93120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1455: 1.4985392093658447\n",
      "Seen so far: 93184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1456: 0.935756504535675\n",
      "Seen so far: 93248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1457: 1.497243881225586\n",
      "Seen so far: 93312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1458: 1.135107159614563\n",
      "Seen so far: 93376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1459: 1.4639118909835815\n",
      "Seen so far: 93440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1460: 1.1536428928375244\n",
      "Seen so far: 93504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1461: 1.371934413909912\n",
      "Seen so far: 93568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1462: 1.2337732315063477\n",
      "Seen so far: 93632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1463: 1.5321424007415771\n",
      "Seen so far: 93696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1464: 0.9313619136810303\n",
      "Seen so far: 93760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1465: 1.4071226119995117\n",
      "Seen so far: 93824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1466: 1.1896324157714844\n",
      "Seen so far: 93888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1467: 1.1589633226394653\n",
      "Seen so far: 93952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1468: 1.1826789379119873\n",
      "Seen so far: 94016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1469: 0.8982402086257935\n",
      "Seen so far: 94080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1470: 1.2446508407592773\n",
      "Seen so far: 94144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1471: 1.0977352857589722\n",
      "Seen so far: 94208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1472: 1.2456518411636353\n",
      "Seen so far: 94272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1473: 1.1667227745056152\n",
      "Seen so far: 94336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1474: 0.9593154788017273\n",
      "Seen so far: 94400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1475: 1.6538506746292114\n",
      "Seen so far: 94464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1476: 0.8608226776123047\n",
      "Seen so far: 94528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1477: 1.2645750045776367\n",
      "Seen so far: 94592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1478: 1.640986680984497\n",
      "Seen so far: 94656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1479: 1.152292251586914\n",
      "Seen so far: 94720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1480: 0.7632100582122803\n",
      "Seen so far: 94784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1481: 1.2471024990081787\n",
      "Seen so far: 94848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1482: 0.8812050819396973\n",
      "Seen so far: 94912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1483: 1.1993285417556763\n",
      "Seen so far: 94976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1484: 0.8403744101524353\n",
      "Seen so far: 95040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1485: 1.0006210803985596\n",
      "Seen so far: 95104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1486: 1.1285794973373413\n",
      "Seen so far: 95168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1487: 0.9413449168205261\n",
      "Seen so far: 95232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1488: 1.3466558456420898\n",
      "Seen so far: 95296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1489: 1.3191163539886475\n",
      "Seen so far: 95360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1490: 1.2455134391784668\n",
      "Seen so far: 95424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1491: 0.9021098017692566\n",
      "Seen so far: 95488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1492: 1.1046521663665771\n",
      "Seen so far: 95552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1493: 1.029757022857666\n",
      "Seen so far: 95616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1494: 1.2151107788085938\n",
      "Seen so far: 95680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1495: 1.6877236366271973\n",
      "Seen so far: 95744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1496: 0.9820349216461182\n",
      "Seen so far: 95808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1497: 1.0593801736831665\n",
      "Seen so far: 95872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1498: 1.0597920417785645\n",
      "Seen so far: 95936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1499: 1.499450922012329\n",
      "Seen so far: 96000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1500: 1.1123416423797607\n",
      "Seen so far: 96064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1501: 1.6756794452667236\n",
      "Seen so far: 96128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1502: 1.2910641431808472\n",
      "Seen so far: 96192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1503: 0.7296410799026489\n",
      "Seen so far: 96256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1504: 1.269789695739746\n",
      "Seen so far: 96320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1505: 1.7284929752349854\n",
      "Seen so far: 96384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1506: 1.3012313842773438\n",
      "Seen so far: 96448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1507: 1.974477767944336\n",
      "Seen so far: 96512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1508: 0.8615513443946838\n",
      "Seen so far: 96576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1509: 1.30055832862854\n",
      "Seen so far: 96640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1510: 1.8549573421478271\n",
      "Seen so far: 96704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1511: 1.5936203002929688\n",
      "Seen so far: 96768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1512: 1.2827651500701904\n",
      "Seen so far: 96832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1513: 1.3590258359909058\n",
      "Seen so far: 96896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1514: 1.2879652976989746\n",
      "Seen so far: 96960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1515: 1.434308409690857\n",
      "Seen so far: 97024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1516: 1.291700839996338\n",
      "Seen so far: 97088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1517: 1.8575187921524048\n",
      "Seen so far: 97152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1518: 1.605506420135498\n",
      "Seen so far: 97216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1519: 0.8450334072113037\n",
      "Seen so far: 97280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1520: 1.356963872909546\n",
      "Seen so far: 97344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1521: 1.058982014656067\n",
      "Seen so far: 97408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1522: 1.50094473361969\n",
      "Seen so far: 97472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1523: 1.3831309080123901\n",
      "Seen so far: 97536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1524: 1.403138279914856\n",
      "Seen so far: 97600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1525: 1.353698968887329\n",
      "Seen so far: 97664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1526: 1.3907924890518188\n",
      "Seen so far: 97728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1527: 1.0911881923675537\n",
      "Seen so far: 97792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1528: 0.9746803045272827\n",
      "Seen so far: 97856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1529: 1.193328619003296\n",
      "Seen so far: 97920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1530: 1.2521421909332275\n",
      "Seen so far: 97984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1531: 0.7252445220947266\n",
      "Seen so far: 98048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1532: 1.1603189706802368\n",
      "Seen so far: 98112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1533: 1.0322833061218262\n",
      "Seen so far: 98176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1534: 1.2408344745635986\n",
      "Seen so far: 98240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1535: 0.9499465227127075\n",
      "Seen so far: 98304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1536: 1.1171183586120605\n",
      "Seen so far: 98368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1537: 1.1542307138442993\n",
      "Seen so far: 98432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1538: 1.2988383769989014\n",
      "Seen so far: 98496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1539: 0.9396907091140747\n",
      "Seen so far: 98560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1540: 1.2292569875717163\n",
      "Seen so far: 98624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1541: 0.8864232301712036\n",
      "Seen so far: 98688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1542: 1.1111762523651123\n",
      "Seen so far: 98752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1543: 1.3054535388946533\n",
      "Seen so far: 98816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1544: 1.1603379249572754\n",
      "Seen so far: 98880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1545: 0.9748970866203308\n",
      "Seen so far: 98944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1546: 1.1933480501174927\n",
      "Seen so far: 99008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1547: 1.334511399269104\n",
      "Seen so far: 99072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1548: 0.9092361330986023\n",
      "Seen so far: 99136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1549: 1.0443339347839355\n",
      "Seen so far: 99200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1550: 1.3189189434051514\n",
      "Seen so far: 99264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1551: 1.4788901805877686\n",
      "Seen so far: 99328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1552: 0.9531033039093018\n",
      "Seen so far: 99392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1553: 1.0827769041061401\n",
      "Seen so far: 99456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1554: 1.6285741329193115\n",
      "Seen so far: 99520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1555: 1.1622488498687744\n",
      "Seen so far: 99584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1556: 1.1041640043258667\n",
      "Seen so far: 99648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1557: 1.2937023639678955\n",
      "Seen so far: 99712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1558: 0.944110631942749\n",
      "Seen so far: 99776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1559: 0.930687427520752\n",
      "Seen so far: 99840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1560: 1.6077394485473633\n",
      "Seen so far: 99904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1561: 1.0218786001205444\n",
      "Seen so far: 99968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1562: 1.2026389837265015\n",
      "Seen so far: 100032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1563: 0.9974400997161865\n",
      "Seen so far: 100096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1564: 1.3028604984283447\n",
      "Seen so far: 100160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1565: 1.5280287265777588\n",
      "Seen so far: 100224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1566: 1.4302334785461426\n",
      "Seen so far: 100288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1567: 0.9828563928604126\n",
      "Seen so far: 100352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1568: 1.1302945613861084\n",
      "Seen so far: 100416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1569: 1.2394866943359375\n",
      "Seen so far: 100480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1570: 1.7624294757843018\n",
      "Seen so far: 100544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1571: 1.5490248203277588\n",
      "Seen so far: 100608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1572: 1.360703945159912\n",
      "Seen so far: 100672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1573: 1.6326549053192139\n",
      "Seen so far: 100736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1574: 1.3937218189239502\n",
      "Seen so far: 100800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1575: 1.5801692008972168\n",
      "Seen so far: 100864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1576: 1.2560064792633057\n",
      "Seen so far: 100928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1577: 1.2185556888580322\n",
      "Seen so far: 100992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1578: 1.4954283237457275\n",
      "Seen so far: 101056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1579: 1.0259697437286377\n",
      "Seen so far: 101120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1580: 1.2470579147338867\n",
      "Seen so far: 101184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1581: 1.0669811964035034\n",
      "Seen so far: 101248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1582: 1.2555227279663086\n",
      "Seen so far: 101312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1583: 1.1442312002182007\n",
      "Seen so far: 101376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1584: 1.3011627197265625\n",
      "Seen so far: 101440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1585: 1.6079306602478027\n",
      "Seen so far: 101504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1586: 1.3069052696228027\n",
      "Seen so far: 101568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1587: 0.6944595575332642\n",
      "Seen so far: 101632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1588: 1.0024528503417969\n",
      "Seen so far: 101696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1589: 1.5150160789489746\n",
      "Seen so far: 101760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1590: 1.1975079774856567\n",
      "Seen so far: 101824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1591: 1.144339919090271\n",
      "Seen so far: 101888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1592: 1.145996332168579\n",
      "Seen so far: 101952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1593: 1.0068204402923584\n",
      "Seen so far: 102016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1594: 1.0682072639465332\n",
      "Seen so far: 102080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1595: 1.2216871976852417\n",
      "Seen so far: 102144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1596: 0.9328388571739197\n",
      "Seen so far: 102208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1597: 1.3331830501556396\n",
      "Seen so far: 102272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1598: 1.3162684440612793\n",
      "Seen so far: 102336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1599: 1.1441770792007446\n",
      "Seen so far: 102400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1600: 0.9430078268051147\n",
      "Seen so far: 102464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1601: 1.1738773584365845\n",
      "Seen so far: 102528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1602: 0.7425992488861084\n",
      "Seen so far: 102592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1603: 1.5709028244018555\n",
      "Seen so far: 102656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1604: 1.2291994094848633\n",
      "Seen so far: 102720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1605: 1.7384980916976929\n",
      "Seen so far: 102784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1606: 1.4303184747695923\n",
      "Seen so far: 102848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1607: 1.2199673652648926\n",
      "Seen so far: 102912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1608: 1.258338451385498\n",
      "Seen so far: 102976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1609: 1.3676460981369019\n",
      "Seen so far: 103040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1610: 1.3956758975982666\n",
      "Seen so far: 103104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1611: 0.9566422700881958\n",
      "Seen so far: 103168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1612: 1.4543482065200806\n",
      "Seen so far: 103232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1613: 1.4116833209991455\n",
      "Seen so far: 103296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1614: 0.8090024590492249\n",
      "Seen so far: 103360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1615: 1.1749626398086548\n",
      "Seen so far: 103424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1616: 1.2965538501739502\n",
      "Seen so far: 103488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1617: 1.5425269603729248\n",
      "Seen so far: 103552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1618: 0.9110741019248962\n",
      "Seen so far: 103616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1619: 1.0588510036468506\n",
      "Seen so far: 103680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1620: 1.2209341526031494\n",
      "Seen so far: 103744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1621: 1.0137474536895752\n",
      "Seen so far: 103808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1622: 1.3058335781097412\n",
      "Seen so far: 103872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1623: 1.1945606470108032\n",
      "Seen so far: 103936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1624: 1.2826344966888428\n",
      "Seen so far: 104000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1625: 1.6220645904541016\n",
      "Seen so far: 104064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1626: 1.4972777366638184\n",
      "Seen so far: 104128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1627: 1.2629315853118896\n",
      "Seen so far: 104192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1628: 1.1351161003112793\n",
      "Seen so far: 104256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1629: 1.228204607963562\n",
      "Seen so far: 104320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1630: 1.3660671710968018\n",
      "Seen so far: 104384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1631: 0.9720509052276611\n",
      "Seen so far: 104448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1632: 1.2484956979751587\n",
      "Seen so far: 104512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1633: 1.2548985481262207\n",
      "Seen so far: 104576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1634: 1.177229881286621\n",
      "Seen so far: 104640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1635: 0.8938677310943604\n",
      "Seen so far: 104704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1636: 1.3598607778549194\n",
      "Seen so far: 104768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1637: 0.9016698002815247\n",
      "Seen so far: 104832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1638: 1.4098953008651733\n",
      "Seen so far: 104896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1639: 0.9231423139572144\n",
      "Seen so far: 104960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1640: 1.3653383255004883\n",
      "Seen so far: 105024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1641: 0.7848824262619019\n",
      "Seen so far: 105088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1642: 1.216109275817871\n",
      "Seen so far: 105152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1643: 1.631742238998413\n",
      "Seen so far: 105216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1644: 1.2486751079559326\n",
      "Seen so far: 105280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1645: 1.1578819751739502\n",
      "Seen so far: 105344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1646: 1.173575520515442\n",
      "Seen so far: 105408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1647: 0.9548961520195007\n",
      "Seen so far: 105472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1648: 1.0755131244659424\n",
      "Seen so far: 105536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1649: 1.7741138935089111\n",
      "Seen so far: 105600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1650: 1.0028619766235352\n",
      "Seen so far: 105664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1651: 1.4264525175094604\n",
      "Seen so far: 105728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1652: 1.1780390739440918\n",
      "Seen so far: 105792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1653: 1.1682524681091309\n",
      "Seen so far: 105856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1654: 1.0126460790634155\n",
      "Seen so far: 105920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1655: 1.1194261312484741\n",
      "Seen so far: 105984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1656: 1.0738627910614014\n",
      "Seen so far: 106048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1657: 1.2540290355682373\n",
      "Seen so far: 106112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1658: 1.055924415588379\n",
      "Seen so far: 106176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1659: 1.3878695964813232\n",
      "Seen so far: 106240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1660: 1.2630391120910645\n",
      "Seen so far: 106304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1661: 1.2721500396728516\n",
      "Seen so far: 106368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1662: 0.8251898884773254\n",
      "Seen so far: 106432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1663: 1.4570237398147583\n",
      "Seen so far: 106496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1664: 1.5547997951507568\n",
      "Seen so far: 106560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1665: 1.581217646598816\n",
      "Seen so far: 106624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1666: 1.1858811378479004\n",
      "Seen so far: 106688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1667: 0.9903790354728699\n",
      "Seen so far: 106752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1668: 1.4509882926940918\n",
      "Seen so far: 106816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1669: 1.0771923065185547\n",
      "Seen so far: 106880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1670: 1.5164315700531006\n",
      "Seen so far: 106944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1671: 1.2712292671203613\n",
      "Seen so far: 107008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1672: 1.453031063079834\n",
      "Seen so far: 107072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1673: 1.112668752670288\n",
      "Seen so far: 107136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1674: 1.0037012100219727\n",
      "Seen so far: 107200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1675: 1.2250823974609375\n",
      "Seen so far: 107264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1676: 1.4540379047393799\n",
      "Seen so far: 107328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1677: 1.124210238456726\n",
      "Seen so far: 107392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1678: 1.0521318912506104\n",
      "Seen so far: 107456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1679: 1.264742136001587\n",
      "Seen so far: 107520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1680: 1.0922237634658813\n",
      "Seen so far: 107584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1681: 1.6653248071670532\n",
      "Seen so far: 107648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1682: 1.0564262866973877\n",
      "Seen so far: 107712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1683: 1.3158984184265137\n",
      "Seen so far: 107776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1684: 1.3349260091781616\n",
      "Seen so far: 107840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1685: 1.1618160009384155\n",
      "Seen so far: 107904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1686: 1.3287415504455566\n",
      "Seen so far: 107968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1687: 1.4365462064743042\n",
      "Seen so far: 108032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1688: 1.3440104722976685\n",
      "Seen so far: 108096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1689: 1.0442068576812744\n",
      "Seen so far: 108160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1690: 1.3035842180252075\n",
      "Seen so far: 108224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1691: 0.7908782958984375\n",
      "Seen so far: 108288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1692: 0.9859139919281006\n",
      "Seen so far: 108352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1693: 1.603468656539917\n",
      "Seen so far: 108416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1694: 1.300602912902832\n",
      "Seen so far: 108480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1695: 1.1222320795059204\n",
      "Seen so far: 108544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1696: 1.5619001388549805\n",
      "Seen so far: 108608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1697: 1.265582799911499\n",
      "Seen so far: 108672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1698: 1.04120934009552\n",
      "Seen so far: 108736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1699: 0.8009552359580994\n",
      "Seen so far: 108800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1700: 0.9877266883850098\n",
      "Seen so far: 108864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1701: 1.278784990310669\n",
      "Seen so far: 108928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1702: 1.6008565425872803\n",
      "Seen so far: 108992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1703: 0.9268001317977905\n",
      "Seen so far: 109056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1704: 1.6405138969421387\n",
      "Seen so far: 109120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1705: 1.610885739326477\n",
      "Seen so far: 109184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1706: 1.599095106124878\n",
      "Seen so far: 109248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1707: 1.3940492868423462\n",
      "Seen so far: 109312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1708: 1.189764142036438\n",
      "Seen so far: 109376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1709: 1.7174385786056519\n",
      "Seen so far: 109440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1710: 1.2149733304977417\n",
      "Seen so far: 109504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1711: 1.1491403579711914\n",
      "Seen so far: 109568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1712: 1.177007794380188\n",
      "Seen so far: 109632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1713: 1.0160675048828125\n",
      "Seen so far: 109696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1714: 1.2116103172302246\n",
      "Seen so far: 109760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1715: 1.038739562034607\n",
      "Seen so far: 109824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1716: 1.6740307807922363\n",
      "Seen so far: 109888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1717: 1.1280193328857422\n",
      "Seen so far: 109952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1718: 0.9235777258872986\n",
      "Seen so far: 110016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1719: 1.0862617492675781\n",
      "Seen so far: 110080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1720: 1.4664453268051147\n",
      "Seen so far: 110144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1721: 1.260873556137085\n",
      "Seen so far: 110208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1722: 1.0164639949798584\n",
      "Seen so far: 110272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1723: 0.8733474016189575\n",
      "Seen so far: 110336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1724: 1.5452570915222168\n",
      "Seen so far: 110400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1725: 1.242783784866333\n",
      "Seen so far: 110464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1726: 1.726841688156128\n",
      "Seen so far: 110528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1727: 1.0454288721084595\n",
      "Seen so far: 110592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1728: 1.0072495937347412\n",
      "Seen so far: 110656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1729: 1.1952420473098755\n",
      "Seen so far: 110720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1730: 1.199472427368164\n",
      "Seen so far: 110784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1731: 0.6786609888076782\n",
      "Seen so far: 110848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1732: 1.2539864778518677\n",
      "Seen so far: 110912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1733: 1.543297529220581\n",
      "Seen so far: 110976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1734: 1.0291398763656616\n",
      "Seen so far: 111040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1735: 1.0569615364074707\n",
      "Seen so far: 111104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1736: 1.2068710327148438\n",
      "Seen so far: 111168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1737: 1.3178308010101318\n",
      "Seen so far: 111232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1738: 0.81843101978302\n",
      "Seen so far: 111296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1739: 1.2872909307479858\n",
      "Seen so far: 111360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1740: 1.301694393157959\n",
      "Seen so far: 111424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1741: 1.001126766204834\n",
      "Seen so far: 111488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1742: 1.1243150234222412\n",
      "Seen so far: 111552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1743: 0.6948572993278503\n",
      "Seen so far: 111616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1744: 0.9753036499023438\n",
      "Seen so far: 111680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1745: 1.1575591564178467\n",
      "Seen so far: 111744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1746: 1.4875802993774414\n",
      "Seen so far: 111808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1747: 1.8598544597625732\n",
      "Seen so far: 111872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1748: 1.139972448348999\n",
      "Seen so far: 111936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1749: 0.9135088920593262\n",
      "Seen so far: 112000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1750: 1.1929435729980469\n",
      "Seen so far: 112064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1751: 0.9331819415092468\n",
      "Seen so far: 112128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1752: 1.4260046482086182\n",
      "Seen so far: 112192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1753: 1.4079022407531738\n",
      "Seen so far: 112256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1754: 1.4259247779846191\n",
      "Seen so far: 112320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1755: 1.1809494495391846\n",
      "Seen so far: 112384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1756: 1.5413672924041748\n",
      "Seen so far: 112448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1757: 1.260675072669983\n",
      "Seen so far: 112512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1758: 1.4591773748397827\n",
      "Seen so far: 112576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1759: 1.1786527633666992\n",
      "Seen so far: 112640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1760: 1.4055445194244385\n",
      "Seen so far: 112704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1761: 1.06722891330719\n",
      "Seen so far: 112768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1762: 1.0629099607467651\n",
      "Seen so far: 112832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1763: 1.5358691215515137\n",
      "Seen so far: 112896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1764: 1.2232155799865723\n",
      "Seen so far: 112960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1765: 0.864976167678833\n",
      "Seen so far: 113024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1766: 1.2369017601013184\n",
      "Seen so far: 113088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1767: 1.3199269771575928\n",
      "Seen so far: 113152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1768: 1.5617611408233643\n",
      "Seen so far: 113216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1769: 1.0756150484085083\n",
      "Seen so far: 113280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1770: 1.2383241653442383\n",
      "Seen so far: 113344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1771: 1.3152501583099365\n",
      "Seen so far: 113408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1772: 1.3472371101379395\n",
      "Seen so far: 113472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1773: 1.1205699443817139\n",
      "Seen so far: 113536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1774: 1.0561926364898682\n",
      "Seen so far: 113600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1775: 0.9947408437728882\n",
      "Seen so far: 113664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1776: 1.583374261856079\n",
      "Seen so far: 113728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1777: 1.4869173765182495\n",
      "Seen so far: 113792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1778: 1.065335988998413\n",
      "Seen so far: 113856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1779: 1.806801199913025\n",
      "Seen so far: 113920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1780: 1.4875550270080566\n",
      "Seen so far: 113984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1781: 1.5059322118759155\n",
      "Seen so far: 114048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1782: 1.1454575061798096\n",
      "Seen so far: 114112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1783: 1.2693449258804321\n",
      "Seen so far: 114176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1784: 1.0867092609405518\n",
      "Seen so far: 114240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1785: 1.1505327224731445\n",
      "Seen so far: 114304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1786: 0.9865341186523438\n",
      "Seen so far: 114368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1787: 1.572214126586914\n",
      "Seen so far: 114432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1788: 1.307863712310791\n",
      "Seen so far: 114496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1789: 1.2978397607803345\n",
      "Seen so far: 114560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1790: 1.6423354148864746\n",
      "Seen so far: 114624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1791: 1.0395857095718384\n",
      "Seen so far: 114688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1792: 0.9184054732322693\n",
      "Seen so far: 114752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1793: 1.2681820392608643\n",
      "Seen so far: 114816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1794: 1.3001949787139893\n",
      "Seen so far: 114880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1795: 1.5152608156204224\n",
      "Seen so far: 114944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1796: 1.1437934637069702\n",
      "Seen so far: 115008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1797: 1.042046308517456\n",
      "Seen so far: 115072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1798: 0.7789405584335327\n",
      "Seen so far: 115136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1799: 1.303655743598938\n",
      "Seen so far: 115200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1800: 0.9918563365936279\n",
      "Seen so far: 115264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1801: 1.0217201709747314\n",
      "Seen so far: 115328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1802: 0.9982959032058716\n",
      "Seen so far: 115392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1803: 1.3597502708435059\n",
      "Seen so far: 115456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1804: 1.2570137977600098\n",
      "Seen so far: 115520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1805: 0.923168420791626\n",
      "Seen so far: 115584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1806: 1.0942614078521729\n",
      "Seen so far: 115648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1807: 1.2735120058059692\n",
      "Seen so far: 115712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1808: 1.2364768981933594\n",
      "Seen so far: 115776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1809: 1.505462408065796\n",
      "Seen so far: 115840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1810: 1.2328612804412842\n",
      "Seen so far: 115904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1811: 1.1179300546646118\n",
      "Seen so far: 115968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1812: 0.9203530550003052\n",
      "Seen so far: 116032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1813: 1.5240981578826904\n",
      "Seen so far: 116096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1814: 1.0817899703979492\n",
      "Seen so far: 116160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1815: 1.4797708988189697\n",
      "Seen so far: 116224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1816: 1.3326140642166138\n",
      "Seen so far: 116288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1817: 1.0605663061141968\n",
      "Seen so far: 116352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1818: 1.2040694952011108\n",
      "Seen so far: 116416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1819: 1.2361741065979004\n",
      "Seen so far: 116480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1820: 1.1890252828598022\n",
      "Seen so far: 116544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1821: 1.6148496866226196\n",
      "Seen so far: 116608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1822: 1.532423496246338\n",
      "Seen so far: 116672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1823: 1.592905044555664\n",
      "Seen so far: 116736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1824: 1.2108967304229736\n",
      "Seen so far: 116800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1825: 1.2464057207107544\n",
      "Seen so far: 116864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1826: 1.538078784942627\n",
      "Seen so far: 116928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1827: 1.598689317703247\n",
      "Seen so far: 116992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1828: 1.1720384359359741\n",
      "Seen so far: 117056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1829: 1.1172890663146973\n",
      "Seen so far: 117120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1830: 1.1418334245681763\n",
      "Seen so far: 117184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1831: 1.1552989482879639\n",
      "Seen so far: 117248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1832: 1.6521587371826172\n",
      "Seen so far: 117312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1833: 1.1674656867980957\n",
      "Seen so far: 117376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1834: 1.5076773166656494\n",
      "Seen so far: 117440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1835: 0.8845187425613403\n",
      "Seen so far: 117504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1836: 1.2474901676177979\n",
      "Seen so far: 117568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1837: 0.8473705053329468\n",
      "Seen so far: 117632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1838: 1.2589728832244873\n",
      "Seen so far: 117696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1839: 1.0558888912200928\n",
      "Seen so far: 117760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1840: 1.524619221687317\n",
      "Seen so far: 117824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1841: 1.0886789560317993\n",
      "Seen so far: 117888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1842: 0.9261782169342041\n",
      "Seen so far: 117952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1843: 1.296543836593628\n",
      "Seen so far: 118016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1844: 1.2566328048706055\n",
      "Seen so far: 118080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1845: 1.3575060367584229\n",
      "Seen so far: 118144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1846: 1.32952880859375\n",
      "Seen so far: 118208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1847: 1.390233039855957\n",
      "Seen so far: 118272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1848: 1.0454506874084473\n",
      "Seen so far: 118336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1849: 1.3924473524093628\n",
      "Seen so far: 118400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1850: 1.1318801641464233\n",
      "Seen so far: 118464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1851: 1.5999548435211182\n",
      "Seen so far: 118528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1852: 1.3801519870758057\n",
      "Seen so far: 118592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1853: 1.0346980094909668\n",
      "Seen so far: 118656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1854: 1.4875820875167847\n",
      "Seen so far: 118720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1855: 1.3785028457641602\n",
      "Seen so far: 118784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1856: 1.1221908330917358\n",
      "Seen so far: 118848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1857: 0.8494530916213989\n",
      "Seen so far: 118912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1858: 1.2569711208343506\n",
      "Seen so far: 118976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1859: 0.9426225423812866\n",
      "Seen so far: 119040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1860: 0.9617732763290405\n",
      "Seen so far: 119104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1861: 1.1358263492584229\n",
      "Seen so far: 119168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1862: 1.0619924068450928\n",
      "Seen so far: 119232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1863: 0.8639043569564819\n",
      "Seen so far: 119296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1864: 1.1308081150054932\n",
      "Seen so far: 119360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1865: 1.007828950881958\n",
      "Seen so far: 119424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1866: 1.1716163158416748\n",
      "Seen so far: 119488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1867: 1.1383333206176758\n",
      "Seen so far: 119552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1868: 1.168306589126587\n",
      "Seen so far: 119616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1869: 0.9745689630508423\n",
      "Seen so far: 119680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1870: 0.902096152305603\n",
      "Seen so far: 119744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1871: 0.9897411465644836\n",
      "Seen so far: 119808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1872: 1.1764886379241943\n",
      "Seen so far: 119872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1873: 1.302923321723938\n",
      "Seen so far: 119936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1874: 1.172167420387268\n",
      "Seen so far: 120000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1875: 1.076157569885254\n",
      "Seen so far: 120064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1876: 0.8464667797088623\n",
      "Seen so far: 120128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1877: 0.7537524700164795\n",
      "Seen so far: 120192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1878: 1.2852084636688232\n",
      "Seen so far: 120256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1879: 1.3714654445648193\n",
      "Seen so far: 120320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1880: 1.2096184492111206\n",
      "Seen so far: 120384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1881: 0.6010341644287109\n",
      "Seen so far: 120448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1882: 1.317373275756836\n",
      "Seen so far: 120512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1883: 0.8282042145729065\n",
      "Seen so far: 120576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1884: 1.1970576047897339\n",
      "Seen so far: 120640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1885: 1.0138661861419678\n",
      "Seen so far: 120704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1886: 1.1658025979995728\n",
      "Seen so far: 120768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1887: 0.9969608187675476\n",
      "Seen so far: 120832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1888: 1.0215574502944946\n",
      "Seen so far: 120896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1889: 1.4842464923858643\n",
      "Seen so far: 120960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1890: 1.5571290254592896\n",
      "Seen so far: 121024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1891: 1.3923697471618652\n",
      "Seen so far: 121088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1892: 0.9202834963798523\n",
      "Seen so far: 121152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1893: 1.273756980895996\n",
      "Seen so far: 121216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1894: 1.4292662143707275\n",
      "Seen so far: 121280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1895: 1.2675589323043823\n",
      "Seen so far: 121344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1896: 0.7233231067657471\n",
      "Seen so far: 121408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1897: 1.6848070621490479\n",
      "Seen so far: 121472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1898: 1.2104555368423462\n",
      "Seen so far: 121536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1899: 1.2172598838806152\n",
      "Seen so far: 121600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1900: 1.290996789932251\n",
      "Seen so far: 121664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1901: 0.8918255567550659\n",
      "Seen so far: 121728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1902: 1.9524915218353271\n",
      "Seen so far: 121792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1903: 1.2597447633743286\n",
      "Seen so far: 121856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1904: 1.572402000427246\n",
      "Seen so far: 121920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1905: 1.1179232597351074\n",
      "Seen so far: 121984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1906: 0.799043595790863\n",
      "Seen so far: 122048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1907: 1.3987460136413574\n",
      "Seen so far: 122112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1908: 1.1294009685516357\n",
      "Seen so far: 122176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1909: 1.1788828372955322\n",
      "Seen so far: 122240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1910: 0.9926049709320068\n",
      "Seen so far: 122304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1911: 1.0325522422790527\n",
      "Seen so far: 122368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1912: 1.1936286687850952\n",
      "Seen so far: 122432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1913: 0.9669104814529419\n",
      "Seen so far: 122496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1914: 1.181807279586792\n",
      "Seen so far: 122560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1915: 0.968274712562561\n",
      "Seen so far: 122624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1916: 1.051817536354065\n",
      "Seen so far: 122688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1917: 1.031095266342163\n",
      "Seen so far: 122752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1918: 1.3963253498077393\n",
      "Seen so far: 122816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1919: 1.4655258655548096\n",
      "Seen so far: 122880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1920: 1.3407920598983765\n",
      "Seen so far: 122944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1921: 1.0671489238739014\n",
      "Seen so far: 123008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1922: 1.1920619010925293\n",
      "Seen so far: 123072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1923: 1.2614649534225464\n",
      "Seen so far: 123136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1924: 1.3063342571258545\n",
      "Seen so far: 123200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1925: 1.0835168361663818\n",
      "Seen so far: 123264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1926: 1.3989449739456177\n",
      "Seen so far: 123328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1927: 1.6148030757904053\n",
      "Seen so far: 123392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1928: 0.7848618030548096\n",
      "Seen so far: 123456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1929: 1.0608758926391602\n",
      "Seen so far: 123520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1930: 1.61631441116333\n",
      "Seen so far: 123584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1931: 1.0172338485717773\n",
      "Seen so far: 123648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1932: 1.5977067947387695\n",
      "Seen so far: 123712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1933: 1.1215323209762573\n",
      "Seen so far: 123776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1934: 1.5521917343139648\n",
      "Seen so far: 123840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1935: 1.6216638088226318\n",
      "Seen so far: 123904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1936: 1.801108956336975\n",
      "Seen so far: 123968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1937: 1.3256601095199585\n",
      "Seen so far: 124032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1938: 1.3545262813568115\n",
      "Seen so far: 124096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1939: 1.5118998289108276\n",
      "Seen so far: 124160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1940: 1.3270163536071777\n",
      "Seen so far: 124224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1941: 1.0945820808410645\n",
      "Seen so far: 124288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1942: 1.6293752193450928\n",
      "Seen so far: 124352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1943: 0.8505510091781616\n",
      "Seen so far: 124416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1944: 1.207495927810669\n",
      "Seen so far: 124480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1945: 1.2826688289642334\n",
      "Seen so far: 124544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1946: 1.1241482496261597\n",
      "Seen so far: 124608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1947: 1.3190301656723022\n",
      "Seen so far: 124672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1948: 1.531286358833313\n",
      "Seen so far: 124736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1949: 1.1441011428833008\n",
      "Seen so far: 124800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1950: 1.5519521236419678\n",
      "Seen so far: 124864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1951: 0.8138399124145508\n",
      "Seen so far: 124928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1952: 0.6964936256408691\n",
      "Seen so far: 124992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1953: 0.9655718207359314\n",
      "Seen so far: 125056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1954: 0.9631044268608093\n",
      "Seen so far: 125120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1955: 1.0437076091766357\n",
      "Seen so far: 125184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1956: 0.8815866112709045\n",
      "Seen so far: 125248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1957: 1.181681752204895\n",
      "Seen so far: 125312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1958: 1.1843714714050293\n",
      "Seen so far: 125376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1959: 1.0881319046020508\n",
      "Seen so far: 125440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1960: 1.4149993658065796\n",
      "Seen so far: 125504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1961: 1.2188940048217773\n",
      "Seen so far: 125568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1962: 1.248152494430542\n",
      "Seen so far: 125632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1963: 1.2184805870056152\n",
      "Seen so far: 125696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1964: 0.9006006717681885\n",
      "Seen so far: 125760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1965: 1.4178235530853271\n",
      "Seen so far: 125824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1966: 0.9924560785293579\n",
      "Seen so far: 125888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1967: 0.9384994506835938\n",
      "Seen so far: 125952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1968: 0.8332481980323792\n",
      "Seen so far: 126016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1969: 1.1256911754608154\n",
      "Seen so far: 126080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1970: 1.2894399166107178\n",
      "Seen so far: 126144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1971: 0.9136463403701782\n",
      "Seen so far: 126208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1972: 1.0129196643829346\n",
      "Seen so far: 126272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1973: 1.5884082317352295\n",
      "Seen so far: 126336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1974: 1.2902376651763916\n",
      "Seen so far: 126400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1975: 1.4461888074874878\n",
      "Seen so far: 126464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1976: 1.4314837455749512\n",
      "Seen so far: 126528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1977: 1.0806100368499756\n",
      "Seen so far: 126592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1978: 1.3146321773529053\n",
      "Seen so far: 126656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1979: 0.7107126116752625\n",
      "Seen so far: 126720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1980: 0.9916806221008301\n",
      "Seen so far: 126784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1981: 1.0105524063110352\n",
      "Seen so far: 126848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1982: 0.8672338724136353\n",
      "Seen so far: 126912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1983: 1.748033046722412\n",
      "Seen so far: 126976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1984: 1.0697405338287354\n",
      "Seen so far: 127040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1985: 1.1084117889404297\n",
      "Seen so far: 127104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1986: 0.9075751304626465\n",
      "Seen so far: 127168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1987: 1.4555708169937134\n",
      "Seen so far: 127232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1988: 1.5152950286865234\n",
      "Seen so far: 127296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1989: 1.1124029159545898\n",
      "Seen so far: 127360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1990: 1.1012650728225708\n",
      "Seen so far: 127424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1991: 1.3887279033660889\n",
      "Seen so far: 127488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1992: 1.4073866605758667\n",
      "Seen so far: 127552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1993: 1.0012133121490479\n",
      "Seen so far: 127616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1994: 1.1101974248886108\n",
      "Seen so far: 127680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1995: 1.0853632688522339\n",
      "Seen so far: 127744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1996: 1.1183505058288574\n",
      "Seen so far: 127808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1997: 1.137740135192871\n",
      "Seen so far: 127872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1998: 0.9626196622848511\n",
      "Seen so far: 127936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1999: 1.1753151416778564\n",
      "Seen so far: 128000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2000: 1.1844868659973145\n",
      "Seen so far: 128064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2001: 1.0950803756713867\n",
      "Seen so far: 128128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2002: 1.4117369651794434\n",
      "Seen so far: 128192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2003: 1.0454539060592651\n",
      "Seen so far: 128256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2004: 1.3035902976989746\n",
      "Seen so far: 128320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2005: 1.195380449295044\n",
      "Seen so far: 128384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2006: 1.4378535747528076\n",
      "Seen so far: 128448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2007: 0.8614728450775146\n",
      "Seen so far: 128512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2008: 1.0607918500900269\n",
      "Seen so far: 128576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2009: 1.058153748512268\n",
      "Seen so far: 128640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2010: 1.3740781545639038\n",
      "Seen so far: 128704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2011: 1.1851321458816528\n",
      "Seen so far: 128768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2012: 1.2331445217132568\n",
      "Seen so far: 128832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2013: 1.3581767082214355\n",
      "Seen so far: 128896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2014: 1.1658716201782227\n",
      "Seen so far: 128960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2015: 1.031320571899414\n",
      "Seen so far: 129024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2016: 1.1138594150543213\n",
      "Seen so far: 129088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2017: 1.391739845275879\n",
      "Seen so far: 129152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2018: 1.1565138101577759\n",
      "Seen so far: 129216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2019: 1.3829271793365479\n",
      "Seen so far: 129280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2020: 0.7206994295120239\n",
      "Seen so far: 129344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2021: 1.5020089149475098\n",
      "Seen so far: 129408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2022: 1.6856344938278198\n",
      "Seen so far: 129472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2023: 1.13005530834198\n",
      "Seen so far: 129536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2024: 1.058751106262207\n",
      "Seen so far: 129600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2025: 1.2294583320617676\n",
      "Seen so far: 129664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2026: 1.0890288352966309\n",
      "Seen so far: 129728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2027: 1.5718841552734375\n",
      "Seen so far: 129792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2028: 1.0301713943481445\n",
      "Seen so far: 129856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2029: 1.2459546327590942\n",
      "Seen so far: 129920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2030: 1.674892783164978\n",
      "Seen so far: 129984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2031: 1.688549518585205\n",
      "Seen so far: 130048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2032: 1.137502908706665\n",
      "Seen so far: 130112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2033: 1.5714995861053467\n",
      "Seen so far: 130176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2034: 1.655165195465088\n",
      "Seen so far: 130240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2035: 1.2423169612884521\n",
      "Seen so far: 130304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2036: 1.0236155986785889\n",
      "Seen so far: 130368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2037: 0.8681339025497437\n",
      "Seen so far: 130432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2038: 1.2903218269348145\n",
      "Seen so far: 130496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2039: 1.5010539293289185\n",
      "Seen so far: 130560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2040: 1.0297033786773682\n",
      "Seen so far: 130624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2041: 1.0242737531661987\n",
      "Seen so far: 130688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2042: 1.5789706707000732\n",
      "Seen so far: 130752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2043: 1.24216890335083\n",
      "Seen so far: 130816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2044: 1.2595797777175903\n",
      "Seen so far: 130880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2045: 1.0088481903076172\n",
      "Seen so far: 130944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2046: 1.1667165756225586\n",
      "Seen so far: 131008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2047: 1.3493447303771973\n",
      "Seen so far: 131072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2048: 0.9805549383163452\n",
      "Seen so far: 131136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2049: 1.2836297750473022\n",
      "Seen so far: 131200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2050: 1.1453559398651123\n",
      "Seen so far: 131264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2051: 1.4805350303649902\n",
      "Seen so far: 131328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2052: 1.328773021697998\n",
      "Seen so far: 131392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2053: 1.300584077835083\n",
      "Seen so far: 131456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2054: 0.9892302751541138\n",
      "Seen so far: 131520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2055: 0.648250937461853\n",
      "Seen so far: 131584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2056: 0.9398889541625977\n",
      "Seen so far: 131648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2057: 1.2492327690124512\n",
      "Seen so far: 131712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2058: 1.0929689407348633\n",
      "Seen so far: 131776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2059: 1.0358881950378418\n",
      "Seen so far: 131840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2060: 0.9416459798812866\n",
      "Seen so far: 131904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2061: 1.5528672933578491\n",
      "Seen so far: 131968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2062: 1.1338844299316406\n",
      "Seen so far: 132032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2063: 1.1910847425460815\n",
      "Seen so far: 132096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2064: 1.4376287460327148\n",
      "Seen so far: 132160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2065: 1.021240472793579\n",
      "Seen so far: 132224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2066: 1.2283265590667725\n",
      "Seen so far: 132288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2067: 1.0918270349502563\n",
      "Seen so far: 132352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2068: 1.4369573593139648\n",
      "Seen so far: 132416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2069: 1.3646974563598633\n",
      "Seen so far: 132480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2070: 1.0633819103240967\n",
      "Seen so far: 132544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2071: 0.9051621556282043\n",
      "Seen so far: 132608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2072: 0.9585541486740112\n",
      "Seen so far: 132672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2073: 0.9895691871643066\n",
      "Seen so far: 132736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2074: 0.9988790154457092\n",
      "Seen so far: 132800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2075: 1.405382752418518\n",
      "Seen so far: 132864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2076: 1.0760146379470825\n",
      "Seen so far: 132928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2077: 1.0195481777191162\n",
      "Seen so far: 132992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2078: 1.1665840148925781\n",
      "Seen so far: 133056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2079: 1.066831350326538\n",
      "Seen so far: 133120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2080: 0.7746682167053223\n",
      "Seen so far: 133184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2081: 1.2879068851470947\n",
      "Seen so far: 133248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2082: 1.1673487424850464\n",
      "Seen so far: 133312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2083: 1.4116920232772827\n",
      "Seen so far: 133376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2084: 1.143036961555481\n",
      "Seen so far: 133440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2085: 0.8101714849472046\n",
      "Seen so far: 133504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2086: 0.9450731873512268\n",
      "Seen so far: 133568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2087: 1.5177124738693237\n",
      "Seen so far: 133632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2088: 0.9124699831008911\n",
      "Seen so far: 133696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2089: 1.321235179901123\n",
      "Seen so far: 133760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2090: 1.0607292652130127\n",
      "Seen so far: 133824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2091: 1.2209699153900146\n",
      "Seen so far: 133888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2092: 1.2055314779281616\n",
      "Seen so far: 133952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2093: 0.9240164160728455\n",
      "Seen so far: 134016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2094: 1.076809287071228\n",
      "Seen so far: 134080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2095: 1.3993165493011475\n",
      "Seen so far: 134144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2096: 1.4043469429016113\n",
      "Seen so far: 134208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2097: 1.0813000202178955\n",
      "Seen so far: 134272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2098: 1.1390516757965088\n",
      "Seen so far: 134336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2099: 0.642047643661499\n",
      "Seen so far: 134400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2100: 1.145921230316162\n",
      "Seen so far: 134464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2101: 0.7662628889083862\n",
      "Seen so far: 134528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2102: 1.1877918243408203\n",
      "Seen so far: 134592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2103: 0.9321141242980957\n",
      "Seen so far: 134656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2104: 1.1816954612731934\n",
      "Seen so far: 134720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2105: 1.0473448038101196\n",
      "Seen so far: 134784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2106: 1.0624468326568604\n",
      "Seen so far: 134848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2107: 1.2449373006820679\n",
      "Seen so far: 134912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2108: 0.7284756898880005\n",
      "Seen so far: 134976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2109: 1.1435199975967407\n",
      "Seen so far: 135040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2110: 1.3293640613555908\n",
      "Seen so far: 135104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2111: 0.956339955329895\n",
      "Seen so far: 135168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2112: 1.1850929260253906\n",
      "Seen so far: 135232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2113: 1.173457145690918\n",
      "Seen so far: 135296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2114: 1.5352072715759277\n",
      "Seen so far: 135360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2115: 1.19081711769104\n",
      "Seen so far: 135424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2116: 1.0110620260238647\n",
      "Seen so far: 135488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2117: 0.9009784460067749\n",
      "Seen so far: 135552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2118: 1.5043671131134033\n",
      "Seen so far: 135616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2119: 1.0264275074005127\n",
      "Seen so far: 135680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2120: 1.3840551376342773\n",
      "Seen so far: 135744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2121: 1.1764073371887207\n",
      "Seen so far: 135808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2122: 1.0433892011642456\n",
      "Seen so far: 135872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2123: 1.2378500699996948\n",
      "Seen so far: 135936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2124: 1.0707287788391113\n",
      "Seen so far: 136000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2125: 1.3835352659225464\n",
      "Seen so far: 136064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2126: 1.1300288438796997\n",
      "Seen so far: 136128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2127: 1.1206138134002686\n",
      "Seen so far: 136192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2128: 1.4689399003982544\n",
      "Seen so far: 136256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2129: 1.4491338729858398\n",
      "Seen so far: 136320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2130: 1.006791114807129\n",
      "Seen so far: 136384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2131: 1.243314504623413\n",
      "Seen so far: 136448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2132: 1.0537941455841064\n",
      "Seen so far: 136512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2133: 1.0477315187454224\n",
      "Seen so far: 136576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2134: 0.5542230010032654\n",
      "Seen so far: 136640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2135: 0.8983955979347229\n",
      "Seen so far: 136704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2136: 0.9363945722579956\n",
      "Seen so far: 136768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2137: 1.0594477653503418\n",
      "Seen so far: 136832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2138: 1.1802599430084229\n",
      "Seen so far: 136896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2139: 1.205979824066162\n",
      "Seen so far: 136960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2140: 1.422959804534912\n",
      "Seen so far: 137024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2141: 1.7029017210006714\n",
      "Seen so far: 137088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2142: 1.0360504388809204\n",
      "Seen so far: 137152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2143: 0.9082844853401184\n",
      "Seen so far: 137216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2144: 1.0543327331542969\n",
      "Seen so far: 137280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2145: 1.2179545164108276\n",
      "Seen so far: 137344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2146: 1.4637048244476318\n",
      "Seen so far: 137408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2147: 0.8876312971115112\n",
      "Seen so far: 137472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2148: 1.3748486042022705\n",
      "Seen so far: 137536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2149: 1.509589433670044\n",
      "Seen so far: 137600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2150: 0.9496545195579529\n",
      "Seen so far: 137664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2151: 1.0364371538162231\n",
      "Seen so far: 137728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2152: 1.2047152519226074\n",
      "Seen so far: 137792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2153: 1.100813627243042\n",
      "Seen so far: 137856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2154: 1.2536157369613647\n",
      "Seen so far: 137920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2155: 1.2938579320907593\n",
      "Seen so far: 137984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2156: 0.8714233636856079\n",
      "Seen so far: 138048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2157: 0.8509912490844727\n",
      "Seen so far: 138112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2158: 1.0131852626800537\n",
      "Seen so far: 138176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2159: 0.8888897895812988\n",
      "Seen so far: 138240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2160: 1.1093828678131104\n",
      "Seen so far: 138304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2161: 1.0130819082260132\n",
      "Seen so far: 138368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2162: 0.985130250453949\n",
      "Seen so far: 138432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2163: 0.8032712340354919\n",
      "Seen so far: 138496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2164: 1.7189098596572876\n",
      "Seen so far: 138560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2165: 1.3109928369522095\n",
      "Seen so far: 138624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2166: 0.914779782295227\n",
      "Seen so far: 138688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2167: 1.4001102447509766\n",
      "Seen so far: 138752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2168: 0.9449898600578308\n",
      "Seen so far: 138816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2169: 0.8652178645133972\n",
      "Seen so far: 138880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2170: 1.2170417308807373\n",
      "Seen so far: 138944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2171: 1.3035731315612793\n",
      "Seen so far: 139008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2172: 1.2903509140014648\n",
      "Seen so far: 139072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2173: 1.1557217836380005\n",
      "Seen so far: 139136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2174: 1.488546371459961\n",
      "Seen so far: 139200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2175: 1.05702805519104\n",
      "Seen so far: 139264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2176: 1.3010814189910889\n",
      "Seen so far: 139328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2177: 1.1721503734588623\n",
      "Seen so far: 139392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2178: 0.8786011934280396\n",
      "Seen so far: 139456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2179: 0.7754813432693481\n",
      "Seen so far: 139520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2180: 0.8992958664894104\n",
      "Seen so far: 139584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2181: 1.312319040298462\n",
      "Seen so far: 139648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2182: 1.5030560493469238\n",
      "Seen so far: 139712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2183: 0.8585063815116882\n",
      "Seen so far: 139776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2184: 1.2604529857635498\n",
      "Seen so far: 139840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2185: 1.3733799457550049\n",
      "Seen so far: 139904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2186: 0.8722750544548035\n",
      "Seen so far: 139968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2187: 1.1567752361297607\n",
      "Seen so far: 140032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2188: 1.0158236026763916\n",
      "Seen so far: 140096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2189: 1.2919343709945679\n",
      "Seen so far: 140160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2190: 1.1565830707550049\n",
      "Seen so far: 140224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2191: 1.008060097694397\n",
      "Seen so far: 140288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2192: 1.2338508367538452\n",
      "Seen so far: 140352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2193: 1.137036919593811\n",
      "Seen so far: 140416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2194: 0.8532958030700684\n",
      "Seen so far: 140480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2195: 1.240386724472046\n",
      "Seen so far: 140544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2196: 0.8909798264503479\n",
      "Seen so far: 140608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2197: 0.9850154519081116\n",
      "Seen so far: 140672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2198: 1.3224632740020752\n",
      "Seen so far: 140736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2199: 1.108054518699646\n",
      "Seen so far: 140800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2200: 1.44634211063385\n",
      "Seen so far: 140864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2201: 1.1842591762542725\n",
      "Seen so far: 140928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2202: 1.086872935295105\n",
      "Seen so far: 140992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2203: 1.4649633169174194\n",
      "Seen so far: 141056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2204: 1.2141282558441162\n",
      "Seen so far: 141120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2205: 0.8377123475074768\n",
      "Seen so far: 141184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2206: 1.442244052886963\n",
      "Seen so far: 141248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2207: 1.184396743774414\n",
      "Seen so far: 141312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2208: 1.8825273513793945\n",
      "Seen so far: 141376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2209: 1.1334633827209473\n",
      "Seen so far: 141440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2210: 0.78748619556427\n",
      "Seen so far: 141504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2211: 1.2032971382141113\n",
      "Seen so far: 141568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2212: 1.009029746055603\n",
      "Seen so far: 141632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2213: 1.1351311206817627\n",
      "Seen so far: 141696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2214: 1.306296706199646\n",
      "Seen so far: 141760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2215: 1.362459659576416\n",
      "Seen so far: 141824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2216: 1.032905101776123\n",
      "Seen so far: 141888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2217: 1.194760799407959\n",
      "Seen so far: 141952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2218: 1.1227424144744873\n",
      "Seen so far: 142016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2219: 1.1883387565612793\n",
      "Seen so far: 142080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2220: 1.1292448043823242\n",
      "Seen so far: 142144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2221: 1.4964423179626465\n",
      "Seen so far: 142208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2222: 1.7616130113601685\n",
      "Seen so far: 142272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2223: 1.1274948120117188\n",
      "Seen so far: 142336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2224: 1.343585729598999\n",
      "Seen so far: 142400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2225: 1.1841559410095215\n",
      "Seen so far: 142464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2226: 1.4586083889007568\n",
      "Seen so far: 142528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2227: 0.891022801399231\n",
      "Seen so far: 142592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2228: 1.4221712350845337\n",
      "Seen so far: 142656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2229: 1.1457985639572144\n",
      "Seen so far: 142720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2230: 1.2974927425384521\n",
      "Seen so far: 142784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2231: 1.0858356952667236\n",
      "Seen so far: 142848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2232: 1.3872495889663696\n",
      "Seen so far: 142912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2233: 1.201866626739502\n",
      "Seen so far: 142976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2234: 0.9927501082420349\n",
      "Seen so far: 143040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2235: 1.468265175819397\n",
      "Seen so far: 143104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2236: 1.1844520568847656\n",
      "Seen so far: 143168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2237: 1.1902923583984375\n",
      "Seen so far: 143232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2238: 1.3500585556030273\n",
      "Seen so far: 143296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2239: 1.281841516494751\n",
      "Seen so far: 143360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2240: 1.2723238468170166\n",
      "Seen so far: 143424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2241: 1.3637418746948242\n",
      "Seen so far: 143488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2242: 1.1061495542526245\n",
      "Seen so far: 143552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2243: 1.753835916519165\n",
      "Seen so far: 143616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2244: 1.1620352268218994\n",
      "Seen so far: 143680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2245: 1.2649785280227661\n",
      "Seen so far: 143744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2246: 1.029592514038086\n",
      "Seen so far: 143808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2247: 1.7984243631362915\n",
      "Seen so far: 143872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2248: 0.7598963975906372\n",
      "Seen so far: 143936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2249: 1.2700066566467285\n",
      "Seen so far: 144000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2250: 0.9545944929122925\n",
      "Seen so far: 144064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2251: 1.1157575845718384\n",
      "Seen so far: 144128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2252: 0.8918619155883789\n",
      "Seen so far: 144192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2253: 1.4220499992370605\n",
      "Seen so far: 144256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2254: 1.1244009733200073\n",
      "Seen so far: 144320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2255: 0.9357880353927612\n",
      "Seen so far: 144384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2256: 0.9907863140106201\n",
      "Seen so far: 144448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2257: 1.284876823425293\n",
      "Seen so far: 144512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2258: 1.4727669954299927\n",
      "Seen so far: 144576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2259: 1.0088794231414795\n",
      "Seen so far: 144640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2260: 1.232365369796753\n",
      "Seen so far: 144704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2261: 1.4189772605895996\n",
      "Seen so far: 144768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2262: 1.1525063514709473\n",
      "Seen so far: 144832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2263: 1.1945502758026123\n",
      "Seen so far: 144896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2264: 1.2455949783325195\n",
      "Seen so far: 144960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2265: 1.3042796850204468\n",
      "Seen so far: 145024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2266: 0.9639819264411926\n",
      "Seen so far: 145088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2267: 0.9176656007766724\n",
      "Seen so far: 145152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2268: 1.0827407836914062\n",
      "Seen so far: 145216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2269: 0.9093085527420044\n",
      "Seen so far: 145280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2270: 1.0907630920410156\n",
      "Seen so far: 145344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2271: 1.1072560548782349\n",
      "Seen so far: 145408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2272: 1.008259654045105\n",
      "Seen so far: 145472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2273: 1.5182521343231201\n",
      "Seen so far: 145536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2274: 1.2923938035964966\n",
      "Seen so far: 145600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2275: 1.2607839107513428\n",
      "Seen so far: 145664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2276: 1.0061739683151245\n",
      "Seen so far: 145728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2277: 0.9915668964385986\n",
      "Seen so far: 145792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2278: 1.6306982040405273\n",
      "Seen so far: 145856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2279: 1.141431450843811\n",
      "Seen so far: 145920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2280: 1.6579877138137817\n",
      "Seen so far: 145984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2281: 0.9462608098983765\n",
      "Seen so far: 146048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2282: 1.340725064277649\n",
      "Seen so far: 146112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2283: 1.3209097385406494\n",
      "Seen so far: 146176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2284: 1.0932440757751465\n",
      "Seen so far: 146240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2285: 1.8130717277526855\n",
      "Seen so far: 146304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2286: 1.2556376457214355\n",
      "Seen so far: 146368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2287: 1.0336933135986328\n",
      "Seen so far: 146432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2288: 1.2219551801681519\n",
      "Seen so far: 146496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2289: 1.447814702987671\n",
      "Seen so far: 146560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2290: 1.3357700109481812\n",
      "Seen so far: 146624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2291: 0.9310022592544556\n",
      "Seen so far: 146688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2292: 0.9390548467636108\n",
      "Seen so far: 146752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2293: 1.2231369018554688\n",
      "Seen so far: 146816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2294: 1.9687148332595825\n",
      "Seen so far: 146880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2295: 1.27517569065094\n",
      "Seen so far: 146944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2296: 1.1621040105819702\n",
      "Seen so far: 147008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2297: 1.387783408164978\n",
      "Seen so far: 147072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2298: 1.2827556133270264\n",
      "Seen so far: 147136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2299: 0.815514326095581\n",
      "Seen so far: 147200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2300: 1.235317349433899\n",
      "Seen so far: 147264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2301: 1.3499077558517456\n",
      "Seen so far: 147328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2302: 1.182018518447876\n",
      "Seen so far: 147392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2303: 1.5297155380249023\n",
      "Seen so far: 147456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2304: 0.8815125226974487\n",
      "Seen so far: 147520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2305: 1.009964942932129\n",
      "Seen so far: 147584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2306: 1.278672456741333\n",
      "Seen so far: 147648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2307: 1.194869041442871\n",
      "Seen so far: 147712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2308: 1.2410486936569214\n",
      "Seen so far: 147776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2309: 1.3361808061599731\n",
      "Seen so far: 147840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2310: 0.8789570331573486\n",
      "Seen so far: 147904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2311: 0.9255568981170654\n",
      "Seen so far: 147968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2312: 1.1504981517791748\n",
      "Seen so far: 148032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2313: 1.0214080810546875\n",
      "Seen so far: 148096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2314: 1.2187895774841309\n",
      "Seen so far: 148160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2315: 1.3182406425476074\n",
      "Seen so far: 148224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2316: 1.1599924564361572\n",
      "Seen so far: 148288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2317: 0.9680597186088562\n",
      "Seen so far: 148352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2318: 0.8597080707550049\n",
      "Seen so far: 148416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2319: 1.0881249904632568\n",
      "Seen so far: 148480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2320: 1.0318599939346313\n",
      "Seen so far: 148544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2321: 0.7663545608520508\n",
      "Seen so far: 148608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2322: 0.7823454141616821\n",
      "Seen so far: 148672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2323: 0.9524452686309814\n",
      "Seen so far: 148736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2324: 1.2604284286499023\n",
      "Seen so far: 148800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2325: 1.144697666168213\n",
      "Seen so far: 148864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2326: 1.2398005723953247\n",
      "Seen so far: 148928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2327: 1.255336880683899\n",
      "Seen so far: 148992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2328: 0.87201327085495\n",
      "Seen so far: 149056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2329: 1.0451756715774536\n",
      "Seen so far: 149120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2330: 1.0989633798599243\n",
      "Seen so far: 149184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2331: 1.3790323734283447\n",
      "Seen so far: 149248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2332: 1.0486382246017456\n",
      "Seen so far: 149312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2333: 1.2837823629379272\n",
      "Seen so far: 149376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2334: 1.3955411911010742\n",
      "Seen so far: 149440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2335: 1.5391998291015625\n",
      "Seen so far: 149504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2336: 1.3234957456588745\n",
      "Seen so far: 149568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2337: 1.1139421463012695\n",
      "Seen so far: 149632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2338: 0.8397011160850525\n",
      "Seen so far: 149696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2339: 1.4531903266906738\n",
      "Seen so far: 149760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2340: 1.3528963327407837\n",
      "Seen so far: 149824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2341: 1.5154926776885986\n",
      "Seen so far: 149888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2342: 0.6853674650192261\n",
      "Seen so far: 149952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2343: 0.8015826344490051\n",
      "Seen so far: 150016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2344: 1.1051747798919678\n",
      "Seen so far: 150080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2345: 1.1750863790512085\n",
      "Seen so far: 150144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2346: 1.0401297807693481\n",
      "Seen so far: 150208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2347: 0.8996483087539673\n",
      "Seen so far: 150272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2348: 1.4490861892700195\n",
      "Seen so far: 150336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2349: 0.988939106464386\n",
      "Seen so far: 150400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2350: 1.1412193775177002\n",
      "Seen so far: 150464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2351: 1.460254430770874\n",
      "Seen so far: 150528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2352: 1.204652190208435\n",
      "Seen so far: 150592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2353: 1.0688953399658203\n",
      "Seen so far: 150656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2354: 1.11836838722229\n",
      "Seen so far: 150720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2355: 1.0400246381759644\n",
      "Seen so far: 150784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2356: 0.9840532541275024\n",
      "Seen so far: 150848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2357: 1.1173393726348877\n",
      "Seen so far: 150912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2358: 1.4347295761108398\n",
      "Seen so far: 150976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2359: 1.0871596336364746\n",
      "Seen so far: 151040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2360: 1.350440502166748\n",
      "Seen so far: 151104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2361: 1.1320033073425293\n",
      "Seen so far: 151168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2362: 1.450211763381958\n",
      "Seen so far: 151232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2363: 1.1161845922470093\n",
      "Seen so far: 151296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2364: 0.9762789607048035\n",
      "Seen so far: 151360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2365: 1.6410311460494995\n",
      "Seen so far: 151424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2366: 1.1786291599273682\n",
      "Seen so far: 151488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2367: 1.221996784210205\n",
      "Seen so far: 151552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2368: 1.4072184562683105\n",
      "Seen so far: 151616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2369: 1.5334515571594238\n",
      "Seen so far: 151680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2370: 1.2484698295593262\n",
      "Seen so far: 151744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2371: 1.4004878997802734\n",
      "Seen so far: 151808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2372: 1.2672948837280273\n",
      "Seen so far: 151872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2373: 1.1759262084960938\n",
      "Seen so far: 151936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2374: 0.9306051135063171\n",
      "Seen so far: 152000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2375: 1.0820503234863281\n",
      "Seen so far: 152064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2376: 1.4002236127853394\n",
      "Seen so far: 152128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2377: 1.344388484954834\n",
      "Seen so far: 152192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2378: 1.14707612991333\n",
      "Seen so far: 152256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2379: 1.2379041910171509\n",
      "Seen so far: 152320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2380: 1.0545494556427002\n",
      "Seen so far: 152384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2381: 1.0906389951705933\n",
      "Seen so far: 152448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2382: 0.8657216429710388\n",
      "Seen so far: 152512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2383: 1.1423137187957764\n",
      "Seen so far: 152576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2384: 1.4197678565979004\n",
      "Seen so far: 152640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2385: 1.338814377784729\n",
      "Seen so far: 152704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2386: 0.9661110639572144\n",
      "Seen so far: 152768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2387: 1.0084859132766724\n",
      "Seen so far: 152832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2388: 0.9787876605987549\n",
      "Seen so far: 152896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2389: 1.1422892808914185\n",
      "Seen so far: 152960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2390: 1.2633042335510254\n",
      "Seen so far: 153024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2391: 1.1992391347885132\n",
      "Seen so far: 153088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2392: 1.0687109231948853\n",
      "Seen so far: 153152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2393: 1.432531714439392\n",
      "Seen so far: 153216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2394: 1.021115779876709\n",
      "Seen so far: 153280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2395: 1.4287205934524536\n",
      "Seen so far: 153344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2396: 1.0437871217727661\n",
      "Seen so far: 153408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2397: 1.337609052658081\n",
      "Seen so far: 153472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2398: 1.048587679862976\n",
      "Seen so far: 153536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2399: 0.8902497291564941\n",
      "Seen so far: 153600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2400: 1.0955067873001099\n",
      "Seen so far: 153664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2401: 0.9240654706954956\n",
      "Seen so far: 153728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2402: 1.0904959440231323\n",
      "Seen so far: 153792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2403: 1.3191301822662354\n",
      "Seen so far: 153856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2404: 1.0176236629486084\n",
      "Seen so far: 153920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2405: 1.203130841255188\n",
      "Seen so far: 153984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2406: 0.9724129438400269\n",
      "Seen so far: 154048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2407: 2.0839459896087646\n",
      "Seen so far: 154112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2408: 0.8085260987281799\n",
      "Seen so far: 154176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2409: 1.5075807571411133\n",
      "Seen so far: 154240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2410: 0.8753724098205566\n",
      "Seen so far: 154304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2411: 1.2233266830444336\n",
      "Seen so far: 154368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2412: 1.4330610036849976\n",
      "Seen so far: 154432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2413: 1.2944376468658447\n",
      "Seen so far: 154496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2414: 1.212525725364685\n",
      "Seen so far: 154560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2415: 1.2668862342834473\n",
      "Seen so far: 154624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2416: 1.2158310413360596\n",
      "Seen so far: 154688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2417: 1.5591156482696533\n",
      "Seen so far: 154752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2418: 1.312643051147461\n",
      "Seen so far: 154816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2419: 1.0545499324798584\n",
      "Seen so far: 154880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2420: 1.548683762550354\n",
      "Seen so far: 154944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2421: 1.0486929416656494\n",
      "Seen so far: 155008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2422: 1.0998330116271973\n",
      "Seen so far: 155072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2423: 1.222783088684082\n",
      "Seen so far: 155136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2424: 1.090505599975586\n",
      "Seen so far: 155200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2425: 1.7184948921203613\n",
      "Seen so far: 155264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2426: 1.3095431327819824\n",
      "Seen so far: 155328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2427: 1.391376256942749\n",
      "Seen so far: 155392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2428: 1.3945704698562622\n",
      "Seen so far: 155456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2429: 0.8623597621917725\n",
      "Seen so far: 155520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2430: 1.2111705541610718\n",
      "Seen so far: 155584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2431: 1.3599417209625244\n",
      "Seen so far: 155648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2432: 0.9256267547607422\n",
      "Seen so far: 155712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2433: 1.0984869003295898\n",
      "Seen so far: 155776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2434: 1.037340521812439\n",
      "Seen so far: 155840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2435: 1.2610996961593628\n",
      "Seen so far: 155904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2436: 1.3661986589431763\n",
      "Seen so far: 155968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2437: 0.7082368731498718\n",
      "Seen so far: 156032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2438: 1.1673892736434937\n",
      "Seen so far: 156096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2439: 1.1745200157165527\n",
      "Seen so far: 156160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2440: 1.1009180545806885\n",
      "Seen so far: 156224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2441: 0.8419750332832336\n",
      "Seen so far: 156288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2442: 1.3042619228363037\n",
      "Seen so far: 156352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2443: 1.1795494556427002\n",
      "Seen so far: 156416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2444: 1.0868268013000488\n",
      "Seen so far: 156480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2445: 1.0199834108352661\n",
      "Seen so far: 156544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2446: 1.0424529314041138\n",
      "Seen so far: 156608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2447: 0.8227900862693787\n",
      "Seen so far: 156672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2448: 1.234574556350708\n",
      "Seen so far: 156736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2449: 0.7437832355499268\n",
      "Seen so far: 156800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2450: 1.1019384860992432\n",
      "Seen so far: 156864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2451: 1.3739033937454224\n",
      "Seen so far: 156928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2452: 1.3810136318206787\n",
      "Seen so far: 156992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2453: 1.2021198272705078\n",
      "Seen so far: 157056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2454: 1.2983133792877197\n",
      "Seen so far: 157120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2455: 1.2440345287322998\n",
      "Seen so far: 157184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2456: 1.071610450744629\n",
      "Seen so far: 157248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2457: 1.406576156616211\n",
      "Seen so far: 157312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2458: 1.1755452156066895\n",
      "Seen so far: 157376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2459: 1.1653594970703125\n",
      "Seen so far: 157440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2460: 1.1093089580535889\n",
      "Seen so far: 157504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2461: 1.0578480958938599\n",
      "Seen so far: 157568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2462: 1.2755539417266846\n",
      "Seen so far: 157632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2463: 1.1601996421813965\n",
      "Seen so far: 157696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2464: 1.0200278759002686\n",
      "Seen so far: 157760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2465: 1.0705292224884033\n",
      "Seen so far: 157824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2466: 1.5824772119522095\n",
      "Seen so far: 157888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2467: 1.4392428398132324\n",
      "Seen so far: 157952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2468: 1.4095518589019775\n",
      "Seen so far: 158016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2469: 1.1847342252731323\n",
      "Seen so far: 158080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2470: 1.0787445306777954\n",
      "Seen so far: 158144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2471: 1.3840467929840088\n",
      "Seen so far: 158208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2472: 1.185133695602417\n",
      "Seen so far: 158272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2473: 1.1877508163452148\n",
      "Seen so far: 158336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2474: 1.551779866218567\n",
      "Seen so far: 158400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2475: 1.191379189491272\n",
      "Seen so far: 158464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2476: 1.007908582687378\n",
      "Seen so far: 158528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2477: 1.0596461296081543\n",
      "Seen so far: 158592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2478: 1.3357640504837036\n",
      "Seen so far: 158656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2479: 1.5819904804229736\n",
      "Seen so far: 158720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2480: 0.9818330407142639\n",
      "Seen so far: 158784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2481: 1.2433812618255615\n",
      "Seen so far: 158848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2482: 1.1736685037612915\n",
      "Seen so far: 158912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2483: 1.0950911045074463\n",
      "Seen so far: 158976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2484: 0.9601699709892273\n",
      "Seen so far: 159040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2485: 0.8250465393066406\n",
      "Seen so far: 159104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2486: 1.2429686784744263\n",
      "Seen so far: 159168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2487: 1.1369893550872803\n",
      "Seen so far: 159232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2488: 1.0995676517486572\n",
      "Seen so far: 159296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2489: 0.7006677985191345\n",
      "Seen so far: 159360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2490: 0.9675190448760986\n",
      "Seen so far: 159424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2491: 1.1510071754455566\n",
      "Seen so far: 159488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2492: 1.1831552982330322\n",
      "Seen so far: 159552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2493: 0.8214551210403442\n",
      "Seen so far: 159616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2494: 0.8595842123031616\n",
      "Seen so far: 159680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2495: 0.6712763905525208\n",
      "Seen so far: 159744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2496: 0.9434794187545776\n",
      "Seen so far: 159808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2497: 1.0104365348815918\n",
      "Seen so far: 159872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2498: 0.7315136194229126\n",
      "Seen so far: 159936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2499: 1.3302388191223145\n",
      "Seen so far: 160000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2500: 1.7362656593322754\n",
      "Seen so far: 160064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2501: 1.176220178604126\n",
      "Seen so far: 160128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2502: 0.66860032081604\n",
      "Seen so far: 160192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2503: 1.1929922103881836\n",
      "Seen so far: 160256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2504: 1.2547067403793335\n",
      "Seen so far: 160320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2505: 1.533006191253662\n",
      "Seen so far: 160384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2506: 1.145132064819336\n",
      "Seen so far: 160448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2507: 1.1888421773910522\n",
      "Seen so far: 160512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2508: 1.0969607830047607\n",
      "Seen so far: 160576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2509: 1.3823925256729126\n",
      "Seen so far: 160640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2510: 1.3417479991912842\n",
      "Seen so far: 160704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2511: 1.2321417331695557\n",
      "Seen so far: 160768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2512: 0.72284334897995\n",
      "Seen so far: 160832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2513: 1.258888840675354\n",
      "Seen so far: 160896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2514: 1.0402835607528687\n",
      "Seen so far: 160960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2515: 0.948237955570221\n",
      "Seen so far: 161024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2516: 1.2151992321014404\n",
      "Seen so far: 161088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2517: 1.2160447835922241\n",
      "Seen so far: 161152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2518: 1.2069268226623535\n",
      "Seen so far: 161216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2519: 1.0720560550689697\n",
      "Seen so far: 161280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2520: 0.8384907841682434\n",
      "Seen so far: 161344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2521: 0.8517941236495972\n",
      "Seen so far: 161408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2522: 0.8647509813308716\n",
      "Seen so far: 161472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2523: 1.401667594909668\n",
      "Seen so far: 161536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2524: 1.1079726219177246\n",
      "Seen so far: 161600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2525: 1.0657602548599243\n",
      "Seen so far: 161664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2526: 0.8662348985671997\n",
      "Seen so far: 161728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2527: 1.0095192193984985\n",
      "Seen so far: 161792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2528: 1.6565306186676025\n",
      "Seen so far: 161856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2529: 1.4378137588500977\n",
      "Seen so far: 161920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2530: 0.9743887186050415\n",
      "Seen so far: 161984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2531: 0.8421822190284729\n",
      "Seen so far: 162048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2532: 0.894207239151001\n",
      "Seen so far: 162112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2533: 1.3535324335098267\n",
      "Seen so far: 162176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2534: 1.4659759998321533\n",
      "Seen so far: 162240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2535: 1.0754039287567139\n",
      "Seen so far: 162304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2536: 1.1314458847045898\n",
      "Seen so far: 162368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2537: 1.3808006048202515\n",
      "Seen so far: 162432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2538: 0.8279598951339722\n",
      "Seen so far: 162496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2539: 1.3745484352111816\n",
      "Seen so far: 162560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2540: 1.2827308177947998\n",
      "Seen so far: 162624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2541: 1.3654091358184814\n",
      "Seen so far: 162688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2542: 0.9919010400772095\n",
      "Seen so far: 162752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2543: 1.2249536514282227\n",
      "Seen so far: 162816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2544: 1.2585351467132568\n",
      "Seen so far: 162880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2545: 1.458248257637024\n",
      "Seen so far: 162944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2546: 0.8350189924240112\n",
      "Seen so far: 163008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2547: 1.373194694519043\n",
      "Seen so far: 163072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2548: 1.55611252784729\n",
      "Seen so far: 163136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2549: 1.3351192474365234\n",
      "Seen so far: 163200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2550: 1.030338168144226\n",
      "Seen so far: 163264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2551: 1.0472519397735596\n",
      "Seen so far: 163328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2552: 1.0879989862442017\n",
      "Seen so far: 163392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2553: 1.401317834854126\n",
      "Seen so far: 163456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2554: 1.0997368097305298\n",
      "Seen so far: 163520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2555: 1.055084228515625\n",
      "Seen so far: 163584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2556: 1.157158374786377\n",
      "Seen so far: 163648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2557: 0.6565990447998047\n",
      "Seen so far: 163712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2558: 0.9367561340332031\n",
      "Seen so far: 163776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2559: 1.183753252029419\n",
      "Seen so far: 163840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2560: 1.2265938520431519\n",
      "Seen so far: 163904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2561: 1.2326608896255493\n",
      "Seen so far: 163968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2562: 0.944514811038971\n",
      "Seen so far: 164032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2563: 1.133925437927246\n",
      "Seen so far: 164096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2564: 1.207697868347168\n",
      "Seen so far: 164160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2565: 0.9858164191246033\n",
      "Seen so far: 164224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2566: 1.3001604080200195\n",
      "Seen so far: 164288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2567: 1.3423080444335938\n",
      "Seen so far: 164352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2568: 1.561690092086792\n",
      "Seen so far: 164416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2569: 1.0585776567459106\n",
      "Seen so far: 164480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2570: 1.1197667121887207\n",
      "Seen so far: 164544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2571: 0.8963083028793335\n",
      "Seen so far: 164608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2572: 1.3163373470306396\n",
      "Seen so far: 164672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2573: 0.9037219285964966\n",
      "Seen so far: 164736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2574: 0.9606679677963257\n",
      "Seen so far: 164800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2575: 0.8538331985473633\n",
      "Seen so far: 164864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2576: 1.1822412014007568\n",
      "Seen so far: 164928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2577: 1.0526723861694336\n",
      "Seen so far: 164992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2578: 0.9718789458274841\n",
      "Seen so far: 165056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2579: 1.018215537071228\n",
      "Seen so far: 165120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2580: 1.0162720680236816\n",
      "Seen so far: 165184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2581: 0.9546402096748352\n",
      "Seen so far: 165248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2582: 1.6323480606079102\n",
      "Seen so far: 165312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2583: 1.0040793418884277\n",
      "Seen so far: 165376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2584: 0.6797043085098267\n",
      "Seen so far: 165440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2585: 1.1845335960388184\n",
      "Seen so far: 165504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2586: 0.808924674987793\n",
      "Seen so far: 165568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2587: 0.8508539199829102\n",
      "Seen so far: 165632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2588: 1.1516153812408447\n",
      "Seen so far: 165696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2589: 1.1913692951202393\n",
      "Seen so far: 165760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2590: 1.3352336883544922\n",
      "Seen so far: 165824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2591: 1.155510663986206\n",
      "Seen so far: 165888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2592: 1.1818451881408691\n",
      "Seen so far: 165952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2593: 1.1062572002410889\n",
      "Seen so far: 166016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2594: 1.2410004138946533\n",
      "Seen so far: 166080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2595: 1.3223376274108887\n",
      "Seen so far: 166144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2596: 1.2748879194259644\n",
      "Seen so far: 166208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2597: 1.207770824432373\n",
      "Seen so far: 166272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2598: 0.9605607986450195\n",
      "Seen so far: 166336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2599: 1.0163776874542236\n",
      "Seen so far: 166400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2600: 1.0525438785552979\n",
      "Seen so far: 166464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2601: 1.1115906238555908\n",
      "Seen so far: 166528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2602: 0.8457324504852295\n",
      "Seen so far: 166592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2603: 0.7526151537895203\n",
      "Seen so far: 166656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2604: 1.3080805540084839\n",
      "Seen so far: 166720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2605: 1.3134546279907227\n",
      "Seen so far: 166784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2606: 1.1971075534820557\n",
      "Seen so far: 166848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2607: 1.6740474700927734\n",
      "Seen so far: 166912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2608: 1.1232293844223022\n",
      "Seen so far: 166976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2609: 1.1694154739379883\n",
      "Seen so far: 167040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2610: 1.0281621217727661\n",
      "Seen so far: 167104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2611: 1.2250735759735107\n",
      "Seen so far: 167168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2612: 1.2585740089416504\n",
      "Seen so far: 167232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2613: 0.7811195850372314\n",
      "Seen so far: 167296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2614: 1.12343430519104\n",
      "Seen so far: 167360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2615: 1.1549807786941528\n",
      "Seen so far: 167424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2616: 1.013429880142212\n",
      "Seen so far: 167488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2617: 1.3141870498657227\n",
      "Seen so far: 167552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2618: 0.9771065711975098\n",
      "Seen so far: 167616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2619: 1.3873579502105713\n",
      "Seen so far: 167680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2620: 1.0426487922668457\n",
      "Seen so far: 167744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2621: 1.3719711303710938\n",
      "Seen so far: 167808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2622: 1.463325023651123\n",
      "Seen so far: 167872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2623: 1.1022913455963135\n",
      "Seen so far: 167936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2624: 1.2654330730438232\n",
      "Seen so far: 168000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2625: 0.8377585411071777\n",
      "Seen so far: 168064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2626: 1.0861737728118896\n",
      "Seen so far: 168128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2627: 1.3606019020080566\n",
      "Seen so far: 168192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2628: 0.6515829563140869\n",
      "Seen so far: 168256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2629: 1.136122226715088\n",
      "Seen so far: 168320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2630: 1.2992520332336426\n",
      "Seen so far: 168384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2631: 1.3652400970458984\n",
      "Seen so far: 168448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2632: 1.164778470993042\n",
      "Seen so far: 168512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2633: 1.021819829940796\n",
      "Seen so far: 168576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2634: 1.1408367156982422\n",
      "Seen so far: 168640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2635: 1.3729305267333984\n",
      "Seen so far: 168704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2636: 1.298137903213501\n",
      "Seen so far: 168768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2637: 0.9375917911529541\n",
      "Seen so far: 168832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2638: 1.787748098373413\n",
      "Seen so far: 168896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2639: 1.2334791421890259\n",
      "Seen so far: 168960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2640: 1.080857276916504\n",
      "Seen so far: 169024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2641: 1.0182809829711914\n",
      "Seen so far: 169088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2642: 1.2035136222839355\n",
      "Seen so far: 169152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2643: 1.2012906074523926\n",
      "Seen so far: 169216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2644: 1.0673325061798096\n",
      "Seen so far: 169280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2645: 1.3082818984985352\n",
      "Seen so far: 169344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2646: 0.9456734657287598\n",
      "Seen so far: 169408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2647: 1.170609712600708\n",
      "Seen so far: 169472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2648: 0.9889657497406006\n",
      "Seen so far: 169536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2649: 1.2714041471481323\n",
      "Seen so far: 169600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2650: 1.0667287111282349\n",
      "Seen so far: 169664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2651: 1.2898578643798828\n",
      "Seen so far: 169728 samples\n",
      "Training acc over epoch: 0.5940030217170715\n",
      "Start of epoch 2\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 0: 0.9976691603660583\n",
      "Seen so far: 64 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1: 1.419670581817627\n",
      "Seen so far: 128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2: 0.9377920031547546\n",
      "Seen so far: 192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 3: 0.9059497714042664\n",
      "Seen so far: 256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 4: 0.898492693901062\n",
      "Seen so far: 320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 5: 1.2335230112075806\n",
      "Seen so far: 384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 6: 1.449767827987671\n",
      "Seen so far: 448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 7: 1.2134790420532227\n",
      "Seen so far: 512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 8: 1.5278112888336182\n",
      "Seen so far: 576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 9: 0.9708923101425171\n",
      "Seen so far: 640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 10: 0.9061423540115356\n",
      "Seen so far: 704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 11: 0.796532392501831\n",
      "Seen so far: 768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 12: 0.9457560777664185\n",
      "Seen so far: 832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 13: 1.0621479749679565\n",
      "Seen so far: 896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 14: 1.669767141342163\n",
      "Seen so far: 960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 15: 1.0166512727737427\n",
      "Seen so far: 1024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 16: 1.3358392715454102\n",
      "Seen so far: 1088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 17: 1.5884084701538086\n",
      "Seen so far: 1152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 18: 1.25065279006958\n",
      "Seen so far: 1216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 19: 1.7423856258392334\n",
      "Seen so far: 1280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 20: 0.9480150938034058\n",
      "Seen so far: 1344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 21: 1.3593151569366455\n",
      "Seen so far: 1408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 22: 1.4455959796905518\n",
      "Seen so far: 1472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 23: 1.7538645267486572\n",
      "Seen so far: 1536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 24: 0.8380257487297058\n",
      "Seen so far: 1600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 25: 1.179050326347351\n",
      "Seen so far: 1664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 26: 1.1451808214187622\n",
      "Seen so far: 1728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 27: 1.578660011291504\n",
      "Seen so far: 1792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 28: 1.0279581546783447\n",
      "Seen so far: 1856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 29: 1.326010823249817\n",
      "Seen so far: 1920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 30: 1.2844939231872559\n",
      "Seen so far: 1984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 31: 1.276455283164978\n",
      "Seen so far: 2048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 32: 1.6764404773712158\n",
      "Seen so far: 2112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 33: 1.1514527797698975\n",
      "Seen so far: 2176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 34: 1.1578450202941895\n",
      "Seen so far: 2240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 35: 1.4916789531707764\n",
      "Seen so far: 2304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 36: 0.9751003980636597\n",
      "Seen so far: 2368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 37: 1.276550054550171\n",
      "Seen so far: 2432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 38: 0.9861773252487183\n",
      "Seen so far: 2496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 39: 1.2795199155807495\n",
      "Seen so far: 2560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 40: 1.057973027229309\n",
      "Seen so far: 2624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 41: 1.5929617881774902\n",
      "Seen so far: 2688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 42: 1.3407866954803467\n",
      "Seen so far: 2752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 43: 1.048065185546875\n",
      "Seen so far: 2816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 44: 1.040391206741333\n",
      "Seen so far: 2880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 45: 1.4627788066864014\n",
      "Seen so far: 2944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 46: 1.0193231105804443\n",
      "Seen so far: 3008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 47: 0.9977843761444092\n",
      "Seen so far: 3072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 48: 1.1962825059890747\n",
      "Seen so far: 3136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 49: 0.9623485803604126\n",
      "Seen so far: 3200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 50: 1.2642087936401367\n",
      "Seen so far: 3264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 51: 1.5263642072677612\n",
      "Seen so far: 3328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 52: 1.1139495372772217\n",
      "Seen so far: 3392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 53: 0.9707465767860413\n",
      "Seen so far: 3456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 54: 0.7762552499771118\n",
      "Seen so far: 3520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 55: 1.3896055221557617\n",
      "Seen so far: 3584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 56: 1.5959324836730957\n",
      "Seen so far: 3648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 57: 1.5996371507644653\n",
      "Seen so far: 3712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 58: 1.1339643001556396\n",
      "Seen so far: 3776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 59: 0.7928808927536011\n",
      "Seen so far: 3840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 60: 0.7306278347969055\n",
      "Seen so far: 3904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 61: 0.8916076421737671\n",
      "Seen so far: 3968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 62: 1.3320990800857544\n",
      "Seen so far: 4032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 63: 0.9997713565826416\n",
      "Seen so far: 4096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 64: 1.0869264602661133\n",
      "Seen so far: 4160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 65: 0.908560037612915\n",
      "Seen so far: 4224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 66: 1.5510119199752808\n",
      "Seen so far: 4288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 67: 1.3885942697525024\n",
      "Seen so far: 4352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 68: 1.3239953517913818\n",
      "Seen so far: 4416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 69: 0.8123079538345337\n",
      "Seen so far: 4480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 70: 0.9594995975494385\n",
      "Seen so far: 4544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 71: 1.3313504457473755\n",
      "Seen so far: 4608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 72: 1.357450008392334\n",
      "Seen so far: 4672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 73: 0.892085075378418\n",
      "Seen so far: 4736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 74: 1.2126654386520386\n",
      "Seen so far: 4800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 75: 1.0379624366760254\n",
      "Seen so far: 4864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 76: 1.3645527362823486\n",
      "Seen so far: 4928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 77: 0.9483472108840942\n",
      "Seen so far: 4992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 78: 0.9983819723129272\n",
      "Seen so far: 5056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 79: 1.44016695022583\n",
      "Seen so far: 5120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 80: 1.019328236579895\n",
      "Seen so far: 5184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 81: 1.2089165449142456\n",
      "Seen so far: 5248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 82: 1.1722121238708496\n",
      "Seen so far: 5312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 83: 0.9452559947967529\n",
      "Seen so far: 5376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 84: 1.1425939798355103\n",
      "Seen so far: 5440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 85: 1.2886223793029785\n",
      "Seen so far: 5504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 86: 1.07537043094635\n",
      "Seen so far: 5568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 87: 1.2847334146499634\n",
      "Seen so far: 5632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 88: 1.0900951623916626\n",
      "Seen so far: 5696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 89: 1.0985301733016968\n",
      "Seen so far: 5760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 90: 1.3654460906982422\n",
      "Seen so far: 5824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 91: 1.385024070739746\n",
      "Seen so far: 5888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 92: 0.9540029764175415\n",
      "Seen so far: 5952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 93: 1.444119930267334\n",
      "Seen so far: 6016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 94: 1.1945738792419434\n",
      "Seen so far: 6080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 95: 0.8001649379730225\n",
      "Seen so far: 6144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 96: 1.4047362804412842\n",
      "Seen so far: 6208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 97: 1.4422051906585693\n",
      "Seen so far: 6272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 98: 1.0182440280914307\n",
      "Seen so far: 6336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 99: 1.1016027927398682\n",
      "Seen so far: 6400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 100: 0.9003517627716064\n",
      "Seen so far: 6464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 101: 0.6785525679588318\n",
      "Seen so far: 6528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 102: 0.7851266860961914\n",
      "Seen so far: 6592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 103: 0.9124921560287476\n",
      "Seen so far: 6656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 104: 1.0966633558273315\n",
      "Seen so far: 6720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 105: 1.1463210582733154\n",
      "Seen so far: 6784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 106: 0.9907522201538086\n",
      "Seen so far: 6848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 107: 1.6242733001708984\n",
      "Seen so far: 6912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 108: 1.091888189315796\n",
      "Seen so far: 6976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 109: 1.2574336528778076\n",
      "Seen so far: 7040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 110: 1.0157670974731445\n",
      "Seen so far: 7104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 111: 1.0403707027435303\n",
      "Seen so far: 7168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 112: 0.8055148720741272\n",
      "Seen so far: 7232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 113: 1.081257939338684\n",
      "Seen so far: 7296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 114: 1.4071414470672607\n",
      "Seen so far: 7360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 115: 0.9231913089752197\n",
      "Seen so far: 7424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 116: 1.3502802848815918\n",
      "Seen so far: 7488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 117: 1.3653703927993774\n",
      "Seen so far: 7552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 118: 1.30281400680542\n",
      "Seen so far: 7616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 119: 1.114871621131897\n",
      "Seen so far: 7680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 120: 1.1939489841461182\n",
      "Seen so far: 7744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 121: 1.3515198230743408\n",
      "Seen so far: 7808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 122: 1.4533650875091553\n",
      "Seen so far: 7872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 123: 0.8581136465072632\n",
      "Seen so far: 7936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 124: 1.280754566192627\n",
      "Seen so far: 8000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 125: 1.2663781642913818\n",
      "Seen so far: 8064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 126: 0.8945522904396057\n",
      "Seen so far: 8128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 127: 1.587246298789978\n",
      "Seen so far: 8192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 128: 0.8377331495285034\n",
      "Seen so far: 8256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 129: 1.0739854574203491\n",
      "Seen so far: 8320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 130: 1.2592276334762573\n",
      "Seen so far: 8384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 131: 1.3676252365112305\n",
      "Seen so far: 8448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 132: 1.2743229866027832\n",
      "Seen so far: 8512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 133: 1.0432887077331543\n",
      "Seen so far: 8576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 134: 1.389272928237915\n",
      "Seen so far: 8640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 135: 1.4949917793273926\n",
      "Seen so far: 8704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 136: 1.191666841506958\n",
      "Seen so far: 8768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 137: 1.390796422958374\n",
      "Seen so far: 8832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 138: 1.012427568435669\n",
      "Seen so far: 8896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 139: 1.171375036239624\n",
      "Seen so far: 8960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 140: 1.000919222831726\n",
      "Seen so far: 9024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 141: 1.2746469974517822\n",
      "Seen so far: 9088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 142: 1.0232348442077637\n",
      "Seen so far: 9152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 143: 1.1608872413635254\n",
      "Seen so far: 9216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 144: 1.4420490264892578\n",
      "Seen so far: 9280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 145: 1.0813106298446655\n",
      "Seen so far: 9344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 146: 1.0403573513031006\n",
      "Seen so far: 9408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 147: 1.3336900472640991\n",
      "Seen so far: 9472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 148: 1.5447452068328857\n",
      "Seen so far: 9536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 149: 1.044654369354248\n",
      "Seen so far: 9600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 150: 0.9116681218147278\n",
      "Seen so far: 9664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 151: 1.217580795288086\n",
      "Seen so far: 9728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 152: 1.6752982139587402\n",
      "Seen so far: 9792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 153: 1.389335036277771\n",
      "Seen so far: 9856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 154: 1.8183847665786743\n",
      "Seen so far: 9920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 155: 0.8640718460083008\n",
      "Seen so far: 9984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 156: 1.246368169784546\n",
      "Seen so far: 10048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 157: 1.1153252124786377\n",
      "Seen so far: 10112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 158: 1.9899423122406006\n",
      "Seen so far: 10176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 159: 1.4278172254562378\n",
      "Seen so far: 10240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 160: 0.9859623908996582\n",
      "Seen so far: 10304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 161: 1.2374169826507568\n",
      "Seen so far: 10368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 162: 1.6897571086883545\n",
      "Seen so far: 10432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 163: 1.1329467296600342\n",
      "Seen so far: 10496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 164: 1.4838590621948242\n",
      "Seen so far: 10560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 165: 1.1053822040557861\n",
      "Seen so far: 10624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 166: 1.049159049987793\n",
      "Seen so far: 10688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 167: 0.9283238053321838\n",
      "Seen so far: 10752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 168: 1.2442667484283447\n",
      "Seen so far: 10816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 169: 0.9747196435928345\n",
      "Seen so far: 10880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 170: 1.1434545516967773\n",
      "Seen so far: 10944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 171: 1.4150749444961548\n",
      "Seen so far: 11008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 172: 1.2142192125320435\n",
      "Seen so far: 11072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 173: 1.1375327110290527\n",
      "Seen so far: 11136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 174: 1.3175026178359985\n",
      "Seen so far: 11200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 175: 1.020656704902649\n",
      "Seen so far: 11264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 176: 1.3247215747833252\n",
      "Seen so far: 11328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 177: 0.9901065826416016\n",
      "Seen so far: 11392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 178: 1.173769235610962\n",
      "Seen so far: 11456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 179: 0.9571525454521179\n",
      "Seen so far: 11520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 180: 1.0660951137542725\n",
      "Seen so far: 11584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 181: 1.204131007194519\n",
      "Seen so far: 11648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 182: 0.920432448387146\n",
      "Seen so far: 11712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 183: 1.2469322681427002\n",
      "Seen so far: 11776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 184: 1.6163583993911743\n",
      "Seen so far: 11840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 185: 1.281543254852295\n",
      "Seen so far: 11904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 186: 1.0426561832427979\n",
      "Seen so far: 11968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 187: 1.459291696548462\n",
      "Seen so far: 12032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 188: 1.2417510747909546\n",
      "Seen so far: 12096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 189: 1.2387986183166504\n",
      "Seen so far: 12160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 190: 1.441523790359497\n",
      "Seen so far: 12224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 191: 0.7285488843917847\n",
      "Seen so far: 12288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 192: 1.1155016422271729\n",
      "Seen so far: 12352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 193: 1.356131911277771\n",
      "Seen so far: 12416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 194: 1.363732933998108\n",
      "Seen so far: 12480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 195: 0.9563828110694885\n",
      "Seen so far: 12544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 196: 0.8742773532867432\n",
      "Seen so far: 12608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 197: 0.9669311046600342\n",
      "Seen so far: 12672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 198: 1.386106014251709\n",
      "Seen so far: 12736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 199: 1.2135441303253174\n",
      "Seen so far: 12800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 200: 1.3229832649230957\n",
      "Seen so far: 12864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 201: 0.9034394025802612\n",
      "Seen so far: 12928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 202: 1.2156404256820679\n",
      "Seen so far: 12992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 203: 1.3110873699188232\n",
      "Seen so far: 13056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 204: 1.1170566082000732\n",
      "Seen so far: 13120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 205: 0.9064948558807373\n",
      "Seen so far: 13184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 206: 1.5089776515960693\n",
      "Seen so far: 13248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 207: 1.2743463516235352\n",
      "Seen so far: 13312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 208: 1.283876657485962\n",
      "Seen so far: 13376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 209: 1.2061291933059692\n",
      "Seen so far: 13440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 210: 1.329240322113037\n",
      "Seen so far: 13504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 211: 1.132805347442627\n",
      "Seen so far: 13568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 212: 1.4934808015823364\n",
      "Seen so far: 13632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 213: 1.3941679000854492\n",
      "Seen so far: 13696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 214: 1.2115256786346436\n",
      "Seen so far: 13760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 215: 1.1912025213241577\n",
      "Seen so far: 13824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 216: 0.8961461782455444\n",
      "Seen so far: 13888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 217: 1.214426875114441\n",
      "Seen so far: 13952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 218: 0.9410483837127686\n",
      "Seen so far: 14016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 219: 1.0390666723251343\n",
      "Seen so far: 14080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 220: 1.2085946798324585\n",
      "Seen so far: 14144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 221: 1.0511878728866577\n",
      "Seen so far: 14208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 222: 1.2527315616607666\n",
      "Seen so far: 14272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 223: 1.2337193489074707\n",
      "Seen so far: 14336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 224: 0.9721837639808655\n",
      "Seen so far: 14400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 225: 1.3237450122833252\n",
      "Seen so far: 14464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 226: 0.8588882088661194\n",
      "Seen so far: 14528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 227: 1.1117525100708008\n",
      "Seen so far: 14592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 228: 1.183153510093689\n",
      "Seen so far: 14656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 229: 1.27223801612854\n",
      "Seen so far: 14720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 230: 1.0816595554351807\n",
      "Seen so far: 14784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 231: 1.0296592712402344\n",
      "Seen so far: 14848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 232: 1.0984281301498413\n",
      "Seen so far: 14912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 233: 1.4154630899429321\n",
      "Seen so far: 14976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 234: 1.0382177829742432\n",
      "Seen so far: 15040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 235: 0.8462526202201843\n",
      "Seen so far: 15104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 236: 1.1190599203109741\n",
      "Seen so far: 15168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 237: 1.2017353773117065\n",
      "Seen so far: 15232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 238: 1.4337425231933594\n",
      "Seen so far: 15296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 239: 1.298749566078186\n",
      "Seen so far: 15360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 240: 1.2103431224822998\n",
      "Seen so far: 15424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 241: 1.2610124349594116\n",
      "Seen so far: 15488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 242: 1.240612268447876\n",
      "Seen so far: 15552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 243: 1.0301177501678467\n",
      "Seen so far: 15616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 244: 1.2583680152893066\n",
      "Seen so far: 15680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 245: 1.2395362854003906\n",
      "Seen so far: 15744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 246: 1.4678698778152466\n",
      "Seen so far: 15808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 247: 1.3805503845214844\n",
      "Seen so far: 15872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 248: 0.9628696441650391\n",
      "Seen so far: 15936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 249: 1.0101823806762695\n",
      "Seen so far: 16000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 250: 1.2379753589630127\n",
      "Seen so far: 16064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 251: 1.3231134414672852\n",
      "Seen so far: 16128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 252: 1.4347124099731445\n",
      "Seen so far: 16192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 253: 1.1382859945297241\n",
      "Seen so far: 16256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 254: 1.0450453758239746\n",
      "Seen so far: 16320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 255: 1.0412483215332031\n",
      "Seen so far: 16384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 256: 1.2060743570327759\n",
      "Seen so far: 16448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 257: 1.7987788915634155\n",
      "Seen so far: 16512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 258: 1.1532206535339355\n",
      "Seen so far: 16576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 259: 1.1101473569869995\n",
      "Seen so far: 16640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 260: 0.7147024273872375\n",
      "Seen so far: 16704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 261: 1.2848048210144043\n",
      "Seen so far: 16768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 262: 1.5823307037353516\n",
      "Seen so far: 16832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 263: 1.1766409873962402\n",
      "Seen so far: 16896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 264: 0.9664229154586792\n",
      "Seen so far: 16960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 265: 1.0978286266326904\n",
      "Seen so far: 17024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 266: 0.7781511545181274\n",
      "Seen so far: 17088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 267: 1.1554172039031982\n",
      "Seen so far: 17152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 268: 1.1729743480682373\n",
      "Seen so far: 17216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 269: 1.0517477989196777\n",
      "Seen so far: 17280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 270: 0.9589720964431763\n",
      "Seen so far: 17344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 271: 1.2973812818527222\n",
      "Seen so far: 17408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 272: 1.0469839572906494\n",
      "Seen so far: 17472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 273: 1.4810199737548828\n",
      "Seen so far: 17536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 274: 0.957289457321167\n",
      "Seen so far: 17600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 275: 0.9255545735359192\n",
      "Seen so far: 17664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 276: 1.3896092176437378\n",
      "Seen so far: 17728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 277: 1.5908664464950562\n",
      "Seen so far: 17792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 278: 1.1872775554656982\n",
      "Seen so far: 17856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 279: 1.413135051727295\n",
      "Seen so far: 17920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 280: 1.0486602783203125\n",
      "Seen so far: 17984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 281: 1.1923366785049438\n",
      "Seen so far: 18048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 282: 1.0526225566864014\n",
      "Seen so far: 18112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 283: 0.6910815834999084\n",
      "Seen so far: 18176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 284: 0.8790303468704224\n",
      "Seen so far: 18240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 285: 0.8314837217330933\n",
      "Seen so far: 18304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 286: 0.9468029737472534\n",
      "Seen so far: 18368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 287: 1.034124493598938\n",
      "Seen so far: 18432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 288: 1.166917085647583\n",
      "Seen so far: 18496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 289: 0.8699662685394287\n",
      "Seen so far: 18560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 290: 1.3705939054489136\n",
      "Seen so far: 18624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 291: 0.7167532444000244\n",
      "Seen so far: 18688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 292: 1.4029043912887573\n",
      "Seen so far: 18752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 293: 1.3142249584197998\n",
      "Seen so far: 18816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 294: 0.7458510398864746\n",
      "Seen so far: 18880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 295: 1.2371547222137451\n",
      "Seen so far: 18944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 296: 1.3178067207336426\n",
      "Seen so far: 19008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 297: 0.9451114535331726\n",
      "Seen so far: 19072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 298: 0.9723080396652222\n",
      "Seen so far: 19136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 299: 1.6021463871002197\n",
      "Seen so far: 19200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 300: 0.7788395285606384\n",
      "Seen so far: 19264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 301: 1.065935492515564\n",
      "Seen so far: 19328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 302: 0.925249457359314\n",
      "Seen so far: 19392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 303: 0.7743126153945923\n",
      "Seen so far: 19456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 304: 1.289130687713623\n",
      "Seen so far: 19520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 305: 1.233650803565979\n",
      "Seen so far: 19584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 306: 1.4839882850646973\n",
      "Seen so far: 19648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 307: 1.1939818859100342\n",
      "Seen so far: 19712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 308: 1.3202712535858154\n",
      "Seen so far: 19776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 309: 0.8716796636581421\n",
      "Seen so far: 19840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 310: 1.21397066116333\n",
      "Seen so far: 19904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 311: 1.1969871520996094\n",
      "Seen so far: 19968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 312: 1.228101372718811\n",
      "Seen so far: 20032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 313: 1.0274221897125244\n",
      "Seen so far: 20096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 314: 0.9870758056640625\n",
      "Seen so far: 20160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 315: 0.9410669803619385\n",
      "Seen so far: 20224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 316: 1.0080721378326416\n",
      "Seen so far: 20288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 317: 1.359607219696045\n",
      "Seen so far: 20352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 318: 1.1996643543243408\n",
      "Seen so far: 20416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 319: 1.151139259338379\n",
      "Seen so far: 20480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 320: 1.2002196311950684\n",
      "Seen so far: 20544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 321: 1.0484812259674072\n",
      "Seen so far: 20608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 322: 0.9263330698013306\n",
      "Seen so far: 20672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 323: 1.319028377532959\n",
      "Seen so far: 20736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 324: 1.2768707275390625\n",
      "Seen so far: 20800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 325: 0.8381440043449402\n",
      "Seen so far: 20864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 326: 0.8740097880363464\n",
      "Seen so far: 20928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 327: 1.0642354488372803\n",
      "Seen so far: 20992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 328: 1.0531423091888428\n",
      "Seen so far: 21056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 329: 1.343765139579773\n",
      "Seen so far: 21120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 330: 1.3685795068740845\n",
      "Seen so far: 21184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 331: 1.0432240962982178\n",
      "Seen so far: 21248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 332: 0.8331462144851685\n",
      "Seen so far: 21312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 333: 1.2306926250457764\n",
      "Seen so far: 21376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 334: 0.8442095518112183\n",
      "Seen so far: 21440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 335: 1.2771695852279663\n",
      "Seen so far: 21504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 336: 1.477879285812378\n",
      "Seen so far: 21568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 337: 0.9390902519226074\n",
      "Seen so far: 21632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 338: 0.9863423109054565\n",
      "Seen so far: 21696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 339: 0.9053125381469727\n",
      "Seen so far: 21760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 340: 1.0736119747161865\n",
      "Seen so far: 21824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 341: 1.2309083938598633\n",
      "Seen so far: 21888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 342: 1.5778645277023315\n",
      "Seen so far: 21952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 343: 1.4212167263031006\n",
      "Seen so far: 22016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 344: 1.3154661655426025\n",
      "Seen so far: 22080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 345: 0.9902902841567993\n",
      "Seen so far: 22144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 346: 1.0881173610687256\n",
      "Seen so far: 22208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 347: 1.3932305574417114\n",
      "Seen so far: 22272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 348: 0.7966248393058777\n",
      "Seen so far: 22336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 349: 1.381690263748169\n",
      "Seen so far: 22400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 350: 1.1178526878356934\n",
      "Seen so far: 22464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 351: 0.9296932220458984\n",
      "Seen so far: 22528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 352: 1.1989338397979736\n",
      "Seen so far: 22592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 353: 1.1702301502227783\n",
      "Seen so far: 22656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 354: 1.229127287864685\n",
      "Seen so far: 22720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 355: 1.1275153160095215\n",
      "Seen so far: 22784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 356: 0.8412032127380371\n",
      "Seen so far: 22848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 357: 1.2739441394805908\n",
      "Seen so far: 22912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 358: 1.4649782180786133\n",
      "Seen so far: 22976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 359: 1.2186615467071533\n",
      "Seen so far: 23040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 360: 1.2482326030731201\n",
      "Seen so far: 23104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 361: 1.0470318794250488\n",
      "Seen so far: 23168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 362: 1.4038982391357422\n",
      "Seen so far: 23232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 363: 1.0829720497131348\n",
      "Seen so far: 23296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 364: 1.275452971458435\n",
      "Seen so far: 23360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 365: 1.2827497720718384\n",
      "Seen so far: 23424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 366: 1.2542868852615356\n",
      "Seen so far: 23488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 367: 1.046108603477478\n",
      "Seen so far: 23552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 368: 1.4017579555511475\n",
      "Seen so far: 23616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 369: 1.4930713176727295\n",
      "Seen so far: 23680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 370: 0.8514297008514404\n",
      "Seen so far: 23744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 371: 1.287315845489502\n",
      "Seen so far: 23808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 372: 0.7344733476638794\n",
      "Seen so far: 23872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 373: 1.2941429615020752\n",
      "Seen so far: 23936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 374: 1.2646111249923706\n",
      "Seen so far: 24000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 375: 1.1649715900421143\n",
      "Seen so far: 24064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 376: 0.8989309072494507\n",
      "Seen so far: 24128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 377: 1.452701210975647\n",
      "Seen so far: 24192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 378: 0.8419674634933472\n",
      "Seen so far: 24256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 379: 0.989799976348877\n",
      "Seen so far: 24320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 380: 1.353161096572876\n",
      "Seen so far: 24384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 381: 1.1039451360702515\n",
      "Seen so far: 24448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 382: 0.9859760999679565\n",
      "Seen so far: 24512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 383: 1.2998950481414795\n",
      "Seen so far: 24576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 384: 1.2890610694885254\n",
      "Seen so far: 24640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 385: 1.400557279586792\n",
      "Seen so far: 24704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 386: 1.6169224977493286\n",
      "Seen so far: 24768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 387: 1.2956897020339966\n",
      "Seen so far: 24832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 388: 1.4387485980987549\n",
      "Seen so far: 24896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 389: 0.9392502307891846\n",
      "Seen so far: 24960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 390: 1.1685702800750732\n",
      "Seen so far: 25024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 391: 0.8857920169830322\n",
      "Seen so far: 25088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 392: 1.3284149169921875\n",
      "Seen so far: 25152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 393: 1.2100059986114502\n",
      "Seen so far: 25216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 394: 0.7117334604263306\n",
      "Seen so far: 25280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 395: 1.3097476959228516\n",
      "Seen so far: 25344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 396: 1.1834771633148193\n",
      "Seen so far: 25408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 397: 1.4617328643798828\n",
      "Seen so far: 25472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 398: 0.9147320985794067\n",
      "Seen so far: 25536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 399: 1.241297721862793\n",
      "Seen so far: 25600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 400: 0.8325468897819519\n",
      "Seen so far: 25664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 401: 1.1282451152801514\n",
      "Seen so far: 25728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 402: 1.5582828521728516\n",
      "Seen so far: 25792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 403: 1.2211930751800537\n",
      "Seen so far: 25856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 404: 0.8585892915725708\n",
      "Seen so far: 25920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 405: 0.9076129794120789\n",
      "Seen so far: 25984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 406: 1.3790624141693115\n",
      "Seen so far: 26048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 407: 1.400996208190918\n",
      "Seen so far: 26112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 408: 1.3661112785339355\n",
      "Seen so far: 26176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 409: 1.1269590854644775\n",
      "Seen so far: 26240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 410: 0.7856577038764954\n",
      "Seen so far: 26304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 411: 1.3813755512237549\n",
      "Seen so far: 26368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 412: 1.3750145435333252\n",
      "Seen so far: 26432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 413: 1.0078895092010498\n",
      "Seen so far: 26496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 414: 0.6115772724151611\n",
      "Seen so far: 26560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 415: 0.9912488460540771\n",
      "Seen so far: 26624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 416: 1.2854440212249756\n",
      "Seen so far: 26688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 417: 1.3695528507232666\n",
      "Seen so far: 26752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 418: 1.3776953220367432\n",
      "Seen so far: 26816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 419: 1.550879716873169\n",
      "Seen so far: 26880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 420: 1.1275169849395752\n",
      "Seen so far: 26944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 421: 1.6705974340438843\n",
      "Seen so far: 27008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 422: 1.0404534339904785\n",
      "Seen so far: 27072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 423: 1.2540955543518066\n",
      "Seen so far: 27136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 424: 1.4105415344238281\n",
      "Seen so far: 27200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 425: 1.2828638553619385\n",
      "Seen so far: 27264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 426: 1.2296335697174072\n",
      "Seen so far: 27328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 427: 1.3431715965270996\n",
      "Seen so far: 27392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 428: 1.1973296403884888\n",
      "Seen so far: 27456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 429: 1.2799813747406006\n",
      "Seen so far: 27520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 430: 1.0659786462783813\n",
      "Seen so far: 27584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 431: 1.159699559211731\n",
      "Seen so far: 27648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 432: 1.558822512626648\n",
      "Seen so far: 27712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 433: 0.95521080493927\n",
      "Seen so far: 27776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 434: 1.0398633480072021\n",
      "Seen so far: 27840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 435: 1.340230941772461\n",
      "Seen so far: 27904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 436: 0.9738752245903015\n",
      "Seen so far: 27968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 437: 1.1902433633804321\n",
      "Seen so far: 28032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 438: 1.3123611211776733\n",
      "Seen so far: 28096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 439: 1.1835920810699463\n",
      "Seen so far: 28160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 440: 1.1820526123046875\n",
      "Seen so far: 28224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 441: 1.2390451431274414\n",
      "Seen so far: 28288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 442: 1.0978834629058838\n",
      "Seen so far: 28352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 443: 0.6423544883728027\n",
      "Seen so far: 28416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 444: 1.3018295764923096\n",
      "Seen so far: 28480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 445: 1.3056256771087646\n",
      "Seen so far: 28544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 446: 0.961663007736206\n",
      "Seen so far: 28608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 447: 1.0419518947601318\n",
      "Seen so far: 28672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 448: 1.011314868927002\n",
      "Seen so far: 28736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 449: 1.1953961849212646\n",
      "Seen so far: 28800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 450: 1.5304343700408936\n",
      "Seen so far: 28864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 451: 1.1371392011642456\n",
      "Seen so far: 28928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 452: 1.2882238626480103\n",
      "Seen so far: 28992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 453: 1.2753500938415527\n",
      "Seen so far: 29056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 454: 1.1677826642990112\n",
      "Seen so far: 29120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 455: 0.9247973561286926\n",
      "Seen so far: 29184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 456: 1.2020220756530762\n",
      "Seen so far: 29248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 457: 0.8433433771133423\n",
      "Seen so far: 29312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 458: 1.1044896841049194\n",
      "Seen so far: 29376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 459: 1.0962302684783936\n",
      "Seen so far: 29440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 460: 1.272733211517334\n",
      "Seen so far: 29504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 461: 1.0929889678955078\n",
      "Seen so far: 29568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 462: 1.1136541366577148\n",
      "Seen so far: 29632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 463: 1.1731350421905518\n",
      "Seen so far: 29696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 464: 1.1521025896072388\n",
      "Seen so far: 29760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 465: 0.7931990623474121\n",
      "Seen so far: 29824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 466: 0.9081707000732422\n",
      "Seen so far: 29888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 467: 1.0356279611587524\n",
      "Seen so far: 29952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 468: 1.1426620483398438\n",
      "Seen so far: 30016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 469: 0.9410618543624878\n",
      "Seen so far: 30080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 470: 0.9930887222290039\n",
      "Seen so far: 30144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 471: 0.9116110801696777\n",
      "Seen so far: 30208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 472: 1.0922162532806396\n",
      "Seen so far: 30272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 473: 1.0602267980575562\n",
      "Seen so far: 30336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 474: 1.007480502128601\n",
      "Seen so far: 30400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 475: 1.16990327835083\n",
      "Seen so far: 30464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 476: 0.8668805360794067\n",
      "Seen so far: 30528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 477: 1.1198070049285889\n",
      "Seen so far: 30592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 478: 1.0518180131912231\n",
      "Seen so far: 30656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 479: 1.2699522972106934\n",
      "Seen so far: 30720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 480: 0.8516319990158081\n",
      "Seen so far: 30784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 481: 1.0548332929611206\n",
      "Seen so far: 30848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 482: 1.0165131092071533\n",
      "Seen so far: 30912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 483: 1.189694881439209\n",
      "Seen so far: 30976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 484: 1.0498170852661133\n",
      "Seen so far: 31040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 485: 0.7992640137672424\n",
      "Seen so far: 31104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 486: 1.2800763845443726\n",
      "Seen so far: 31168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 487: 1.0010676383972168\n",
      "Seen so far: 31232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 488: 1.1576499938964844\n",
      "Seen so far: 31296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 489: 1.410097360610962\n",
      "Seen so far: 31360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 490: 0.8436225652694702\n",
      "Seen so far: 31424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 491: 1.2215750217437744\n",
      "Seen so far: 31488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 492: 1.0130865573883057\n",
      "Seen so far: 31552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 493: 1.080641508102417\n",
      "Seen so far: 31616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 494: 1.0546388626098633\n",
      "Seen so far: 31680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 495: 1.1417890787124634\n",
      "Seen so far: 31744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 496: 1.3399386405944824\n",
      "Seen so far: 31808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 497: 1.1458735466003418\n",
      "Seen so far: 31872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 498: 0.966359555721283\n",
      "Seen so far: 31936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 499: 1.6417696475982666\n",
      "Seen so far: 32000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 500: 0.7421588897705078\n",
      "Seen so far: 32064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 501: 0.9197806715965271\n",
      "Seen so far: 32128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 502: 1.051794171333313\n",
      "Seen so far: 32192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 503: 0.9859752655029297\n",
      "Seen so far: 32256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 504: 1.4694064855575562\n",
      "Seen so far: 32320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 505: 1.3527692556381226\n",
      "Seen so far: 32384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 506: 1.152247428894043\n",
      "Seen so far: 32448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 507: 1.7051507234573364\n",
      "Seen so far: 32512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 508: 0.8981409072875977\n",
      "Seen so far: 32576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 509: 1.1662373542785645\n",
      "Seen so far: 32640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 510: 1.205113172531128\n",
      "Seen so far: 32704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 511: 1.2494744062423706\n",
      "Seen so far: 32768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 512: 1.1658364534378052\n",
      "Seen so far: 32832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 513: 1.2947120666503906\n",
      "Seen so far: 32896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 514: 1.2055857181549072\n",
      "Seen so far: 32960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 515: 1.1648567914962769\n",
      "Seen so far: 33024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 516: 0.9766848087310791\n",
      "Seen so far: 33088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 517: 1.465912103652954\n",
      "Seen so far: 33152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 518: 1.0658884048461914\n",
      "Seen so far: 33216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 519: 1.1208112239837646\n",
      "Seen so far: 33280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 520: 0.9309303760528564\n",
      "Seen so far: 33344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 521: 0.9359357357025146\n",
      "Seen so far: 33408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 522: 1.028456449508667\n",
      "Seen so far: 33472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 523: 1.1191887855529785\n",
      "Seen so far: 33536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 524: 1.1319730281829834\n",
      "Seen so far: 33600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 525: 0.9558967351913452\n",
      "Seen so far: 33664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 526: 1.3768523931503296\n",
      "Seen so far: 33728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 527: 1.2001656293869019\n",
      "Seen so far: 33792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 528: 1.3650283813476562\n",
      "Seen so far: 33856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 529: 0.6658629179000854\n",
      "Seen so far: 33920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 530: 1.061011791229248\n",
      "Seen so far: 33984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 531: 0.5486167669296265\n",
      "Seen so far: 34048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 532: 0.9867286682128906\n",
      "Seen so far: 34112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 533: 1.4259531497955322\n",
      "Seen so far: 34176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 534: 0.9429086446762085\n",
      "Seen so far: 34240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 535: 1.4545366764068604\n",
      "Seen so far: 34304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 536: 0.9772152900695801\n",
      "Seen so far: 34368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 537: 1.000354528427124\n",
      "Seen so far: 34432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 538: 0.9787214994430542\n",
      "Seen so far: 34496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 539: 0.7497190237045288\n",
      "Seen so far: 34560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 540: 1.3276134729385376\n",
      "Seen so far: 34624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 541: 1.0250599384307861\n",
      "Seen so far: 34688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 542: 1.0843677520751953\n",
      "Seen so far: 34752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 543: 1.0700634717941284\n",
      "Seen so far: 34816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 544: 0.7142947912216187\n",
      "Seen so far: 34880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 545: 1.2665860652923584\n",
      "Seen so far: 34944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 546: 1.165550947189331\n",
      "Seen so far: 35008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 547: 1.167004942893982\n",
      "Seen so far: 35072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 548: 1.4319064617156982\n",
      "Seen so far: 35136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 549: 1.0510449409484863\n",
      "Seen so far: 35200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 550: 1.1222996711730957\n",
      "Seen so far: 35264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 551: 0.8156446218490601\n",
      "Seen so far: 35328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 552: 0.8257396221160889\n",
      "Seen so far: 35392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 553: 1.250962495803833\n",
      "Seen so far: 35456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 554: 1.3678617477416992\n",
      "Seen so far: 35520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 555: 1.4652528762817383\n",
      "Seen so far: 35584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 556: 1.0943121910095215\n",
      "Seen so far: 35648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 557: 1.221778392791748\n",
      "Seen so far: 35712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 558: 0.8200293183326721\n",
      "Seen so far: 35776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 559: 1.268300175666809\n",
      "Seen so far: 35840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 560: 1.2204771041870117\n",
      "Seen so far: 35904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 561: 0.994271993637085\n",
      "Seen so far: 35968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 562: 1.1553150415420532\n",
      "Seen so far: 36032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 563: 1.3468126058578491\n",
      "Seen so far: 36096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 564: 0.9010543823242188\n",
      "Seen so far: 36160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 565: 1.014570713043213\n",
      "Seen so far: 36224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 566: 1.040704607963562\n",
      "Seen so far: 36288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 567: 1.0296436548233032\n",
      "Seen so far: 36352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 568: 1.141335129737854\n",
      "Seen so far: 36416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 569: 1.0252621173858643\n",
      "Seen so far: 36480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 570: 1.5663366317749023\n",
      "Seen so far: 36544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 571: 1.2419955730438232\n",
      "Seen so far: 36608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 572: 1.381911277770996\n",
      "Seen so far: 36672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 573: 1.15470290184021\n",
      "Seen so far: 36736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 574: 1.0601582527160645\n",
      "Seen so far: 36800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 575: 1.5508127212524414\n",
      "Seen so far: 36864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 576: 1.0058252811431885\n",
      "Seen so far: 36928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 577: 1.3149778842926025\n",
      "Seen so far: 36992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 578: 1.0342670679092407\n",
      "Seen so far: 37056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 579: 1.2897179126739502\n",
      "Seen so far: 37120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 580: 0.7967280149459839\n",
      "Seen so far: 37184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 581: 1.0926799774169922\n",
      "Seen so far: 37248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 582: 1.855590581893921\n",
      "Seen so far: 37312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 583: 1.23447585105896\n",
      "Seen so far: 37376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 584: 1.1253035068511963\n",
      "Seen so far: 37440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 585: 0.8985053896903992\n",
      "Seen so far: 37504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 586: 1.1736119985580444\n",
      "Seen so far: 37568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 587: 0.8693925142288208\n",
      "Seen so far: 37632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 588: 1.0199403762817383\n",
      "Seen so far: 37696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 589: 1.1920307874679565\n",
      "Seen so far: 37760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 590: 1.1497756242752075\n",
      "Seen so far: 37824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 591: 0.9661545753479004\n",
      "Seen so far: 37888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 592: 1.1861035823822021\n",
      "Seen so far: 37952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 593: 1.1712546348571777\n",
      "Seen so far: 38016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 594: 0.6666236519813538\n",
      "Seen so far: 38080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 595: 0.895363450050354\n",
      "Seen so far: 38144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 596: 1.1613690853118896\n",
      "Seen so far: 38208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 597: 0.992824137210846\n",
      "Seen so far: 38272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 598: 0.780957818031311\n",
      "Seen so far: 38336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 599: 0.7648526430130005\n",
      "Seen so far: 38400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 600: 0.6364233493804932\n",
      "Seen so far: 38464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 601: 0.7599111199378967\n",
      "Seen so far: 38528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 602: 1.269775152206421\n",
      "Seen so far: 38592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 603: 1.7037596702575684\n",
      "Seen so far: 38656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 604: 1.3531036376953125\n",
      "Seen so far: 38720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 605: 0.8898344039916992\n",
      "Seen so far: 38784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 606: 2.0306410789489746\n",
      "Seen so far: 38848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 607: 1.062592625617981\n",
      "Seen so far: 38912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 608: 1.1748507022857666\n",
      "Seen so far: 38976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 609: 1.0945322513580322\n",
      "Seen so far: 39040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 610: 0.7566943168640137\n",
      "Seen so far: 39104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 611: 0.9504159688949585\n",
      "Seen so far: 39168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 612: 1.0580804347991943\n",
      "Seen so far: 39232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 613: 1.0072826147079468\n",
      "Seen so far: 39296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 614: 0.8849207758903503\n",
      "Seen so far: 39360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 615: 1.0099406242370605\n",
      "Seen so far: 39424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 616: 0.9746905565261841\n",
      "Seen so far: 39488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 617: 1.4406957626342773\n",
      "Seen so far: 39552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 618: 1.158854603767395\n",
      "Seen so far: 39616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 619: 1.0409749746322632\n",
      "Seen so far: 39680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 620: 1.251437783241272\n",
      "Seen so far: 39744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 621: 1.300236701965332\n",
      "Seen so far: 39808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 622: 1.1600100994110107\n",
      "Seen so far: 39872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 623: 1.036024570465088\n",
      "Seen so far: 39936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 624: 0.9449658393859863\n",
      "Seen so far: 40000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 625: 1.037656307220459\n",
      "Seen so far: 40064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 626: 1.0038235187530518\n",
      "Seen so far: 40128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 627: 0.7201217412948608\n",
      "Seen so far: 40192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 628: 1.0555740594863892\n",
      "Seen so far: 40256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 629: 1.4376659393310547\n",
      "Seen so far: 40320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 630: 1.0993552207946777\n",
      "Seen so far: 40384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 631: 1.0838284492492676\n",
      "Seen so far: 40448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 632: 1.1282317638397217\n",
      "Seen so far: 40512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 633: 1.0125435590744019\n",
      "Seen so far: 40576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 634: 0.7403401136398315\n",
      "Seen so far: 40640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 635: 0.9781973958015442\n",
      "Seen so far: 40704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 636: 1.121762990951538\n",
      "Seen so far: 40768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 637: 0.46674880385398865\n",
      "Seen so far: 40832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 638: 0.8229979276657104\n",
      "Seen so far: 40896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 639: 1.0731385946273804\n",
      "Seen so far: 40960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 640: 0.7995684146881104\n",
      "Seen so far: 41024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 641: 0.5135452747344971\n",
      "Seen so far: 41088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 642: 0.936942458152771\n",
      "Seen so far: 41152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 643: 0.9473311901092529\n",
      "Seen so far: 41216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 644: 1.0498216152191162\n",
      "Seen so far: 41280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 645: 1.001571774482727\n",
      "Seen so far: 41344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 646: 0.9536792635917664\n",
      "Seen so far: 41408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 647: 1.0254865884780884\n",
      "Seen so far: 41472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 648: 1.0012426376342773\n",
      "Seen so far: 41536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 649: 1.0843007564544678\n",
      "Seen so far: 41600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 650: 1.2549667358398438\n",
      "Seen so far: 41664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 651: 1.2001750469207764\n",
      "Seen so far: 41728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 652: 1.0335586071014404\n",
      "Seen so far: 41792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 653: 1.2058348655700684\n",
      "Seen so far: 41856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 654: 1.0263495445251465\n",
      "Seen so far: 41920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 655: 1.1574528217315674\n",
      "Seen so far: 41984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 656: 1.0379667282104492\n",
      "Seen so far: 42048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 657: 1.3750100135803223\n",
      "Seen so far: 42112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 658: 0.9887051582336426\n",
      "Seen so far: 42176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 659: 0.9392534494400024\n",
      "Seen so far: 42240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 660: 1.1988866329193115\n",
      "Seen so far: 42304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 661: 0.9161293506622314\n",
      "Seen so far: 42368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 662: 1.2264161109924316\n",
      "Seen so far: 42432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 663: 1.2590196132659912\n",
      "Seen so far: 42496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 664: 0.9786060452461243\n",
      "Seen so far: 42560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 665: 1.1231991052627563\n",
      "Seen so far: 42624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 666: 0.8739703893661499\n",
      "Seen so far: 42688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 667: 1.0515620708465576\n",
      "Seen so far: 42752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 668: 1.0640007257461548\n",
      "Seen so far: 42816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 669: 1.1236953735351562\n",
      "Seen so far: 42880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 670: 1.148404598236084\n",
      "Seen so far: 42944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 671: 1.7270702123641968\n",
      "Seen so far: 43008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 672: 1.423871636390686\n",
      "Seen so far: 43072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 673: 1.544284462928772\n",
      "Seen so far: 43136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 674: 0.9215455055236816\n",
      "Seen so far: 43200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 675: 0.940000593662262\n",
      "Seen so far: 43264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 676: 1.1932141780853271\n",
      "Seen so far: 43328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 677: 1.2818961143493652\n",
      "Seen so far: 43392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 678: 1.3518192768096924\n",
      "Seen so far: 43456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 679: 1.225638747215271\n",
      "Seen so far: 43520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 680: 0.9457220435142517\n",
      "Seen so far: 43584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 681: 1.282684564590454\n",
      "Seen so far: 43648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 682: 0.9582705497741699\n",
      "Seen so far: 43712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 683: 0.7440201640129089\n",
      "Seen so far: 43776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 684: 1.0293781757354736\n",
      "Seen so far: 43840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 685: 0.9567023515701294\n",
      "Seen so far: 43904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 686: 1.3764411211013794\n",
      "Seen so far: 43968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 687: 1.5412404537200928\n",
      "Seen so far: 44032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 688: 1.07182776927948\n",
      "Seen so far: 44096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 689: 0.9903935194015503\n",
      "Seen so far: 44160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 690: 1.0212633609771729\n",
      "Seen so far: 44224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 691: 1.203877568244934\n",
      "Seen so far: 44288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 692: 1.374680519104004\n",
      "Seen so far: 44352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 693: 1.4595789909362793\n",
      "Seen so far: 44416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 694: 1.1209534406661987\n",
      "Seen so far: 44480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 695: 1.0401544570922852\n",
      "Seen so far: 44544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 696: 0.9671106338500977\n",
      "Seen so far: 44608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 697: 1.0633835792541504\n",
      "Seen so far: 44672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 698: 0.9052903652191162\n",
      "Seen so far: 44736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 699: 0.9293636083602905\n",
      "Seen so far: 44800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 700: 1.6833267211914062\n",
      "Seen so far: 44864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 701: 1.127549409866333\n",
      "Seen so far: 44928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 702: 0.8911624550819397\n",
      "Seen so far: 44992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 703: 0.9095579385757446\n",
      "Seen so far: 45056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 704: 0.9133455753326416\n",
      "Seen so far: 45120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 705: 1.0411909818649292\n",
      "Seen so far: 45184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 706: 1.025611162185669\n",
      "Seen so far: 45248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 707: 0.907818078994751\n",
      "Seen so far: 45312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 708: 0.8602896928787231\n",
      "Seen so far: 45376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 709: 1.5150458812713623\n",
      "Seen so far: 45440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 710: 1.2283291816711426\n",
      "Seen so far: 45504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 711: 0.9315876960754395\n",
      "Seen so far: 45568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 712: 1.2153218984603882\n",
      "Seen so far: 45632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 713: 1.3415875434875488\n",
      "Seen so far: 45696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 714: 1.2965295314788818\n",
      "Seen so far: 45760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 715: 1.4921905994415283\n",
      "Seen so far: 45824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 716: 0.595420241355896\n",
      "Seen so far: 45888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 717: 1.4002892971038818\n",
      "Seen so far: 45952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 718: 1.395696997642517\n",
      "Seen so far: 46016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 719: 1.1897119283676147\n",
      "Seen so far: 46080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 720: 1.242772102355957\n",
      "Seen so far: 46144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 721: 1.2230123281478882\n",
      "Seen so far: 46208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 722: 0.7973890900611877\n",
      "Seen so far: 46272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 723: 1.0523204803466797\n",
      "Seen so far: 46336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 724: 1.0312237739562988\n",
      "Seen so far: 46400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 725: 1.4758596420288086\n",
      "Seen so far: 46464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 726: 1.1059184074401855\n",
      "Seen so far: 46528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 727: 1.0409600734710693\n",
      "Seen so far: 46592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 728: 1.221895456314087\n",
      "Seen so far: 46656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 729: 1.0615652799606323\n",
      "Seen so far: 46720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 730: 1.1896129846572876\n",
      "Seen so far: 46784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 731: 1.3136940002441406\n",
      "Seen so far: 46848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 732: 1.5585079193115234\n",
      "Seen so far: 46912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 733: 1.0301005840301514\n",
      "Seen so far: 46976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 734: 0.9118039608001709\n",
      "Seen so far: 47040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 735: 0.9428242444992065\n",
      "Seen so far: 47104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 736: 0.8704829216003418\n",
      "Seen so far: 47168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 737: 0.9706237316131592\n",
      "Seen so far: 47232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 738: 1.0395967960357666\n",
      "Seen so far: 47296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 739: 1.6645972728729248\n",
      "Seen so far: 47360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 740: 1.1254512071609497\n",
      "Seen so far: 47424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 741: 0.8739622831344604\n",
      "Seen so far: 47488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 742: 0.9316315054893494\n",
      "Seen so far: 47552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 743: 1.39634370803833\n",
      "Seen so far: 47616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 744: 0.7565304040908813\n",
      "Seen so far: 47680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 745: 1.1826550960540771\n",
      "Seen so far: 47744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 746: 1.2520430088043213\n",
      "Seen so far: 47808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 747: 1.324291706085205\n",
      "Seen so far: 47872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 748: 0.8940014243125916\n",
      "Seen so far: 47936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 749: 1.718651533126831\n",
      "Seen so far: 48000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 750: 0.9700051546096802\n",
      "Seen so far: 48064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 751: 0.9648683667182922\n",
      "Seen so far: 48128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 752: 1.3718953132629395\n",
      "Seen so far: 48192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 753: 1.5414843559265137\n",
      "Seen so far: 48256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 754: 1.1527438163757324\n",
      "Seen so far: 48320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 755: 1.049139142036438\n",
      "Seen so far: 48384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 756: 1.1885114908218384\n",
      "Seen so far: 48448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 757: 1.5298088788986206\n",
      "Seen so far: 48512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 758: 0.8634570837020874\n",
      "Seen so far: 48576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 759: 1.2577897310256958\n",
      "Seen so far: 48640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 760: 1.343323826789856\n",
      "Seen so far: 48704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 761: 1.2559431791305542\n",
      "Seen so far: 48768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 762: 1.1668530702590942\n",
      "Seen so far: 48832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 763: 1.1451207399368286\n",
      "Seen so far: 48896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 764: 1.1879374980926514\n",
      "Seen so far: 48960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 765: 1.229828119277954\n",
      "Seen so far: 49024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 766: 1.3156342506408691\n",
      "Seen so far: 49088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 767: 1.3556485176086426\n",
      "Seen so far: 49152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 768: 1.0101630687713623\n",
      "Seen so far: 49216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 769: 0.9486547708511353\n",
      "Seen so far: 49280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 770: 1.00150728225708\n",
      "Seen so far: 49344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 771: 1.0937857627868652\n",
      "Seen so far: 49408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 772: 1.2251302003860474\n",
      "Seen so far: 49472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 773: 0.9965301752090454\n",
      "Seen so far: 49536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 774: 1.1480090618133545\n",
      "Seen so far: 49600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 775: 1.1356701850891113\n",
      "Seen so far: 49664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 776: 1.186478614807129\n",
      "Seen so far: 49728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 777: 1.2585532665252686\n",
      "Seen so far: 49792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 778: 1.0176342725753784\n",
      "Seen so far: 49856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 779: 0.8500536680221558\n",
      "Seen so far: 49920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 780: 1.4646353721618652\n",
      "Seen so far: 49984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 781: 1.2348508834838867\n",
      "Seen so far: 50048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 782: 1.2231606245040894\n",
      "Seen so far: 50112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 783: 1.291666030883789\n",
      "Seen so far: 50176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 784: 1.1044942140579224\n",
      "Seen so far: 50240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 785: 1.2836873531341553\n",
      "Seen so far: 50304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 786: 1.183904767036438\n",
      "Seen so far: 50368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 787: 1.5426021814346313\n",
      "Seen so far: 50432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 788: 0.9256101846694946\n",
      "Seen so far: 50496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 789: 1.5532002449035645\n",
      "Seen so far: 50560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 790: 1.344024658203125\n",
      "Seen so far: 50624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 791: 0.9264180660247803\n",
      "Seen so far: 50688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 792: 0.8176039457321167\n",
      "Seen so far: 50752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 793: 0.773425817489624\n",
      "Seen so far: 50816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 794: 1.464043140411377\n",
      "Seen so far: 50880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 795: 0.7994734048843384\n",
      "Seen so far: 50944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 796: 1.1079537868499756\n",
      "Seen so far: 51008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 797: 1.4241840839385986\n",
      "Seen so far: 51072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 798: 1.5659575462341309\n",
      "Seen so far: 51136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 799: 1.3831732273101807\n",
      "Seen so far: 51200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 800: 1.044069528579712\n",
      "Seen so far: 51264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 801: 1.0083059072494507\n",
      "Seen so far: 51328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 802: 1.5184786319732666\n",
      "Seen so far: 51392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 803: 1.0263934135437012\n",
      "Seen so far: 51456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 804: 0.812909722328186\n",
      "Seen so far: 51520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 805: 1.446368932723999\n",
      "Seen so far: 51584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 806: 1.197777509689331\n",
      "Seen so far: 51648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 807: 0.8033533096313477\n",
      "Seen so far: 51712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 808: 1.0831944942474365\n",
      "Seen so far: 51776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 809: 1.0180907249450684\n",
      "Seen so far: 51840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 810: 1.0120831727981567\n",
      "Seen so far: 51904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 811: 1.1974211931228638\n",
      "Seen so far: 51968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 812: 1.3154534101486206\n",
      "Seen so far: 52032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 813: 0.742680549621582\n",
      "Seen so far: 52096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 814: 0.664434552192688\n",
      "Seen so far: 52160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 815: 1.547508716583252\n",
      "Seen so far: 52224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 816: 1.0470383167266846\n",
      "Seen so far: 52288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 817: 0.8732849359512329\n",
      "Seen so far: 52352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 818: 1.5502864122390747\n",
      "Seen so far: 52416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 819: 0.5169820785522461\n",
      "Seen so far: 52480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 820: 1.5277435779571533\n",
      "Seen so far: 52544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 821: 1.189115285873413\n",
      "Seen so far: 52608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 822: 1.1336569786071777\n",
      "Seen so far: 52672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 823: 1.2341053485870361\n",
      "Seen so far: 52736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 824: 1.274167776107788\n",
      "Seen so far: 52800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 825: 1.1255264282226562\n",
      "Seen so far: 52864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 826: 1.3084640502929688\n",
      "Seen so far: 52928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 827: 1.1387920379638672\n",
      "Seen so far: 52992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 828: 1.162144660949707\n",
      "Seen so far: 53056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 829: 1.1353192329406738\n",
      "Seen so far: 53120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 830: 1.0207244157791138\n",
      "Seen so far: 53184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 831: 1.2682478427886963\n",
      "Seen so far: 53248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 832: 1.2186481952667236\n",
      "Seen so far: 53312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 833: 1.4383108615875244\n",
      "Seen so far: 53376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 834: 1.1269166469573975\n",
      "Seen so far: 53440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 835: 0.7661118507385254\n",
      "Seen so far: 53504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 836: 1.0703718662261963\n",
      "Seen so far: 53568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 837: 1.036920428276062\n",
      "Seen so far: 53632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 838: 0.661062479019165\n",
      "Seen so far: 53696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 839: 0.6911269426345825\n",
      "Seen so far: 53760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 840: 0.9656001329421997\n",
      "Seen so far: 53824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 841: 1.454901099205017\n",
      "Seen so far: 53888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 842: 0.891423761844635\n",
      "Seen so far: 53952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 843: 1.1219482421875\n",
      "Seen so far: 54016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 844: 1.0360937118530273\n",
      "Seen so far: 54080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 845: 1.1098301410675049\n",
      "Seen so far: 54144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 846: 1.1719589233398438\n",
      "Seen so far: 54208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 847: 1.2062866687774658\n",
      "Seen so far: 54272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 848: 1.2574734687805176\n",
      "Seen so far: 54336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 849: 0.7897050380706787\n",
      "Seen so far: 54400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 850: 0.6420202255249023\n",
      "Seen so far: 54464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 851: 0.9332756996154785\n",
      "Seen so far: 54528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 852: 0.5998529195785522\n",
      "Seen so far: 54592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 853: 0.6522180438041687\n",
      "Seen so far: 54656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 854: 0.8539060354232788\n",
      "Seen so far: 54720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 855: 0.6979730129241943\n",
      "Seen so far: 54784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 856: 1.0026233196258545\n",
      "Seen so far: 54848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 857: 0.8132113218307495\n",
      "Seen so far: 54912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 858: 1.0539982318878174\n",
      "Seen so far: 54976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 859: 1.2614409923553467\n",
      "Seen so far: 55040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 860: 0.8370265960693359\n",
      "Seen so far: 55104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 861: 0.7836768627166748\n",
      "Seen so far: 55168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 862: 0.7637872099876404\n",
      "Seen so far: 55232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 863: 1.737303614616394\n",
      "Seen so far: 55296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 864: 1.1068897247314453\n",
      "Seen so far: 55360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 865: 0.7682442665100098\n",
      "Seen so far: 55424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 866: 0.8841136693954468\n",
      "Seen so far: 55488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 867: 0.9458898901939392\n",
      "Seen so far: 55552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 868: 1.0343302488327026\n",
      "Seen so far: 55616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 869: 1.0481109619140625\n",
      "Seen so far: 55680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 870: 1.3845313787460327\n",
      "Seen so far: 55744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 871: 1.2121787071228027\n",
      "Seen so far: 55808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 872: 0.932615339756012\n",
      "Seen so far: 55872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 873: 1.0942637920379639\n",
      "Seen so far: 55936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 874: 1.2457410097122192\n",
      "Seen so far: 56000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 875: 1.172464370727539\n",
      "Seen so far: 56064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 876: 1.3562023639678955\n",
      "Seen so far: 56128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 877: 1.148576259613037\n",
      "Seen so far: 56192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 878: 1.2285211086273193\n",
      "Seen so far: 56256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 879: 0.9866968393325806\n",
      "Seen so far: 56320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 880: 1.2195003032684326\n",
      "Seen so far: 56384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 881: 1.7066845893859863\n",
      "Seen so far: 56448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 882: 1.0877859592437744\n",
      "Seen so far: 56512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 883: 0.9592640399932861\n",
      "Seen so far: 56576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 884: 0.6989733576774597\n",
      "Seen so far: 56640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 885: 0.7525235414505005\n",
      "Seen so far: 56704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 886: 1.2610483169555664\n",
      "Seen so far: 56768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 887: 0.9054664969444275\n",
      "Seen so far: 56832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 888: 1.2521337270736694\n",
      "Seen so far: 56896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 889: 1.7813148498535156\n",
      "Seen so far: 56960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 890: 1.1247360706329346\n",
      "Seen so far: 57024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 891: 1.2440849542617798\n",
      "Seen so far: 57088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 892: 0.9486867785453796\n",
      "Seen so far: 57152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 893: 1.1207499504089355\n",
      "Seen so far: 57216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 894: 1.2011117935180664\n",
      "Seen so far: 57280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 895: 1.1376745700836182\n",
      "Seen so far: 57344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 896: 1.8822118043899536\n",
      "Seen so far: 57408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 897: 1.3638200759887695\n",
      "Seen so far: 57472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 898: 1.1877696514129639\n",
      "Seen so far: 57536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 899: 0.9492799043655396\n",
      "Seen so far: 57600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 900: 1.0949307680130005\n",
      "Seen so far: 57664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 901: 1.581421136856079\n",
      "Seen so far: 57728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 902: 1.3942064046859741\n",
      "Seen so far: 57792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 903: 0.9737504720687866\n",
      "Seen so far: 57856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 904: 1.1347501277923584\n",
      "Seen so far: 57920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 905: 1.233302116394043\n",
      "Seen so far: 57984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 906: 1.435487985610962\n",
      "Seen so far: 58048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 907: 1.1248106956481934\n",
      "Seen so far: 58112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 908: 0.8715559840202332\n",
      "Seen so far: 58176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 909: 0.914812445640564\n",
      "Seen so far: 58240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 910: 0.8992415070533752\n",
      "Seen so far: 58304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 911: 1.2096537351608276\n",
      "Seen so far: 58368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 912: 1.0048022270202637\n",
      "Seen so far: 58432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 913: 1.3938546180725098\n",
      "Seen so far: 58496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 914: 0.8732678890228271\n",
      "Seen so far: 58560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 915: 0.8713085651397705\n",
      "Seen so far: 58624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 916: 1.2446213960647583\n",
      "Seen so far: 58688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 917: 0.9171336889266968\n",
      "Seen so far: 58752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 918: 1.2770001888275146\n",
      "Seen so far: 58816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 919: 1.1180709600448608\n",
      "Seen so far: 58880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 920: 1.1394020318984985\n",
      "Seen so far: 58944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 921: 0.9981693029403687\n",
      "Seen so far: 59008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 922: 1.2775177955627441\n",
      "Seen so far: 59072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 923: 1.2454251050949097\n",
      "Seen so far: 59136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 924: 1.1799851655960083\n",
      "Seen so far: 59200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 925: 0.9981982707977295\n",
      "Seen so far: 59264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 926: 1.3918066024780273\n",
      "Seen so far: 59328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 927: 1.0109970569610596\n",
      "Seen so far: 59392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 928: 1.4018250703811646\n",
      "Seen so far: 59456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 929: 1.1247165203094482\n",
      "Seen so far: 59520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 930: 0.94501793384552\n",
      "Seen so far: 59584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 931: 1.3445439338684082\n",
      "Seen so far: 59648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 932: 1.437322735786438\n",
      "Seen so far: 59712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 933: 1.0454356670379639\n",
      "Seen so far: 59776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 934: 1.2150664329528809\n",
      "Seen so far: 59840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 935: 0.9373353719711304\n",
      "Seen so far: 59904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 936: 1.0244206190109253\n",
      "Seen so far: 59968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 937: 1.0120530128479004\n",
      "Seen so far: 60032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 938: 1.2119247913360596\n",
      "Seen so far: 60096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 939: 0.8373245596885681\n",
      "Seen so far: 60160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 940: 0.796607494354248\n",
      "Seen so far: 60224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 941: 0.9864548444747925\n",
      "Seen so far: 60288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 942: 1.118551254272461\n",
      "Seen so far: 60352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 943: 1.0726584196090698\n",
      "Seen so far: 60416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 944: 0.9034830331802368\n",
      "Seen so far: 60480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 945: 1.20066499710083\n",
      "Seen so far: 60544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 946: 1.2003921270370483\n",
      "Seen so far: 60608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 947: 1.321549654006958\n",
      "Seen so far: 60672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 948: 0.8397213220596313\n",
      "Seen so far: 60736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 949: 1.1600013971328735\n",
      "Seen so far: 60800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 950: 1.0986196994781494\n",
      "Seen so far: 60864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 951: 0.9743082523345947\n",
      "Seen so far: 60928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 952: 1.1629230976104736\n",
      "Seen so far: 60992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 953: 1.2500065565109253\n",
      "Seen so far: 61056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 954: 1.3154773712158203\n",
      "Seen so far: 61120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 955: 1.1167831420898438\n",
      "Seen so far: 61184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 956: 1.5831420421600342\n",
      "Seen so far: 61248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 957: 1.3076648712158203\n",
      "Seen so far: 61312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 958: 1.2205018997192383\n",
      "Seen so far: 61376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 959: 0.8639461398124695\n",
      "Seen so far: 61440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 960: 1.1472649574279785\n",
      "Seen so far: 61504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 961: 1.2395864725112915\n",
      "Seen so far: 61568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 962: 0.8638439774513245\n",
      "Seen so far: 61632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 963: 1.1150364875793457\n",
      "Seen so far: 61696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 964: 1.2707546949386597\n",
      "Seen so far: 61760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 965: 1.02420175075531\n",
      "Seen so far: 61824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 966: 1.048108696937561\n",
      "Seen so far: 61888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 967: 0.9330441951751709\n",
      "Seen so far: 61952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 968: 0.9525569677352905\n",
      "Seen so far: 62016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 969: 1.180423617362976\n",
      "Seen so far: 62080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 970: 1.3081860542297363\n",
      "Seen so far: 62144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 971: 1.1657506227493286\n",
      "Seen so far: 62208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 972: 1.1733769178390503\n",
      "Seen so far: 62272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 973: 1.2224276065826416\n",
      "Seen so far: 62336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 974: 0.8148496150970459\n",
      "Seen so far: 62400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 975: 0.916635274887085\n",
      "Seen so far: 62464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 976: 1.0175909996032715\n",
      "Seen so far: 62528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 977: 0.8604491949081421\n",
      "Seen so far: 62592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 978: 1.2117245197296143\n",
      "Seen so far: 62656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 979: 0.9713531732559204\n",
      "Seen so far: 62720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 980: 1.230607509613037\n",
      "Seen so far: 62784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 981: 1.0503945350646973\n",
      "Seen so far: 62848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 982: 0.9742776155471802\n",
      "Seen so far: 62912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 983: 0.7783727645874023\n",
      "Seen so far: 62976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 984: 0.7926320433616638\n",
      "Seen so far: 63040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 985: 1.130010724067688\n",
      "Seen so far: 63104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 986: 1.0467958450317383\n",
      "Seen so far: 63168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 987: 1.2746835947036743\n",
      "Seen so far: 63232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 988: 1.0425257682800293\n",
      "Seen so far: 63296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 989: 0.9708398580551147\n",
      "Seen so far: 63360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 990: 1.161212682723999\n",
      "Seen so far: 63424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 991: 0.9924187660217285\n",
      "Seen so far: 63488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 992: 0.7823052406311035\n",
      "Seen so far: 63552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 993: 0.8504971861839294\n",
      "Seen so far: 63616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 994: 0.9621824026107788\n",
      "Seen so far: 63680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 995: 1.229276180267334\n",
      "Seen so far: 63744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 996: 1.3546907901763916\n",
      "Seen so far: 63808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 997: 0.7924913167953491\n",
      "Seen so far: 63872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 998: 1.1780848503112793\n",
      "Seen so far: 63936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 999: 0.8979744911193848\n",
      "Seen so far: 64000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1000: 1.0826178789138794\n",
      "Seen so far: 64064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1001: 0.9017112255096436\n",
      "Seen so far: 64128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1002: 0.8547465205192566\n",
      "Seen so far: 64192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1003: 1.0695611238479614\n",
      "Seen so far: 64256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1004: 0.8936454057693481\n",
      "Seen so far: 64320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1005: 0.882411003112793\n",
      "Seen so far: 64384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1006: 1.2703192234039307\n",
      "Seen so far: 64448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1007: 1.1287013292312622\n",
      "Seen so far: 64512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1008: 1.2979978322982788\n",
      "Seen so far: 64576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1009: 1.1229933500289917\n",
      "Seen so far: 64640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1010: 0.9391762018203735\n",
      "Seen so far: 64704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1011: 0.903801679611206\n",
      "Seen so far: 64768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1012: 1.1078031063079834\n",
      "Seen so far: 64832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1013: 1.0250074863433838\n",
      "Seen so far: 64896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1014: 1.273345947265625\n",
      "Seen so far: 64960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1015: 0.7479281425476074\n",
      "Seen so far: 65024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1016: 1.1977120637893677\n",
      "Seen so far: 65088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1017: 1.3634986877441406\n",
      "Seen so far: 65152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1018: 0.8517134189605713\n",
      "Seen so far: 65216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1019: 1.4231176376342773\n",
      "Seen so far: 65280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1020: 0.7598391175270081\n",
      "Seen so far: 65344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1021: 0.7367435097694397\n",
      "Seen so far: 65408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1022: 0.8649881482124329\n",
      "Seen so far: 65472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1023: 1.7535284757614136\n",
      "Seen so far: 65536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1024: 0.8316755890846252\n",
      "Seen so far: 65600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1025: 1.2083760499954224\n",
      "Seen so far: 65664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1026: 0.9198112487792969\n",
      "Seen so far: 65728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1027: 1.0699090957641602\n",
      "Seen so far: 65792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1028: 0.95399010181427\n",
      "Seen so far: 65856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1029: 1.217535376548767\n",
      "Seen so far: 65920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1030: 1.5409598350524902\n",
      "Seen so far: 65984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1031: 0.949714183807373\n",
      "Seen so far: 66048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1032: 0.9114402532577515\n",
      "Seen so far: 66112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1033: 1.54128098487854\n",
      "Seen so far: 66176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1034: 1.3546655178070068\n",
      "Seen so far: 66240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1035: 1.3026049137115479\n",
      "Seen so far: 66304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1036: 0.7944561839103699\n",
      "Seen so far: 66368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1037: 1.182163953781128\n",
      "Seen so far: 66432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1038: 1.1793206930160522\n",
      "Seen so far: 66496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1039: 0.9609538316726685\n",
      "Seen so far: 66560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1040: 1.3037033081054688\n",
      "Seen so far: 66624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1041: 1.4699876308441162\n",
      "Seen so far: 66688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1042: 0.7205365896224976\n",
      "Seen so far: 66752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1043: 1.191465139389038\n",
      "Seen so far: 66816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1044: 0.6473478078842163\n",
      "Seen so far: 66880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1045: 0.9700214862823486\n",
      "Seen so far: 66944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1046: 1.2978371381759644\n",
      "Seen so far: 67008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1047: 0.8210021257400513\n",
      "Seen so far: 67072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1048: 1.2388670444488525\n",
      "Seen so far: 67136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1049: 0.7406601905822754\n",
      "Seen so far: 67200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1050: 1.7426162958145142\n",
      "Seen so far: 67264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1051: 1.1537764072418213\n",
      "Seen so far: 67328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1052: 0.8769420385360718\n",
      "Seen so far: 67392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1053: 1.2927815914154053\n",
      "Seen so far: 67456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1054: 1.1497070789337158\n",
      "Seen so far: 67520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1055: 1.4021457433700562\n",
      "Seen so far: 67584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1056: 0.9706902503967285\n",
      "Seen so far: 67648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1057: 1.1278949975967407\n",
      "Seen so far: 67712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1058: 0.891757071018219\n",
      "Seen so far: 67776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1059: 0.7775183320045471\n",
      "Seen so far: 67840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1060: 1.0307369232177734\n",
      "Seen so far: 67904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1061: 1.294387698173523\n",
      "Seen so far: 67968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1062: 1.5121748447418213\n",
      "Seen so far: 68032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1063: 0.5356967449188232\n",
      "Seen so far: 68096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1064: 1.4304838180541992\n",
      "Seen so far: 68160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1065: 1.1409919261932373\n",
      "Seen so far: 68224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1066: 1.1765985488891602\n",
      "Seen so far: 68288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1067: 0.9031146764755249\n",
      "Seen so far: 68352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1068: 1.0523420572280884\n",
      "Seen so far: 68416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1069: 1.1587905883789062\n",
      "Seen so far: 68480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1070: 0.7104730010032654\n",
      "Seen so far: 68544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1071: 0.9278825521469116\n",
      "Seen so far: 68608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1072: 1.0774710178375244\n",
      "Seen so far: 68672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1073: 1.1375160217285156\n",
      "Seen so far: 68736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1074: 0.6911331415176392\n",
      "Seen so far: 68800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1075: 1.0878382921218872\n",
      "Seen so far: 68864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1076: 0.7729003429412842\n",
      "Seen so far: 68928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1077: 1.4245736598968506\n",
      "Seen so far: 68992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1078: 1.3201494216918945\n",
      "Seen so far: 69056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1079: 0.8674755096435547\n",
      "Seen so far: 69120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1080: 1.037436842918396\n",
      "Seen so far: 69184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1081: 1.1019526720046997\n",
      "Seen so far: 69248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1082: 1.2946631908416748\n",
      "Seen so far: 69312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1083: 1.3181431293487549\n",
      "Seen so far: 69376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1084: 1.393160343170166\n",
      "Seen so far: 69440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1085: 1.0167236328125\n",
      "Seen so far: 69504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1086: 1.0798299312591553\n",
      "Seen so far: 69568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1087: 1.520045280456543\n",
      "Seen so far: 69632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1088: 1.247443437576294\n",
      "Seen so far: 69696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1089: 0.9324536323547363\n",
      "Seen so far: 69760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1090: 1.1204222440719604\n",
      "Seen so far: 69824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1091: 1.2991951704025269\n",
      "Seen so far: 69888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1092: 1.0907001495361328\n",
      "Seen so far: 69952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1093: 0.7527773380279541\n",
      "Seen so far: 70016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1094: 1.0143970251083374\n",
      "Seen so far: 70080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1095: 1.2853989601135254\n",
      "Seen so far: 70144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1096: 0.8730835914611816\n",
      "Seen so far: 70208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1097: 0.9857301115989685\n",
      "Seen so far: 70272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1098: 1.4926655292510986\n",
      "Seen so far: 70336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1099: 1.1744205951690674\n",
      "Seen so far: 70400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1100: 1.7109965085983276\n",
      "Seen so far: 70464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1101: 1.381813406944275\n",
      "Seen so far: 70528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1102: 1.0440245866775513\n",
      "Seen so far: 70592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1103: 1.1789308786392212\n",
      "Seen so far: 70656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1104: 0.834250807762146\n",
      "Seen so far: 70720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1105: 0.9899814128875732\n",
      "Seen so far: 70784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1106: 1.2837680578231812\n",
      "Seen so far: 70848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1107: 0.9303445816040039\n",
      "Seen so far: 70912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1108: 1.0915629863739014\n",
      "Seen so far: 70976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1109: 0.970537543296814\n",
      "Seen so far: 71040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1110: 0.8809413909912109\n",
      "Seen so far: 71104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1111: 1.311056137084961\n",
      "Seen so far: 71168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1112: 1.2364743947982788\n",
      "Seen so far: 71232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1113: 1.2983276844024658\n",
      "Seen so far: 71296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1114: 0.9157008528709412\n",
      "Seen so far: 71360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1115: 1.3658676147460938\n",
      "Seen so far: 71424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1116: 1.0944639444351196\n",
      "Seen so far: 71488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1117: 0.9846360683441162\n",
      "Seen so far: 71552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1118: 0.8079842925071716\n",
      "Seen so far: 71616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1119: 1.2441685199737549\n",
      "Seen so far: 71680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1120: 0.9391930103302002\n",
      "Seen so far: 71744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1121: 1.135009765625\n",
      "Seen so far: 71808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1122: 0.8745783567428589\n",
      "Seen so far: 71872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1123: 0.7675002813339233\n",
      "Seen so far: 71936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1124: 1.0092562437057495\n",
      "Seen so far: 72000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1125: 1.5309524536132812\n",
      "Seen so far: 72064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1126: 1.0531208515167236\n",
      "Seen so far: 72128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1127: 1.0746963024139404\n",
      "Seen so far: 72192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1128: 1.542992115020752\n",
      "Seen so far: 72256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1129: 1.081632137298584\n",
      "Seen so far: 72320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1130: 0.8964042663574219\n",
      "Seen so far: 72384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1131: 1.2640572786331177\n",
      "Seen so far: 72448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1132: 1.012967586517334\n",
      "Seen so far: 72512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1133: 1.2125985622406006\n",
      "Seen so far: 72576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1134: 1.3728523254394531\n",
      "Seen so far: 72640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1135: 1.4342124462127686\n",
      "Seen so far: 72704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1136: 1.2149218320846558\n",
      "Seen so far: 72768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1137: 1.2624963521957397\n",
      "Seen so far: 72832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1138: 1.0775716304779053\n",
      "Seen so far: 72896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1139: 1.0581486225128174\n",
      "Seen so far: 72960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1140: 1.0412533283233643\n",
      "Seen so far: 73024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1141: 0.9120156168937683\n",
      "Seen so far: 73088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1142: 1.406726360321045\n",
      "Seen so far: 73152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1143: 1.012438416481018\n",
      "Seen so far: 73216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1144: 1.1087275743484497\n",
      "Seen so far: 73280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1145: 1.3553900718688965\n",
      "Seen so far: 73344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1146: 1.4584449529647827\n",
      "Seen so far: 73408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1147: 1.4389960765838623\n",
      "Seen so far: 73472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1148: 1.5331840515136719\n",
      "Seen so far: 73536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1149: 0.9697491526603699\n",
      "Seen so far: 73600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1150: 1.0239338874816895\n",
      "Seen so far: 73664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1151: 0.9551031589508057\n",
      "Seen so far: 73728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1152: 1.135894775390625\n",
      "Seen so far: 73792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1153: 1.043062448501587\n",
      "Seen so far: 73856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1154: 0.9588337540626526\n",
      "Seen so far: 73920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1155: 1.0164165496826172\n",
      "Seen so far: 73984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1156: 1.087437629699707\n",
      "Seen so far: 74048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1157: 1.0582520961761475\n",
      "Seen so far: 74112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1158: 0.986430287361145\n",
      "Seen so far: 74176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1159: 0.9726495742797852\n",
      "Seen so far: 74240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1160: 1.3656848669052124\n",
      "Seen so far: 74304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1161: 0.9876792430877686\n",
      "Seen so far: 74368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1162: 0.6923628449440002\n",
      "Seen so far: 74432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1163: 1.0461373329162598\n",
      "Seen so far: 74496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1164: 0.9967514276504517\n",
      "Seen so far: 74560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1165: 1.0262327194213867\n",
      "Seen so far: 74624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1166: 1.1664009094238281\n",
      "Seen so far: 74688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1167: 0.8427594304084778\n",
      "Seen so far: 74752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1168: 0.7866319417953491\n",
      "Seen so far: 74816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1169: 1.1510543823242188\n",
      "Seen so far: 74880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1170: 1.2076778411865234\n",
      "Seen so far: 74944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1171: 1.1326872110366821\n",
      "Seen so far: 75008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1172: 1.8872032165527344\n",
      "Seen so far: 75072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1173: 1.017641544342041\n",
      "Seen so far: 75136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1174: 1.1624854803085327\n",
      "Seen so far: 75200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1175: 1.3429903984069824\n",
      "Seen so far: 75264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1176: 1.1275181770324707\n",
      "Seen so far: 75328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1177: 1.0284934043884277\n",
      "Seen so far: 75392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1178: 1.4956883192062378\n",
      "Seen so far: 75456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1179: 0.6788493394851685\n",
      "Seen so far: 75520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1180: 1.2135894298553467\n",
      "Seen so far: 75584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1181: 1.0122385025024414\n",
      "Seen so far: 75648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1182: 1.5362972021102905\n",
      "Seen so far: 75712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1183: 1.2953557968139648\n",
      "Seen so far: 75776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1184: 1.2221684455871582\n",
      "Seen so far: 75840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1185: 1.0271539688110352\n",
      "Seen so far: 75904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1186: 0.9214359521865845\n",
      "Seen so far: 75968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1187: 1.1489050388336182\n",
      "Seen so far: 76032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1188: 1.1782084703445435\n",
      "Seen so far: 76096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1189: 0.8758199214935303\n",
      "Seen so far: 76160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1190: 0.89601731300354\n",
      "Seen so far: 76224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1191: 0.8210315704345703\n",
      "Seen so far: 76288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1192: 1.330382227897644\n",
      "Seen so far: 76352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1193: 0.9197999238967896\n",
      "Seen so far: 76416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1194: 1.7640700340270996\n",
      "Seen so far: 76480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1195: 0.9006717801094055\n",
      "Seen so far: 76544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1196: 0.832064151763916\n",
      "Seen so far: 76608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1197: 1.4507925510406494\n",
      "Seen so far: 76672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1198: 1.2889277935028076\n",
      "Seen so far: 76736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1199: 1.3637058734893799\n",
      "Seen so far: 76800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1200: 1.2366936206817627\n",
      "Seen so far: 76864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1201: 1.0755093097686768\n",
      "Seen so far: 76928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1202: 1.332146167755127\n",
      "Seen so far: 76992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1203: 0.9371452331542969\n",
      "Seen so far: 77056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1204: 1.4037020206451416\n",
      "Seen so far: 77120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1205: 0.8120166659355164\n",
      "Seen so far: 77184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1206: 0.9969096183776855\n",
      "Seen so far: 77248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1207: 1.2935163974761963\n",
      "Seen so far: 77312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1208: 1.3872138261795044\n",
      "Seen so far: 77376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1209: 1.2604525089263916\n",
      "Seen so far: 77440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1210: 1.0500121116638184\n",
      "Seen so far: 77504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1211: 0.8835728168487549\n",
      "Seen so far: 77568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1212: 0.7007331252098083\n",
      "Seen so far: 77632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1213: 0.9682315587997437\n",
      "Seen so far: 77696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1214: 1.8578377962112427\n",
      "Seen so far: 77760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1215: 0.7254135608673096\n",
      "Seen so far: 77824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1216: 0.972376823425293\n",
      "Seen so far: 77888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1217: 1.160712480545044\n",
      "Seen so far: 77952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1218: 1.2511634826660156\n",
      "Seen so far: 78016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1219: 1.2588121891021729\n",
      "Seen so far: 78080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1220: 0.9886415004730225\n",
      "Seen so far: 78144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1221: 1.1082894802093506\n",
      "Seen so far: 78208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1222: 1.0358790159225464\n",
      "Seen so far: 78272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1223: 0.8904850482940674\n",
      "Seen so far: 78336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1224: 0.8212785720825195\n",
      "Seen so far: 78400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1225: 1.0644755363464355\n",
      "Seen so far: 78464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1226: 1.059881329536438\n",
      "Seen so far: 78528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1227: 1.1010345220565796\n",
      "Seen so far: 78592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1228: 1.0562529563903809\n",
      "Seen so far: 78656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1229: 1.1126503944396973\n",
      "Seen so far: 78720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1230: 1.1070847511291504\n",
      "Seen so far: 78784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1231: 0.9445840120315552\n",
      "Seen so far: 78848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1232: 1.1250487565994263\n",
      "Seen so far: 78912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1233: 1.220428705215454\n",
      "Seen so far: 78976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1234: 1.2900075912475586\n",
      "Seen so far: 79040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1235: 1.0316120386123657\n",
      "Seen so far: 79104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1236: 0.9313905239105225\n",
      "Seen so far: 79168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1237: 1.1542832851409912\n",
      "Seen so far: 79232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1238: 1.2317023277282715\n",
      "Seen so far: 79296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1239: 1.0865671634674072\n",
      "Seen so far: 79360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1240: 1.2471492290496826\n",
      "Seen so far: 79424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1241: 1.087958812713623\n",
      "Seen so far: 79488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1242: 0.9596517086029053\n",
      "Seen so far: 79552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1243: 1.3303287029266357\n",
      "Seen so far: 79616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1244: 0.9796866178512573\n",
      "Seen so far: 79680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1245: 1.2672780752182007\n",
      "Seen so far: 79744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1246: 1.0394558906555176\n",
      "Seen so far: 79808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1247: 0.838705837726593\n",
      "Seen so far: 79872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1248: 0.8249307870864868\n",
      "Seen so far: 79936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1249: 1.2663559913635254\n",
      "Seen so far: 80000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1250: 1.0604431629180908\n",
      "Seen so far: 80064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1251: 0.5700682401657104\n",
      "Seen so far: 80128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1252: 1.4053266048431396\n",
      "Seen so far: 80192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1253: 0.9856473803520203\n",
      "Seen so far: 80256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1254: 0.9091742038726807\n",
      "Seen so far: 80320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1255: 0.8205920457839966\n",
      "Seen so far: 80384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1256: 1.439880132675171\n",
      "Seen so far: 80448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1257: 1.1146001815795898\n",
      "Seen so far: 80512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1258: 0.8893218040466309\n",
      "Seen so far: 80576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1259: 0.7226539850234985\n",
      "Seen so far: 80640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1260: 0.9973012208938599\n",
      "Seen so far: 80704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1261: 0.7165019512176514\n",
      "Seen so far: 80768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1262: 0.8533560037612915\n",
      "Seen so far: 80832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1263: 0.9440540671348572\n",
      "Seen so far: 80896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1264: 1.1085911989212036\n",
      "Seen so far: 80960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1265: 1.047544002532959\n",
      "Seen so far: 81024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1266: 0.9405888319015503\n",
      "Seen so far: 81088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1267: 1.1160014867782593\n",
      "Seen so far: 81152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1268: 0.8871908783912659\n",
      "Seen so far: 81216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1269: 1.2837392091751099\n",
      "Seen so far: 81280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1270: 1.2781964540481567\n",
      "Seen so far: 81344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1271: 0.7092528343200684\n",
      "Seen so far: 81408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1272: 1.1102502346038818\n",
      "Seen so far: 81472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1273: 0.978444516658783\n",
      "Seen so far: 81536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1274: 1.0059916973114014\n",
      "Seen so far: 81600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1275: 1.0994151830673218\n",
      "Seen so far: 81664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1276: 0.8599649667739868\n",
      "Seen so far: 81728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1277: 0.886655867099762\n",
      "Seen so far: 81792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1278: 1.2606306076049805\n",
      "Seen so far: 81856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1279: 1.0295085906982422\n",
      "Seen so far: 81920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1280: 1.22023606300354\n",
      "Seen so far: 81984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1281: 0.8923199772834778\n",
      "Seen so far: 82048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1282: 0.9280656576156616\n",
      "Seen so far: 82112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1283: 1.0454232692718506\n",
      "Seen so far: 82176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1284: 1.4869123697280884\n",
      "Seen so far: 82240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1285: 1.0547292232513428\n",
      "Seen so far: 82304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1286: 0.9465909004211426\n",
      "Seen so far: 82368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1287: 1.0115113258361816\n",
      "Seen so far: 82432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1288: 0.781480073928833\n",
      "Seen so far: 82496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1289: 1.381223440170288\n",
      "Seen so far: 82560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1290: 0.7714049816131592\n",
      "Seen so far: 82624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1291: 1.13346529006958\n",
      "Seen so far: 82688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1292: 0.5468084216117859\n",
      "Seen so far: 82752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1293: 1.038077712059021\n",
      "Seen so far: 82816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1294: 1.2409420013427734\n",
      "Seen so far: 82880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1295: 0.9369269609451294\n",
      "Seen so far: 82944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1296: 0.7965318560600281\n",
      "Seen so far: 83008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1297: 1.0834271907806396\n",
      "Seen so far: 83072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1298: 0.6431667804718018\n",
      "Seen so far: 83136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1299: 0.893851101398468\n",
      "Seen so far: 83200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1300: 1.1968514919281006\n",
      "Seen so far: 83264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1301: 1.0086596012115479\n",
      "Seen so far: 83328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1302: 1.2296314239501953\n",
      "Seen so far: 83392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1303: 1.2806788682937622\n",
      "Seen so far: 83456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1304: 0.7521160840988159\n",
      "Seen so far: 83520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1305: 0.7431857585906982\n",
      "Seen so far: 83584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1306: 1.1814827919006348\n",
      "Seen so far: 83648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1307: 0.9325153827667236\n",
      "Seen so far: 83712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1308: 1.1367861032485962\n",
      "Seen so far: 83776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1309: 0.9748159050941467\n",
      "Seen so far: 83840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1310: 0.958082914352417\n",
      "Seen so far: 83904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1311: 1.0712382793426514\n",
      "Seen so far: 83968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1312: 1.0875766277313232\n",
      "Seen so far: 84032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1313: 1.1561105251312256\n",
      "Seen so far: 84096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1314: 1.1735187768936157\n",
      "Seen so far: 84160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1315: 1.3342500925064087\n",
      "Seen so far: 84224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1316: 1.2021350860595703\n",
      "Seen so far: 84288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1317: 1.1618421077728271\n",
      "Seen so far: 84352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1318: 1.1185017824172974\n",
      "Seen so far: 84416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1319: 1.1162950992584229\n",
      "Seen so far: 84480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1320: 1.1030501127243042\n",
      "Seen so far: 84544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1321: 1.6665489673614502\n",
      "Seen so far: 84608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1322: 1.2410142421722412\n",
      "Seen so far: 84672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1323: 0.847861111164093\n",
      "Seen so far: 84736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1324: 0.9219516515731812\n",
      "Seen so far: 84800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1325: 1.168367624282837\n",
      "Seen so far: 84864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1326: 0.9636639356613159\n",
      "Seen so far: 84928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1327: 0.8865916728973389\n",
      "Seen so far: 84992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1328: 1.2407337427139282\n",
      "Seen so far: 85056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1329: 0.9207478761672974\n",
      "Seen so far: 85120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1330: 0.9922292232513428\n",
      "Seen so far: 85184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1331: 1.3266077041625977\n",
      "Seen so far: 85248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1332: 1.0954391956329346\n",
      "Seen so far: 85312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1333: 1.2924957275390625\n",
      "Seen so far: 85376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1334: 1.2737228870391846\n",
      "Seen so far: 85440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1335: 0.9357568025588989\n",
      "Seen so far: 85504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1336: 0.872769832611084\n",
      "Seen so far: 85568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1337: 1.1403319835662842\n",
      "Seen so far: 85632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1338: 1.0294296741485596\n",
      "Seen so far: 85696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1339: 1.082420825958252\n",
      "Seen so far: 85760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1340: 1.391838788986206\n",
      "Seen so far: 85824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1341: 1.4144631624221802\n",
      "Seen so far: 85888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1342: 0.8716028928756714\n",
      "Seen so far: 85952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1343: 1.2877025604248047\n",
      "Seen so far: 86016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1344: 1.4493756294250488\n",
      "Seen so far: 86080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1345: 0.9451794624328613\n",
      "Seen so far: 86144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1346: 1.049077033996582\n",
      "Seen so far: 86208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1347: 0.8635749220848083\n",
      "Seen so far: 86272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1348: 1.4071744680404663\n",
      "Seen so far: 86336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1349: 1.2414774894714355\n",
      "Seen so far: 86400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1350: 1.099165439605713\n",
      "Seen so far: 86464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1351: 0.6858597993850708\n",
      "Seen so far: 86528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1352: 1.3796366453170776\n",
      "Seen so far: 86592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1353: 0.7207450866699219\n",
      "Seen so far: 86656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1354: 1.7857871055603027\n",
      "Seen so far: 86720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1355: 1.0697553157806396\n",
      "Seen so far: 86784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1356: 0.9307596683502197\n",
      "Seen so far: 86848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1357: 1.1194202899932861\n",
      "Seen so far: 86912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1358: 0.8940405249595642\n",
      "Seen so far: 86976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1359: 1.0583890676498413\n",
      "Seen so far: 87040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1360: 1.1377904415130615\n",
      "Seen so far: 87104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1361: 0.7564406394958496\n",
      "Seen so far: 87168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1362: 1.0347447395324707\n",
      "Seen so far: 87232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1363: 1.011493444442749\n",
      "Seen so far: 87296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1364: 1.1075794696807861\n",
      "Seen so far: 87360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1365: 0.9941359758377075\n",
      "Seen so far: 87424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1366: 1.0440928936004639\n",
      "Seen so far: 87488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1367: 1.5815491676330566\n",
      "Seen so far: 87552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1368: 1.3179473876953125\n",
      "Seen so far: 87616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1369: 0.6439404487609863\n",
      "Seen so far: 87680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1370: 0.877203106880188\n",
      "Seen so far: 87744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1371: 0.9531139135360718\n",
      "Seen so far: 87808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1372: 1.404914379119873\n",
      "Seen so far: 87872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1373: 0.9074918031692505\n",
      "Seen so far: 87936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1374: 1.028883934020996\n",
      "Seen so far: 88000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1375: 1.0231081247329712\n",
      "Seen so far: 88064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1376: 1.1624737977981567\n",
      "Seen so far: 88128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1377: 1.0629339218139648\n",
      "Seen so far: 88192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1378: 1.248907446861267\n",
      "Seen so far: 88256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1379: 1.4289830923080444\n",
      "Seen so far: 88320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1380: 1.1295592784881592\n",
      "Seen so far: 88384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1381: 0.9218738079071045\n",
      "Seen so far: 88448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1382: 0.8937159776687622\n",
      "Seen so far: 88512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1383: 1.371882677078247\n",
      "Seen so far: 88576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1384: 0.6703518629074097\n",
      "Seen so far: 88640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1385: 0.8477705121040344\n",
      "Seen so far: 88704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1386: 1.1275017261505127\n",
      "Seen so far: 88768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1387: 1.0410103797912598\n",
      "Seen so far: 88832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1388: 1.1795274019241333\n",
      "Seen so far: 88896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1389: 0.7932292222976685\n",
      "Seen so far: 88960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1390: 0.7950951457023621\n",
      "Seen so far: 89024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1391: 1.1687042713165283\n",
      "Seen so far: 89088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1392: 1.4859436750411987\n",
      "Seen so far: 89152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1393: 1.603726863861084\n",
      "Seen so far: 89216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1394: 1.0090769529342651\n",
      "Seen so far: 89280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1395: 1.243028998374939\n",
      "Seen so far: 89344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1396: 1.1644675731658936\n",
      "Seen so far: 89408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1397: 1.2011563777923584\n",
      "Seen so far: 89472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1398: 0.8250003457069397\n",
      "Seen so far: 89536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1399: 1.3492640256881714\n",
      "Seen so far: 89600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1400: 1.3912802934646606\n",
      "Seen so far: 89664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1401: 1.003507375717163\n",
      "Seen so far: 89728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1402: 1.1758320331573486\n",
      "Seen so far: 89792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1403: 1.185814619064331\n",
      "Seen so far: 89856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1404: 0.9386643171310425\n",
      "Seen so far: 89920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1405: 0.9366120100021362\n",
      "Seen so far: 89984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1406: 1.5256385803222656\n",
      "Seen so far: 90048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1407: 0.8659781217575073\n",
      "Seen so far: 90112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1408: 0.9035868644714355\n",
      "Seen so far: 90176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1409: 0.8690947890281677\n",
      "Seen so far: 90240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1410: 0.8946187496185303\n",
      "Seen so far: 90304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1411: 0.7141714096069336\n",
      "Seen so far: 90368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1412: 1.1022169589996338\n",
      "Seen so far: 90432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1413: 1.165274977684021\n",
      "Seen so far: 90496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1414: 0.8757152557373047\n",
      "Seen so far: 90560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1415: 0.9930046796798706\n",
      "Seen so far: 90624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1416: 0.8121959567070007\n",
      "Seen so far: 90688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1417: 1.2783918380737305\n",
      "Seen so far: 90752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1418: 0.9750016927719116\n",
      "Seen so far: 90816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1419: 1.0901106595993042\n",
      "Seen so far: 90880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1420: 0.8962964415550232\n",
      "Seen so far: 90944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1421: 0.8081837892532349\n",
      "Seen so far: 91008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1422: 0.9953413009643555\n",
      "Seen so far: 91072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1423: 0.8440542221069336\n",
      "Seen so far: 91136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1424: 1.016859531402588\n",
      "Seen so far: 91200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1425: 0.8994470238685608\n",
      "Seen so far: 91264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1426: 0.9501508474349976\n",
      "Seen so far: 91328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1427: 1.1029729843139648\n",
      "Seen so far: 91392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1428: 1.3847119808197021\n",
      "Seen so far: 91456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1429: 1.0407991409301758\n",
      "Seen so far: 91520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1430: 1.0252230167388916\n",
      "Seen so far: 91584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1431: 1.1059644222259521\n",
      "Seen so far: 91648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1432: 0.7814773321151733\n",
      "Seen so far: 91712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1433: 1.2326351404190063\n",
      "Seen so far: 91776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1434: 0.7173353433609009\n",
      "Seen so far: 91840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1435: 1.087093472480774\n",
      "Seen so far: 91904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1436: 0.8498766422271729\n",
      "Seen so far: 91968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1437: 0.8803861737251282\n",
      "Seen so far: 92032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1438: 1.4758497476577759\n",
      "Seen so far: 92096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1439: 1.1810544729232788\n",
      "Seen so far: 92160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1440: 1.206357479095459\n",
      "Seen so far: 92224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1441: 0.9742368459701538\n",
      "Seen so far: 92288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1442: 1.3573256731033325\n",
      "Seen so far: 92352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1443: 1.2484424114227295\n",
      "Seen so far: 92416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1444: 1.2629640102386475\n",
      "Seen so far: 92480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1445: 1.148249626159668\n",
      "Seen so far: 92544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1446: 1.1588325500488281\n",
      "Seen so far: 92608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1447: 0.8530571460723877\n",
      "Seen so far: 92672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1448: 0.9328170418739319\n",
      "Seen so far: 92736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1449: 1.4305129051208496\n",
      "Seen so far: 92800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1450: 0.9238601326942444\n",
      "Seen so far: 92864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1451: 1.3567975759506226\n",
      "Seen so far: 92928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1452: 0.704673707485199\n",
      "Seen so far: 92992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1453: 1.2525746822357178\n",
      "Seen so far: 93056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1454: 0.8364414572715759\n",
      "Seen so far: 93120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1455: 1.252058744430542\n",
      "Seen so far: 93184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1456: 0.7828925848007202\n",
      "Seen so far: 93248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1457: 1.276839017868042\n",
      "Seen so far: 93312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1458: 1.0545098781585693\n",
      "Seen so far: 93376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1459: 1.1597999334335327\n",
      "Seen so far: 93440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1460: 0.9322664737701416\n",
      "Seen so far: 93504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1461: 1.0624548196792603\n",
      "Seen so far: 93568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1462: 1.0239684581756592\n",
      "Seen so far: 93632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1463: 1.2286137342453003\n",
      "Seen so far: 93696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1464: 0.7025780081748962\n",
      "Seen so far: 93760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1465: 1.2415764331817627\n",
      "Seen so far: 93824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1466: 0.9111775755882263\n",
      "Seen so far: 93888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1467: 1.02206552028656\n",
      "Seen so far: 93952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1468: 1.079193115234375\n",
      "Seen so far: 94016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1469: 0.840857982635498\n",
      "Seen so far: 94080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1470: 1.2505892515182495\n",
      "Seen so far: 94144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1471: 0.7150967121124268\n",
      "Seen so far: 94208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1472: 1.1417174339294434\n",
      "Seen so far: 94272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1473: 1.0408556461334229\n",
      "Seen so far: 94336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1474: 0.7771280407905579\n",
      "Seen so far: 94400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1475: 1.745784044265747\n",
      "Seen so far: 94464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1476: 0.6598065495491028\n",
      "Seen so far: 94528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1477: 1.0814034938812256\n",
      "Seen so far: 94592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1478: 1.3963285684585571\n",
      "Seen so far: 94656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1479: 1.1197612285614014\n",
      "Seen so far: 94720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1480: 0.6023585796356201\n",
      "Seen so far: 94784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1481: 1.1887164115905762\n",
      "Seen so far: 94848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1482: 0.7316790819168091\n",
      "Seen so far: 94912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1483: 1.018971562385559\n",
      "Seen so far: 94976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1484: 0.7386395931243896\n",
      "Seen so far: 95040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1485: 0.974166989326477\n",
      "Seen so far: 95104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1486: 0.9417682886123657\n",
      "Seen so far: 95168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1487: 0.8499757051467896\n",
      "Seen so far: 95232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1488: 1.2985281944274902\n",
      "Seen so far: 95296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1489: 0.9690461158752441\n",
      "Seen so far: 95360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1490: 1.090757131576538\n",
      "Seen so far: 95424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1491: 0.6955256462097168\n",
      "Seen so far: 95488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1492: 0.9243936538696289\n",
      "Seen so far: 95552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1493: 0.8651207685470581\n",
      "Seen so far: 95616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1494: 1.1212044954299927\n",
      "Seen so far: 95680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1495: 1.4274253845214844\n",
      "Seen so far: 95744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1496: 0.8101454973220825\n",
      "Seen so far: 95808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1497: 1.0346119403839111\n",
      "Seen so far: 95872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1498: 0.8993358612060547\n",
      "Seen so far: 95936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1499: 1.4240385293960571\n",
      "Seen so far: 96000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1500: 1.0528852939605713\n",
      "Seen so far: 96064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1501: 1.5889971256256104\n",
      "Seen so far: 96128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1502: 0.9034679532051086\n",
      "Seen so far: 96192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1503: 0.6073316931724548\n",
      "Seen so far: 96256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1504: 1.1767934560775757\n",
      "Seen so far: 96320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1505: 1.094624400138855\n",
      "Seen so far: 96384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1506: 0.8696537613868713\n",
      "Seen so far: 96448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1507: 1.9185975790023804\n",
      "Seen so far: 96512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1508: 0.771017849445343\n",
      "Seen so far: 96576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1509: 1.0326001644134521\n",
      "Seen so far: 96640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1510: 1.708580493927002\n",
      "Seen so far: 96704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1511: 1.098142147064209\n",
      "Seen so far: 96768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1512: 1.008244276046753\n",
      "Seen so far: 96832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1513: 1.2148118019104004\n",
      "Seen so far: 96896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1514: 1.0815725326538086\n",
      "Seen so far: 96960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1515: 1.4998857975006104\n",
      "Seen so far: 97024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1516: 1.1719759702682495\n",
      "Seen so far: 97088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1517: 1.6113494634628296\n",
      "Seen so far: 97152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1518: 1.2529844045639038\n",
      "Seen so far: 97216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1519: 0.6699974536895752\n",
      "Seen so far: 97280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1520: 0.9920988082885742\n",
      "Seen so far: 97344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1521: 1.003286600112915\n",
      "Seen so far: 97408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1522: 1.4110963344573975\n",
      "Seen so far: 97472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1523: 1.4381564855575562\n",
      "Seen so far: 97536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1524: 1.2665349245071411\n",
      "Seen so far: 97600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1525: 1.1928138732910156\n",
      "Seen so far: 97664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1526: 1.3601281642913818\n",
      "Seen so far: 97728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1527: 0.9153808355331421\n",
      "Seen so far: 97792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1528: 0.7743744850158691\n",
      "Seen so far: 97856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1529: 1.077858328819275\n",
      "Seen so far: 97920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1530: 1.0033456087112427\n",
      "Seen so far: 97984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1531: 0.6510248184204102\n",
      "Seen so far: 98048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1532: 1.0469751358032227\n",
      "Seen so far: 98112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1533: 0.8290982842445374\n",
      "Seen so far: 98176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1534: 1.1728661060333252\n",
      "Seen so far: 98240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1535: 1.016695261001587\n",
      "Seen so far: 98304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1536: 0.9575306177139282\n",
      "Seen so far: 98368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1537: 1.0513522624969482\n",
      "Seen so far: 98432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1538: 1.1399970054626465\n",
      "Seen so far: 98496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1539: 0.7889120578765869\n",
      "Seen so far: 98560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1540: 1.0411560535430908\n",
      "Seen so far: 98624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1541: 0.865605890750885\n",
      "Seen so far: 98688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1542: 1.1120675802230835\n",
      "Seen so far: 98752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1543: 1.1594746112823486\n",
      "Seen so far: 98816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1544: 0.9196706414222717\n",
      "Seen so far: 98880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1545: 0.8005529642105103\n",
      "Seen so far: 98944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1546: 1.0720500946044922\n",
      "Seen so far: 99008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1547: 1.045437216758728\n",
      "Seen so far: 99072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1548: 0.7493977546691895\n",
      "Seen so far: 99136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1549: 0.9111182689666748\n",
      "Seen so far: 99200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1550: 1.3140335083007812\n",
      "Seen so far: 99264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1551: 1.2594507932662964\n",
      "Seen so far: 99328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1552: 0.7246996164321899\n",
      "Seen so far: 99392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1553: 0.8091303110122681\n",
      "Seen so far: 99456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1554: 1.5124512910842896\n",
      "Seen so far: 99520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1555: 1.1530647277832031\n",
      "Seen so far: 99584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1556: 1.052628755569458\n",
      "Seen so far: 99648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1557: 1.170975685119629\n",
      "Seen so far: 99712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1558: 0.9020459055900574\n",
      "Seen so far: 99776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1559: 0.6909382343292236\n",
      "Seen so far: 99840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1560: 1.4205045700073242\n",
      "Seen so far: 99904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1561: 0.9828182458877563\n",
      "Seen so far: 99968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1562: 1.1305820941925049\n",
      "Seen so far: 100032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1563: 0.9076921343803406\n",
      "Seen so far: 100096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1564: 1.2387734651565552\n",
      "Seen so far: 100160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1565: 1.3546037673950195\n",
      "Seen so far: 100224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1566: 1.0485000610351562\n",
      "Seen so far: 100288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1567: 0.7623694539070129\n",
      "Seen so far: 100352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1568: 1.0414553880691528\n",
      "Seen so far: 100416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1569: 1.1481491327285767\n",
      "Seen so far: 100480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1570: 1.4526926279067993\n",
      "Seen so far: 100544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1571: 1.3851468563079834\n",
      "Seen so far: 100608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1572: 0.892051100730896\n",
      "Seen so far: 100672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1573: 1.3794653415679932\n",
      "Seen so far: 100736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1574: 0.9382118582725525\n",
      "Seen so far: 100800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1575: 1.469396710395813\n",
      "Seen so far: 100864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1576: 1.2144041061401367\n",
      "Seen so far: 100928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1577: 0.876998782157898\n",
      "Seen so far: 100992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1578: 1.3574175834655762\n",
      "Seen so far: 101056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1579: 0.8878378868103027\n",
      "Seen so far: 101120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1580: 1.1235299110412598\n",
      "Seen so far: 101184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1581: 1.0426665544509888\n",
      "Seen so far: 101248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1582: 1.1801936626434326\n",
      "Seen so far: 101312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1583: 0.9542862176895142\n",
      "Seen so far: 101376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1584: 1.2410359382629395\n",
      "Seen so far: 101440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1585: 1.5664440393447876\n",
      "Seen so far: 101504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1586: 1.1621490716934204\n",
      "Seen so far: 101568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1587: 0.6407049894332886\n",
      "Seen so far: 101632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1588: 0.7934979796409607\n",
      "Seen so far: 101696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1589: 1.2658095359802246\n",
      "Seen so far: 101760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1590: 1.1417304277420044\n",
      "Seen so far: 101824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1591: 1.1164867877960205\n",
      "Seen so far: 101888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1592: 0.9655671715736389\n",
      "Seen so far: 101952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1593: 0.898990273475647\n",
      "Seen so far: 102016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1594: 0.7456021904945374\n",
      "Seen so far: 102080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1595: 1.2208259105682373\n",
      "Seen so far: 102144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1596: 0.9676997661590576\n",
      "Seen so far: 102208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1597: 1.2580729722976685\n",
      "Seen so far: 102272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1598: 1.101087212562561\n",
      "Seen so far: 102336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1599: 0.9867414236068726\n",
      "Seen so far: 102400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1600: 0.6835457682609558\n",
      "Seen so far: 102464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1601: 1.0158259868621826\n",
      "Seen so far: 102528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1602: 0.6733602285385132\n",
      "Seen so far: 102592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1603: 1.4747343063354492\n",
      "Seen so far: 102656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1604: 0.8746976256370544\n",
      "Seen so far: 102720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1605: 1.6566689014434814\n",
      "Seen so far: 102784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1606: 1.0578343868255615\n",
      "Seen so far: 102848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1607: 1.1749358177185059\n",
      "Seen so far: 102912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1608: 1.1181702613830566\n",
      "Seen so far: 102976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1609: 1.1407653093338013\n",
      "Seen so far: 103040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1610: 1.2627530097961426\n",
      "Seen so far: 103104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1611: 0.8455348014831543\n",
      "Seen so far: 103168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1612: 1.2959507703781128\n",
      "Seen so far: 103232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1613: 1.2733088731765747\n",
      "Seen so far: 103296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1614: 0.7879523038864136\n",
      "Seen so far: 103360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1615: 0.9329358339309692\n",
      "Seen so far: 103424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1616: 1.054897665977478\n",
      "Seen so far: 103488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1617: 1.2746880054473877\n",
      "Seen so far: 103552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1618: 0.8583322167396545\n",
      "Seen so far: 103616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1619: 1.028602957725525\n",
      "Seen so far: 103680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1620: 0.9431197047233582\n",
      "Seen so far: 103744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1621: 0.8230689764022827\n",
      "Seen so far: 103808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1622: 1.1648688316345215\n",
      "Seen so far: 103872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1623: 1.136151909828186\n",
      "Seen so far: 103936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1624: 1.1688348054885864\n",
      "Seen so far: 104000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1625: 1.424009919166565\n",
      "Seen so far: 104064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1626: 1.2627804279327393\n",
      "Seen so far: 104128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1627: 1.142282247543335\n",
      "Seen so far: 104192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1628: 0.9196349382400513\n",
      "Seen so far: 104256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1629: 0.9255646467208862\n",
      "Seen so far: 104320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1630: 1.2052998542785645\n",
      "Seen so far: 104384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1631: 0.8241716027259827\n",
      "Seen so far: 104448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1632: 1.3477007150650024\n",
      "Seen so far: 104512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1633: 0.9647104740142822\n",
      "Seen so far: 104576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1634: 1.109359860420227\n",
      "Seen so far: 104640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1635: 0.8634935617446899\n",
      "Seen so far: 104704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1636: 0.9994461536407471\n",
      "Seen so far: 104768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1637: 0.7743789553642273\n",
      "Seen so far: 104832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1638: 1.2096911668777466\n",
      "Seen so far: 104896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1639: 0.6300008893013\n",
      "Seen so far: 104960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1640: 1.2484569549560547\n",
      "Seen so far: 105024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1641: 0.7966715693473816\n",
      "Seen so far: 105088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1642: 1.025995135307312\n",
      "Seen so far: 105152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1643: 1.4331449270248413\n",
      "Seen so far: 105216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1644: 1.212519645690918\n",
      "Seen so far: 105280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1645: 1.057356357574463\n",
      "Seen so far: 105344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1646: 1.0094735622406006\n",
      "Seen so far: 105408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1647: 0.7637922167778015\n",
      "Seen so far: 105472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1648: 0.9201797246932983\n",
      "Seen so far: 105536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1649: 1.5321637392044067\n",
      "Seen so far: 105600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1650: 0.9134060740470886\n",
      "Seen so far: 105664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1651: 1.3679202795028687\n",
      "Seen so far: 105728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1652: 1.0320135354995728\n",
      "Seen so far: 105792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1653: 0.9657684564590454\n",
      "Seen so far: 105856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1654: 1.1012372970581055\n",
      "Seen so far: 105920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1655: 0.8849077820777893\n",
      "Seen so far: 105984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1656: 0.9387402534484863\n",
      "Seen so far: 106048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1657: 1.0273313522338867\n",
      "Seen so far: 106112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1658: 0.7514786720275879\n",
      "Seen so far: 106176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1659: 1.175485610961914\n",
      "Seen so far: 106240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1660: 1.2179679870605469\n",
      "Seen so far: 106304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1661: 1.224731206893921\n",
      "Seen so far: 106368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1662: 0.7989696264266968\n",
      "Seen so far: 106432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1663: 1.1007598638534546\n",
      "Seen so far: 106496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1664: 1.3290035724639893\n",
      "Seen so far: 106560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1665: 1.5233440399169922\n",
      "Seen so far: 106624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1666: 0.9659954309463501\n",
      "Seen so far: 106688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1667: 0.7982505559921265\n",
      "Seen so far: 106752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1668: 1.3637492656707764\n",
      "Seen so far: 106816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1669: 1.022714376449585\n",
      "Seen so far: 106880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1670: 1.0904350280761719\n",
      "Seen so far: 106944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1671: 1.1096069812774658\n",
      "Seen so far: 107008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1672: 1.296103596687317\n",
      "Seen so far: 107072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1673: 0.8678093552589417\n",
      "Seen so far: 107136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1674: 0.8012138605117798\n",
      "Seen so far: 107200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1675: 1.2344611883163452\n",
      "Seen so far: 107264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1676: 1.078450322151184\n",
      "Seen so far: 107328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1677: 1.0004677772521973\n",
      "Seen so far: 107392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1678: 0.7502150535583496\n",
      "Seen so far: 107456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1679: 0.9185115098953247\n",
      "Seen so far: 107520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1680: 1.0488903522491455\n",
      "Seen so far: 107584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1681: 1.295428991317749\n",
      "Seen so far: 107648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1682: 0.8616602420806885\n",
      "Seen so far: 107712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1683: 1.109409213066101\n",
      "Seen so far: 107776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1684: 1.1906771659851074\n",
      "Seen so far: 107840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1685: 0.9117512702941895\n",
      "Seen so far: 107904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1686: 1.1173173189163208\n",
      "Seen so far: 107968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1687: 1.1576582193374634\n",
      "Seen so far: 108032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1688: 1.4166011810302734\n",
      "Seen so far: 108096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1689: 0.8271059989929199\n",
      "Seen so far: 108160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1690: 1.1459532976150513\n",
      "Seen so far: 108224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1691: 0.6091029644012451\n",
      "Seen so far: 108288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1692: 0.9410172700881958\n",
      "Seen so far: 108352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1693: 1.1706712245941162\n",
      "Seen so far: 108416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1694: 1.1487526893615723\n",
      "Seen so far: 108480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1695: 1.053409218788147\n",
      "Seen so far: 108544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1696: 1.3218234777450562\n",
      "Seen so far: 108608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1697: 1.4333293437957764\n",
      "Seen so far: 108672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1698: 0.845186173915863\n",
      "Seen so far: 108736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1699: 0.6580624580383301\n",
      "Seen so far: 108800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1700: 0.9193911552429199\n",
      "Seen so far: 108864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1701: 1.183427333831787\n",
      "Seen so far: 108928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1702: 1.443770170211792\n",
      "Seen so far: 108992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1703: 0.6678268909454346\n",
      "Seen so far: 109056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1704: 1.3802385330200195\n",
      "Seen so far: 109120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1705: 1.499727487564087\n",
      "Seen so far: 109184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1706: 1.3527534008026123\n",
      "Seen so far: 109248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1707: 1.2156579494476318\n",
      "Seen so far: 109312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1708: 1.2574892044067383\n",
      "Seen so far: 109376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1709: 1.4367815256118774\n",
      "Seen so far: 109440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1710: 1.087270975112915\n",
      "Seen so far: 109504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1711: 1.0816974639892578\n",
      "Seen so far: 109568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1712: 0.9061050415039062\n",
      "Seen so far: 109632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1713: 0.7844973206520081\n",
      "Seen so far: 109696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1714: 0.948593258857727\n",
      "Seen so far: 109760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1715: 0.8058327436447144\n",
      "Seen so far: 109824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1716: 1.5523515939712524\n",
      "Seen so far: 109888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1717: 0.8101727962493896\n",
      "Seen so far: 109952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1718: 0.8548807501792908\n",
      "Seen so far: 110016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1719: 0.7630655765533447\n",
      "Seen so far: 110080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1720: 1.3141393661499023\n",
      "Seen so far: 110144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1721: 1.105592966079712\n",
      "Seen so far: 110208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1722: 0.8722492456436157\n",
      "Seen so far: 110272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1723: 0.8421962261199951\n",
      "Seen so far: 110336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1724: 1.2269519567489624\n",
      "Seen so far: 110400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1725: 1.04791259765625\n",
      "Seen so far: 110464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1726: 1.6193325519561768\n",
      "Seen so far: 110528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1727: 0.9096563458442688\n",
      "Seen so far: 110592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1728: 0.9244564771652222\n",
      "Seen so far: 110656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1729: 1.0046405792236328\n",
      "Seen so far: 110720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1730: 0.817690372467041\n",
      "Seen so far: 110784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1731: 0.6143383979797363\n",
      "Seen so far: 110848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1732: 1.1897549629211426\n",
      "Seen so far: 110912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1733: 1.3576624393463135\n",
      "Seen so far: 110976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1734: 0.8650276064872742\n",
      "Seen so far: 111040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1735: 0.8332633376121521\n",
      "Seen so far: 111104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1736: 1.1878206729888916\n",
      "Seen so far: 111168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1737: 1.2021799087524414\n",
      "Seen so far: 111232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1738: 0.8746559619903564\n",
      "Seen so far: 111296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1739: 1.260894775390625\n",
      "Seen so far: 111360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1740: 1.1579697132110596\n",
      "Seen so far: 111424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1741: 0.9739991426467896\n",
      "Seen so far: 111488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1742: 1.1151704788208008\n",
      "Seen so far: 111552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1743: 0.5731930732727051\n",
      "Seen so far: 111616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1744: 0.9437381625175476\n",
      "Seen so far: 111680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1745: 1.1342244148254395\n",
      "Seen so far: 111744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1746: 1.3143280744552612\n",
      "Seen so far: 111808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1747: 1.8485974073410034\n",
      "Seen so far: 111872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1748: 0.9068992733955383\n",
      "Seen so far: 111936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1749: 0.7757595777511597\n",
      "Seen so far: 112000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1750: 1.127753496170044\n",
      "Seen so far: 112064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1751: 1.0079423189163208\n",
      "Seen so far: 112128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1752: 1.3439159393310547\n",
      "Seen so far: 112192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1753: 0.9613100290298462\n",
      "Seen so far: 112256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1754: 1.3180451393127441\n",
      "Seen so far: 112320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1755: 0.9444711804389954\n",
      "Seen so far: 112384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1756: 1.3920495510101318\n",
      "Seen so far: 112448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1757: 0.9929636120796204\n",
      "Seen so far: 112512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1758: 1.2244806289672852\n",
      "Seen so far: 112576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1759: 0.9265048503875732\n",
      "Seen so far: 112640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1760: 1.2236287593841553\n",
      "Seen so far: 112704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1761: 0.9415119886398315\n",
      "Seen so far: 112768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1762: 0.8855518102645874\n",
      "Seen so far: 112832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1763: 1.38472580909729\n",
      "Seen so far: 112896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1764: 1.1317561864852905\n",
      "Seen so far: 112960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1765: 0.7923163771629333\n",
      "Seen so far: 113024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1766: 1.0099903345108032\n",
      "Seen so far: 113088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1767: 1.2197880744934082\n",
      "Seen so far: 113152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1768: 1.1613316535949707\n",
      "Seen so far: 113216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1769: 0.8817126750946045\n",
      "Seen so far: 113280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1770: 1.0317937135696411\n",
      "Seen so far: 113344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1771: 1.0857949256896973\n",
      "Seen so far: 113408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1772: 1.1812959909439087\n",
      "Seen so far: 113472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1773: 1.0048038959503174\n",
      "Seen so far: 113536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1774: 0.8026626110076904\n",
      "Seen so far: 113600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1775: 1.1003520488739014\n",
      "Seen so far: 113664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1776: 1.4162282943725586\n",
      "Seen so far: 113728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1777: 1.1870458126068115\n",
      "Seen so far: 113792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1778: 0.9620406031608582\n",
      "Seen so far: 113856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1779: 1.5588223934173584\n",
      "Seen so far: 113920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1780: 1.3384230136871338\n",
      "Seen so far: 113984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1781: 1.4594268798828125\n",
      "Seen so far: 114048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1782: 0.9034407138824463\n",
      "Seen so far: 114112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1783: 1.2993509769439697\n",
      "Seen so far: 114176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1784: 1.0336596965789795\n",
      "Seen so far: 114240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1785: 0.992387056350708\n",
      "Seen so far: 114304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1786: 0.9291778206825256\n",
      "Seen so far: 114368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1787: 0.9971818923950195\n",
      "Seen so far: 114432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1788: 1.0946087837219238\n",
      "Seen so far: 114496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1789: 1.0608820915222168\n",
      "Seen so far: 114560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1790: 1.0955822467803955\n",
      "Seen so far: 114624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1791: 0.9361032843589783\n",
      "Seen so far: 114688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1792: 0.7561893463134766\n",
      "Seen so far: 114752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1793: 1.167741298675537\n",
      "Seen so far: 114816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1794: 0.9786503911018372\n",
      "Seen so far: 114880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1795: 0.9048802852630615\n",
      "Seen so far: 114944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1796: 0.8910404443740845\n",
      "Seen so far: 115008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1797: 0.6926968693733215\n",
      "Seen so far: 115072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1798: 0.8011132478713989\n",
      "Seen so far: 115136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1799: 1.0992839336395264\n",
      "Seen so far: 115200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1800: 0.8795328140258789\n",
      "Seen so far: 115264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1801: 0.9319155216217041\n",
      "Seen so far: 115328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1802: 0.8186632990837097\n",
      "Seen so far: 115392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1803: 0.9187443852424622\n",
      "Seen so far: 115456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1804: 0.8683453798294067\n",
      "Seen so far: 115520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1805: 0.6683156490325928\n",
      "Seen so far: 115584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1806: 0.9109625220298767\n",
      "Seen so far: 115648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1807: 1.1311618089675903\n",
      "Seen so far: 115712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1808: 1.2561230659484863\n",
      "Seen so far: 115776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1809: 1.0899382829666138\n",
      "Seen so far: 115840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1810: 0.8361643552780151\n",
      "Seen so far: 115904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1811: 0.930654764175415\n",
      "Seen so far: 115968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1812: 0.7118445634841919\n",
      "Seen so far: 116032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1813: 1.2550342082977295\n",
      "Seen so far: 116096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1814: 0.906564474105835\n",
      "Seen so far: 116160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1815: 1.4995344877243042\n",
      "Seen so far: 116224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1816: 1.0245193243026733\n",
      "Seen so far: 116288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1817: 1.0190070867538452\n",
      "Seen so far: 116352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1818: 1.0865404605865479\n",
      "Seen so far: 116416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1819: 0.8546097278594971\n",
      "Seen so far: 116480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1820: 0.9581174850463867\n",
      "Seen so far: 116544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1821: 1.2219822406768799\n",
      "Seen so far: 116608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1822: 1.350153923034668\n",
      "Seen so far: 116672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1823: 1.2876598834991455\n",
      "Seen so far: 116736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1824: 1.1867749691009521\n",
      "Seen so far: 116800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1825: 0.9928186535835266\n",
      "Seen so far: 116864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1826: 1.1906180381774902\n",
      "Seen so far: 116928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1827: 1.2459617853164673\n",
      "Seen so far: 116992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1828: 1.201413631439209\n",
      "Seen so far: 117056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1829: 0.9429717063903809\n",
      "Seen so far: 117120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1830: 1.0633939504623413\n",
      "Seen so far: 117184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1831: 0.8868497610092163\n",
      "Seen so far: 117248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1832: 1.5243823528289795\n",
      "Seen so far: 117312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1833: 0.9633750915527344\n",
      "Seen so far: 117376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1834: 1.5658140182495117\n",
      "Seen so far: 117440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1835: 0.8166615962982178\n",
      "Seen so far: 117504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1836: 0.9714187383651733\n",
      "Seen so far: 117568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1837: 0.6649494171142578\n",
      "Seen so far: 117632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1838: 1.116323709487915\n",
      "Seen so far: 117696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1839: 0.8184636831283569\n",
      "Seen so far: 117760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1840: 1.503733515739441\n",
      "Seen so far: 117824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1841: 0.9546352028846741\n",
      "Seen so far: 117888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1842: 0.7258639335632324\n",
      "Seen so far: 117952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1843: 1.1569147109985352\n",
      "Seen so far: 118016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1844: 0.9278517961502075\n",
      "Seen so far: 118080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1845: 1.256016731262207\n",
      "Seen so far: 118144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1846: 1.384588599205017\n",
      "Seen so far: 118208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1847: 1.2647340297698975\n",
      "Seen so far: 118272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1848: 1.000528335571289\n",
      "Seen so far: 118336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1849: 1.2379357814788818\n",
      "Seen so far: 118400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1850: 0.852310061454773\n",
      "Seen so far: 118464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1851: 1.3666753768920898\n",
      "Seen so far: 118528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1852: 1.1867257356643677\n",
      "Seen so far: 118592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1853: 0.8150432705879211\n",
      "Seen so far: 118656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1854: 1.436690092086792\n",
      "Seen so far: 118720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1855: 1.264955997467041\n",
      "Seen so far: 118784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1856: 1.0177648067474365\n",
      "Seen so far: 118848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1857: 0.792579174041748\n",
      "Seen so far: 118912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1858: 1.1688642501831055\n",
      "Seen so far: 118976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1859: 0.6132909059524536\n",
      "Seen so far: 119040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1860: 0.9889111518859863\n",
      "Seen so far: 119104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1861: 1.2830848693847656\n",
      "Seen so far: 119168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1862: 0.8634874820709229\n",
      "Seen so far: 119232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1863: 0.8338295221328735\n",
      "Seen so far: 119296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1864: 1.0779237747192383\n",
      "Seen so far: 119360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1865: 0.9600821733474731\n",
      "Seen so far: 119424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1866: 1.0573930740356445\n",
      "Seen so far: 119488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1867: 0.8232060074806213\n",
      "Seen so far: 119552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1868: 0.9329299330711365\n",
      "Seen so far: 119616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1869: 0.9262244701385498\n",
      "Seen so far: 119680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1870: 0.8647315502166748\n",
      "Seen so far: 119744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1871: 0.8571142554283142\n",
      "Seen so far: 119808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1872: 1.0261447429656982\n",
      "Seen so far: 119872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1873: 1.1988263130187988\n",
      "Seen so far: 119936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1874: 1.1391620635986328\n",
      "Seen so far: 120000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1875: 1.0066969394683838\n",
      "Seen so far: 120064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1876: 0.7685829997062683\n",
      "Seen so far: 120128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1877: 0.8095670938491821\n",
      "Seen so far: 120192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1878: 1.1386287212371826\n",
      "Seen so far: 120256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1879: 1.3084254264831543\n",
      "Seen so far: 120320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1880: 1.042001724243164\n",
      "Seen so far: 120384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1881: 0.5234955549240112\n",
      "Seen so far: 120448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1882: 1.1461631059646606\n",
      "Seen so far: 120512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1883: 0.7916780710220337\n",
      "Seen so far: 120576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1884: 1.1620171070098877\n",
      "Seen so far: 120640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1885: 0.9560450315475464\n",
      "Seen so far: 120704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1886: 1.05955171585083\n",
      "Seen so far: 120768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1887: 1.0234555006027222\n",
      "Seen so far: 120832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1888: 0.8232300877571106\n",
      "Seen so far: 120896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1889: 1.303840160369873\n",
      "Seen so far: 120960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1890: 1.3203322887420654\n",
      "Seen so far: 121024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1891: 1.2845656871795654\n",
      "Seen so far: 121088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1892: 0.9411396980285645\n",
      "Seen so far: 121152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1893: 1.045501708984375\n",
      "Seen so far: 121216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1894: 1.2988412380218506\n",
      "Seen so far: 121280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1895: 1.1860792636871338\n",
      "Seen so far: 121344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1896: 0.6696323156356812\n",
      "Seen so far: 121408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1897: 1.4924612045288086\n",
      "Seen so far: 121472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1898: 1.0866401195526123\n",
      "Seen so far: 121536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1899: 1.313902497291565\n",
      "Seen so far: 121600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1900: 1.1375129222869873\n",
      "Seen so far: 121664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1901: 0.8708584308624268\n",
      "Seen so far: 121728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1902: 1.5304107666015625\n",
      "Seen so far: 121792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1903: 1.0396414995193481\n",
      "Seen so far: 121856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1904: 1.1012485027313232\n",
      "Seen so far: 121920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1905: 0.9830044507980347\n",
      "Seen so far: 121984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1906: 0.8146126866340637\n",
      "Seen so far: 122048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1907: 1.514341115951538\n",
      "Seen so far: 122112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1908: 1.194197654724121\n",
      "Seen so far: 122176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1909: 1.0207165479660034\n",
      "Seen so far: 122240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1910: 0.8948130011558533\n",
      "Seen so far: 122304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1911: 0.8765146732330322\n",
      "Seen so far: 122368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1912: 1.00260329246521\n",
      "Seen so far: 122432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1913: 0.7388736009597778\n",
      "Seen so far: 122496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1914: 1.008228063583374\n",
      "Seen so far: 122560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1915: 0.8970616459846497\n",
      "Seen so far: 122624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1916: 0.9700819849967957\n",
      "Seen so far: 122688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1917: 1.1553410291671753\n",
      "Seen so far: 122752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1918: 1.1866188049316406\n",
      "Seen so far: 122816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1919: 1.183247685432434\n",
      "Seen so far: 122880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1920: 1.178680658340454\n",
      "Seen so far: 122944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1921: 1.0207784175872803\n",
      "Seen so far: 123008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1922: 1.2601491212844849\n",
      "Seen so far: 123072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1923: 1.363695740699768\n",
      "Seen so far: 123136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1924: 0.9061444997787476\n",
      "Seen so far: 123200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1925: 0.9992797374725342\n",
      "Seen so far: 123264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1926: 1.2283241748809814\n",
      "Seen so far: 123328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1927: 1.246476173400879\n",
      "Seen so far: 123392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1928: 0.708662748336792\n",
      "Seen so far: 123456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1929: 0.9543619155883789\n",
      "Seen so far: 123520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1930: 1.3697619438171387\n",
      "Seen so far: 123584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1931: 1.0008893013000488\n",
      "Seen so far: 123648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1932: 1.3704569339752197\n",
      "Seen so far: 123712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1933: 1.0680551528930664\n",
      "Seen so far: 123776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1934: 1.147188663482666\n",
      "Seen so far: 123840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1935: 1.3791229724884033\n",
      "Seen so far: 123904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1936: 1.6382702589035034\n",
      "Seen so far: 123968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1937: 1.2279056310653687\n",
      "Seen so far: 124032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1938: 0.8703161478042603\n",
      "Seen so far: 124096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1939: 1.3052833080291748\n",
      "Seen so far: 124160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1940: 1.136805534362793\n",
      "Seen so far: 124224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1941: 0.9432958364486694\n",
      "Seen so far: 124288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1942: 1.6466983556747437\n",
      "Seen so far: 124352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1943: 0.7561588287353516\n",
      "Seen so far: 124416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1944: 1.228651762008667\n",
      "Seen so far: 124480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1945: 1.3042197227478027\n",
      "Seen so far: 124544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1946: 1.124421238899231\n",
      "Seen so far: 124608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1947: 1.0653109550476074\n",
      "Seen so far: 124672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1948: 1.4948879480361938\n",
      "Seen so far: 124736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1949: 0.9744717478752136\n",
      "Seen so far: 124800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1950: 1.4005420207977295\n",
      "Seen so far: 124864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1951: 0.6516530513763428\n",
      "Seen so far: 124928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1952: 0.5833197832107544\n",
      "Seen so far: 124992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1953: 0.7392516136169434\n",
      "Seen so far: 125056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1954: 1.1558526754379272\n",
      "Seen so far: 125120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1955: 0.9629744291305542\n",
      "Seen so far: 125184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1956: 0.9530478715896606\n",
      "Seen so far: 125248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1957: 0.9262315034866333\n",
      "Seen so far: 125312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1958: 0.8243659138679504\n",
      "Seen so far: 125376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1959: 0.9538638591766357\n",
      "Seen so far: 125440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1960: 1.2959332466125488\n",
      "Seen so far: 125504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1961: 1.0571668148040771\n",
      "Seen so far: 125568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1962: 1.0289803743362427\n",
      "Seen so far: 125632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1963: 0.8932000398635864\n",
      "Seen so far: 125696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1964: 0.7902278900146484\n",
      "Seen so far: 125760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1965: 1.2726919651031494\n",
      "Seen so far: 125824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1966: 0.9014434814453125\n",
      "Seen so far: 125888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1967: 1.1060277223587036\n",
      "Seen so far: 125952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1968: 0.7932077646255493\n",
      "Seen so far: 126016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1969: 1.0847662687301636\n",
      "Seen so far: 126080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1970: 1.2381665706634521\n",
      "Seen so far: 126144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1971: 1.00433349609375\n",
      "Seen so far: 126208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1972: 1.0189071893692017\n",
      "Seen so far: 126272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1973: 1.3207283020019531\n",
      "Seen so far: 126336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1974: 0.9912446141242981\n",
      "Seen so far: 126400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1975: 1.4504210948944092\n",
      "Seen so far: 126464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1976: 1.1165447235107422\n",
      "Seen so far: 126528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1977: 0.8052287697792053\n",
      "Seen so far: 126592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1978: 1.1657602787017822\n",
      "Seen so far: 126656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1979: 0.6149188280105591\n",
      "Seen so far: 126720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1980: 1.1324825286865234\n",
      "Seen so far: 126784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1981: 0.8325755596160889\n",
      "Seen so far: 126848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1982: 0.7258361577987671\n",
      "Seen so far: 126912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1983: 1.4550864696502686\n",
      "Seen so far: 126976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1984: 0.9546554088592529\n",
      "Seen so far: 127040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1985: 1.133549690246582\n",
      "Seen so far: 127104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1986: 0.725906252861023\n",
      "Seen so far: 127168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1987: 1.286914587020874\n",
      "Seen so far: 127232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1988: 1.3071658611297607\n",
      "Seen so far: 127296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1989: 0.8719903826713562\n",
      "Seen so far: 127360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1990: 1.0337283611297607\n",
      "Seen so far: 127424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1991: 1.403291940689087\n",
      "Seen so far: 127488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1992: 1.2967593669891357\n",
      "Seen so far: 127552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1993: 0.8233753442764282\n",
      "Seen so far: 127616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1994: 0.9527263045310974\n",
      "Seen so far: 127680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1995: 0.7388591766357422\n",
      "Seen so far: 127744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1996: 1.0394099950790405\n",
      "Seen so far: 127808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1997: 1.0814521312713623\n",
      "Seen so far: 127872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1998: 0.8751460313796997\n",
      "Seen so far: 127936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1999: 1.1217145919799805\n",
      "Seen so far: 128000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2000: 1.1548848152160645\n",
      "Seen so far: 128064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2001: 0.8466106653213501\n",
      "Seen so far: 128128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2002: 1.3956389427185059\n",
      "Seen so far: 128192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2003: 0.7843402028083801\n",
      "Seen so far: 128256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2004: 1.179894208908081\n",
      "Seen so far: 128320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2005: 1.0114161968231201\n",
      "Seen so far: 128384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2006: 1.2352298498153687\n",
      "Seen so far: 128448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2007: 0.9012680053710938\n",
      "Seen so far: 128512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2008: 0.990966796875\n",
      "Seen so far: 128576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2009: 0.899541974067688\n",
      "Seen so far: 128640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2010: 1.3315362930297852\n",
      "Seen so far: 128704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2011: 1.0353515148162842\n",
      "Seen so far: 128768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2012: 1.0854709148406982\n",
      "Seen so far: 128832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2013: 1.3379355669021606\n",
      "Seen so far: 128896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2014: 0.9488853812217712\n",
      "Seen so far: 128960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2015: 1.0019642114639282\n",
      "Seen so far: 129024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2016: 0.8708578944206238\n",
      "Seen so far: 129088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2017: 1.161125898361206\n",
      "Seen so far: 129152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2018: 0.7984384298324585\n",
      "Seen so far: 129216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2019: 1.1901310682296753\n",
      "Seen so far: 129280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2020: 0.6320468783378601\n",
      "Seen so far: 129344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2021: 1.2463992834091187\n",
      "Seen so far: 129408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2022: 1.4682024717330933\n",
      "Seen so far: 129472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2023: 1.0282901525497437\n",
      "Seen so far: 129536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2024: 0.859004020690918\n",
      "Seen so far: 129600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2025: 1.0302042961120605\n",
      "Seen so far: 129664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2026: 1.119138240814209\n",
      "Seen so far: 129728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2027: 1.396466851234436\n",
      "Seen so far: 129792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2028: 0.8819024562835693\n",
      "Seen so far: 129856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2029: 0.9083133935928345\n",
      "Seen so far: 129920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2030: 1.446700096130371\n",
      "Seen so far: 129984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2031: 1.531469702720642\n",
      "Seen so far: 130048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2032: 1.0392236709594727\n",
      "Seen so far: 130112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2033: 1.3160698413848877\n",
      "Seen so far: 130176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2034: 1.3272225856781006\n",
      "Seen so far: 130240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2035: 1.0563557147979736\n",
      "Seen so far: 130304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2036: 0.835695743560791\n",
      "Seen so far: 130368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2037: 0.8275606632232666\n",
      "Seen so far: 130432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2038: 0.9307643175125122\n",
      "Seen so far: 130496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2039: 1.2227786779403687\n",
      "Seen so far: 130560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2040: 0.6713464260101318\n",
      "Seen so far: 130624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2041: 0.8377290368080139\n",
      "Seen so far: 130688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2042: 1.2466537952423096\n",
      "Seen so far: 130752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2043: 0.9015821218490601\n",
      "Seen so far: 130816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2044: 1.1268806457519531\n",
      "Seen so far: 130880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2045: 0.9350895881652832\n",
      "Seen so far: 130944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2046: 0.9576614499092102\n",
      "Seen so far: 131008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2047: 1.1686893701553345\n",
      "Seen so far: 131072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2048: 0.8601971864700317\n",
      "Seen so far: 131136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2049: 1.2073582410812378\n",
      "Seen so far: 131200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2050: 1.033968210220337\n",
      "Seen so far: 131264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2051: 1.31669282913208\n",
      "Seen so far: 131328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2052: 1.156909704208374\n",
      "Seen so far: 131392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2053: 1.1873990297317505\n",
      "Seen so far: 131456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2054: 0.8850927948951721\n",
      "Seen so far: 131520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2055: 0.4898260235786438\n",
      "Seen so far: 131584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2056: 0.7677954435348511\n",
      "Seen so far: 131648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2057: 0.9948413372039795\n",
      "Seen so far: 131712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2058: 0.9560803174972534\n",
      "Seen so far: 131776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2059: 0.812684178352356\n",
      "Seen so far: 131840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2060: 0.9653826355934143\n",
      "Seen so far: 131904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2061: 1.3269827365875244\n",
      "Seen so far: 131968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2062: 1.1429024934768677\n",
      "Seen so far: 132032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2063: 1.054352879524231\n",
      "Seen so far: 132096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2064: 1.3333064317703247\n",
      "Seen so far: 132160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2065: 0.794624924659729\n",
      "Seen so far: 132224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2066: 1.1314356327056885\n",
      "Seen so far: 132288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2067: 0.9624125957489014\n",
      "Seen so far: 132352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2068: 1.3935317993164062\n",
      "Seen so far: 132416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2069: 1.158189058303833\n",
      "Seen so far: 132480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2070: 0.6811895966529846\n",
      "Seen so far: 132544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2071: 0.7088460922241211\n",
      "Seen so far: 132608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2072: 0.8905622363090515\n",
      "Seen so far: 132672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2073: 0.9862287044525146\n",
      "Seen so far: 132736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2074: 0.8035547733306885\n",
      "Seen so far: 132800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2075: 1.2685428857803345\n",
      "Seen so far: 132864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2076: 0.8715541362762451\n",
      "Seen so far: 132928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2077: 1.0259623527526855\n",
      "Seen so far: 132992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2078: 1.0375890731811523\n",
      "Seen so far: 133056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2079: 0.9258946180343628\n",
      "Seen so far: 133120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2080: 0.6781558990478516\n",
      "Seen so far: 133184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2081: 1.1385529041290283\n",
      "Seen so far: 133248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2082: 0.9849978685379028\n",
      "Seen so far: 133312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2083: 1.132779598236084\n",
      "Seen so far: 133376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2084: 1.0410679578781128\n",
      "Seen so far: 133440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2085: 0.7487801313400269\n",
      "Seen so far: 133504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2086: 0.6842378377914429\n",
      "Seen so far: 133568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2087: 1.2815983295440674\n",
      "Seen so far: 133632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2088: 0.7890492081642151\n",
      "Seen so far: 133696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2089: 1.1786999702453613\n",
      "Seen so far: 133760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2090: 0.9822205305099487\n",
      "Seen so far: 133824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2091: 0.9567975997924805\n",
      "Seen so far: 133888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2092: 1.0552433729171753\n",
      "Seen so far: 133952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2093: 0.9422157406806946\n",
      "Seen so far: 134016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2094: 0.9765686988830566\n",
      "Seen so far: 134080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2095: 1.257038950920105\n",
      "Seen so far: 134144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2096: 1.1404821872711182\n",
      "Seen so far: 134208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2097: 0.8084651827812195\n",
      "Seen so far: 134272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2098: 0.9767113327980042\n",
      "Seen so far: 134336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2099: 0.7781124114990234\n",
      "Seen so far: 134400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2100: 1.0446233749389648\n",
      "Seen so far: 134464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2101: 0.7178688049316406\n",
      "Seen so far: 134528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2102: 1.1260628700256348\n",
      "Seen so far: 134592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2103: 0.8774354457855225\n",
      "Seen so far: 134656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2104: 1.0464131832122803\n",
      "Seen so far: 134720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2105: 0.8313477039337158\n",
      "Seen so far: 134784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2106: 0.9881008863449097\n",
      "Seen so far: 134848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2107: 1.2111587524414062\n",
      "Seen so far: 134912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2108: 0.5149940252304077\n",
      "Seen so far: 134976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2109: 0.7760310173034668\n",
      "Seen so far: 135040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2110: 1.1931110620498657\n",
      "Seen so far: 135104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2111: 0.7524540424346924\n",
      "Seen so far: 135168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2112: 0.8185741901397705\n",
      "Seen so far: 135232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2113: 1.3178703784942627\n",
      "Seen so far: 135296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2114: 1.2723009586334229\n",
      "Seen so far: 135360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2115: 1.0691553354263306\n",
      "Seen so far: 135424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2116: 0.7488601803779602\n",
      "Seen so far: 135488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2117: 0.7429280281066895\n",
      "Seen so far: 135552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2118: 1.4864977598190308\n",
      "Seen so far: 135616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2119: 0.8720968961715698\n",
      "Seen so far: 135680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2120: 1.2667872905731201\n",
      "Seen so far: 135744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2121: 0.9932685494422913\n",
      "Seen so far: 135808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2122: 0.9291055202484131\n",
      "Seen so far: 135872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2123: 0.9429433345794678\n",
      "Seen so far: 135936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2124: 1.0009880065917969\n",
      "Seen so far: 136000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2125: 1.1859186887741089\n",
      "Seen so far: 136064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2126: 1.056633472442627\n",
      "Seen so far: 136128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2127: 0.9850012063980103\n",
      "Seen so far: 136192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2128: 1.1237096786499023\n",
      "Seen so far: 136256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2129: 1.097456693649292\n",
      "Seen so far: 136320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2130: 0.8585186004638672\n",
      "Seen so far: 136384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2131: 1.0431311130523682\n",
      "Seen so far: 136448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2132: 0.9945946931838989\n",
      "Seen so far: 136512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2133: 0.727431058883667\n",
      "Seen so far: 136576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2134: 0.4574081003665924\n",
      "Seen so far: 136640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2135: 0.7678648233413696\n",
      "Seen so far: 136704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2136: 0.7600592374801636\n",
      "Seen so far: 136768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2137: 1.1322393417358398\n",
      "Seen so far: 136832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2138: 1.1196520328521729\n",
      "Seen so far: 136896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2139: 1.1454715728759766\n",
      "Seen so far: 136960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2140: 1.0090726613998413\n",
      "Seen so far: 137024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2141: 1.514473795890808\n",
      "Seen so far: 137088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2142: 0.8966286778450012\n",
      "Seen so far: 137152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2143: 0.8747124671936035\n",
      "Seen so far: 137216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2144: 0.8401986360549927\n",
      "Seen so far: 137280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2145: 1.1733399629592896\n",
      "Seen so far: 137344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2146: 1.4343161582946777\n",
      "Seen so far: 137408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2147: 0.7419242858886719\n",
      "Seen so far: 137472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2148: 1.152066707611084\n",
      "Seen so far: 137536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2149: 1.0923347473144531\n",
      "Seen so far: 137600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2150: 0.7766838073730469\n",
      "Seen so far: 137664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2151: 0.849715530872345\n",
      "Seen so far: 137728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2152: 1.1110059022903442\n",
      "Seen so far: 137792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2153: 0.8856986165046692\n",
      "Seen so far: 137856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2154: 1.294745683670044\n",
      "Seen so far: 137920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2155: 1.0002487897872925\n",
      "Seen so far: 137984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2156: 0.7533292770385742\n",
      "Seen so far: 138048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2157: 0.5994607210159302\n",
      "Seen so far: 138112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2158: 0.9557856321334839\n",
      "Seen so far: 138176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2159: 0.6607539653778076\n",
      "Seen so far: 138240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2160: 1.1510770320892334\n",
      "Seen so far: 138304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2161: 0.8527368307113647\n",
      "Seen so far: 138368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2162: 0.8287274837493896\n",
      "Seen so far: 138432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2163: 0.7678498029708862\n",
      "Seen so far: 138496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2164: 1.5622817277908325\n",
      "Seen so far: 138560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2165: 1.053325891494751\n",
      "Seen so far: 138624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2166: 0.8022568225860596\n",
      "Seen so far: 138688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2167: 1.1597023010253906\n",
      "Seen so far: 138752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2168: 0.8297287225723267\n",
      "Seen so far: 138816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2169: 0.6234790682792664\n",
      "Seen so far: 138880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2170: 1.1460586786270142\n",
      "Seen so far: 138944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2171: 1.1637554168701172\n",
      "Seen so far: 139008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2172: 1.0726311206817627\n",
      "Seen so far: 139072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2173: 0.9283276200294495\n",
      "Seen so far: 139136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2174: 1.3992987871170044\n",
      "Seen so far: 139200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2175: 1.0251953601837158\n",
      "Seen so far: 139264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2176: 1.001917839050293\n",
      "Seen so far: 139328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2177: 0.9935888051986694\n",
      "Seen so far: 139392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2178: 0.6179410815238953\n",
      "Seen so far: 139456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2179: 0.5941221117973328\n",
      "Seen so far: 139520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2180: 0.8165663480758667\n",
      "Seen so far: 139584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2181: 1.1944549083709717\n",
      "Seen so far: 139648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2182: 1.4696942567825317\n",
      "Seen so far: 139712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2183: 0.7837040424346924\n",
      "Seen so far: 139776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2184: 1.1828246116638184\n",
      "Seen so far: 139840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2185: 1.1704623699188232\n",
      "Seen so far: 139904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2186: 0.8372719287872314\n",
      "Seen so far: 139968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2187: 0.8812408447265625\n",
      "Seen so far: 140032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2188: 0.779194712638855\n",
      "Seen so far: 140096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2189: 1.2364695072174072\n",
      "Seen so far: 140160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2190: 0.9756381511688232\n",
      "Seen so far: 140224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2191: 0.866667628288269\n",
      "Seen so far: 140288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2192: 1.0877095460891724\n",
      "Seen so far: 140352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2193: 0.9669662714004517\n",
      "Seen so far: 140416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2194: 0.6783978939056396\n",
      "Seen so far: 140480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2195: 1.321882724761963\n",
      "Seen so far: 140544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2196: 0.7904038429260254\n",
      "Seen so far: 140608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2197: 0.8617890477180481\n",
      "Seen so far: 140672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2198: 1.2065441608428955\n",
      "Seen so far: 140736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2199: 0.8459457755088806\n",
      "Seen so far: 140800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2200: 1.2754302024841309\n",
      "Seen so far: 140864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2201: 1.1032705307006836\n",
      "Seen so far: 140928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2202: 0.9497520327568054\n",
      "Seen so far: 140992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2203: 1.3057994842529297\n",
      "Seen so far: 141056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2204: 1.0162107944488525\n",
      "Seen so far: 141120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2205: 0.7275362610816956\n",
      "Seen so far: 141184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2206: 1.324202299118042\n",
      "Seen so far: 141248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2207: 1.1215335130691528\n",
      "Seen so far: 141312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2208: 1.8921891450881958\n",
      "Seen so far: 141376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2209: 0.9304304122924805\n",
      "Seen so far: 141440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2210: 0.7059547305107117\n",
      "Seen so far: 141504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2211: 1.1365526914596558\n",
      "Seen so far: 141568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2212: 0.9606764912605286\n",
      "Seen so far: 141632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2213: 0.8162204027175903\n",
      "Seen so far: 141696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2214: 1.3057795763015747\n",
      "Seen so far: 141760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2215: 1.0949726104736328\n",
      "Seen so far: 141824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2216: 0.8349819779396057\n",
      "Seen so far: 141888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2217: 1.0881941318511963\n",
      "Seen so far: 141952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2218: 1.001254677772522\n",
      "Seen so far: 142016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2219: 1.0834596157073975\n",
      "Seen so far: 142080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2220: 1.1348106861114502\n",
      "Seen so far: 142144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2221: 1.4169037342071533\n",
      "Seen so far: 142208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2222: 1.6321738958358765\n",
      "Seen so far: 142272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2223: 0.9122757315635681\n",
      "Seen so far: 142336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2224: 1.188119649887085\n",
      "Seen so far: 142400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2225: 1.022304892539978\n",
      "Seen so far: 142464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2226: 1.476190209388733\n",
      "Seen so far: 142528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2227: 0.8460984230041504\n",
      "Seen so far: 142592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2228: 1.2873330116271973\n",
      "Seen so far: 142656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2229: 1.1191235780715942\n",
      "Seen so far: 142720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2230: 1.1304430961608887\n",
      "Seen so far: 142784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2231: 1.0993142127990723\n",
      "Seen so far: 142848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2232: 1.3438951969146729\n",
      "Seen so far: 142912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2233: 0.9824678301811218\n",
      "Seen so far: 142976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2234: 1.1656591892242432\n",
      "Seen so far: 143040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2235: 1.3535265922546387\n",
      "Seen so far: 143104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2236: 1.2021647691726685\n",
      "Seen so far: 143168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2237: 1.2266650199890137\n",
      "Seen so far: 143232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2238: 1.0289907455444336\n",
      "Seen so far: 143296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2239: 1.0145087242126465\n",
      "Seen so far: 143360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2240: 0.9343193769454956\n",
      "Seen so far: 143424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2241: 1.3930919170379639\n",
      "Seen so far: 143488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2242: 0.9790669679641724\n",
      "Seen so far: 143552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2243: 1.3834588527679443\n",
      "Seen so far: 143616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2244: 1.0128206014633179\n",
      "Seen so far: 143680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2245: 0.8468559980392456\n",
      "Seen so far: 143744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2246: 0.8634533882141113\n",
      "Seen so far: 143808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2247: 1.5533642768859863\n",
      "Seen so far: 143872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2248: 0.6442237496376038\n",
      "Seen so far: 143936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2249: 1.2445454597473145\n",
      "Seen so far: 144000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2250: 0.9585989117622375\n",
      "Seen so far: 144064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2251: 1.2731349468231201\n",
      "Seen so far: 144128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2252: 0.8519973158836365\n",
      "Seen so far: 144192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2253: 1.2637780904769897\n",
      "Seen so far: 144256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2254: 1.0151774883270264\n",
      "Seen so far: 144320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2255: 0.7877051830291748\n",
      "Seen so far: 144384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2256: 0.9044150710105896\n",
      "Seen so far: 144448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2257: 1.2015984058380127\n",
      "Seen so far: 144512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2258: 1.4816951751708984\n",
      "Seen so far: 144576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2259: 0.8768600225448608\n",
      "Seen so far: 144640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2260: 1.0613253116607666\n",
      "Seen so far: 144704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2261: 1.3016551733016968\n",
      "Seen so far: 144768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2262: 1.0409457683563232\n",
      "Seen so far: 144832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2263: 1.0766615867614746\n",
      "Seen so far: 144896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2264: 1.3439829349517822\n",
      "Seen so far: 144960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2265: 0.8852587342262268\n",
      "Seen so far: 145024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2266: 0.8933730721473694\n",
      "Seen so far: 145088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2267: 0.9196584224700928\n",
      "Seen so far: 145152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2268: 0.9536073207855225\n",
      "Seen so far: 145216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2269: 0.7954660654067993\n",
      "Seen so far: 145280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2270: 0.8917222023010254\n",
      "Seen so far: 145344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2271: 0.8066560626029968\n",
      "Seen so far: 145408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2272: 0.9570397734642029\n",
      "Seen so far: 145472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2273: 1.2673425674438477\n",
      "Seen so far: 145536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2274: 1.0737674236297607\n",
      "Seen so far: 145600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2275: 1.0806958675384521\n",
      "Seen so far: 145664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2276: 0.959749698638916\n",
      "Seen so far: 145728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2277: 0.862459123134613\n",
      "Seen so far: 145792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2278: 1.513877272605896\n",
      "Seen so far: 145856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2279: 0.7339536547660828\n",
      "Seen so far: 145920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2280: 1.5371105670928955\n",
      "Seen so far: 145984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2281: 0.910086989402771\n",
      "Seen so far: 146048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2282: 1.267544150352478\n",
      "Seen so far: 146112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2283: 1.0162615776062012\n",
      "Seen so far: 146176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2284: 0.8784558773040771\n",
      "Seen so far: 146240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2285: 1.339943289756775\n",
      "Seen so far: 146304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2286: 1.2671539783477783\n",
      "Seen so far: 146368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2287: 0.8709957003593445\n",
      "Seen so far: 146432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2288: 1.1135343313217163\n",
      "Seen so far: 146496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2289: 1.096224308013916\n",
      "Seen so far: 146560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2290: 1.1545246839523315\n",
      "Seen so far: 146624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2291: 0.7405670881271362\n",
      "Seen so far: 146688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2292: 0.7820320129394531\n",
      "Seen so far: 146752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2293: 1.2199087142944336\n",
      "Seen so far: 146816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2294: 1.8596793413162231\n",
      "Seen so far: 146880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2295: 1.255753755569458\n",
      "Seen so far: 146944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2296: 1.0853278636932373\n",
      "Seen so far: 147008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2297: 1.297829508781433\n",
      "Seen so far: 147072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2298: 1.0086863040924072\n",
      "Seen so far: 147136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2299: 0.7882556319236755\n",
      "Seen so far: 147200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2300: 1.2943477630615234\n",
      "Seen so far: 147264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2301: 1.1313276290893555\n",
      "Seen so far: 147328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2302: 1.18258535861969\n",
      "Seen so far: 147392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2303: 1.551973581314087\n",
      "Seen so far: 147456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2304: 0.795110285282135\n",
      "Seen so far: 147520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2305: 0.9196698069572449\n",
      "Seen so far: 147584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2306: 0.9459993839263916\n",
      "Seen so far: 147648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2307: 0.8226776123046875\n",
      "Seen so far: 147712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2308: 0.9930866360664368\n",
      "Seen so far: 147776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2309: 1.3462841510772705\n",
      "Seen so far: 147840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2310: 0.7154861092567444\n",
      "Seen so far: 147904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2311: 0.8769435882568359\n",
      "Seen so far: 147968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2312: 0.8180490136146545\n",
      "Seen so far: 148032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2313: 0.8996769189834595\n",
      "Seen so far: 148096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2314: 1.3406060934066772\n",
      "Seen so far: 148160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2315: 1.060657024383545\n",
      "Seen so far: 148224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2316: 1.0171568393707275\n",
      "Seen so far: 148288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2317: 0.9353752136230469\n",
      "Seen so far: 148352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2318: 0.7541362047195435\n",
      "Seen so far: 148416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2319: 1.1615796089172363\n",
      "Seen so far: 148480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2320: 1.0094354152679443\n",
      "Seen so far: 148544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2321: 0.7172380089759827\n",
      "Seen so far: 148608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2322: 0.6023379564285278\n",
      "Seen so far: 148672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2323: 0.9164109230041504\n",
      "Seen so far: 148736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2324: 1.2284107208251953\n",
      "Seen so far: 148800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2325: 1.0151493549346924\n",
      "Seen so far: 148864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2326: 1.0628032684326172\n",
      "Seen so far: 148928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2327: 1.174356460571289\n",
      "Seen so far: 148992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2328: 0.742272138595581\n",
      "Seen so far: 149056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2329: 0.9962869882583618\n",
      "Seen so far: 149120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2330: 0.9952884912490845\n",
      "Seen so far: 149184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2331: 1.0264145135879517\n",
      "Seen so far: 149248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2332: 0.981867790222168\n",
      "Seen so far: 149312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2333: 1.0581786632537842\n",
      "Seen so far: 149376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2334: 1.2745033502578735\n",
      "Seen so far: 149440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2335: 1.387580394744873\n",
      "Seen so far: 149504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2336: 1.2334706783294678\n",
      "Seen so far: 149568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2337: 1.0248773097991943\n",
      "Seen so far: 149632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2338: 0.9391536116600037\n",
      "Seen so far: 149696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2339: 1.168031930923462\n",
      "Seen so far: 149760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2340: 1.3023117780685425\n",
      "Seen so far: 149824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2341: 1.3133692741394043\n",
      "Seen so far: 149888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2342: 0.5838130116462708\n",
      "Seen so far: 149952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2343: 0.6702713966369629\n",
      "Seen so far: 150016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2344: 1.1729159355163574\n",
      "Seen so far: 150080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2345: 1.0639042854309082\n",
      "Seen so far: 150144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2346: 0.9314906597137451\n",
      "Seen so far: 150208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2347: 0.8670897483825684\n",
      "Seen so far: 150272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2348: 1.2168574333190918\n",
      "Seen so far: 150336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2349: 0.8894785642623901\n",
      "Seen so far: 150400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2350: 1.083580732345581\n",
      "Seen so far: 150464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2351: 1.249806523323059\n",
      "Seen so far: 150528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2352: 1.2051318883895874\n",
      "Seen so far: 150592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2353: 0.951637327671051\n",
      "Seen so far: 150656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2354: 0.899821400642395\n",
      "Seen so far: 150720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2355: 0.9728198051452637\n",
      "Seen so far: 150784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2356: 0.7944307327270508\n",
      "Seen so far: 150848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2357: 1.120603084564209\n",
      "Seen so far: 150912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2358: 1.3072655200958252\n",
      "Seen so far: 150976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2359: 1.079574704170227\n",
      "Seen so far: 151040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2360: 1.3315017223358154\n",
      "Seen so far: 151104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2361: 0.9992276430130005\n",
      "Seen so far: 151168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2362: 1.3059613704681396\n",
      "Seen so far: 151232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2363: 1.0138988494873047\n",
      "Seen so far: 151296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2364: 0.8474024534225464\n",
      "Seen so far: 151360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2365: 1.4944497346878052\n",
      "Seen so far: 151424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2366: 1.2107963562011719\n",
      "Seen so far: 151488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2367: 1.0999327898025513\n",
      "Seen so far: 151552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2368: 1.2773326635360718\n",
      "Seen so far: 151616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2369: 1.4034373760223389\n",
      "Seen so far: 151680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2370: 1.1905548572540283\n",
      "Seen so far: 151744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2371: 1.24855637550354\n",
      "Seen so far: 151808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2372: 1.1877031326293945\n",
      "Seen so far: 151872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2373: 1.048899531364441\n",
      "Seen so far: 151936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2374: 0.8293899893760681\n",
      "Seen so far: 152000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2375: 1.0655810832977295\n",
      "Seen so far: 152064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2376: 1.382548213005066\n",
      "Seen so far: 152128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2377: 1.2409647703170776\n",
      "Seen so far: 152192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2378: 0.8858474493026733\n",
      "Seen so far: 152256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2379: 1.1871973276138306\n",
      "Seen so far: 152320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2380: 0.8002632856369019\n",
      "Seen so far: 152384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2381: 0.7426177263259888\n",
      "Seen so far: 152448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2382: 0.6911329627037048\n",
      "Seen so far: 152512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2383: 0.8165801763534546\n",
      "Seen so far: 152576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2384: 1.3497207164764404\n",
      "Seen so far: 152640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2385: 1.1751962900161743\n",
      "Seen so far: 152704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2386: 0.9772592782974243\n",
      "Seen so far: 152768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2387: 0.8419874906539917\n",
      "Seen so far: 152832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2388: 0.8799291849136353\n",
      "Seen so far: 152896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2389: 1.0271530151367188\n",
      "Seen so far: 152960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2390: 1.3002450466156006\n",
      "Seen so far: 153024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2391: 1.1068503856658936\n",
      "Seen so far: 153088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2392: 0.8049073815345764\n",
      "Seen so far: 153152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2393: 1.2965939044952393\n",
      "Seen so far: 153216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2394: 0.9107909202575684\n",
      "Seen so far: 153280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2395: 1.4408416748046875\n",
      "Seen so far: 153344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2396: 0.8513180017471313\n",
      "Seen so far: 153408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2397: 1.268174409866333\n",
      "Seen so far: 153472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2398: 0.9328835010528564\n",
      "Seen so far: 153536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2399: 0.7546427845954895\n",
      "Seen so far: 153600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2400: 0.939879298210144\n",
      "Seen so far: 153664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2401: 0.7516505122184753\n",
      "Seen so far: 153728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2402: 1.1782166957855225\n",
      "Seen so far: 153792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2403: 1.1837635040283203\n",
      "Seen so far: 153856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2404: 1.0475358963012695\n",
      "Seen so far: 153920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2405: 1.0695184469223022\n",
      "Seen so far: 153984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2406: 0.8655979633331299\n",
      "Seen so far: 154048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2407: 1.7786325216293335\n",
      "Seen so far: 154112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2408: 0.6968874931335449\n",
      "Seen so far: 154176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2409: 1.2439078092575073\n",
      "Seen so far: 154240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2410: 0.8352006673812866\n",
      "Seen so far: 154304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2411: 1.2977259159088135\n",
      "Seen so far: 154368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2412: 1.1492047309875488\n",
      "Seen so far: 154432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2413: 1.3049509525299072\n",
      "Seen so far: 154496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2414: 1.0796146392822266\n",
      "Seen so far: 154560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2415: 1.2036007642745972\n",
      "Seen so far: 154624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2416: 1.0634229183197021\n",
      "Seen so far: 154688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2417: 1.226444959640503\n",
      "Seen so far: 154752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2418: 1.1252050399780273\n",
      "Seen so far: 154816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2419: 0.9274956583976746\n",
      "Seen so far: 154880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2420: 1.1890144348144531\n",
      "Seen so far: 154944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2421: 0.9563522338867188\n",
      "Seen so far: 155008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2422: 1.0084664821624756\n",
      "Seen so far: 155072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2423: 1.0860154628753662\n",
      "Seen so far: 155136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2424: 1.0747389793395996\n",
      "Seen so far: 155200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2425: 1.43119215965271\n",
      "Seen so far: 155264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2426: 1.2065398693084717\n",
      "Seen so far: 155328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2427: 1.5016872882843018\n",
      "Seen so far: 155392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2428: 1.3257533311843872\n",
      "Seen so far: 155456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2429: 0.8348397016525269\n",
      "Seen so far: 155520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2430: 1.1443341970443726\n",
      "Seen so far: 155584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2431: 1.4038918018341064\n",
      "Seen so far: 155648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2432: 0.8378965854644775\n",
      "Seen so far: 155712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2433: 0.8431136608123779\n",
      "Seen so far: 155776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2434: 1.0471389293670654\n",
      "Seen so far: 155840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2435: 1.338891863822937\n",
      "Seen so far: 155904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2436: 1.257886290550232\n",
      "Seen so far: 155968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2437: 0.5313794016838074\n",
      "Seen so far: 156032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2438: 1.0558269023895264\n",
      "Seen so far: 156096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2439: 1.0761762857437134\n",
      "Seen so far: 156160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2440: 1.1069188117980957\n",
      "Seen so far: 156224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2441: 0.7587241530418396\n",
      "Seen so far: 156288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2442: 1.2413192987442017\n",
      "Seen so far: 156352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2443: 0.9636403322219849\n",
      "Seen so far: 156416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2444: 0.9596400260925293\n",
      "Seen so far: 156480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2445: 1.1459238529205322\n",
      "Seen so far: 156544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2446: 0.997255265712738\n",
      "Seen so far: 156608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2447: 0.6158347129821777\n",
      "Seen so far: 156672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2448: 1.176017165184021\n",
      "Seen so far: 156736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2449: 0.776490330696106\n",
      "Seen so far: 156800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2450: 0.8832731246948242\n",
      "Seen so far: 156864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2451: 1.156528115272522\n",
      "Seen so far: 156928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2452: 1.0949515104293823\n",
      "Seen so far: 156992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2453: 0.9188492894172668\n",
      "Seen so far: 157056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2454: 1.2458781003952026\n",
      "Seen so far: 157120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2455: 1.214447021484375\n",
      "Seen so far: 157184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2456: 0.8626720905303955\n",
      "Seen so far: 157248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2457: 1.2314149141311646\n",
      "Seen so far: 157312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2458: 1.042966365814209\n",
      "Seen so far: 157376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2459: 0.9636250734329224\n",
      "Seen so far: 157440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2460: 0.9213268756866455\n",
      "Seen so far: 157504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2461: 0.9303364753723145\n",
      "Seen so far: 157568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2462: 1.1389954090118408\n",
      "Seen so far: 157632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2463: 0.8543295860290527\n",
      "Seen so far: 157696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2464: 1.0039730072021484\n",
      "Seen so far: 157760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2465: 1.036888599395752\n",
      "Seen so far: 157824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2466: 1.394287109375\n",
      "Seen so far: 157888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2467: 1.2349965572357178\n",
      "Seen so far: 157952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2468: 1.166289210319519\n",
      "Seen so far: 158016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2469: 0.8280031085014343\n",
      "Seen so far: 158080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2470: 0.8718366622924805\n",
      "Seen so far: 158144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2471: 1.4563275575637817\n",
      "Seen so far: 158208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2472: 1.1272426843643188\n",
      "Seen so far: 158272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2473: 1.023118019104004\n",
      "Seen so far: 158336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2474: 1.5702414512634277\n",
      "Seen so far: 158400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2475: 1.1838551759719849\n",
      "Seen so far: 158464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2476: 0.8290860652923584\n",
      "Seen so far: 158528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2477: 1.0045783519744873\n",
      "Seen so far: 158592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2478: 1.1611502170562744\n",
      "Seen so far: 158656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2479: 1.4173489809036255\n",
      "Seen so far: 158720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2480: 0.8449010848999023\n",
      "Seen so far: 158784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2481: 1.011306643486023\n",
      "Seen so far: 158848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2482: 1.1134448051452637\n",
      "Seen so far: 158912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2483: 1.0045334100723267\n",
      "Seen so far: 158976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2484: 0.7972991466522217\n",
      "Seen so far: 159040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2485: 0.6804813742637634\n",
      "Seen so far: 159104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2486: 1.1421202421188354\n",
      "Seen so far: 159168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2487: 1.1395080089569092\n",
      "Seen so far: 159232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2488: 1.019789457321167\n",
      "Seen so far: 159296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2489: 0.6511401534080505\n",
      "Seen so far: 159360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2490: 0.7900079488754272\n",
      "Seen so far: 159424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2491: 0.9774805307388306\n",
      "Seen so far: 159488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2492: 1.0696934461593628\n",
      "Seen so far: 159552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2493: 0.7392153739929199\n",
      "Seen so far: 159616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2494: 0.7640866637229919\n",
      "Seen so far: 159680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2495: 0.5025224685668945\n",
      "Seen so far: 159744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2496: 0.8346056342124939\n",
      "Seen so far: 159808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2497: 1.048067569732666\n",
      "Seen so far: 159872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2498: 0.7716984152793884\n",
      "Seen so far: 159936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2499: 1.207210659980774\n",
      "Seen so far: 160000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2500: 1.3967286348342896\n",
      "Seen so far: 160064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2501: 0.8620527386665344\n",
      "Seen so far: 160128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2502: 0.7230972051620483\n",
      "Seen so far: 160192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2503: 1.0443158149719238\n",
      "Seen so far: 160256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2504: 1.3353899717330933\n",
      "Seen so far: 160320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2505: 1.472956895828247\n",
      "Seen so far: 160384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2506: 1.1086950302124023\n",
      "Seen so far: 160448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2507: 1.0187549591064453\n",
      "Seen so far: 160512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2508: 0.8550879955291748\n",
      "Seen so far: 160576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2509: 1.3370000123977661\n",
      "Seen so far: 160640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2510: 1.1789833307266235\n",
      "Seen so far: 160704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2511: 1.2455658912658691\n",
      "Seen so far: 160768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2512: 0.7606407403945923\n",
      "Seen so far: 160832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2513: 1.0247642993927002\n",
      "Seen so far: 160896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2514: 0.891982913017273\n",
      "Seen so far: 160960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2515: 0.7759071588516235\n",
      "Seen so far: 161024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2516: 0.9894782304763794\n",
      "Seen so far: 161088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2517: 1.0466728210449219\n",
      "Seen so far: 161152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2518: 1.1858633756637573\n",
      "Seen so far: 161216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2519: 0.9789434671401978\n",
      "Seen so far: 161280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2520: 0.7686620354652405\n",
      "Seen so far: 161344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2521: 0.9737898111343384\n",
      "Seen so far: 161408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2522: 0.7262150645256042\n",
      "Seen so far: 161472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2523: 1.0204520225524902\n",
      "Seen so far: 161536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2524: 0.9118345379829407\n",
      "Seen so far: 161600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2525: 0.9936401844024658\n",
      "Seen so far: 161664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2526: 0.8804721236228943\n",
      "Seen so far: 161728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2527: 0.991151750087738\n",
      "Seen so far: 161792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2528: 1.521323323249817\n",
      "Seen so far: 161856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2529: 1.2163386344909668\n",
      "Seen so far: 161920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2530: 0.7627074718475342\n",
      "Seen so far: 161984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2531: 0.8354547619819641\n",
      "Seen so far: 162048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2532: 0.6263951063156128\n",
      "Seen so far: 162112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2533: 1.118004560470581\n",
      "Seen so far: 162176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2534: 1.2361745834350586\n",
      "Seen so far: 162240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2535: 0.9727991819381714\n",
      "Seen so far: 162304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2536: 0.9687328934669495\n",
      "Seen so far: 162368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2537: 1.125633716583252\n",
      "Seen so far: 162432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2538: 0.6609448194503784\n",
      "Seen so far: 162496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2539: 1.2216726541519165\n",
      "Seen so far: 162560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2540: 1.3336412906646729\n",
      "Seen so far: 162624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2541: 1.4692964553833008\n",
      "Seen so far: 162688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2542: 0.9273462891578674\n",
      "Seen so far: 162752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2543: 1.1395827531814575\n",
      "Seen so far: 162816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2544: 1.1901192665100098\n",
      "Seen so far: 162880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2545: 1.3230952024459839\n",
      "Seen so far: 162944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2546: 0.7406682372093201\n",
      "Seen so far: 163008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2547: 1.270240306854248\n",
      "Seen so far: 163072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2548: 1.2762912511825562\n",
      "Seen so far: 163136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2549: 1.339404582977295\n",
      "Seen so far: 163200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2550: 1.0223798751831055\n",
      "Seen so far: 163264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2551: 0.8458551168441772\n",
      "Seen so far: 163328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2552: 0.7895598411560059\n",
      "Seen so far: 163392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2553: 1.245219349861145\n",
      "Seen so far: 163456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2554: 0.9628940224647522\n",
      "Seen so far: 163520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2555: 0.8733463883399963\n",
      "Seen so far: 163584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2556: 1.2208902835845947\n",
      "Seen so far: 163648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2557: 0.6513725519180298\n",
      "Seen so far: 163712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2558: 0.7597624063491821\n",
      "Seen so far: 163776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2559: 1.266923189163208\n",
      "Seen so far: 163840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2560: 1.1648643016815186\n",
      "Seen so far: 163904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2561: 1.235851764678955\n",
      "Seen so far: 163968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2562: 0.9105212688446045\n",
      "Seen so far: 164032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2563: 1.0392693281173706\n",
      "Seen so far: 164096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2564: 1.138521671295166\n",
      "Seen so far: 164160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2565: 0.8409356474876404\n",
      "Seen so far: 164224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2566: 1.076580286026001\n",
      "Seen so far: 164288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2567: 1.505976676940918\n",
      "Seen so far: 164352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2568: 1.3779264688491821\n",
      "Seen so far: 164416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2569: 0.9655831456184387\n",
      "Seen so far: 164480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2570: 1.0890095233917236\n",
      "Seen so far: 164544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2571: 0.7036082744598389\n",
      "Seen so far: 164608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2572: 1.2265793085098267\n",
      "Seen so far: 164672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2573: 0.7411990165710449\n",
      "Seen so far: 164736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2574: 0.895478367805481\n",
      "Seen so far: 164800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2575: 0.7224586009979248\n",
      "Seen so far: 164864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2576: 1.1229116916656494\n",
      "Seen so far: 164928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2577: 0.9565974473953247\n",
      "Seen so far: 164992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2578: 0.8218815326690674\n",
      "Seen so far: 165056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2579: 0.9892057180404663\n",
      "Seen so far: 165120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2580: 0.8028160333633423\n",
      "Seen so far: 165184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2581: 0.9511850476264954\n",
      "Seen so far: 165248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2582: 1.3002513647079468\n",
      "Seen so far: 165312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2583: 0.9051325917243958\n",
      "Seen so far: 165376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2584: 0.47926831245422363\n",
      "Seen so far: 165440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2585: 0.9896779656410217\n",
      "Seen so far: 165504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2586: 0.8004704713821411\n",
      "Seen so far: 165568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2587: 0.8433750867843628\n",
      "Seen so far: 165632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2588: 0.920538067817688\n",
      "Seen so far: 165696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2589: 1.0252702236175537\n",
      "Seen so far: 165760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2590: 1.1370117664337158\n",
      "Seen so far: 165824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2591: 1.164856195449829\n",
      "Seen so far: 165888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2592: 1.06039297580719\n",
      "Seen so far: 165952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2593: 1.1633836030960083\n",
      "Seen so far: 166016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2594: 1.0656118392944336\n",
      "Seen so far: 166080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2595: 1.0104939937591553\n",
      "Seen so far: 166144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2596: 0.9902249574661255\n",
      "Seen so far: 166208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2597: 1.010884165763855\n",
      "Seen so far: 166272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2598: 1.1750695705413818\n",
      "Seen so far: 166336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2599: 1.0131441354751587\n",
      "Seen so far: 166400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2600: 0.7984104156494141\n",
      "Seen so far: 166464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2601: 0.8615701794624329\n",
      "Seen so far: 166528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2602: 0.8194893598556519\n",
      "Seen so far: 166592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2603: 0.7650272846221924\n",
      "Seen so far: 166656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2604: 1.1604795455932617\n",
      "Seen so far: 166720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2605: 1.0530611276626587\n",
      "Seen so far: 166784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2606: 1.1948633193969727\n",
      "Seen so far: 166848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2607: 1.6270755529403687\n",
      "Seen so far: 166912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2608: 0.8663179278373718\n",
      "Seen so far: 166976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2609: 0.8533955812454224\n",
      "Seen so far: 167040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2610: 1.0136499404907227\n",
      "Seen so far: 167104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2611: 0.9495584964752197\n",
      "Seen so far: 167168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2612: 1.1358741521835327\n",
      "Seen so far: 167232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2613: 0.7127035856246948\n",
      "Seen so far: 167296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2614: 1.2643576860427856\n",
      "Seen so far: 167360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2615: 1.074150562286377\n",
      "Seen so far: 167424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2616: 0.8489294052124023\n",
      "Seen so far: 167488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2617: 1.0807411670684814\n",
      "Seen so far: 167552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2618: 0.8978880643844604\n",
      "Seen so far: 167616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2619: 1.5870171785354614\n",
      "Seen so far: 167680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2620: 0.889215350151062\n",
      "Seen so far: 167744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2621: 1.3318737745285034\n",
      "Seen so far: 167808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2622: 1.231261968612671\n",
      "Seen so far: 167872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2623: 0.9885311722755432\n",
      "Seen so far: 167936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2624: 1.1988856792449951\n",
      "Seen so far: 168000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2625: 0.8531322479248047\n",
      "Seen so far: 168064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2626: 0.9213311076164246\n",
      "Seen so far: 168128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2627: 1.1373989582061768\n",
      "Seen so far: 168192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2628: 0.579842209815979\n",
      "Seen so far: 168256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2629: 1.081440806388855\n",
      "Seen so far: 168320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2630: 1.0510708093643188\n",
      "Seen so far: 168384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2631: 1.1319266557693481\n",
      "Seen so far: 168448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2632: 0.975520670413971\n",
      "Seen so far: 168512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2633: 0.7767954468727112\n",
      "Seen so far: 168576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2634: 0.9229836463928223\n",
      "Seen so far: 168640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2635: 1.191318154335022\n",
      "Seen so far: 168704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2636: 1.2573473453521729\n",
      "Seen so far: 168768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2637: 0.9410812854766846\n",
      "Seen so far: 168832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2638: 1.9252358675003052\n",
      "Seen so far: 168896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2639: 1.1437926292419434\n",
      "Seen so far: 168960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2640: 0.9390125274658203\n",
      "Seen so far: 169024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2641: 0.8607128858566284\n",
      "Seen so far: 169088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2642: 0.8317450881004333\n",
      "Seen so far: 169152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2643: 1.0565611124038696\n",
      "Seen so far: 169216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2644: 0.9893912076950073\n",
      "Seen so far: 169280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2645: 1.0068752765655518\n",
      "Seen so far: 169344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2646: 0.8362910151481628\n",
      "Seen so far: 169408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2647: 0.9318796396255493\n",
      "Seen so far: 169472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2648: 0.909115731716156\n",
      "Seen so far: 169536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2649: 0.9609546661376953\n",
      "Seen so far: 169600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2650: 0.9275131225585938\n",
      "Seen so far: 169664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2651: 1.1761078834533691\n",
      "Seen so far: 169728 samples\n",
      "Training acc over epoch: 0.6452860236167908\n",
      "Start of epoch 3\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 0: 0.8396880626678467\n",
      "Seen so far: 64 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1: 0.9014725685119629\n",
      "Seen so far: 128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2: 0.8178271055221558\n",
      "Seen so far: 192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 3: 0.7476544380187988\n",
      "Seen so far: 256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 4: 0.8284446597099304\n",
      "Seen so far: 320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 5: 1.4125776290893555\n",
      "Seen so far: 384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 6: 1.3252248764038086\n",
      "Seen so far: 448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 7: 1.0078667402267456\n",
      "Seen so far: 512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 8: 1.4231090545654297\n",
      "Seen so far: 576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 9: 0.937986433506012\n",
      "Seen so far: 640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 10: 0.7279709577560425\n",
      "Seen so far: 704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 11: 0.7229620218276978\n",
      "Seen so far: 768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 12: 0.796967625617981\n",
      "Seen so far: 832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 13: 0.7634442448616028\n",
      "Seen so far: 896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 14: 1.4476933479309082\n",
      "Seen so far: 960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 15: 0.7910453081130981\n",
      "Seen so far: 1024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 16: 1.1007411479949951\n",
      "Seen so far: 1088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 17: 1.5815856456756592\n",
      "Seen so far: 1152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 18: 1.1617305278778076\n",
      "Seen so far: 1216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 19: 1.4063044786453247\n",
      "Seen so far: 1280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 20: 1.116817593574524\n",
      "Seen so far: 1344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 21: 1.188570261001587\n",
      "Seen so far: 1408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 22: 1.1702784299850464\n",
      "Seen so far: 1472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 23: 1.5919866561889648\n",
      "Seen so far: 1536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 24: 0.6573390960693359\n",
      "Seen so far: 1600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 25: 0.9161465764045715\n",
      "Seen so far: 1664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 26: 0.8827320337295532\n",
      "Seen so far: 1728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 27: 1.4878759384155273\n",
      "Seen so far: 1792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 28: 1.0664865970611572\n",
      "Seen so far: 1856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 29: 1.073725938796997\n",
      "Seen so far: 1920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 30: 1.1760540008544922\n",
      "Seen so far: 1984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 31: 1.163573980331421\n",
      "Seen so far: 2048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 32: 1.5554625988006592\n",
      "Seen so far: 2112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 33: 0.9315900802612305\n",
      "Seen so far: 2176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 34: 1.123772144317627\n",
      "Seen so far: 2240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 35: 1.226880669593811\n",
      "Seen so far: 2304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 36: 0.9290580153465271\n",
      "Seen so far: 2368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 37: 1.139070987701416\n",
      "Seen so far: 2432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 38: 0.9792370796203613\n",
      "Seen so far: 2496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 39: 1.0696935653686523\n",
      "Seen so far: 2560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 40: 1.0010955333709717\n",
      "Seen so far: 2624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 41: 1.5821919441223145\n",
      "Seen so far: 2688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 42: 1.156205177307129\n",
      "Seen so far: 2752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 43: 0.9901332855224609\n",
      "Seen so far: 2816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 44: 0.9911918044090271\n",
      "Seen so far: 2880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 45: 1.3163056373596191\n",
      "Seen so far: 2944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 46: 0.915296733379364\n",
      "Seen so far: 3008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 47: 0.7530496716499329\n",
      "Seen so far: 3072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 48: 1.058719515800476\n",
      "Seen so far: 3136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 49: 0.8004384636878967\n",
      "Seen so far: 3200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 50: 1.1533203125\n",
      "Seen so far: 3264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 51: 1.1447447538375854\n",
      "Seen so far: 3328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 52: 1.0467746257781982\n",
      "Seen so far: 3392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 53: 0.825325608253479\n",
      "Seen so far: 3456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 54: 0.6863717436790466\n",
      "Seen so far: 3520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 55: 1.3299667835235596\n",
      "Seen so far: 3584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 56: 1.4575318098068237\n",
      "Seen so far: 3648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 57: 1.5600550174713135\n",
      "Seen so far: 3712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 58: 0.6780045032501221\n",
      "Seen so far: 3776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 59: 0.6551269292831421\n",
      "Seen so far: 3840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 60: 0.5138226747512817\n",
      "Seen so far: 3904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 61: 0.6205440163612366\n",
      "Seen so far: 3968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 62: 1.1531720161437988\n",
      "Seen so far: 4032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 63: 0.862811267375946\n",
      "Seen so far: 4096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 64: 0.9865977764129639\n",
      "Seen so far: 4160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 65: 0.8493194580078125\n",
      "Seen so far: 4224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 66: 1.5297751426696777\n",
      "Seen so far: 4288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 67: 1.3796544075012207\n",
      "Seen so far: 4352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 68: 1.2505769729614258\n",
      "Seen so far: 4416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 69: 0.7355486750602722\n",
      "Seen so far: 4480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 70: 0.9015688300132751\n",
      "Seen so far: 4544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 71: 1.2360332012176514\n",
      "Seen so far: 4608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 72: 1.311560869216919\n",
      "Seen so far: 4672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 73: 0.9392836689949036\n",
      "Seen so far: 4736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 74: 1.0626389980316162\n",
      "Seen so far: 4800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 75: 0.9499477744102478\n",
      "Seen so far: 4864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 76: 1.3611629009246826\n",
      "Seen so far: 4928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 77: 0.8456556797027588\n",
      "Seen so far: 4992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 78: 0.8456213474273682\n",
      "Seen so far: 5056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 79: 1.2883610725402832\n",
      "Seen so far: 5120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 80: 0.795671820640564\n",
      "Seen so far: 5184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 81: 1.0283323526382446\n",
      "Seen so far: 5248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 82: 1.1512588262557983\n",
      "Seen so far: 5312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 83: 0.9721599817276001\n",
      "Seen so far: 5376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 84: 1.0394299030303955\n",
      "Seen so far: 5440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 85: 1.085437536239624\n",
      "Seen so far: 5504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 86: 0.9887259006500244\n",
      "Seen so far: 5568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 87: 1.2103832960128784\n",
      "Seen so far: 5632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 88: 1.009280800819397\n",
      "Seen so far: 5696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 89: 1.0216782093048096\n",
      "Seen so far: 5760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 90: 1.1490943431854248\n",
      "Seen so far: 5824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 91: 1.3616763353347778\n",
      "Seen so far: 5888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 92: 0.9147063493728638\n",
      "Seen so far: 5952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 93: 1.2999763488769531\n",
      "Seen so far: 6016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 94: 1.1463327407836914\n",
      "Seen so far: 6080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 95: 0.6325938105583191\n",
      "Seen so far: 6144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 96: 1.1015100479125977\n",
      "Seen so far: 6208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 97: 1.113685965538025\n",
      "Seen so far: 6272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 98: 0.8289092779159546\n",
      "Seen so far: 6336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 99: 1.0034126043319702\n",
      "Seen so far: 6400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 100: 0.8020792603492737\n",
      "Seen so far: 6464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 101: 0.639655590057373\n",
      "Seen so far: 6528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 102: 0.7657878398895264\n",
      "Seen so far: 6592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 103: 0.7907774448394775\n",
      "Seen so far: 6656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 104: 1.0311442613601685\n",
      "Seen so far: 6720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 105: 1.0979690551757812\n",
      "Seen so far: 6784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 106: 0.8031806945800781\n",
      "Seen so far: 6848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 107: 1.2121384143829346\n",
      "Seen so far: 6912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 108: 1.0250983238220215\n",
      "Seen so far: 6976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 109: 1.1048583984375\n",
      "Seen so far: 7040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 110: 0.8024780750274658\n",
      "Seen so far: 7104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 111: 0.9864874482154846\n",
      "Seen so far: 7168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 112: 0.6490976214408875\n",
      "Seen so far: 7232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 113: 1.033490538597107\n",
      "Seen so far: 7296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 114: 1.1955890655517578\n",
      "Seen so far: 7360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 115: 0.8345820903778076\n",
      "Seen so far: 7424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 116: 1.1835193634033203\n",
      "Seen so far: 7488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 117: 1.2395286560058594\n",
      "Seen so far: 7552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 118: 1.1809426546096802\n",
      "Seen so far: 7616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 119: 0.9546309113502502\n",
      "Seen so far: 7680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 120: 1.1138250827789307\n",
      "Seen so far: 7744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 121: 1.3864957094192505\n",
      "Seen so far: 7808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 122: 1.3661442995071411\n",
      "Seen so far: 7872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 123: 0.8388566970825195\n",
      "Seen so far: 7936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 124: 1.1590290069580078\n",
      "Seen so far: 8000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 125: 1.0906873941421509\n",
      "Seen so far: 8064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 126: 0.8263305425643921\n",
      "Seen so far: 8128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 127: 1.3671793937683105\n",
      "Seen so far: 8192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 128: 0.6969757676124573\n",
      "Seen so far: 8256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 129: 0.9549046158790588\n",
      "Seen so far: 8320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 130: 1.183371663093567\n",
      "Seen so far: 8384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 131: 1.3050258159637451\n",
      "Seen so far: 8448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 132: 0.962468147277832\n",
      "Seen so far: 8512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 133: 0.929764449596405\n",
      "Seen so far: 8576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 134: 1.2490053176879883\n",
      "Seen so far: 8640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 135: 1.5038156509399414\n",
      "Seen so far: 8704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 136: 1.2296154499053955\n",
      "Seen so far: 8768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 137: 1.4186939001083374\n",
      "Seen so far: 8832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 138: 0.7957127094268799\n",
      "Seen so far: 8896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 139: 1.0922801494598389\n",
      "Seen so far: 8960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 140: 1.026108980178833\n",
      "Seen so far: 9024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 141: 1.2401323318481445\n",
      "Seen so far: 9088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 142: 0.9548865556716919\n",
      "Seen so far: 9152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 143: 1.1001029014587402\n",
      "Seen so far: 9216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 144: 1.2910517454147339\n",
      "Seen so far: 9280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 145: 1.0226027965545654\n",
      "Seen so far: 9344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 146: 0.8653368949890137\n",
      "Seen so far: 9408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 147: 1.1676167249679565\n",
      "Seen so far: 9472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 148: 1.649405598640442\n",
      "Seen so far: 9536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 149: 0.9772334694862366\n",
      "Seen so far: 9600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 150: 0.7218490242958069\n",
      "Seen so far: 9664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 151: 0.8566930890083313\n",
      "Seen so far: 9728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 152: 1.4888209104537964\n",
      "Seen so far: 9792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 153: 1.4060587882995605\n",
      "Seen so far: 9856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 154: 1.8034827709197998\n",
      "Seen so far: 9920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 155: 0.8809105157852173\n",
      "Seen so far: 9984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 156: 1.1179512739181519\n",
      "Seen so far: 10048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 157: 1.0604579448699951\n",
      "Seen so far: 10112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 158: 1.5872260332107544\n",
      "Seen so far: 10176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 159: 1.4098381996154785\n",
      "Seen so far: 10240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 160: 0.9221134185791016\n",
      "Seen so far: 10304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 161: 1.1420371532440186\n",
      "Seen so far: 10368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 162: 1.4499707221984863\n",
      "Seen so far: 10432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 163: 0.9580557942390442\n",
      "Seen so far: 10496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 164: 1.3557188510894775\n",
      "Seen so far: 10560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 165: 1.0465978384017944\n",
      "Seen so far: 10624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 166: 0.8498115539550781\n",
      "Seen so far: 10688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 167: 0.8717358708381653\n",
      "Seen so far: 10752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 168: 1.3062418699264526\n",
      "Seen so far: 10816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 169: 0.8053126335144043\n",
      "Seen so far: 10880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 170: 1.1548280715942383\n",
      "Seen so far: 10944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 171: 1.1309038400650024\n",
      "Seen so far: 11008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 172: 1.133768081665039\n",
      "Seen so far: 11072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 173: 1.020595908164978\n",
      "Seen so far: 11136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 174: 1.3632287979125977\n",
      "Seen so far: 11200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 175: 0.9331865906715393\n",
      "Seen so far: 11264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 176: 1.2317477464675903\n",
      "Seen so far: 11328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 177: 0.7739428281784058\n",
      "Seen so far: 11392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 178: 0.9768710136413574\n",
      "Seen so far: 11456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 179: 0.8390941023826599\n",
      "Seen so far: 11520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 180: 0.9830958843231201\n",
      "Seen so far: 11584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 181: 1.1497018337249756\n",
      "Seen so far: 11648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 182: 0.9096752405166626\n",
      "Seen so far: 11712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 183: 1.334911823272705\n",
      "Seen so far: 11776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 184: 1.123148798942566\n",
      "Seen so far: 11840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 185: 1.2148287296295166\n",
      "Seen so far: 11904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 186: 1.073652744293213\n",
      "Seen so far: 11968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 187: 1.2831592559814453\n",
      "Seen so far: 12032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 188: 1.3460273742675781\n",
      "Seen so far: 12096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 189: 1.0840435028076172\n",
      "Seen so far: 12160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 190: 1.3628523349761963\n",
      "Seen so far: 12224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 191: 0.5744354724884033\n",
      "Seen so far: 12288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 192: 1.1687527894973755\n",
      "Seen so far: 12352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 193: 1.31997811794281\n",
      "Seen so far: 12416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 194: 1.257568120956421\n",
      "Seen so far: 12480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 195: 1.0249395370483398\n",
      "Seen so far: 12544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 196: 0.7517309188842773\n",
      "Seen so far: 12608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 197: 0.9047752022743225\n",
      "Seen so far: 12672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 198: 1.4070013761520386\n",
      "Seen so far: 12736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 199: 0.9934290051460266\n",
      "Seen so far: 12800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 200: 1.0424981117248535\n",
      "Seen so far: 12864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 201: 0.8408420085906982\n",
      "Seen so far: 12928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 202: 1.0771125555038452\n",
      "Seen so far: 12992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 203: 0.957342267036438\n",
      "Seen so far: 13056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 204: 1.2159528732299805\n",
      "Seen so far: 13120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 205: 0.7957918643951416\n",
      "Seen so far: 13184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 206: 1.4447352886199951\n",
      "Seen so far: 13248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 207: 1.1758267879486084\n",
      "Seen so far: 13312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 208: 1.279623031616211\n",
      "Seen so far: 13376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 209: 1.1018357276916504\n",
      "Seen so far: 13440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 210: 1.0746510028839111\n",
      "Seen so far: 13504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 211: 1.068967342376709\n",
      "Seen so far: 13568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 212: 1.4330341815948486\n",
      "Seen so far: 13632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 213: 1.211883544921875\n",
      "Seen so far: 13696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 214: 1.2210195064544678\n",
      "Seen so far: 13760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 215: 1.0494897365570068\n",
      "Seen so far: 13824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 216: 0.753289520740509\n",
      "Seen so far: 13888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 217: 1.027618169784546\n",
      "Seen so far: 13952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 218: 0.9003086686134338\n",
      "Seen so far: 14016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 219: 0.8751190304756165\n",
      "Seen so far: 14080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 220: 1.1991119384765625\n",
      "Seen so far: 14144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 221: 0.9595394134521484\n",
      "Seen so far: 14208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 222: 1.1009001731872559\n",
      "Seen so far: 14272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 223: 1.0570404529571533\n",
      "Seen so far: 14336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 224: 0.6940969228744507\n",
      "Seen so far: 14400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 225: 1.0073121786117554\n",
      "Seen so far: 14464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 226: 0.8123836517333984\n",
      "Seen so far: 14528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 227: 1.0093729496002197\n",
      "Seen so far: 14592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 228: 1.0004820823669434\n",
      "Seen so far: 14656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 229: 1.1659640073776245\n",
      "Seen so far: 14720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 230: 0.8861021399497986\n",
      "Seen so far: 14784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 231: 0.9762123227119446\n",
      "Seen so far: 14848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 232: 1.1026346683502197\n",
      "Seen so far: 14912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 233: 1.3658640384674072\n",
      "Seen so far: 14976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 234: 1.0035754442214966\n",
      "Seen so far: 15040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 235: 0.6334362626075745\n",
      "Seen so far: 15104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 236: 0.9652968049049377\n",
      "Seen so far: 15168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 237: 1.0050808191299438\n",
      "Seen so far: 15232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 238: 1.2303870916366577\n",
      "Seen so far: 15296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 239: 1.1014988422393799\n",
      "Seen so far: 15360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 240: 1.1566108465194702\n",
      "Seen so far: 15424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 241: 1.019080638885498\n",
      "Seen so far: 15488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 242: 1.242728590965271\n",
      "Seen so far: 15552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 243: 0.9198042750358582\n",
      "Seen so far: 15616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 244: 1.2113332748413086\n",
      "Seen so far: 15680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 245: 1.1424531936645508\n",
      "Seen so far: 15744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 246: 1.3111127614974976\n",
      "Seen so far: 15808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 247: 1.2195638418197632\n",
      "Seen so far: 15872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 248: 0.8208237290382385\n",
      "Seen so far: 15936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 249: 0.8563973903656006\n",
      "Seen so far: 16000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 250: 1.202972173690796\n",
      "Seen so far: 16064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 251: 1.3656076192855835\n",
      "Seen so far: 16128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 252: 1.3679721355438232\n",
      "Seen so far: 16192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 253: 0.9296976923942566\n",
      "Seen so far: 16256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 254: 0.8881333470344543\n",
      "Seen so far: 16320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 255: 1.090470314025879\n",
      "Seen so far: 16384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 256: 1.1543734073638916\n",
      "Seen so far: 16448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 257: 1.523834466934204\n",
      "Seen so far: 16512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 258: 0.7982686161994934\n",
      "Seen so far: 16576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 259: 0.9891347885131836\n",
      "Seen so far: 16640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 260: 0.5545246601104736\n",
      "Seen so far: 16704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 261: 1.0809897184371948\n",
      "Seen so far: 16768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 262: 1.4851670265197754\n",
      "Seen so far: 16832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 263: 1.022583246231079\n",
      "Seen so far: 16896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 264: 0.748008131980896\n",
      "Seen so far: 16960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 265: 1.072271704673767\n",
      "Seen so far: 17024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 266: 0.7093291282653809\n",
      "Seen so far: 17088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 267: 0.9947856068611145\n",
      "Seen so far: 17152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 268: 1.088439702987671\n",
      "Seen so far: 17216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 269: 0.9197044372558594\n",
      "Seen so far: 17280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 270: 0.639834463596344\n",
      "Seen so far: 17344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 271: 1.3516886234283447\n",
      "Seen so far: 17408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 272: 0.8416893482208252\n",
      "Seen so far: 17472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 273: 1.2432360649108887\n",
      "Seen so far: 17536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 274: 1.067081093788147\n",
      "Seen so far: 17600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 275: 0.7334595322608948\n",
      "Seen so far: 17664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 276: 1.2789571285247803\n",
      "Seen so far: 17728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 277: 1.4741735458374023\n",
      "Seen so far: 17792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 278: 0.8747991323471069\n",
      "Seen so far: 17856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 279: 1.2632554769515991\n",
      "Seen so far: 17920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 280: 0.7934934496879578\n",
      "Seen so far: 17984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 281: 0.9969621896743774\n",
      "Seen so far: 18048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 282: 0.9370282888412476\n",
      "Seen so far: 18112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 283: 0.666935920715332\n",
      "Seen so far: 18176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 284: 0.6935418844223022\n",
      "Seen so far: 18240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 285: 0.7121981978416443\n",
      "Seen so far: 18304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 286: 0.8254388570785522\n",
      "Seen so far: 18368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 287: 0.7090011835098267\n",
      "Seen so far: 18432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 288: 1.1275553703308105\n",
      "Seen so far: 18496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 289: 0.8561477661132812\n",
      "Seen so far: 18560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 290: 1.2621874809265137\n",
      "Seen so far: 18624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 291: 0.572422981262207\n",
      "Seen so far: 18688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 292: 1.223992109298706\n",
      "Seen so far: 18752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 293: 1.2537987232208252\n",
      "Seen so far: 18816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 294: 0.6700297594070435\n",
      "Seen so far: 18880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 295: 1.2487961053848267\n",
      "Seen so far: 18944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 296: 1.0666954517364502\n",
      "Seen so far: 19008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 297: 0.8630956411361694\n",
      "Seen so far: 19072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 298: 0.8400897979736328\n",
      "Seen so far: 19136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 299: 1.4625184535980225\n",
      "Seen so far: 19200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 300: 0.8759793043136597\n",
      "Seen so far: 19264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 301: 0.97322016954422\n",
      "Seen so far: 19328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 302: 0.8027517795562744\n",
      "Seen so far: 19392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 303: 0.8152863383293152\n",
      "Seen so far: 19456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 304: 1.1522804498672485\n",
      "Seen so far: 19520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 305: 0.9950894117355347\n",
      "Seen so far: 19584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 306: 1.2647547721862793\n",
      "Seen so far: 19648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 307: 1.0150572061538696\n",
      "Seen so far: 19712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 308: 1.1119110584259033\n",
      "Seen so far: 19776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 309: 0.7852269411087036\n",
      "Seen so far: 19840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 310: 0.9316304922103882\n",
      "Seen so far: 19904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 311: 1.1218695640563965\n",
      "Seen so far: 19968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 312: 1.2423231601715088\n",
      "Seen so far: 20032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 313: 0.9633910059928894\n",
      "Seen so far: 20096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 314: 1.1136493682861328\n",
      "Seen so far: 20160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 315: 0.7342519164085388\n",
      "Seen so far: 20224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 316: 0.9898908138275146\n",
      "Seen so far: 20288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 317: 1.1015117168426514\n",
      "Seen so far: 20352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 318: 1.2859516143798828\n",
      "Seen so far: 20416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 319: 0.9828433990478516\n",
      "Seen so far: 20480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 320: 1.082418441772461\n",
      "Seen so far: 20544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 321: 0.982380747795105\n",
      "Seen so far: 20608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 322: 0.9466496706008911\n",
      "Seen so far: 20672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 323: 1.2269196510314941\n",
      "Seen so far: 20736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 324: 1.2472492456436157\n",
      "Seen so far: 20800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 325: 0.907707691192627\n",
      "Seen so far: 20864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 326: 0.7654459476470947\n",
      "Seen so far: 20928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 327: 1.237316370010376\n",
      "Seen so far: 20992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 328: 1.0507442951202393\n",
      "Seen so far: 21056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 329: 1.2654109001159668\n",
      "Seen so far: 21120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 330: 0.9618498086929321\n",
      "Seen so far: 21184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 331: 0.9636434316635132\n",
      "Seen so far: 21248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 332: 1.0322234630584717\n",
      "Seen so far: 21312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 333: 1.0270508527755737\n",
      "Seen so far: 21376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 334: 0.8829723596572876\n",
      "Seen so far: 21440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 335: 1.2510789632797241\n",
      "Seen so far: 21504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 336: 1.1745631694793701\n",
      "Seen so far: 21568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 337: 0.7895352840423584\n",
      "Seen so far: 21632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 338: 0.941888153553009\n",
      "Seen so far: 21696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 339: 0.8532258868217468\n",
      "Seen so far: 21760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 340: 0.90528404712677\n",
      "Seen so far: 21824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 341: 1.3353676795959473\n",
      "Seen so far: 21888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 342: 1.3295040130615234\n",
      "Seen so far: 21952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 343: 1.3313895463943481\n",
      "Seen so far: 22016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 344: 1.1326758861541748\n",
      "Seen so far: 22080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 345: 0.8226083517074585\n",
      "Seen so far: 22144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 346: 0.7706923484802246\n",
      "Seen so far: 22208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 347: 1.352846384048462\n",
      "Seen so far: 22272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 348: 0.5401132106781006\n",
      "Seen so far: 22336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 349: 1.1522908210754395\n",
      "Seen so far: 22400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 350: 1.1393067836761475\n",
      "Seen so far: 22464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 351: 0.7797475457191467\n",
      "Seen so far: 22528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 352: 1.1014440059661865\n",
      "Seen so far: 22592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 353: 0.9714064002037048\n",
      "Seen so far: 22656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 354: 1.0791538953781128\n",
      "Seen so far: 22720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 355: 1.0911704301834106\n",
      "Seen so far: 22784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 356: 0.7354739308357239\n",
      "Seen so far: 22848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 357: 1.2641377449035645\n",
      "Seen so far: 22912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 358: 1.3688445091247559\n",
      "Seen so far: 22976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 359: 1.0452673435211182\n",
      "Seen so far: 23040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 360: 1.1792166233062744\n",
      "Seen so far: 23104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 361: 0.8521122932434082\n",
      "Seen so far: 23168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 362: 1.148761510848999\n",
      "Seen so far: 23232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 363: 1.0306531190872192\n",
      "Seen so far: 23296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 364: 0.9715853929519653\n",
      "Seen so far: 23360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 365: 1.2872480154037476\n",
      "Seen so far: 23424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 366: 1.265060544013977\n",
      "Seen so far: 23488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 367: 1.0667898654937744\n",
      "Seen so far: 23552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 368: 1.0793384313583374\n",
      "Seen so far: 23616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 369: 1.2073930501937866\n",
      "Seen so far: 23680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 370: 0.6595766544342041\n",
      "Seen so far: 23744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 371: 1.2734426259994507\n",
      "Seen so far: 23808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 372: 0.5616010427474976\n",
      "Seen so far: 23872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 373: 1.2518571615219116\n",
      "Seen so far: 23936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 374: 1.1385629177093506\n",
      "Seen so far: 24000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 375: 1.1781034469604492\n",
      "Seen so far: 24064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 376: 0.76865553855896\n",
      "Seen so far: 24128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 377: 1.3990216255187988\n",
      "Seen so far: 24192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 378: 0.8919903039932251\n",
      "Seen so far: 24256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 379: 0.8337864875793457\n",
      "Seen so far: 24320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 380: 1.1536962985992432\n",
      "Seen so far: 24384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 381: 0.8985902070999146\n",
      "Seen so far: 24448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 382: 0.842780590057373\n",
      "Seen so far: 24512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 383: 1.1100642681121826\n",
      "Seen so far: 24576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 384: 0.9885212779045105\n",
      "Seen so far: 24640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 385: 1.2328317165374756\n",
      "Seen so far: 24704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 386: 1.4863717555999756\n",
      "Seen so far: 24768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 387: 1.0167133808135986\n",
      "Seen so far: 24832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 388: 1.2906501293182373\n",
      "Seen so far: 24896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 389: 0.8110602498054504\n",
      "Seen so far: 24960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 390: 1.3406583070755005\n",
      "Seen so far: 25024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 391: 0.6719335317611694\n",
      "Seen so far: 25088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 392: 1.0952630043029785\n",
      "Seen so far: 25152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 393: 1.1250998973846436\n",
      "Seen so far: 25216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 394: 0.668012261390686\n",
      "Seen so far: 25280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 395: 1.252375602722168\n",
      "Seen so far: 25344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 396: 0.9640023708343506\n",
      "Seen so far: 25408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 397: 1.306471347808838\n",
      "Seen so far: 25472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 398: 0.766555666923523\n",
      "Seen so far: 25536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 399: 1.236349105834961\n",
      "Seen so far: 25600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 400: 0.8658344745635986\n",
      "Seen so far: 25664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 401: 0.9364708662033081\n",
      "Seen so far: 25728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 402: 1.2913204431533813\n",
      "Seen so far: 25792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 403: 1.0313982963562012\n",
      "Seen so far: 25856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 404: 0.6828116178512573\n",
      "Seen so far: 25920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 405: 0.8577617406845093\n",
      "Seen so far: 25984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 406: 1.1794651746749878\n",
      "Seen so far: 26048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 407: 1.060935616493225\n",
      "Seen so far: 26112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 408: 1.1872529983520508\n",
      "Seen so far: 26176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 409: 0.994046688079834\n",
      "Seen so far: 26240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 410: 0.6488304138183594\n",
      "Seen so far: 26304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 411: 1.31000816822052\n",
      "Seen so far: 26368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 412: 1.2181832790374756\n",
      "Seen so far: 26432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 413: 1.051577091217041\n",
      "Seen so far: 26496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 414: 0.5035157203674316\n",
      "Seen so far: 26560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 415: 0.998488187789917\n",
      "Seen so far: 26624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 416: 1.0593260526657104\n",
      "Seen so far: 26688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 417: 1.1554954051971436\n",
      "Seen so far: 26752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 418: 1.2235435247421265\n",
      "Seen so far: 26816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 419: 1.4523473978042603\n",
      "Seen so far: 26880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 420: 0.9762399196624756\n",
      "Seen so far: 26944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 421: 1.5774683952331543\n",
      "Seen so far: 27008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 422: 0.7534176111221313\n",
      "Seen so far: 27072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 423: 1.1368982791900635\n",
      "Seen so far: 27136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 424: 1.2301642894744873\n",
      "Seen so far: 27200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 425: 1.1701338291168213\n",
      "Seen so far: 27264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 426: 1.3187170028686523\n",
      "Seen so far: 27328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 427: 1.3307695388793945\n",
      "Seen so far: 27392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 428: 1.069396734237671\n",
      "Seen so far: 27456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 429: 1.0982420444488525\n",
      "Seen so far: 27520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 430: 1.0221424102783203\n",
      "Seen so far: 27584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 431: 0.989671528339386\n",
      "Seen so far: 27648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 432: 1.3177398443222046\n",
      "Seen so far: 27712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 433: 0.7663824558258057\n",
      "Seen so far: 27776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 434: 1.0195326805114746\n",
      "Seen so far: 27840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 435: 1.0821599960327148\n",
      "Seen so far: 27904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 436: 0.7776697278022766\n",
      "Seen so far: 27968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 437: 0.9711118340492249\n",
      "Seen so far: 28032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 438: 1.30280339717865\n",
      "Seen so far: 28096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 439: 1.1872245073318481\n",
      "Seen so far: 28160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 440: 1.178786039352417\n",
      "Seen so far: 28224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 441: 1.0792267322540283\n",
      "Seen so far: 28288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 442: 1.1064844131469727\n",
      "Seen so far: 28352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 443: 0.6113616228103638\n",
      "Seen so far: 28416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 444: 1.2420296669006348\n",
      "Seen so far: 28480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 445: 1.340644121170044\n",
      "Seen so far: 28544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 446: 0.8381495475769043\n",
      "Seen so far: 28608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 447: 1.0509660243988037\n",
      "Seen so far: 28672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 448: 0.8860348463058472\n",
      "Seen so far: 28736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 449: 0.9913187026977539\n",
      "Seen so far: 28800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 450: 1.4318351745605469\n",
      "Seen so far: 28864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 451: 1.0817707777023315\n",
      "Seen so far: 28928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 452: 1.377763271331787\n",
      "Seen so far: 28992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 453: 1.2268047332763672\n",
      "Seen so far: 29056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 454: 1.0798969268798828\n",
      "Seen so far: 29120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 455: 0.8275101184844971\n",
      "Seen so far: 29184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 456: 1.07122802734375\n",
      "Seen so far: 29248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 457: 0.7166642546653748\n",
      "Seen so far: 29312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 458: 1.3267381191253662\n",
      "Seen so far: 29376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 459: 0.9270905256271362\n",
      "Seen so far: 29440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 460: 1.2464033365249634\n",
      "Seen so far: 29504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 461: 1.0199075937271118\n",
      "Seen so far: 29568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 462: 0.9868132472038269\n",
      "Seen so far: 29632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 463: 1.1611638069152832\n",
      "Seen so far: 29696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 464: 0.9826650023460388\n",
      "Seen so far: 29760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 465: 0.8233962059020996\n",
      "Seen so far: 29824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 466: 0.9558905959129333\n",
      "Seen so far: 29888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 467: 0.996059238910675\n",
      "Seen so far: 29952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 468: 1.1116442680358887\n",
      "Seen so far: 30016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 469: 0.8825159668922424\n",
      "Seen so far: 30080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 470: 0.8347383737564087\n",
      "Seen so far: 30144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 471: 0.9236743450164795\n",
      "Seen so far: 30208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 472: 0.9985501170158386\n",
      "Seen so far: 30272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 473: 0.9583640098571777\n",
      "Seen so far: 30336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 474: 0.7843236923217773\n",
      "Seen so far: 30400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 475: 1.0753047466278076\n",
      "Seen so far: 30464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 476: 0.846676766872406\n",
      "Seen so far: 30528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 477: 1.1350748538970947\n",
      "Seen so far: 30592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 478: 0.9074795246124268\n",
      "Seen so far: 30656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 479: 1.2649881839752197\n",
      "Seen so far: 30720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 480: 0.8815209269523621\n",
      "Seen so far: 30784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 481: 1.000833511352539\n",
      "Seen so far: 30848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 482: 0.7114217877388\n",
      "Seen so far: 30912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 483: 1.1928112506866455\n",
      "Seen so far: 30976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 484: 0.8946638107299805\n",
      "Seen so far: 31040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 485: 0.8192353844642639\n",
      "Seen so far: 31104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 486: 1.0860669612884521\n",
      "Seen so far: 31168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 487: 0.8864368200302124\n",
      "Seen so far: 31232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 488: 1.1460041999816895\n",
      "Seen so far: 31296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 489: 1.2329065799713135\n",
      "Seen so far: 31360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 490: 0.9931994676589966\n",
      "Seen so far: 31424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 491: 1.1720435619354248\n",
      "Seen so far: 31488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 492: 1.047635793685913\n",
      "Seen so far: 31552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 493: 0.9717493057250977\n",
      "Seen so far: 31616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 494: 0.8853265643119812\n",
      "Seen so far: 31680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 495: 0.888089120388031\n",
      "Seen so far: 31744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 496: 1.2171151638031006\n",
      "Seen so far: 31808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 497: 1.0297839641571045\n",
      "Seen so far: 31872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 498: 1.0208109617233276\n",
      "Seen so far: 31936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 499: 1.418769121170044\n",
      "Seen so far: 32000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 500: 0.7640748620033264\n",
      "Seen so far: 32064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 501: 0.811752438545227\n",
      "Seen so far: 32128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 502: 0.8946224451065063\n",
      "Seen so far: 32192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 503: 0.8118369579315186\n",
      "Seen so far: 32256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 504: 1.4000614881515503\n",
      "Seen so far: 32320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 505: 1.1902923583984375\n",
      "Seen so far: 32384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 506: 1.160965919494629\n",
      "Seen so far: 32448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 507: 1.444419264793396\n",
      "Seen so far: 32512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 508: 0.8292225003242493\n",
      "Seen so far: 32576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 509: 0.9286381006240845\n",
      "Seen so far: 32640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 510: 1.1164222955703735\n",
      "Seen so far: 32704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 511: 1.1481103897094727\n",
      "Seen so far: 32768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 512: 1.0648319721221924\n",
      "Seen so far: 32832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 513: 1.2533928155899048\n",
      "Seen so far: 32896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 514: 0.9107545018196106\n",
      "Seen so far: 32960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 515: 0.9551619291305542\n",
      "Seen so far: 33024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 516: 0.8812952041625977\n",
      "Seen so far: 33088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 517: 1.2136456966400146\n",
      "Seen so far: 33152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 518: 0.9509435296058655\n",
      "Seen so far: 33216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 519: 0.9671756029129028\n",
      "Seen so far: 33280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 520: 0.9934945702552795\n",
      "Seen so far: 33344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 521: 0.8141158819198608\n",
      "Seen so far: 33408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 522: 0.8482775092124939\n",
      "Seen so far: 33472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 523: 1.095163345336914\n",
      "Seen so far: 33536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 524: 0.9568366408348083\n",
      "Seen so far: 33600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 525: 1.0215083360671997\n",
      "Seen so far: 33664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 526: 1.2118052244186401\n",
      "Seen so far: 33728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 527: 1.1242876052856445\n",
      "Seen so far: 33792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 528: 0.872579038143158\n",
      "Seen so far: 33856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 529: 0.6418907642364502\n",
      "Seen so far: 33920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 530: 0.9899648427963257\n",
      "Seen so far: 33984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 531: 0.5509293079376221\n",
      "Seen so far: 34048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 532: 0.9467370510101318\n",
      "Seen so far: 34112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 533: 1.3807263374328613\n",
      "Seen so far: 34176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 534: 0.994671642780304\n",
      "Seen so far: 34240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 535: 1.243586778640747\n",
      "Seen so far: 34304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 536: 0.8622905611991882\n",
      "Seen so far: 34368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 537: 0.9554765224456787\n",
      "Seen so far: 34432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 538: 0.8129168152809143\n",
      "Seen so far: 34496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 539: 0.699859619140625\n",
      "Seen so far: 34560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 540: 1.0800464153289795\n",
      "Seen so far: 34624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 541: 0.8102256655693054\n",
      "Seen so far: 34688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 542: 0.909646213054657\n",
      "Seen so far: 34752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 543: 0.8150920867919922\n",
      "Seen so far: 34816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 544: 0.6553949117660522\n",
      "Seen so far: 34880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 545: 1.1661094427108765\n",
      "Seen so far: 34944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 546: 0.8809249997138977\n",
      "Seen so far: 35008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 547: 1.1449522972106934\n",
      "Seen so far: 35072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 548: 1.2743028402328491\n",
      "Seen so far: 35136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 549: 0.9275059103965759\n",
      "Seen so far: 35200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 550: 0.9871865510940552\n",
      "Seen so far: 35264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 551: 0.6228888034820557\n",
      "Seen so far: 35328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 552: 0.8786326050758362\n",
      "Seen so far: 35392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 553: 1.0344663858413696\n",
      "Seen so far: 35456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 554: 1.109497308731079\n",
      "Seen so far: 35520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 555: 1.334976077079773\n",
      "Seen so far: 35584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 556: 0.9401671886444092\n",
      "Seen so far: 35648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 557: 1.093008279800415\n",
      "Seen so far: 35712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 558: 0.705394446849823\n",
      "Seen so far: 35776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 559: 1.12553071975708\n",
      "Seen so far: 35840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 560: 1.0651640892028809\n",
      "Seen so far: 35904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 561: 0.8981020450592041\n",
      "Seen so far: 35968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 562: 1.2564207315444946\n",
      "Seen so far: 36032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 563: 1.0510555505752563\n",
      "Seen so far: 36096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 564: 0.7663819789886475\n",
      "Seen so far: 36160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 565: 0.8988163471221924\n",
      "Seen so far: 36224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 566: 0.8830398321151733\n",
      "Seen so far: 36288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 567: 0.8778873682022095\n",
      "Seen so far: 36352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 568: 0.9483832120895386\n",
      "Seen so far: 36416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 569: 0.8511236906051636\n",
      "Seen so far: 36480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 570: 1.3136167526245117\n",
      "Seen so far: 36544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 571: 1.1198333501815796\n",
      "Seen so far: 36608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 572: 1.1572619676589966\n",
      "Seen so far: 36672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 573: 1.0656580924987793\n",
      "Seen so far: 36736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 574: 1.0058602094650269\n",
      "Seen so far: 36800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 575: 1.3674589395523071\n",
      "Seen so far: 36864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 576: 0.756826639175415\n",
      "Seen so far: 36928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 577: 1.2625662088394165\n",
      "Seen so far: 36992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 578: 0.8448466062545776\n",
      "Seen so far: 37056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 579: 1.174893856048584\n",
      "Seen so far: 37120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 580: 0.7848502397537231\n",
      "Seen so far: 37184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 581: 0.9023553133010864\n",
      "Seen so far: 37248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 582: 1.5924856662750244\n",
      "Seen so far: 37312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 583: 1.026634693145752\n",
      "Seen so far: 37376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 584: 1.0377931594848633\n",
      "Seen so far: 37440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 585: 0.8199989795684814\n",
      "Seen so far: 37504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 586: 1.2087268829345703\n",
      "Seen so far: 37568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 587: 0.7311198115348816\n",
      "Seen so far: 37632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 588: 0.915416419506073\n",
      "Seen so far: 37696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 589: 0.9323525428771973\n",
      "Seen so far: 37760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 590: 0.9743303060531616\n",
      "Seen so far: 37824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 591: 0.8354682326316833\n",
      "Seen so far: 37888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 592: 0.9877683520317078\n",
      "Seen so far: 37952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 593: 1.1574190855026245\n",
      "Seen so far: 38016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 594: 0.6027933359146118\n",
      "Seen so far: 38080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 595: 1.0264356136322021\n",
      "Seen so far: 38144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 596: 1.070435881614685\n",
      "Seen so far: 38208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 597: 0.94287109375\n",
      "Seen so far: 38272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 598: 0.6642497777938843\n",
      "Seen so far: 38336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 599: 0.7183943390846252\n",
      "Seen so far: 38400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 600: 0.6722017526626587\n",
      "Seen so far: 38464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 601: 0.6014365553855896\n",
      "Seen so far: 38528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 602: 1.1765594482421875\n",
      "Seen so far: 38592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 603: 1.6912081241607666\n",
      "Seen so far: 38656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 604: 1.2399954795837402\n",
      "Seen so far: 38720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 605: 0.7832856178283691\n",
      "Seen so far: 38784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 606: 1.8248463869094849\n",
      "Seen so far: 38848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 607: 1.1464393138885498\n",
      "Seen so far: 38912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 608: 1.0182477235794067\n",
      "Seen so far: 38976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 609: 1.0724126100540161\n",
      "Seen so far: 39040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 610: 0.7000977993011475\n",
      "Seen so far: 39104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 611: 0.7354540228843689\n",
      "Seen so far: 39168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 612: 0.851863443851471\n",
      "Seen so far: 39232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 613: 0.8872186541557312\n",
      "Seen so far: 39296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 614: 1.0751616954803467\n",
      "Seen so far: 39360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 615: 0.9393316507339478\n",
      "Seen so far: 39424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 616: 0.8796860575675964\n",
      "Seen so far: 39488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 617: 1.2896325588226318\n",
      "Seen so far: 39552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 618: 1.2915802001953125\n",
      "Seen so far: 39616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 619: 0.8350318670272827\n",
      "Seen so far: 39680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 620: 1.0669811964035034\n",
      "Seen so far: 39744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 621: 1.1628341674804688\n",
      "Seen so far: 39808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 622: 1.1435000896453857\n",
      "Seen so far: 39872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 623: 0.8524782657623291\n",
      "Seen so far: 39936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 624: 0.9001251459121704\n",
      "Seen so far: 40000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 625: 0.9271854162216187\n",
      "Seen so far: 40064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 626: 0.803504228591919\n",
      "Seen so far: 40128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 627: 0.6986574530601501\n",
      "Seen so far: 40192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 628: 1.0109539031982422\n",
      "Seen so far: 40256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 629: 1.1514906883239746\n",
      "Seen so far: 40320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 630: 1.0931909084320068\n",
      "Seen so far: 40384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 631: 0.9795439839363098\n",
      "Seen so far: 40448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 632: 1.0584317445755005\n",
      "Seen so far: 40512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 633: 0.9553554654121399\n",
      "Seen so far: 40576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 634: 0.690780758857727\n",
      "Seen so far: 40640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 635: 0.9091333150863647\n",
      "Seen so far: 40704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 636: 1.2050416469573975\n",
      "Seen so far: 40768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 637: 0.4139827489852905\n",
      "Seen so far: 40832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 638: 0.7271902561187744\n",
      "Seen so far: 40896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 639: 0.8775227069854736\n",
      "Seen so far: 40960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 640: 0.6913741827011108\n",
      "Seen so far: 41024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 641: 0.3922424614429474\n",
      "Seen so far: 41088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 642: 0.7580869197845459\n",
      "Seen so far: 41152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 643: 0.7448149919509888\n",
      "Seen so far: 41216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 644: 0.9936977624893188\n",
      "Seen so far: 41280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 645: 0.9572999477386475\n",
      "Seen so far: 41344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 646: 0.9411748647689819\n",
      "Seen so far: 41408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 647: 0.8864063024520874\n",
      "Seen so far: 41472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 648: 0.9101459383964539\n",
      "Seen so far: 41536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 649: 1.0591305494308472\n",
      "Seen so far: 41600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 650: 1.1563010215759277\n",
      "Seen so far: 41664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 651: 1.0233818292617798\n",
      "Seen so far: 41728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 652: 1.0540125370025635\n",
      "Seen so far: 41792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 653: 0.929608941078186\n",
      "Seen so far: 41856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 654: 1.0532219409942627\n",
      "Seen so far: 41920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 655: 0.9583116173744202\n",
      "Seen so far: 41984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 656: 0.9247796535491943\n",
      "Seen so far: 42048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 657: 1.4906017780303955\n",
      "Seen so far: 42112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 658: 0.8959519863128662\n",
      "Seen so far: 42176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 659: 0.852642834186554\n",
      "Seen so far: 42240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 660: 1.2545467615127563\n",
      "Seen so far: 42304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 661: 0.9888064861297607\n",
      "Seen so far: 42368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 662: 0.9827463030815125\n",
      "Seen so far: 42432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 663: 1.170448899269104\n",
      "Seen so far: 42496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 664: 0.8585500717163086\n",
      "Seen so far: 42560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 665: 1.2131613492965698\n",
      "Seen so far: 42624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 666: 0.9234872460365295\n",
      "Seen so far: 42688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 667: 0.7777400016784668\n",
      "Seen so far: 42752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 668: 0.8320852518081665\n",
      "Seen so far: 42816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 669: 1.0668530464172363\n",
      "Seen so far: 42880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 670: 0.9482983350753784\n",
      "Seen so far: 42944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 671: 1.613376498222351\n",
      "Seen so far: 43008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 672: 1.3282127380371094\n",
      "Seen so far: 43072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 673: 1.4620920419692993\n",
      "Seen so far: 43136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 674: 0.9589937925338745\n",
      "Seen so far: 43200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 675: 0.9067919254302979\n",
      "Seen so far: 43264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 676: 1.1569538116455078\n",
      "Seen so far: 43328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 677: 0.9813198447227478\n",
      "Seen so far: 43392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 678: 1.2162926197052002\n",
      "Seen so far: 43456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 679: 1.3260852098464966\n",
      "Seen so far: 43520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 680: 1.0453064441680908\n",
      "Seen so far: 43584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 681: 1.2352033853530884\n",
      "Seen so far: 43648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 682: 1.1106088161468506\n",
      "Seen so far: 43712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 683: 0.5632848143577576\n",
      "Seen so far: 43776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 684: 1.766893982887268\n",
      "Seen so far: 43840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 685: 0.773385763168335\n",
      "Seen so far: 43904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 686: 1.4798922538757324\n",
      "Seen so far: 43968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 687: 1.357991099357605\n",
      "Seen so far: 44032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 688: 1.1406643390655518\n",
      "Seen so far: 44096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 689: 0.8654665946960449\n",
      "Seen so far: 44160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 690: 1.0313758850097656\n",
      "Seen so far: 44224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 691: 1.1937464475631714\n",
      "Seen so far: 44288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 692: 1.1269279718399048\n",
      "Seen so far: 44352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 693: 1.1585074663162231\n",
      "Seen so far: 44416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 694: 1.038648247718811\n",
      "Seen so far: 44480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 695: 0.7687508463859558\n",
      "Seen so far: 44544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 696: 0.8616819381713867\n",
      "Seen so far: 44608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 697: 0.9064322710037231\n",
      "Seen so far: 44672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 698: 0.9254422783851624\n",
      "Seen so far: 44736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 699: 0.9450840353965759\n",
      "Seen so far: 44800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 700: 1.300403356552124\n",
      "Seen so far: 44864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 701: 1.0475335121154785\n",
      "Seen so far: 44928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 702: 0.7595219016075134\n",
      "Seen so far: 44992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 703: 0.7922573089599609\n",
      "Seen so far: 45056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 704: 0.8571036458015442\n",
      "Seen so far: 45120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 705: 0.8162890672683716\n",
      "Seen so far: 45184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 706: 1.0384790897369385\n",
      "Seen so far: 45248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 707: 0.7086842060089111\n",
      "Seen so far: 45312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 708: 0.7357233166694641\n",
      "Seen so far: 45376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 709: 1.4287075996398926\n",
      "Seen so far: 45440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 710: 1.2014942169189453\n",
      "Seen so far: 45504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 711: 0.8277286291122437\n",
      "Seen so far: 45568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 712: 1.1027040481567383\n",
      "Seen so far: 45632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 713: 1.2170984745025635\n",
      "Seen so far: 45696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 714: 1.1145012378692627\n",
      "Seen so far: 45760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 715: 1.2786353826522827\n",
      "Seen so far: 45824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 716: 0.6480667591094971\n",
      "Seen so far: 45888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 717: 1.392155408859253\n",
      "Seen so far: 45952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 718: 1.333170771598816\n",
      "Seen so far: 46016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 719: 1.094241976737976\n",
      "Seen so far: 46080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 720: 1.0959579944610596\n",
      "Seen so far: 46144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 721: 1.0571644306182861\n",
      "Seen so far: 46208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 722: 0.6577643156051636\n",
      "Seen so far: 46272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 723: 0.9863024950027466\n",
      "Seen so far: 46336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 724: 0.9357723593711853\n",
      "Seen so far: 46400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 725: 1.2109642028808594\n",
      "Seen so far: 46464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 726: 0.9668934345245361\n",
      "Seen so far: 46528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 727: 1.0568314790725708\n",
      "Seen so far: 46592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 728: 1.1849846839904785\n",
      "Seen so far: 46656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 729: 0.8578510284423828\n",
      "Seen so far: 46720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 730: 0.9185353517532349\n",
      "Seen so far: 46784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 731: 1.282098650932312\n",
      "Seen so far: 46848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 732: 1.5589585304260254\n",
      "Seen so far: 46912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 733: 0.9664319157600403\n",
      "Seen so far: 46976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 734: 0.8312016725540161\n",
      "Seen so far: 47040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 735: 0.7504034638404846\n",
      "Seen so far: 47104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 736: 0.7760418653488159\n",
      "Seen so far: 47168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 737: 0.7626211047172546\n",
      "Seen so far: 47232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 738: 0.7963191270828247\n",
      "Seen so far: 47296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 739: 1.2134943008422852\n",
      "Seen so far: 47360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 740: 0.9503129124641418\n",
      "Seen so far: 47424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 741: 0.7633261680603027\n",
      "Seen so far: 47488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 742: 0.8614439368247986\n",
      "Seen so far: 47552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 743: 1.249037504196167\n",
      "Seen so far: 47616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 744: 0.7019988298416138\n",
      "Seen so far: 47680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 745: 1.034264087677002\n",
      "Seen so far: 47744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 746: 1.179694652557373\n",
      "Seen so far: 47808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 747: 1.2655887603759766\n",
      "Seen so far: 47872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 748: 0.7828898429870605\n",
      "Seen so far: 47936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 749: 1.590453028678894\n",
      "Seen so far: 48000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 750: 0.8753568530082703\n",
      "Seen so far: 48064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 751: 0.7420798540115356\n",
      "Seen so far: 48128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 752: 1.295295238494873\n",
      "Seen so far: 48192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 753: 1.3428689241409302\n",
      "Seen so far: 48256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 754: 1.1452100276947021\n",
      "Seen so far: 48320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 755: 0.8189098834991455\n",
      "Seen so far: 48384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 756: 1.1319701671600342\n",
      "Seen so far: 48448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 757: 1.4892613887786865\n",
      "Seen so far: 48512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 758: 0.7343496084213257\n",
      "Seen so far: 48576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 759: 1.098670482635498\n",
      "Seen so far: 48640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 760: 1.152771234512329\n",
      "Seen so far: 48704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 761: 1.1458569765090942\n",
      "Seen so far: 48768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 762: 0.9946702718734741\n",
      "Seen so far: 48832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 763: 1.1869500875473022\n",
      "Seen so far: 48896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 764: 1.1474103927612305\n",
      "Seen so far: 48960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 765: 1.1454241275787354\n",
      "Seen so far: 49024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 766: 1.1981990337371826\n",
      "Seen so far: 49088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 767: 1.1540595293045044\n",
      "Seen so far: 49152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 768: 0.7610458731651306\n",
      "Seen so far: 49216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 769: 0.7845430374145508\n",
      "Seen so far: 49280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 770: 0.8218073844909668\n",
      "Seen so far: 49344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 771: 0.9185628890991211\n",
      "Seen so far: 49408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 772: 1.186000108718872\n",
      "Seen so far: 49472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 773: 0.9109219908714294\n",
      "Seen so far: 49536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 774: 0.9782769680023193\n",
      "Seen so far: 49600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 775: 0.9944717288017273\n",
      "Seen so far: 49664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 776: 1.0120553970336914\n",
      "Seen so far: 49728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 777: 1.126323938369751\n",
      "Seen so far: 49792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 778: 0.7597976326942444\n",
      "Seen so far: 49856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 779: 0.658017635345459\n",
      "Seen so far: 49920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 780: 1.4683053493499756\n",
      "Seen so far: 49984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 781: 1.252107858657837\n",
      "Seen so far: 50048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 782: 1.118978500366211\n",
      "Seen so far: 50112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 783: 1.11710786819458\n",
      "Seen so far: 50176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 784: 1.045750379562378\n",
      "Seen so far: 50240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 785: 1.0699398517608643\n",
      "Seen so far: 50304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 786: 1.1493717432022095\n",
      "Seen so far: 50368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 787: 1.423058271408081\n",
      "Seen so far: 50432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 788: 0.6960036754608154\n",
      "Seen so far: 50496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 789: 1.285448431968689\n",
      "Seen so far: 50560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 790: 1.230696439743042\n",
      "Seen so far: 50624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 791: 0.7635803818702698\n",
      "Seen so far: 50688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 792: 0.8519428968429565\n",
      "Seen so far: 50752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 793: 0.7152242064476013\n",
      "Seen so far: 50816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 794: 1.4481496810913086\n",
      "Seen so far: 50880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 795: 0.7758989334106445\n",
      "Seen so far: 50944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 796: 0.9582662582397461\n",
      "Seen so far: 51008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 797: 1.2187609672546387\n",
      "Seen so far: 51072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 798: 1.4365832805633545\n",
      "Seen so far: 51136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 799: 1.4553414583206177\n",
      "Seen so far: 51200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 800: 0.946256697177887\n",
      "Seen so far: 51264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 801: 0.9214779138565063\n",
      "Seen so far: 51328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 802: 1.2261464595794678\n",
      "Seen so far: 51392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 803: 0.9476224184036255\n",
      "Seen so far: 51456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 804: 0.7835216522216797\n",
      "Seen so far: 51520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 805: 1.371870517730713\n",
      "Seen so far: 51584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 806: 1.1200658082962036\n",
      "Seen so far: 51648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 807: 0.686924934387207\n",
      "Seen so far: 51712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 808: 0.9832920432090759\n",
      "Seen so far: 51776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 809: 1.0425974130630493\n",
      "Seen so far: 51840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 810: 0.9187734127044678\n",
      "Seen so far: 51904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 811: 0.9218817949295044\n",
      "Seen so far: 51968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 812: 1.250727653503418\n",
      "Seen so far: 52032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 813: 0.7291340231895447\n",
      "Seen so far: 52096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 814: 0.7214517593383789\n",
      "Seen so far: 52160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 815: 1.2977354526519775\n",
      "Seen so far: 52224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 816: 1.0158110857009888\n",
      "Seen so far: 52288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 817: 0.7243845462799072\n",
      "Seen so far: 52352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 818: 1.311036229133606\n",
      "Seen so far: 52416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 819: 0.4220614433288574\n",
      "Seen so far: 52480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 820: 1.4424360990524292\n",
      "Seen so far: 52544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 821: 1.053349494934082\n",
      "Seen so far: 52608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 822: 0.9324586391448975\n",
      "Seen so far: 52672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 823: 1.1055951118469238\n",
      "Seen so far: 52736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 824: 1.3736798763275146\n",
      "Seen so far: 52800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 825: 1.0393165349960327\n",
      "Seen so far: 52864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 826: 1.2212435007095337\n",
      "Seen so far: 52928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 827: 1.1953505277633667\n",
      "Seen so far: 52992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 828: 0.8534457087516785\n",
      "Seen so far: 53056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 829: 1.1625925302505493\n",
      "Seen so far: 53120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 830: 0.9136309623718262\n",
      "Seen so far: 53184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 831: 1.1754517555236816\n",
      "Seen so far: 53248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 832: 1.0909063816070557\n",
      "Seen so far: 53312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 833: 1.077998161315918\n",
      "Seen so far: 53376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 834: 1.0014495849609375\n",
      "Seen so far: 53440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 835: 0.8340277671813965\n",
      "Seen so far: 53504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 836: 0.953407883644104\n",
      "Seen so far: 53568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 837: 0.9243601560592651\n",
      "Seen so far: 53632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 838: 0.5393131375312805\n",
      "Seen so far: 53696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 839: 0.653773307800293\n",
      "Seen so far: 53760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 840: 0.9265163540840149\n",
      "Seen so far: 53824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 841: 1.324960470199585\n",
      "Seen so far: 53888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 842: 0.8870040774345398\n",
      "Seen so far: 53952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 843: 1.0542293787002563\n",
      "Seen so far: 54016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 844: 0.9592747688293457\n",
      "Seen so far: 54080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 845: 0.9990458488464355\n",
      "Seen so far: 54144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 846: 1.1875964403152466\n",
      "Seen so far: 54208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 847: 1.0412002801895142\n",
      "Seen so far: 54272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 848: 1.0948584079742432\n",
      "Seen so far: 54336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 849: 0.7628074884414673\n",
      "Seen so far: 54400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 850: 0.5572307109832764\n",
      "Seen so far: 54464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 851: 0.7094764709472656\n",
      "Seen so far: 54528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 852: 0.5128325819969177\n",
      "Seen so far: 54592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 853: 0.6456973552703857\n",
      "Seen so far: 54656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 854: 0.7142612934112549\n",
      "Seen so far: 54720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 855: 0.7232908010482788\n",
      "Seen so far: 54784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 856: 0.7694135308265686\n",
      "Seen so far: 54848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 857: 0.7984815835952759\n",
      "Seen so far: 54912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 858: 0.8503158092498779\n",
      "Seen so far: 54976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 859: 1.2183301448822021\n",
      "Seen so far: 55040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 860: 0.8349816799163818\n",
      "Seen so far: 55104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 861: 0.9148404598236084\n",
      "Seen so far: 55168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 862: 0.7194153070449829\n",
      "Seen so far: 55232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 863: 1.29244065284729\n",
      "Seen so far: 55296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 864: 1.0144548416137695\n",
      "Seen so far: 55360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 865: 0.7916855812072754\n",
      "Seen so far: 55424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 866: 0.7579397559165955\n",
      "Seen so far: 55488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 867: 0.7665454745292664\n",
      "Seen so far: 55552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 868: 1.0874046087265015\n",
      "Seen so far: 55616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 869: 1.074995994567871\n",
      "Seen so far: 55680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 870: 1.7031264305114746\n",
      "Seen so far: 55744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 871: 1.123136043548584\n",
      "Seen so far: 55808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 872: 0.7911303043365479\n",
      "Seen so far: 55872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 873: 0.9521006345748901\n",
      "Seen so far: 55936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 874: 1.0224883556365967\n",
      "Seen so far: 56000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 875: 1.0917978286743164\n",
      "Seen so far: 56064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 876: 1.0898268222808838\n",
      "Seen so far: 56128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 877: 1.0005699396133423\n",
      "Seen so far: 56192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 878: 1.0055978298187256\n",
      "Seen so far: 56256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 879: 0.7977573275566101\n",
      "Seen so far: 56320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 880: 1.2557196617126465\n",
      "Seen so far: 56384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 881: 1.4165565967559814\n",
      "Seen so far: 56448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 882: 1.1423574686050415\n",
      "Seen so far: 56512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 883: 1.0854945182800293\n",
      "Seen so far: 56576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 884: 0.6198642253875732\n",
      "Seen so far: 56640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 885: 0.7687187194824219\n",
      "Seen so far: 56704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 886: 1.1894240379333496\n",
      "Seen so far: 56768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 887: 0.8893160820007324\n",
      "Seen so far: 56832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 888: 0.9691454172134399\n",
      "Seen so far: 56896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 889: 1.5891534090042114\n",
      "Seen so far: 56960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 890: 1.0739874839782715\n",
      "Seen so far: 57024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 891: 1.1682004928588867\n",
      "Seen so far: 57088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 892: 0.6871232986450195\n",
      "Seen so far: 57152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 893: 1.2659661769866943\n",
      "Seen so far: 57216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 894: 1.1351208686828613\n",
      "Seen so far: 57280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 895: 1.0824651718139648\n",
      "Seen so far: 57344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 896: 1.6176187992095947\n",
      "Seen so far: 57408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 897: 1.4498326778411865\n",
      "Seen so far: 57472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 898: 0.7759166955947876\n",
      "Seen so far: 57536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 899: 0.750527560710907\n",
      "Seen so far: 57600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 900: 0.8725865483283997\n",
      "Seen so far: 57664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 901: 1.3391845226287842\n",
      "Seen so far: 57728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 902: 1.2655436992645264\n",
      "Seen so far: 57792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 903: 1.1119813919067383\n",
      "Seen so far: 57856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 904: 1.1195420026779175\n",
      "Seen so far: 57920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 905: 1.0942914485931396\n",
      "Seen so far: 57984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 906: 1.248155951499939\n",
      "Seen so far: 58048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 907: 0.9977123737335205\n",
      "Seen so far: 58112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 908: 0.8485510349273682\n",
      "Seen so far: 58176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 909: 1.0353642702102661\n",
      "Seen so far: 58240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 910: 0.797808051109314\n",
      "Seen so far: 58304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 911: 1.1574881076812744\n",
      "Seen so far: 58368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 912: 0.8100327253341675\n",
      "Seen so far: 58432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 913: 1.4809350967407227\n",
      "Seen so far: 58496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 914: 0.7493308782577515\n",
      "Seen so far: 58560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 915: 0.7038941979408264\n",
      "Seen so far: 58624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 916: 1.134805679321289\n",
      "Seen so far: 58688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 917: 0.6967911720275879\n",
      "Seen so far: 58752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 918: 1.1332354545593262\n",
      "Seen so far: 58816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 919: 0.9140357971191406\n",
      "Seen so far: 58880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 920: 1.0459494590759277\n",
      "Seen so far: 58944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 921: 0.8490746021270752\n",
      "Seen so far: 59008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 922: 1.129400372505188\n",
      "Seen so far: 59072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 923: 1.1755670309066772\n",
      "Seen so far: 59136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 924: 0.9699661731719971\n",
      "Seen so far: 59200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 925: 1.0342998504638672\n",
      "Seen so far: 59264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 926: 1.4158251285552979\n",
      "Seen so far: 59328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 927: 0.9526773691177368\n",
      "Seen so far: 59392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 928: 1.1940653324127197\n",
      "Seen so far: 59456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 929: 0.8884344100952148\n",
      "Seen so far: 59520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 930: 0.9747163653373718\n",
      "Seen so far: 59584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 931: 1.1544289588928223\n",
      "Seen so far: 59648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 932: 1.3086386919021606\n",
      "Seen so far: 59712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 933: 0.9554004669189453\n",
      "Seen so far: 59776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 934: 1.1919167041778564\n",
      "Seen so far: 59840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 935: 0.7849506139755249\n",
      "Seen so far: 59904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 936: 0.8773154020309448\n",
      "Seen so far: 59968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 937: 1.0566625595092773\n",
      "Seen so far: 60032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 938: 1.1554962396621704\n",
      "Seen so far: 60096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 939: 0.7055540084838867\n",
      "Seen so far: 60160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 940: 0.7475780248641968\n",
      "Seen so far: 60224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 941: 0.7336316108703613\n",
      "Seen so far: 60288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 942: 1.0731239318847656\n",
      "Seen so far: 60352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 943: 1.0924893617630005\n",
      "Seen so far: 60416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 944: 0.8665454387664795\n",
      "Seen so far: 60480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 945: 1.1661765575408936\n",
      "Seen so far: 60544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 946: 0.8834456205368042\n",
      "Seen so far: 60608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 947: 1.2866230010986328\n",
      "Seen so far: 60672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 948: 0.6826733350753784\n",
      "Seen so far: 60736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 949: 1.1820048093795776\n",
      "Seen so far: 60800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 950: 1.0090937614440918\n",
      "Seen so far: 60864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 951: 0.9585796594619751\n",
      "Seen so far: 60928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 952: 1.0630357265472412\n",
      "Seen so far: 60992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 953: 1.1418066024780273\n",
      "Seen so far: 61056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 954: 1.0598528385162354\n",
      "Seen so far: 61120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 955: 0.8706732392311096\n",
      "Seen so far: 61184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 956: 1.445365071296692\n",
      "Seen so far: 61248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 957: 1.1852688789367676\n",
      "Seen so far: 61312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 958: 1.1834166049957275\n",
      "Seen so far: 61376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 959: 0.795272171497345\n",
      "Seen so far: 61440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 960: 1.0576012134552002\n",
      "Seen so far: 61504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 961: 0.9709608554840088\n",
      "Seen so far: 61568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 962: 0.7785601019859314\n",
      "Seen so far: 61632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 963: 1.0318844318389893\n",
      "Seen so far: 61696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 964: 0.9570309519767761\n",
      "Seen so far: 61760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 965: 1.0003087520599365\n",
      "Seen so far: 61824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 966: 0.9065839052200317\n",
      "Seen so far: 61888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 967: 0.731562077999115\n",
      "Seen so far: 61952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 968: 0.7826487421989441\n",
      "Seen so far: 62016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 969: 1.0991790294647217\n",
      "Seen so far: 62080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 970: 1.125469446182251\n",
      "Seen so far: 62144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 971: 1.027851939201355\n",
      "Seen so far: 62208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 972: 1.1700232028961182\n",
      "Seen so far: 62272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 973: 1.2268548011779785\n",
      "Seen so far: 62336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 974: 0.8710570335388184\n",
      "Seen so far: 62400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 975: 0.8779520392417908\n",
      "Seen so far: 62464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 976: 0.9243361949920654\n",
      "Seen so far: 62528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 977: 0.8589739799499512\n",
      "Seen so far: 62592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 978: 1.1628546714782715\n",
      "Seen so far: 62656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 979: 0.9505072236061096\n",
      "Seen so far: 62720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 980: 1.1223243474960327\n",
      "Seen so far: 62784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 981: 0.9664120674133301\n",
      "Seen so far: 62848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 982: 1.0271680355072021\n",
      "Seen so far: 62912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 983: 0.746938943862915\n",
      "Seen so far: 62976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 984: 0.9118898510932922\n",
      "Seen so far: 63040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 985: 1.135496973991394\n",
      "Seen so far: 63104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 986: 1.054305911064148\n",
      "Seen so far: 63168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 987: 1.0699039697647095\n",
      "Seen so far: 63232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 988: 0.8832782506942749\n",
      "Seen so far: 63296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 989: 1.1894724369049072\n",
      "Seen so far: 63360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 990: 0.9400765299797058\n",
      "Seen so far: 63424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 991: 0.7865132093429565\n",
      "Seen so far: 63488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 992: 0.5972258448600769\n",
      "Seen so far: 63552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 993: 0.7697690725326538\n",
      "Seen so far: 63616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 994: 0.9870090484619141\n",
      "Seen so far: 63680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 995: 0.8997068405151367\n",
      "Seen so far: 63744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 996: 1.2814363241195679\n",
      "Seen so far: 63808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 997: 0.5941808223724365\n",
      "Seen so far: 63872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 998: 1.0738526582717896\n",
      "Seen so far: 63936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 999: 0.7532507181167603\n",
      "Seen so far: 64000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1000: 0.8969389796257019\n",
      "Seen so far: 64064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1001: 0.7696523070335388\n",
      "Seen so far: 64128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1002: 0.8311125040054321\n",
      "Seen so far: 64192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1003: 0.8205544948577881\n",
      "Seen so far: 64256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1004: 0.8411545753479004\n",
      "Seen so far: 64320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1005: 0.8591578006744385\n",
      "Seen so far: 64384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1006: 1.097535252571106\n",
      "Seen so far: 64448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1007: 0.9371083974838257\n",
      "Seen so far: 64512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1008: 1.1547296047210693\n",
      "Seen so far: 64576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1009: 0.9718236923217773\n",
      "Seen so far: 64640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1010: 0.6821352243423462\n",
      "Seen so far: 64704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1011: 0.8313170671463013\n",
      "Seen so far: 64768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1012: 1.026684284210205\n",
      "Seen so far: 64832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1013: 1.0859808921813965\n",
      "Seen so far: 64896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1014: 1.008693814277649\n",
      "Seen so far: 64960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1015: 0.51756751537323\n",
      "Seen so far: 65024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1016: 1.147143840789795\n",
      "Seen so far: 65088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1017: 1.297240972518921\n",
      "Seen so far: 65152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1018: 0.7161929607391357\n",
      "Seen so far: 65216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1019: 1.233534574508667\n",
      "Seen so far: 65280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1020: 0.5442889928817749\n",
      "Seen so far: 65344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1021: 0.6097733974456787\n",
      "Seen so far: 65408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1022: 0.7199205160140991\n",
      "Seen so far: 65472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1023: 1.7274909019470215\n",
      "Seen so far: 65536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1024: 0.7471106052398682\n",
      "Seen so far: 65600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1025: 1.1356745958328247\n",
      "Seen so far: 65664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1026: 0.8455617427825928\n",
      "Seen so far: 65728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1027: 1.151964783668518\n",
      "Seen so far: 65792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1028: 0.6093631982803345\n",
      "Seen so far: 65856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1029: 1.2251591682434082\n",
      "Seen so far: 65920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1030: 1.3876116275787354\n",
      "Seen so far: 65984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1031: 0.7323140501976013\n",
      "Seen so far: 66048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1032: 0.8699597120285034\n",
      "Seen so far: 66112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1033: 1.328491449356079\n",
      "Seen so far: 66176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1034: 1.304334282875061\n",
      "Seen so far: 66240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1035: 1.1977369785308838\n",
      "Seen so far: 66304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1036: 0.6491805911064148\n",
      "Seen so far: 66368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1037: 0.990151047706604\n",
      "Seen so far: 66432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1038: 1.1646990776062012\n",
      "Seen so far: 66496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1039: 0.7673494815826416\n",
      "Seen so far: 66560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1040: 1.266470193862915\n",
      "Seen so far: 66624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1041: 1.3222572803497314\n",
      "Seen so far: 66688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1042: 0.657351553440094\n",
      "Seen so far: 66752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1043: 1.0477393865585327\n",
      "Seen so far: 66816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1044: 0.6041793823242188\n",
      "Seen so far: 66880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1045: 0.9926496744155884\n",
      "Seen so far: 66944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1046: 1.0650720596313477\n",
      "Seen so far: 67008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1047: 0.7913106083869934\n",
      "Seen so far: 67072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1048: 1.019223690032959\n",
      "Seen so far: 67136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1049: 0.7194052934646606\n",
      "Seen so far: 67200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1050: 1.5991411209106445\n",
      "Seen so far: 67264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1051: 1.1401737928390503\n",
      "Seen so far: 67328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1052: 0.8158327341079712\n",
      "Seen so far: 67392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1053: 1.2326390743255615\n",
      "Seen so far: 67456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1054: 1.0705056190490723\n",
      "Seen so far: 67520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1055: 1.3160862922668457\n",
      "Seen so far: 67584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1056: 0.8631340861320496\n",
      "Seen so far: 67648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1057: 0.9607778191566467\n",
      "Seen so far: 67712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1058: 0.7813531756401062\n",
      "Seen so far: 67776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1059: 0.7941311001777649\n",
      "Seen so far: 67840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1060: 0.946191668510437\n",
      "Seen so far: 67904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1061: 0.9057152271270752\n",
      "Seen so far: 67968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1062: 1.5289667844772339\n",
      "Seen so far: 68032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1063: 0.5019644498825073\n",
      "Seen so far: 68096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1064: 1.3248980045318604\n",
      "Seen so far: 68160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1065: 0.9693297743797302\n",
      "Seen so far: 68224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1066: 1.0524308681488037\n",
      "Seen so far: 68288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1067: 0.9319494962692261\n",
      "Seen so far: 68352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1068: 0.8735995888710022\n",
      "Seen so far: 68416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1069: 0.9301624298095703\n",
      "Seen so far: 68480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1070: 0.5531657934188843\n",
      "Seen so far: 68544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1071: 0.8575640320777893\n",
      "Seen so far: 68608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1072: 0.9748316407203674\n",
      "Seen so far: 68672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1073: 1.1446017026901245\n",
      "Seen so far: 68736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1074: 0.7163147926330566\n",
      "Seen so far: 68800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1075: 1.013347864151001\n",
      "Seen so far: 68864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1076: 0.6645439863204956\n",
      "Seen so far: 68928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1077: 1.2356572151184082\n",
      "Seen so far: 68992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1078: 1.276841402053833\n",
      "Seen so far: 69056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1079: 0.9566409587860107\n",
      "Seen so far: 69120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1080: 0.8310394287109375\n",
      "Seen so far: 69184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1081: 1.2582180500030518\n",
      "Seen so far: 69248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1082: 1.3283958435058594\n",
      "Seen so far: 69312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1083: 1.0437450408935547\n",
      "Seen so far: 69376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1084: 1.1821805238723755\n",
      "Seen so far: 69440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1085: 0.8643287420272827\n",
      "Seen so far: 69504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1086: 0.9536309242248535\n",
      "Seen so far: 69568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1087: 1.3514163494110107\n",
      "Seen so far: 69632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1088: 1.2565693855285645\n",
      "Seen so far: 69696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1089: 0.7745091915130615\n",
      "Seen so far: 69760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1090: 0.9111067056655884\n",
      "Seen so far: 69824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1091: 1.0044946670532227\n",
      "Seen so far: 69888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1092: 1.1283237934112549\n",
      "Seen so far: 69952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1093: 0.6753697395324707\n",
      "Seen so far: 70016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1094: 1.097125768661499\n",
      "Seen so far: 70080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1095: 1.0674655437469482\n",
      "Seen so far: 70144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1096: 0.7156457901000977\n",
      "Seen so far: 70208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1097: 0.9542270302772522\n",
      "Seen so far: 70272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1098: 1.5080265998840332\n",
      "Seen so far: 70336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1099: 0.9340609908103943\n",
      "Seen so far: 70400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1100: 1.629748821258545\n",
      "Seen so far: 70464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1101: 1.4546343088150024\n",
      "Seen so far: 70528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1102: 1.0319936275482178\n",
      "Seen so far: 70592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1103: 1.074784517288208\n",
      "Seen so far: 70656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1104: 0.8073775768280029\n",
      "Seen so far: 70720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1105: 0.9848626852035522\n",
      "Seen so far: 70784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1106: 1.0634589195251465\n",
      "Seen so far: 70848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1107: 0.8150042295455933\n",
      "Seen so far: 70912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1108: 0.911871075630188\n",
      "Seen so far: 70976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1109: 0.9350180625915527\n",
      "Seen so far: 71040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1110: 0.8308977484703064\n",
      "Seen so far: 71104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1111: 1.1057912111282349\n",
      "Seen so far: 71168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1112: 1.2580698728561401\n",
      "Seen so far: 71232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1113: 1.2938132286071777\n",
      "Seen so far: 71296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1114: 0.7495893239974976\n",
      "Seen so far: 71360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1115: 1.3261656761169434\n",
      "Seen so far: 71424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1116: 1.0021510124206543\n",
      "Seen so far: 71488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1117: 0.896120011806488\n",
      "Seen so far: 71552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1118: 0.7266364097595215\n",
      "Seen so far: 71616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1119: 1.1711807250976562\n",
      "Seen so far: 71680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1120: 0.8710739016532898\n",
      "Seen so far: 71744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1121: 1.2515590190887451\n",
      "Seen so far: 71808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1122: 0.7301607728004456\n",
      "Seen so far: 71872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1123: 0.75034499168396\n",
      "Seen so far: 71936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1124: 0.947819173336029\n",
      "Seen so far: 72000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1125: 1.3565651178359985\n",
      "Seen so far: 72064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1126: 0.9971442222595215\n",
      "Seen so far: 72128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1127: 0.8986952900886536\n",
      "Seen so far: 72192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1128: 1.4595801830291748\n",
      "Seen so far: 72256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1129: 0.903096079826355\n",
      "Seen so far: 72320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1130: 0.795403003692627\n",
      "Seen so far: 72384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1131: 1.0558409690856934\n",
      "Seen so far: 72448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1132: 0.8922221660614014\n",
      "Seen so far: 72512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1133: 1.0505067110061646\n",
      "Seen so far: 72576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1134: 1.1088929176330566\n",
      "Seen so far: 72640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1135: 1.304786205291748\n",
      "Seen so far: 72704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1136: 1.1281014680862427\n",
      "Seen so far: 72768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1137: 1.2364298105239868\n",
      "Seen so far: 72832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1138: 0.9755942225456238\n",
      "Seen so far: 72896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1139: 0.9481130838394165\n",
      "Seen so far: 72960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1140: 1.018683910369873\n",
      "Seen so far: 73024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1141: 0.7315771579742432\n",
      "Seen so far: 73088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1142: 1.1107947826385498\n",
      "Seen so far: 73152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1143: 0.8126771450042725\n",
      "Seen so far: 73216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1144: 1.1268715858459473\n",
      "Seen so far: 73280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1145: 1.323362112045288\n",
      "Seen so far: 73344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1146: 1.2015365362167358\n",
      "Seen so far: 73408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1147: 1.2668647766113281\n",
      "Seen so far: 73472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1148: 1.4644194841384888\n",
      "Seen so far: 73536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1149: 0.825760006904602\n",
      "Seen so far: 73600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1150: 0.8679215312004089\n",
      "Seen so far: 73664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1151: 0.8651448488235474\n",
      "Seen so far: 73728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1152: 0.8199853301048279\n",
      "Seen so far: 73792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1153: 0.8679769039154053\n",
      "Seen so far: 73856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1154: 0.7971270680427551\n",
      "Seen so far: 73920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1155: 1.0105600357055664\n",
      "Seen so far: 73984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1156: 0.980623722076416\n",
      "Seen so far: 74048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1157: 0.995753824710846\n",
      "Seen so far: 74112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1158: 0.9519211053848267\n",
      "Seen so far: 74176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1159: 0.9961497783660889\n",
      "Seen so far: 74240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1160: 1.1591215133666992\n",
      "Seen so far: 74304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1161: 0.8340779542922974\n",
      "Seen so far: 74368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1162: 0.6023250818252563\n",
      "Seen so far: 74432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1163: 0.9266461133956909\n",
      "Seen so far: 74496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1164: 1.054219126701355\n",
      "Seen so far: 74560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1165: 0.9371223449707031\n",
      "Seen so far: 74624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1166: 1.2637369632720947\n",
      "Seen so far: 74688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1167: 0.8639368414878845\n",
      "Seen so far: 74752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1168: 0.6306750774383545\n",
      "Seen so far: 74816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1169: 1.0414235591888428\n",
      "Seen so far: 74880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1170: 1.1154615879058838\n",
      "Seen so far: 74944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1171: 0.8295869827270508\n",
      "Seen so far: 75008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1172: 1.8466390371322632\n",
      "Seen so far: 75072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1173: 0.9264268279075623\n",
      "Seen so far: 75136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1174: 0.8825967311859131\n",
      "Seen so far: 75200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1175: 1.3329367637634277\n",
      "Seen so far: 75264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1176: 1.118039846420288\n",
      "Seen so far: 75328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1177: 0.8738439679145813\n",
      "Seen so far: 75392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1178: 1.424454927444458\n",
      "Seen so far: 75456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1179: 0.49810048937797546\n",
      "Seen so far: 75520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1180: 0.9899908900260925\n",
      "Seen so far: 75584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1181: 1.0768885612487793\n",
      "Seen so far: 75648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1182: 1.3704979419708252\n",
      "Seen so far: 75712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1183: 1.0573961734771729\n",
      "Seen so far: 75776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1184: 1.0192899703979492\n",
      "Seen so far: 75840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1185: 0.9781081676483154\n",
      "Seen so far: 75904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1186: 0.8105264902114868\n",
      "Seen so far: 75968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1187: 1.0177185535430908\n",
      "Seen so far: 76032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1188: 1.0909223556518555\n",
      "Seen so far: 76096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1189: 0.7712652683258057\n",
      "Seen so far: 76160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1190: 0.7786972522735596\n",
      "Seen so far: 76224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1191: 0.5830042958259583\n",
      "Seen so far: 76288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1192: 1.3362114429473877\n",
      "Seen so far: 76352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1193: 0.8090299367904663\n",
      "Seen so far: 76416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1194: 1.745985746383667\n",
      "Seen so far: 76480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1195: 0.7037014961242676\n",
      "Seen so far: 76544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1196: 0.7919349670410156\n",
      "Seen so far: 76608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1197: 1.31829833984375\n",
      "Seen so far: 76672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1198: 1.3270295858383179\n",
      "Seen so far: 76736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1199: 1.1821889877319336\n",
      "Seen so far: 76800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1200: 1.0428080558776855\n",
      "Seen so far: 76864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1201: 1.0064105987548828\n",
      "Seen so far: 76928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1202: 1.1221648454666138\n",
      "Seen so far: 76992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1203: 0.7468281388282776\n",
      "Seen so far: 77056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1204: 1.1749069690704346\n",
      "Seen so far: 77120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1205: 0.6957616209983826\n",
      "Seen so far: 77184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1206: 0.7882777452468872\n",
      "Seen so far: 77248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1207: 1.196800708770752\n",
      "Seen so far: 77312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1208: 1.2850719690322876\n",
      "Seen so far: 77376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1209: 1.1692512035369873\n",
      "Seen so far: 77440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1210: 0.9977940917015076\n",
      "Seen so far: 77504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1211: 0.9148435592651367\n",
      "Seen so far: 77568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1212: 0.7095839977264404\n",
      "Seen so far: 77632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1213: 0.9577018618583679\n",
      "Seen so far: 77696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1214: 1.7123310565948486\n",
      "Seen so far: 77760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1215: 0.5762529969215393\n",
      "Seen so far: 77824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1216: 0.8280861973762512\n",
      "Seen so far: 77888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1217: 1.1024832725524902\n",
      "Seen so far: 77952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1218: 1.1181223392486572\n",
      "Seen so far: 78016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1219: 1.2942370176315308\n",
      "Seen so far: 78080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1220: 0.9528510570526123\n",
      "Seen so far: 78144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1221: 0.966590404510498\n",
      "Seen so far: 78208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1222: 1.0689246654510498\n",
      "Seen so far: 78272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1223: 0.7314857244491577\n",
      "Seen so far: 78336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1224: 0.6678136587142944\n",
      "Seen so far: 78400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1225: 0.9518589973449707\n",
      "Seen so far: 78464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1226: 0.9333966374397278\n",
      "Seen so far: 78528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1227: 0.9796550869941711\n",
      "Seen so far: 78592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1228: 0.9634668827056885\n",
      "Seen so far: 78656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1229: 0.9327489137649536\n",
      "Seen so far: 78720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1230: 0.9767335653305054\n",
      "Seen so far: 78784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1231: 0.8962200284004211\n",
      "Seen so far: 78848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1232: 1.1016439199447632\n",
      "Seen so far: 78912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1233: 1.0607142448425293\n",
      "Seen so far: 78976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1234: 1.1863105297088623\n",
      "Seen so far: 79040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1235: 0.8506719470024109\n",
      "Seen so far: 79104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1236: 1.019841194152832\n",
      "Seen so far: 79168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1237: 0.9222883582115173\n",
      "Seen so far: 79232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1238: 1.1391847133636475\n",
      "Seen so far: 79296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1239: 1.0185285806655884\n",
      "Seen so far: 79360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1240: 1.2048357725143433\n",
      "Seen so far: 79424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1241: 1.0753661394119263\n",
      "Seen so far: 79488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1242: 0.7505694627761841\n",
      "Seen so far: 79552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1243: 1.17619788646698\n",
      "Seen so far: 79616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1244: 0.9018369317054749\n",
      "Seen so far: 79680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1245: 1.0757994651794434\n",
      "Seen so far: 79744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1246: 0.9613598585128784\n",
      "Seen so far: 79808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1247: 0.738426148891449\n",
      "Seen so far: 79872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1248: 0.7725133895874023\n",
      "Seen so far: 79936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1249: 1.1836521625518799\n",
      "Seen so far: 80000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1250: 0.9911211729049683\n",
      "Seen so far: 80064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1251: 0.4544987678527832\n",
      "Seen so far: 80128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1252: 1.1968849897384644\n",
      "Seen so far: 80192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1253: 0.8005484342575073\n",
      "Seen so far: 80256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1254: 0.8045334815979004\n",
      "Seen so far: 80320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1255: 0.7901608347892761\n",
      "Seen so far: 80384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1256: 1.1986228227615356\n",
      "Seen so far: 80448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1257: 1.0108187198638916\n",
      "Seen so far: 80512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1258: 0.7767931818962097\n",
      "Seen so far: 80576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1259: 0.6259400844573975\n",
      "Seen so far: 80640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1260: 0.8422328233718872\n",
      "Seen so far: 80704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1261: 0.6351432800292969\n",
      "Seen so far: 80768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1262: 0.8808869123458862\n",
      "Seen so far: 80832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1263: 0.6924842596054077\n",
      "Seen so far: 80896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1264: 1.0753852128982544\n",
      "Seen so far: 80960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1265: 0.874994695186615\n",
      "Seen so far: 81024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1266: 0.823742151260376\n",
      "Seen so far: 81088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1267: 0.8571933507919312\n",
      "Seen so far: 81152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1268: 0.8598740696907043\n",
      "Seen so far: 81216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1269: 1.1101593971252441\n",
      "Seen so far: 81280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1270: 1.1540188789367676\n",
      "Seen so far: 81344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1271: 0.6456876993179321\n",
      "Seen so far: 81408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1272: 1.1081454753875732\n",
      "Seen so far: 81472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1273: 1.0672037601470947\n",
      "Seen so far: 81536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1274: 0.7933748960494995\n",
      "Seen so far: 81600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1275: 0.8995139002799988\n",
      "Seen so far: 81664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1276: 0.8246499300003052\n",
      "Seen so far: 81728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1277: 0.8467591404914856\n",
      "Seen so far: 81792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1278: 1.2297765016555786\n",
      "Seen so far: 81856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1279: 0.9311659336090088\n",
      "Seen so far: 81920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1280: 1.130981206893921\n",
      "Seen so far: 81984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1281: 0.7980701327323914\n",
      "Seen so far: 82048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1282: 0.8484397530555725\n",
      "Seen so far: 82112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1283: 0.9090602397918701\n",
      "Seen so far: 82176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1284: 1.5286438465118408\n",
      "Seen so far: 82240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1285: 1.0493791103363037\n",
      "Seen so far: 82304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1286: 0.8216204047203064\n",
      "Seen so far: 82368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1287: 0.9972535371780396\n",
      "Seen so far: 82432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1288: 0.735206127166748\n",
      "Seen so far: 82496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1289: 1.2601927518844604\n",
      "Seen so far: 82560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1290: 0.5425139665603638\n",
      "Seen so far: 82624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1291: 1.0320794582366943\n",
      "Seen so far: 82688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1292: 0.3805920481681824\n",
      "Seen so far: 82752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1293: 0.911119818687439\n",
      "Seen so far: 82816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1294: 1.1176657676696777\n",
      "Seen so far: 82880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1295: 0.8826138377189636\n",
      "Seen so far: 82944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1296: 0.6968625783920288\n",
      "Seen so far: 83008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1297: 0.9419523477554321\n",
      "Seen so far: 83072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1298: 0.6066622734069824\n",
      "Seen so far: 83136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1299: 0.8092578053474426\n",
      "Seen so far: 83200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1300: 1.202096700668335\n",
      "Seen so far: 83264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1301: 1.0277736186981201\n",
      "Seen so far: 83328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1302: 1.1679811477661133\n",
      "Seen so far: 83392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1303: 1.175999641418457\n",
      "Seen so far: 83456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1304: 0.7152230739593506\n",
      "Seen so far: 83520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1305: 0.7279762029647827\n",
      "Seen so far: 83584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1306: 1.000382900238037\n",
      "Seen so far: 83648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1307: 0.8341361284255981\n",
      "Seen so far: 83712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1308: 1.0376183986663818\n",
      "Seen so far: 83776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1309: 0.9526397585868835\n",
      "Seen so far: 83840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1310: 0.8577452898025513\n",
      "Seen so far: 83904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1311: 1.025774598121643\n",
      "Seen so far: 83968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1312: 0.8095587491989136\n",
      "Seen so far: 84032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1313: 0.9912110567092896\n",
      "Seen so far: 84096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1314: 1.0388047695159912\n",
      "Seen so far: 84160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1315: 1.1463165283203125\n",
      "Seen so far: 84224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1316: 0.9951869249343872\n",
      "Seen so far: 84288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1317: 1.216925859451294\n",
      "Seen so far: 84352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1318: 1.0096983909606934\n",
      "Seen so far: 84416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1319: 1.0800443887710571\n",
      "Seen so far: 84480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1320: 0.945597767829895\n",
      "Seen so far: 84544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1321: 1.563380241394043\n",
      "Seen so far: 84608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1322: 1.020287036895752\n",
      "Seen so far: 84672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1323: 0.8030713796615601\n",
      "Seen so far: 84736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1324: 0.8153505325317383\n",
      "Seen so far: 84800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1325: 1.0224277973175049\n",
      "Seen so far: 84864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1326: 0.9688094258308411\n",
      "Seen so far: 84928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1327: 0.8252208232879639\n",
      "Seen so far: 84992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1328: 1.2547411918640137\n",
      "Seen so far: 85056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1329: 0.7353600263595581\n",
      "Seen so far: 85120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1330: 0.8143633604049683\n",
      "Seen so far: 85184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1331: 1.2051095962524414\n",
      "Seen so far: 85248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1332: 1.125452995300293\n",
      "Seen so far: 85312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1333: 1.165842056274414\n",
      "Seen so far: 85376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1334: 1.1059683561325073\n",
      "Seen so far: 85440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1335: 0.9011695384979248\n",
      "Seen so far: 85504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1336: 0.7985629439353943\n",
      "Seen so far: 85568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1337: 1.1118006706237793\n",
      "Seen so far: 85632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1338: 1.0803009271621704\n",
      "Seen so far: 85696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1339: 1.0476454496383667\n",
      "Seen so far: 85760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1340: 1.517672061920166\n",
      "Seen so far: 85824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1341: 1.2626519203186035\n",
      "Seen so far: 85888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1342: 0.7424294948577881\n",
      "Seen so far: 85952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1343: 1.00663161277771\n",
      "Seen so far: 86016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1344: 1.3488514423370361\n",
      "Seen so far: 86080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1345: 0.9665642976760864\n",
      "Seen so far: 86144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1346: 1.0403666496276855\n",
      "Seen so far: 86208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1347: 0.7990096211433411\n",
      "Seen so far: 86272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1348: 1.2239291667938232\n",
      "Seen so far: 86336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1349: 1.2159581184387207\n",
      "Seen so far: 86400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1350: 1.0483132600784302\n",
      "Seen so far: 86464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1351: 0.6095393300056458\n",
      "Seen so far: 86528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1352: 1.4190071821212769\n",
      "Seen so far: 86592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1353: 0.8373966217041016\n",
      "Seen so far: 86656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1354: 1.8061249256134033\n",
      "Seen so far: 86720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1355: 0.9005902409553528\n",
      "Seen so far: 86784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1356: 0.8136584758758545\n",
      "Seen so far: 86848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1357: 1.086875557899475\n",
      "Seen so far: 86912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1358: 0.8088973760604858\n",
      "Seen so far: 86976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1359: 0.9724352955818176\n",
      "Seen so far: 87040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1360: 1.0502121448516846\n",
      "Seen so far: 87104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1361: 0.6865530014038086\n",
      "Seen so far: 87168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1362: 0.9243481159210205\n",
      "Seen so far: 87232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1363: 0.8753584623336792\n",
      "Seen so far: 87296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1364: 0.9126777648925781\n",
      "Seen so far: 87360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1365: 0.7990471720695496\n",
      "Seen so far: 87424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1366: 1.0158318281173706\n",
      "Seen so far: 87488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1367: 1.3304839134216309\n",
      "Seen so far: 87552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1368: 1.0352740287780762\n",
      "Seen so far: 87616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1369: 0.613945484161377\n",
      "Seen so far: 87680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1370: 0.8208147883415222\n",
      "Seen so far: 87744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1371: 0.9723458290100098\n",
      "Seen so far: 87808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1372: 1.1626733541488647\n",
      "Seen so far: 87872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1373: 0.8263829946517944\n",
      "Seen so far: 87936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1374: 0.852351188659668\n",
      "Seen so far: 88000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1375: 1.1281646490097046\n",
      "Seen so far: 88064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1376: 1.272085428237915\n",
      "Seen so far: 88128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1377: 0.949140191078186\n",
      "Seen so far: 88192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1378: 1.1430954933166504\n",
      "Seen so far: 88256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1379: 1.1580498218536377\n",
      "Seen so far: 88320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1380: 1.1029938459396362\n",
      "Seen so far: 88384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1381: 0.8901448249816895\n",
      "Seen so far: 88448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1382: 0.8597843050956726\n",
      "Seen so far: 88512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1383: 1.284905195236206\n",
      "Seen so far: 88576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1384: 0.6486712098121643\n",
      "Seen so far: 88640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1385: 0.802336573600769\n",
      "Seen so far: 88704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1386: 1.051816463470459\n",
      "Seen so far: 88768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1387: 1.041431188583374\n",
      "Seen so far: 88832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1388: 1.0610153675079346\n",
      "Seen so far: 88896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1389: 0.7072373032569885\n",
      "Seen so far: 88960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1390: 0.7046528458595276\n",
      "Seen so far: 89024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1391: 1.1526943445205688\n",
      "Seen so far: 89088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1392: 1.3249672651290894\n",
      "Seen so far: 89152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1393: 1.5054044723510742\n",
      "Seen so far: 89216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1394: 0.9444944858551025\n",
      "Seen so far: 89280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1395: 1.0453356504440308\n",
      "Seen so far: 89344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1396: 1.0494349002838135\n",
      "Seen so far: 89408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1397: 1.1092818975448608\n",
      "Seen so far: 89472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1398: 0.7006625533103943\n",
      "Seen so far: 89536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1399: 1.0985398292541504\n",
      "Seen so far: 89600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1400: 1.2699241638183594\n",
      "Seen so far: 89664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1401: 0.871489405632019\n",
      "Seen so far: 89728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1402: 1.033778429031372\n",
      "Seen so far: 89792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1403: 1.1571849584579468\n",
      "Seen so far: 89856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1404: 0.8680894374847412\n",
      "Seen so far: 89920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1405: 0.6360679268836975\n",
      "Seen so far: 89984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1406: 1.3613755702972412\n",
      "Seen so far: 90048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1407: 0.871395468711853\n",
      "Seen so far: 90112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1408: 0.7830052971839905\n",
      "Seen so far: 90176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1409: 0.8608249425888062\n",
      "Seen so far: 90240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1410: 0.9131648540496826\n",
      "Seen so far: 90304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1411: 0.9098448753356934\n",
      "Seen so far: 90368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1412: 1.063633680343628\n",
      "Seen so far: 90432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1413: 0.8912768363952637\n",
      "Seen so far: 90496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1414: 0.7637428045272827\n",
      "Seen so far: 90560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1415: 0.9585472941398621\n",
      "Seen so far: 90624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1416: 0.8989299535751343\n",
      "Seen so far: 90688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1417: 1.219730257987976\n",
      "Seen so far: 90752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1418: 0.7942065596580505\n",
      "Seen so far: 90816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1419: 1.0286141633987427\n",
      "Seen so far: 90880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1420: 0.8140376806259155\n",
      "Seen so far: 90944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1421: 0.7034574747085571\n",
      "Seen so far: 91008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1422: 0.8584989309310913\n",
      "Seen so far: 91072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1423: 0.7965810298919678\n",
      "Seen so far: 91136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1424: 0.7048903703689575\n",
      "Seen so far: 91200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1425: 0.8327817916870117\n",
      "Seen so far: 91264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1426: 1.0033390522003174\n",
      "Seen so far: 91328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1427: 1.0572683811187744\n",
      "Seen so far: 91392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1428: 1.290553092956543\n",
      "Seen so far: 91456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1429: 0.9500997066497803\n",
      "Seen so far: 91520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1430: 0.892837643623352\n",
      "Seen so far: 91584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1431: 1.144270420074463\n",
      "Seen so far: 91648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1432: 0.6522119045257568\n",
      "Seen so far: 91712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1433: 1.0675517320632935\n",
      "Seen so far: 91776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1434: 0.6958928108215332\n",
      "Seen so far: 91840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1435: 1.010305643081665\n",
      "Seen so far: 91904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1436: 0.720686674118042\n",
      "Seen so far: 91968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1437: 0.790413498878479\n",
      "Seen so far: 92032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1438: 1.3222427368164062\n",
      "Seen so far: 92096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1439: 1.1448650360107422\n",
      "Seen so far: 92160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1440: 1.1579511165618896\n",
      "Seen so far: 92224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1441: 0.7262961864471436\n",
      "Seen so far: 92288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1442: 1.2322590351104736\n",
      "Seen so far: 92352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1443: 1.1996455192565918\n",
      "Seen so far: 92416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1444: 1.2886886596679688\n",
      "Seen so far: 92480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1445: 1.0893471240997314\n",
      "Seen so far: 92544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1446: 0.932476282119751\n",
      "Seen so far: 92608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1447: 0.701041579246521\n",
      "Seen so far: 92672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1448: 0.8756986260414124\n",
      "Seen so far: 92736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1449: 1.303105115890503\n",
      "Seen so far: 92800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1450: 0.7887111902236938\n",
      "Seen so far: 92864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1451: 1.3046722412109375\n",
      "Seen so far: 92928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1452: 0.5536355972290039\n",
      "Seen so far: 92992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1453: 1.1152503490447998\n",
      "Seen so far: 93056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1454: 0.8520745038986206\n",
      "Seen so far: 93120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1455: 1.1922581195831299\n",
      "Seen so far: 93184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1456: 0.7174484133720398\n",
      "Seen so far: 93248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1457: 1.1936943531036377\n",
      "Seen so far: 93312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1458: 0.950973391532898\n",
      "Seen so far: 93376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1459: 1.1860178709030151\n",
      "Seen so far: 93440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1460: 1.0137717723846436\n",
      "Seen so far: 93504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1461: 0.9764949083328247\n",
      "Seen so far: 93568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1462: 0.9480841159820557\n",
      "Seen so far: 93632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1463: 1.217190146446228\n",
      "Seen so far: 93696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1464: 0.5741679668426514\n",
      "Seen so far: 93760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1465: 0.9631360173225403\n",
      "Seen so far: 93824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1466: 0.8032944202423096\n",
      "Seen so far: 93888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1467: 0.9270192384719849\n",
      "Seen so far: 93952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1468: 1.0798066854476929\n",
      "Seen so far: 94016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1469: 0.7892084121704102\n",
      "Seen so far: 94080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1470: 1.1605167388916016\n",
      "Seen so far: 94144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1471: 0.5566001534461975\n",
      "Seen so far: 94208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1472: 0.9944239258766174\n",
      "Seen so far: 94272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1473: 1.0586520433425903\n",
      "Seen so far: 94336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1474: 0.7307727932929993\n",
      "Seen so far: 94400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1475: 1.6285122632980347\n",
      "Seen so far: 94464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1476: 0.5405234098434448\n",
      "Seen so far: 94528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1477: 0.9188941717147827\n",
      "Seen so far: 94592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1478: 1.3351386785507202\n",
      "Seen so far: 94656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1479: 1.1670565605163574\n",
      "Seen so far: 94720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1480: 0.642122745513916\n",
      "Seen so far: 94784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1481: 1.056593894958496\n",
      "Seen so far: 94848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1482: 0.6400021910667419\n",
      "Seen so far: 94912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1483: 0.9645864963531494\n",
      "Seen so far: 94976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1484: 0.6878688335418701\n",
      "Seen so far: 95040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1485: 0.7291052937507629\n",
      "Seen so far: 95104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1486: 0.7626728415489197\n",
      "Seen so far: 95168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1487: 0.852868914604187\n",
      "Seen so far: 95232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1488: 1.113187551498413\n",
      "Seen so far: 95296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1489: 0.8978460431098938\n",
      "Seen so far: 95360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1490: 0.944420337677002\n",
      "Seen so far: 95424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1491: 0.647625744342804\n",
      "Seen so far: 95488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1492: 0.9339521527290344\n",
      "Seen so far: 95552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1493: 0.832431435585022\n",
      "Seen so far: 95616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1494: 1.0180763006210327\n",
      "Seen so far: 95680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1495: 1.3257064819335938\n",
      "Seen so far: 95744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1496: 0.7923242449760437\n",
      "Seen so far: 95808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1497: 1.2065480947494507\n",
      "Seen so far: 95872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1498: 0.7958523035049438\n",
      "Seen so far: 95936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1499: 1.2947561740875244\n",
      "Seen so far: 96000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1500: 0.8105635643005371\n",
      "Seen so far: 96064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1501: 1.3784682750701904\n",
      "Seen so far: 96128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1502: 0.805160403251648\n",
      "Seen so far: 96192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1503: 0.6155346035957336\n",
      "Seen so far: 96256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1504: 1.0040019750595093\n",
      "Seen so far: 96320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1505: 1.0910074710845947\n",
      "Seen so far: 96384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1506: 0.7602370977401733\n",
      "Seen so far: 96448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1507: 1.8344932794570923\n",
      "Seen so far: 96512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1508: 0.7259435057640076\n",
      "Seen so far: 96576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1509: 0.9426471590995789\n",
      "Seen so far: 96640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1510: 1.5395112037658691\n",
      "Seen so far: 96704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1511: 1.0025928020477295\n",
      "Seen so far: 96768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1512: 0.8849186301231384\n",
      "Seen so far: 96832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1513: 1.0490121841430664\n",
      "Seen so far: 96896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1514: 0.8678511381149292\n",
      "Seen so far: 96960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1515: 1.4701530933380127\n",
      "Seen so far: 97024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1516: 1.0508426427841187\n",
      "Seen so far: 97088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1517: 1.5042321681976318\n",
      "Seen so far: 97152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1518: 0.9947178959846497\n",
      "Seen so far: 97216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1519: 0.5805982351303101\n",
      "Seen so far: 97280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1520: 0.9671617150306702\n",
      "Seen so far: 97344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1521: 0.8853358030319214\n",
      "Seen so far: 97408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1522: 1.245559811592102\n",
      "Seen so far: 97472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1523: 1.328812837600708\n",
      "Seen so far: 97536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1524: 1.2081804275512695\n",
      "Seen so far: 97600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1525: 1.1599830389022827\n",
      "Seen so far: 97664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1526: 1.390285849571228\n",
      "Seen so far: 97728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1527: 0.8554149866104126\n",
      "Seen so far: 97792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1528: 0.7202184200286865\n",
      "Seen so far: 97856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1529: 0.9314075708389282\n",
      "Seen so far: 97920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1530: 1.0716485977172852\n",
      "Seen so far: 97984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1531: 0.6185336112976074\n",
      "Seen so far: 98048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1532: 0.9292805790901184\n",
      "Seen so far: 98112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1533: 0.7150744795799255\n",
      "Seen so far: 98176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1534: 1.1055644750595093\n",
      "Seen so far: 98240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1535: 0.8586940169334412\n",
      "Seen so far: 98304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1536: 0.8972886204719543\n",
      "Seen so far: 98368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1537: 0.9099472761154175\n",
      "Seen so far: 98432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1538: 1.2134838104248047\n",
      "Seen so far: 98496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1539: 0.8516111969947815\n",
      "Seen so far: 98560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1540: 0.8280493021011353\n",
      "Seen so far: 98624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1541: 0.6674172878265381\n",
      "Seen so far: 98688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1542: 0.9309983253479004\n",
      "Seen so far: 98752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1543: 1.1932414770126343\n",
      "Seen so far: 98816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1544: 0.811170220375061\n",
      "Seen so far: 98880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1545: 0.7366220355033875\n",
      "Seen so far: 98944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1546: 0.9904903173446655\n",
      "Seen so far: 99008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1547: 0.9801313281059265\n",
      "Seen so far: 99072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1548: 0.715654730796814\n",
      "Seen so far: 99136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1549: 0.7650652527809143\n",
      "Seen so far: 99200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1550: 1.1326558589935303\n",
      "Seen so far: 99264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1551: 1.1702364683151245\n",
      "Seen so far: 99328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1552: 0.6685284376144409\n",
      "Seen so far: 99392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1553: 0.7330803871154785\n",
      "Seen so far: 99456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1554: 1.4094290733337402\n",
      "Seen so far: 99520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1555: 1.0749266147613525\n",
      "Seen so far: 99584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1556: 1.0646858215332031\n",
      "Seen so far: 99648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1557: 1.1045050621032715\n",
      "Seen so far: 99712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1558: 0.8052975535392761\n",
      "Seen so far: 99776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1559: 0.6371267437934875\n",
      "Seen so far: 99840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1560: 1.3310742378234863\n",
      "Seen so far: 99904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1561: 0.9341564178466797\n",
      "Seen so far: 99968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1562: 0.9998472929000854\n",
      "Seen so far: 100032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1563: 0.8963935375213623\n",
      "Seen so far: 100096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1564: 1.14207124710083\n",
      "Seen so far: 100160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1565: 1.214678406715393\n",
      "Seen so far: 100224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1566: 1.0183106660842896\n",
      "Seen so far: 100288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1567: 0.675984799861908\n",
      "Seen so far: 100352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1568: 0.8360084295272827\n",
      "Seen so far: 100416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1569: 0.9946402907371521\n",
      "Seen so far: 100480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1570: 1.330613374710083\n",
      "Seen so far: 100544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1571: 1.171751618385315\n",
      "Seen so far: 100608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1572: 0.7402626872062683\n",
      "Seen so far: 100672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1573: 1.3592549562454224\n",
      "Seen so far: 100736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1574: 0.8324406147003174\n",
      "Seen so far: 100800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1575: 1.2167575359344482\n",
      "Seen so far: 100864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1576: 1.0157909393310547\n",
      "Seen so far: 100928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1577: 0.8204878568649292\n",
      "Seen so far: 100992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1578: 1.1653988361358643\n",
      "Seen so far: 101056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1579: 0.9210191965103149\n",
      "Seen so far: 101120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1580: 1.0444235801696777\n",
      "Seen so far: 101184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1581: 0.9209882020950317\n",
      "Seen so far: 101248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1582: 1.069957971572876\n",
      "Seen so far: 101312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1583: 0.8657736778259277\n",
      "Seen so far: 101376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1584: 1.0618443489074707\n",
      "Seen so far: 101440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1585: 1.5071477890014648\n",
      "Seen so far: 101504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1586: 1.02150559425354\n",
      "Seen so far: 101568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1587: 0.6200253963470459\n",
      "Seen so far: 101632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1588: 0.6972326040267944\n",
      "Seen so far: 101696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1589: 1.0057518482208252\n",
      "Seen so far: 101760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1590: 0.8994244337081909\n",
      "Seen so far: 101824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1591: 1.0955424308776855\n",
      "Seen so far: 101888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1592: 0.9400344491004944\n",
      "Seen so far: 101952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1593: 0.8762117624282837\n",
      "Seen so far: 102016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1594: 0.6222195029258728\n",
      "Seen so far: 102080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1595: 1.2255839109420776\n",
      "Seen so far: 102144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1596: 0.9711577296257019\n",
      "Seen so far: 102208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1597: 1.1872549057006836\n",
      "Seen so far: 102272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1598: 0.9187918305397034\n",
      "Seen so far: 102336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1599: 0.8639727830886841\n",
      "Seen so far: 102400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1600: 0.4990982413291931\n",
      "Seen so far: 102464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1601: 0.9992763996124268\n",
      "Seen so far: 102528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1602: 0.6354984045028687\n",
      "Seen so far: 102592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1603: 1.437941312789917\n",
      "Seen so far: 102656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1604: 0.7575750350952148\n",
      "Seen so far: 102720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1605: 1.5728392601013184\n",
      "Seen so far: 102784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1606: 1.1121256351470947\n",
      "Seen so far: 102848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1607: 0.9266037344932556\n",
      "Seen so far: 102912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1608: 1.0412533283233643\n",
      "Seen so far: 102976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1609: 0.9962692856788635\n",
      "Seen so far: 103040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1610: 1.1190747022628784\n",
      "Seen so far: 103104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1611: 0.9232568740844727\n",
      "Seen so far: 103168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1612: 1.3456110954284668\n",
      "Seen so far: 103232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1613: 1.2165594100952148\n",
      "Seen so far: 103296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1614: 0.7338095903396606\n",
      "Seen so far: 103360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1615: 0.8114079236984253\n",
      "Seen so far: 103424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1616: 0.9498791694641113\n",
      "Seen so far: 103488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1617: 1.1166179180145264\n",
      "Seen so far: 103552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1618: 0.887553334236145\n",
      "Seen so far: 103616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1619: 1.023869514465332\n",
      "Seen so far: 103680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1620: 0.8714150190353394\n",
      "Seen so far: 103744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1621: 0.7880805730819702\n",
      "Seen so far: 103808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1622: 1.0357452630996704\n",
      "Seen so far: 103872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1623: 1.1340079307556152\n",
      "Seen so far: 103936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1624: 0.9694169759750366\n",
      "Seen so far: 104000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1625: 1.3551584482192993\n",
      "Seen so far: 104064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1626: 0.960961103439331\n",
      "Seen so far: 104128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1627: 1.0528738498687744\n",
      "Seen so far: 104192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1628: 0.8658241033554077\n",
      "Seen so far: 104256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1629: 0.8391213417053223\n",
      "Seen so far: 104320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1630: 1.1971442699432373\n",
      "Seen so far: 104384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1631: 0.8586316704750061\n",
      "Seen so far: 104448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1632: 1.3051683902740479\n",
      "Seen so far: 104512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1633: 0.9622307419776917\n",
      "Seen so far: 104576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1634: 1.2218447923660278\n",
      "Seen so far: 104640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1635: 0.8829941749572754\n",
      "Seen so far: 104704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1636: 0.9618258476257324\n",
      "Seen so far: 104768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1637: 0.6923916935920715\n",
      "Seen so far: 104832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1638: 1.1358654499053955\n",
      "Seen so far: 104896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1639: 0.5925121903419495\n",
      "Seen so far: 104960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1640: 1.1723387241363525\n",
      "Seen so far: 105024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1641: 0.8030382990837097\n",
      "Seen so far: 105088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1642: 0.9618700742721558\n",
      "Seen so far: 105152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1643: 1.371415138244629\n",
      "Seen so far: 105216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1644: 0.991442084312439\n",
      "Seen so far: 105280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1645: 1.1303884983062744\n",
      "Seen so far: 105344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1646: 0.8162450790405273\n",
      "Seen so far: 105408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1647: 0.7443047761917114\n",
      "Seen so far: 105472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1648: 0.8763937950134277\n",
      "Seen so far: 105536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1649: 1.3794862031936646\n",
      "Seen so far: 105600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1650: 0.7291041612625122\n",
      "Seen so far: 105664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1651: 1.2484081983566284\n",
      "Seen so far: 105728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1652: 0.9758647680282593\n",
      "Seen so far: 105792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1653: 0.946692705154419\n",
      "Seen so far: 105856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1654: 1.0293822288513184\n",
      "Seen so far: 105920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1655: 0.8091998100280762\n",
      "Seen so far: 105984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1656: 0.7634159326553345\n",
      "Seen so far: 106048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1657: 0.8953410387039185\n",
      "Seen so far: 106112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1658: 0.6997189521789551\n",
      "Seen so far: 106176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1659: 0.964173436164856\n",
      "Seen so far: 106240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1660: 1.0623130798339844\n",
      "Seen so far: 106304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1661: 1.0269360542297363\n",
      "Seen so far: 106368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1662: 0.6773548126220703\n",
      "Seen so far: 106432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1663: 0.9101866483688354\n",
      "Seen so far: 106496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1664: 1.2411601543426514\n",
      "Seen so far: 106560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1665: 1.3652288913726807\n",
      "Seen so far: 106624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1666: 0.9225916266441345\n",
      "Seen so far: 106688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1667: 0.7005459070205688\n",
      "Seen so far: 106752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1668: 1.254122257232666\n",
      "Seen so far: 106816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1669: 0.7786818146705627\n",
      "Seen so far: 106880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1670: 1.0099642276763916\n",
      "Seen so far: 106944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1671: 0.9042624235153198\n",
      "Seen so far: 107008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1672: 1.171143889427185\n",
      "Seen so far: 107072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1673: 0.6892486810684204\n",
      "Seen so far: 107136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1674: 0.8090106248855591\n",
      "Seen so far: 107200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1675: 1.2282154560089111\n",
      "Seen so far: 107264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1676: 0.9816336035728455\n",
      "Seen so far: 107328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1677: 0.8944368362426758\n",
      "Seen so far: 107392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1678: 0.7964198589324951\n",
      "Seen so far: 107456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1679: 0.8542047739028931\n",
      "Seen so far: 107520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1680: 0.9832318425178528\n",
      "Seen so far: 107584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1681: 1.419848084449768\n",
      "Seen so far: 107648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1682: 0.8335294127464294\n",
      "Seen so far: 107712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1683: 1.0781400203704834\n",
      "Seen so far: 107776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1684: 0.9285557270050049\n",
      "Seen so far: 107840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1685: 0.8965272903442383\n",
      "Seen so far: 107904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1686: 1.1102025508880615\n",
      "Seen so far: 107968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1687: 1.1601604223251343\n",
      "Seen so far: 108032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1688: 1.3885688781738281\n",
      "Seen so far: 108096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1689: 0.6892992258071899\n",
      "Seen so far: 108160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1690: 1.1757926940917969\n",
      "Seen so far: 108224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1691: 0.642789363861084\n",
      "Seen so far: 108288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1692: 0.8449571132659912\n",
      "Seen so far: 108352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1693: 1.204728364944458\n",
      "Seen so far: 108416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1694: 1.0318021774291992\n",
      "Seen so far: 108480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1695: 1.0303893089294434\n",
      "Seen so far: 108544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1696: 1.2685878276824951\n",
      "Seen so far: 108608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1697: 1.2181603908538818\n",
      "Seen so far: 108672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1698: 0.7536206245422363\n",
      "Seen so far: 108736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1699: 0.6545873880386353\n",
      "Seen so far: 108800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1700: 0.8363966941833496\n",
      "Seen so far: 108864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1701: 1.0278593301773071\n",
      "Seen so far: 108928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1702: 1.2359795570373535\n",
      "Seen so far: 108992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1703: 0.6178542375564575\n",
      "Seen so far: 109056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1704: 1.136655569076538\n",
      "Seen so far: 109120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1705: 1.2396798133850098\n",
      "Seen so far: 109184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1706: 1.296445369720459\n",
      "Seen so far: 109248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1707: 1.0061571598052979\n",
      "Seen so far: 109312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1708: 1.1169894933700562\n",
      "Seen so far: 109376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1709: 1.4294955730438232\n",
      "Seen so far: 109440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1710: 0.8345015048980713\n",
      "Seen so far: 109504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1711: 0.9403030872344971\n",
      "Seen so far: 109568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1712: 0.8410364389419556\n",
      "Seen so far: 109632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1713: 0.590626060962677\n",
      "Seen so far: 109696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1714: 0.9000829458236694\n",
      "Seen so far: 109760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1715: 0.7854307889938354\n",
      "Seen so far: 109824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1716: 1.2845295667648315\n",
      "Seen so far: 109888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1717: 0.6535120010375977\n",
      "Seen so far: 109952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1718: 0.8186754584312439\n",
      "Seen so far: 110016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1719: 0.7749168872833252\n",
      "Seen so far: 110080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1720: 1.1878552436828613\n",
      "Seen so far: 110144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1721: 1.0281553268432617\n",
      "Seen so far: 110208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1722: 0.8260794878005981\n",
      "Seen so far: 110272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1723: 0.7309311628341675\n",
      "Seen so far: 110336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1724: 1.1727581024169922\n",
      "Seen so far: 110400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1725: 0.8123483061790466\n",
      "Seen so far: 110464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1726: 1.5329372882843018\n",
      "Seen so far: 110528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1727: 0.9468791484832764\n",
      "Seen so far: 110592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1728: 0.8450254201889038\n",
      "Seen so far: 110656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1729: 0.9220573902130127\n",
      "Seen so far: 110720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1730: 0.7828992009162903\n",
      "Seen so far: 110784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1731: 0.6222320795059204\n",
      "Seen so far: 110848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1732: 1.2934770584106445\n",
      "Seen so far: 110912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1733: 1.3677325248718262\n",
      "Seen so far: 110976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1734: 0.8544809818267822\n",
      "Seen so far: 111040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1735: 0.8792182207107544\n",
      "Seen so far: 111104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1736: 0.9943772554397583\n",
      "Seen so far: 111168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1737: 1.2077579498291016\n",
      "Seen so far: 111232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1738: 0.8907746076583862\n",
      "Seen so far: 111296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1739: 1.1065800189971924\n",
      "Seen so far: 111360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1740: 1.2034822702407837\n",
      "Seen so far: 111424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1741: 0.9831974506378174\n",
      "Seen so far: 111488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1742: 1.0788352489471436\n",
      "Seen so far: 111552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1743: 0.4703371822834015\n",
      "Seen so far: 111616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1744: 0.8707672357559204\n",
      "Seen so far: 111680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1745: 1.143369436264038\n",
      "Seen so far: 111744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1746: 1.2877414226531982\n",
      "Seen so far: 111808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1747: 1.576806664466858\n",
      "Seen so far: 111872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1748: 0.8992301225662231\n",
      "Seen so far: 111936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1749: 0.7730022668838501\n",
      "Seen so far: 112000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1750: 1.0232188701629639\n",
      "Seen so far: 112064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1751: 1.041717529296875\n",
      "Seen so far: 112128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1752: 1.2915949821472168\n",
      "Seen so far: 112192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1753: 1.0918805599212646\n",
      "Seen so far: 112256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1754: 1.3544833660125732\n",
      "Seen so far: 112320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1755: 0.7858814001083374\n",
      "Seen so far: 112384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1756: 1.4154157638549805\n",
      "Seen so far: 112448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1757: 0.8858386278152466\n",
      "Seen so far: 112512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1758: 1.2333879470825195\n",
      "Seen so far: 112576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1759: 0.863964319229126\n",
      "Seen so far: 112640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1760: 1.0385035276412964\n",
      "Seen so far: 112704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1761: 0.9047986268997192\n",
      "Seen so far: 112768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1762: 0.9275615811347961\n",
      "Seen so far: 112832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1763: 1.3678058385849\n",
      "Seen so far: 112896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1764: 0.9771891236305237\n",
      "Seen so far: 112960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1765: 0.7730457782745361\n",
      "Seen so far: 113024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1766: 0.8049031496047974\n",
      "Seen so far: 113088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1767: 0.978786826133728\n",
      "Seen so far: 113152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1768: 1.0253162384033203\n",
      "Seen so far: 113216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1769: 0.8392463326454163\n",
      "Seen so far: 113280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1770: 0.8373681306838989\n",
      "Seen so far: 113344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1771: 1.020302653312683\n",
      "Seen so far: 113408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1772: 1.2187933921813965\n",
      "Seen so far: 113472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1773: 0.967995285987854\n",
      "Seen so far: 113536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1774: 0.7278717756271362\n",
      "Seen so far: 113600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1775: 1.1717119216918945\n",
      "Seen so far: 113664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1776: 1.3043973445892334\n",
      "Seen so far: 113728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1777: 1.0622758865356445\n",
      "Seen so far: 113792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1778: 0.9309751987457275\n",
      "Seen so far: 113856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1779: 1.4411194324493408\n",
      "Seen so far: 113920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1780: 1.2754989862442017\n",
      "Seen so far: 113984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1781: 1.3448171615600586\n",
      "Seen so far: 114048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1782: 0.7348825931549072\n",
      "Seen so far: 114112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1783: 1.1380876302719116\n",
      "Seen so far: 114176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1784: 0.944526195526123\n",
      "Seen so far: 114240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1785: 0.8762120604515076\n",
      "Seen so far: 114304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1786: 1.0024195909500122\n",
      "Seen so far: 114368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1787: 1.060105800628662\n",
      "Seen so far: 114432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1788: 0.9946611523628235\n",
      "Seen so far: 114496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1789: 0.9170979261398315\n",
      "Seen so far: 114560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1790: 1.0381442308425903\n",
      "Seen so far: 114624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1791: 0.7921241521835327\n",
      "Seen so far: 114688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1792: 0.721611738204956\n",
      "Seen so far: 114752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1793: 1.0667228698730469\n",
      "Seen so far: 114816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1794: 0.8853662014007568\n",
      "Seen so far: 114880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1795: 0.792660117149353\n",
      "Seen so far: 114944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1796: 0.8623039722442627\n",
      "Seen so far: 115008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1797: 0.6126994490623474\n",
      "Seen so far: 115072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1798: 0.8110494017601013\n",
      "Seen so far: 115136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1799: 0.9327932000160217\n",
      "Seen so far: 115200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1800: 0.8788492679595947\n",
      "Seen so far: 115264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1801: 0.833571195602417\n",
      "Seen so far: 115328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1802: 0.7284656763076782\n",
      "Seen so far: 115392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1803: 0.9810976982116699\n",
      "Seen so far: 115456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1804: 0.7899526357650757\n",
      "Seen so far: 115520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1805: 0.6537858843803406\n",
      "Seen so far: 115584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1806: 0.9351392984390259\n",
      "Seen so far: 115648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1807: 0.9344073534011841\n",
      "Seen so far: 115712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1808: 1.1517720222473145\n",
      "Seen so far: 115776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1809: 1.0524158477783203\n",
      "Seen so far: 115840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1810: 0.7151646018028259\n",
      "Seen so far: 115904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1811: 0.8573428988456726\n",
      "Seen so far: 115968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1812: 0.6951946020126343\n",
      "Seen so far: 116032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1813: 1.2605969905853271\n",
      "Seen so far: 116096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1814: 0.9564400911331177\n",
      "Seen so far: 116160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1815: 1.4632657766342163\n",
      "Seen so far: 116224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1816: 1.007349967956543\n",
      "Seen so far: 116288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1817: 0.8028528690338135\n",
      "Seen so far: 116352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1818: 0.9195166826248169\n",
      "Seen so far: 116416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1819: 0.7080987095832825\n",
      "Seen so far: 116480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1820: 0.7941762208938599\n",
      "Seen so far: 116544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1821: 1.1943137645721436\n",
      "Seen so far: 116608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1822: 1.2392468452453613\n",
      "Seen so far: 116672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1823: 1.241632342338562\n",
      "Seen so far: 116736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1824: 1.1072745323181152\n",
      "Seen so far: 116800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1825: 0.9403101801872253\n",
      "Seen so far: 116864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1826: 1.1473422050476074\n",
      "Seen so far: 116928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1827: 1.1622235774993896\n",
      "Seen so far: 116992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1828: 1.1631839275360107\n",
      "Seen so far: 117056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1829: 0.9720652103424072\n",
      "Seen so far: 117120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1830: 1.0173094272613525\n",
      "Seen so far: 117184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1831: 0.8609896898269653\n",
      "Seen so far: 117248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1832: 1.26571524143219\n",
      "Seen so far: 117312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1833: 0.885773777961731\n",
      "Seen so far: 117376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1834: 1.3301939964294434\n",
      "Seen so far: 117440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1835: 0.8320539593696594\n",
      "Seen so far: 117504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1836: 0.9159814119338989\n",
      "Seen so far: 117568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1837: 0.7161159515380859\n",
      "Seen so far: 117632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1838: 1.0297795534133911\n",
      "Seen so far: 117696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1839: 0.7746564149856567\n",
      "Seen so far: 117760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1840: 1.4402692317962646\n",
      "Seen so far: 117824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1841: 0.9034556150436401\n",
      "Seen so far: 117888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1842: 0.588870108127594\n",
      "Seen so far: 117952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1843: 1.0732513666152954\n",
      "Seen so far: 118016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1844: 0.9190037846565247\n",
      "Seen so far: 118080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1845: 0.9897150993347168\n",
      "Seen so far: 118144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1846: 1.1502115726470947\n",
      "Seen so far: 118208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1847: 1.1071808338165283\n",
      "Seen so far: 118272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1848: 0.8707807064056396\n",
      "Seen so far: 118336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1849: 1.2461235523223877\n",
      "Seen so far: 118400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1850: 0.8277097344398499\n",
      "Seen so far: 118464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1851: 1.374640941619873\n",
      "Seen so far: 118528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1852: 0.9743053913116455\n",
      "Seen so far: 118592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1853: 0.5503233671188354\n",
      "Seen so far: 118656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1854: 1.2914475202560425\n",
      "Seen so far: 118720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1855: 1.2531994581222534\n",
      "Seen so far: 118784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1856: 1.0655313730239868\n",
      "Seen so far: 118848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1857: 0.8528121709823608\n",
      "Seen so far: 118912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1858: 1.2329778671264648\n",
      "Seen so far: 118976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1859: 0.6669187545776367\n",
      "Seen so far: 119040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1860: 0.8057337403297424\n",
      "Seen so far: 119104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1861: 1.2390871047973633\n",
      "Seen so far: 119168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1862: 0.766054630279541\n",
      "Seen so far: 119232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1863: 0.8679084777832031\n",
      "Seen so far: 119296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1864: 0.8283491730690002\n",
      "Seen so far: 119360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1865: 0.8696813583374023\n",
      "Seen so far: 119424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1866: 1.0600484609603882\n",
      "Seen so far: 119488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1867: 0.6951959729194641\n",
      "Seen so far: 119552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1868: 0.8314331769943237\n",
      "Seen so far: 119616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1869: 0.8641932010650635\n",
      "Seen so far: 119680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1870: 0.879368245601654\n",
      "Seen so far: 119744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1871: 0.8901393413543701\n",
      "Seen so far: 119808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1872: 1.0689448118209839\n",
      "Seen so far: 119872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1873: 1.2173902988433838\n",
      "Seen so far: 119936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1874: 1.1561665534973145\n",
      "Seen so far: 120000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1875: 0.9191787838935852\n",
      "Seen so far: 120064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1876: 0.6330744028091431\n",
      "Seen so far: 120128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1877: 0.7459676265716553\n",
      "Seen so far: 120192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1878: 1.173285961151123\n",
      "Seen so far: 120256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1879: 0.9811588525772095\n",
      "Seen so far: 120320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1880: 0.9487665891647339\n",
      "Seen so far: 120384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1881: 0.5789801478385925\n",
      "Seen so far: 120448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1882: 1.0534745454788208\n",
      "Seen so far: 120512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1883: 0.7191033363342285\n",
      "Seen so far: 120576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1884: 1.0405864715576172\n",
      "Seen so far: 120640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1885: 0.9726241827011108\n",
      "Seen so far: 120704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1886: 0.923442006111145\n",
      "Seen so far: 120768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1887: 1.0411198139190674\n",
      "Seen so far: 120832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1888: 0.5666535496711731\n",
      "Seen so far: 120896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1889: 1.315190315246582\n",
      "Seen so far: 120960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1890: 1.3078433275222778\n",
      "Seen so far: 121024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1891: 1.2018790245056152\n",
      "Seen so far: 121088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1892: 0.9610356688499451\n",
      "Seen so far: 121152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1893: 1.0968362092971802\n",
      "Seen so far: 121216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1894: 1.346552848815918\n",
      "Seen so far: 121280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1895: 1.037715196609497\n",
      "Seen so far: 121344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1896: 0.5290224552154541\n",
      "Seen so far: 121408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1897: 1.271920919418335\n",
      "Seen so far: 121472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1898: 0.8599048852920532\n",
      "Seen so far: 121536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1899: 1.0472664833068848\n",
      "Seen so far: 121600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1900: 1.0685404539108276\n",
      "Seen so far: 121664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1901: 0.6260852813720703\n",
      "Seen so far: 121728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1902: 1.3293516635894775\n",
      "Seen so far: 121792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1903: 0.9531328082084656\n",
      "Seen so far: 121856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1904: 1.003970742225647\n",
      "Seen so far: 121920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1905: 0.9889482855796814\n",
      "Seen so far: 121984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1906: 0.713984489440918\n",
      "Seen so far: 122048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1907: 1.267833948135376\n",
      "Seen so far: 122112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1908: 1.02620530128479\n",
      "Seen so far: 122176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1909: 0.9374428391456604\n",
      "Seen so far: 122240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1910: 0.8443532586097717\n",
      "Seen so far: 122304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1911: 0.826286792755127\n",
      "Seen so far: 122368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1912: 1.0839813947677612\n",
      "Seen so far: 122432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1913: 0.7276487946510315\n",
      "Seen so far: 122496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1914: 0.8381081223487854\n",
      "Seen so far: 122560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1915: 0.796288251876831\n",
      "Seen so far: 122624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1916: 0.9354329705238342\n",
      "Seen so far: 122688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1917: 1.0820282697677612\n",
      "Seen so far: 122752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1918: 1.109269142150879\n",
      "Seen so far: 122816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1919: 1.0703777074813843\n",
      "Seen so far: 122880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1920: 1.2084097862243652\n",
      "Seen so far: 122944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1921: 0.8700254559516907\n",
      "Seen so far: 123008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1922: 0.9764566421508789\n",
      "Seen so far: 123072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1923: 1.188210368156433\n",
      "Seen so far: 123136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1924: 0.8308671712875366\n",
      "Seen so far: 123200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1925: 0.9050264954566956\n",
      "Seen so far: 123264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1926: 1.1331562995910645\n",
      "Seen so far: 123328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1927: 1.1592789888381958\n",
      "Seen so far: 123392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1928: 0.6646895408630371\n",
      "Seen so far: 123456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1929: 0.8115572929382324\n",
      "Seen so far: 123520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1930: 1.297978162765503\n",
      "Seen so far: 123584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1931: 1.0380494594573975\n",
      "Seen so far: 123648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1932: 1.3567867279052734\n",
      "Seen so far: 123712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1933: 0.9792172908782959\n",
      "Seen so far: 123776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1934: 1.057957649230957\n",
      "Seen so far: 123840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1935: 1.333033561706543\n",
      "Seen so far: 123904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1936: 1.5718039274215698\n",
      "Seen so far: 123968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1937: 1.1005504131317139\n",
      "Seen so far: 124032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1938: 0.8008183836936951\n",
      "Seen so far: 124096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1939: 1.3200852870941162\n",
      "Seen so far: 124160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1940: 0.9736588597297668\n",
      "Seen so far: 124224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1941: 0.8406385779380798\n",
      "Seen so far: 124288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1942: 1.1404216289520264\n",
      "Seen so far: 124352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1943: 0.7029273509979248\n",
      "Seen so far: 124416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1944: 1.1377723217010498\n",
      "Seen so far: 124480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1945: 1.1394133567810059\n",
      "Seen so far: 124544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1946: 0.9451959133148193\n",
      "Seen so far: 124608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1947: 0.8643952012062073\n",
      "Seen so far: 124672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1948: 1.3539212942123413\n",
      "Seen so far: 124736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1949: 0.8974519968032837\n",
      "Seen so far: 124800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1950: 1.2307515144348145\n",
      "Seen so far: 124864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1951: 0.5935673713684082\n",
      "Seen so far: 124928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1952: 0.6088131666183472\n",
      "Seen so far: 124992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1953: 0.6065670251846313\n",
      "Seen so far: 125056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1954: 1.1979482173919678\n",
      "Seen so far: 125120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1955: 0.970782995223999\n",
      "Seen so far: 125184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1956: 0.9845596551895142\n",
      "Seen so far: 125248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1957: 0.9665504693984985\n",
      "Seen so far: 125312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1958: 0.6438597440719604\n",
      "Seen so far: 125376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1959: 0.8165578842163086\n",
      "Seen so far: 125440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1960: 1.2476648092269897\n",
      "Seen so far: 125504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1961: 1.014829397201538\n",
      "Seen so far: 125568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1962: 0.8113493323326111\n",
      "Seen so far: 125632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1963: 0.8054262399673462\n",
      "Seen so far: 125696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1964: 0.6658418774604797\n",
      "Seen so far: 125760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1965: 1.1968003511428833\n",
      "Seen so far: 125824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1966: 0.7375068664550781\n",
      "Seen so far: 125888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1967: 0.9945152997970581\n",
      "Seen so far: 125952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1968: 0.7937676906585693\n",
      "Seen so far: 126016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1969: 0.8746917843818665\n",
      "Seen so far: 126080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1970: 1.0638585090637207\n",
      "Seen so far: 126144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1971: 0.9577116966247559\n",
      "Seen so far: 126208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1972: 1.057442545890808\n",
      "Seen so far: 126272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1973: 1.1008086204528809\n",
      "Seen so far: 126336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1974: 0.98966383934021\n",
      "Seen so far: 126400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1975: 1.2981375455856323\n",
      "Seen so far: 126464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1976: 0.8009848594665527\n",
      "Seen so far: 126528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1977: 0.7058714628219604\n",
      "Seen so far: 126592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1978: 0.9863757491111755\n",
      "Seen so far: 126656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1979: 0.6143054962158203\n",
      "Seen so far: 126720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1980: 1.2358397245407104\n",
      "Seen so far: 126784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1981: 0.8601142168045044\n",
      "Seen so far: 126848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1982: 0.6987988948822021\n",
      "Seen so far: 126912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1983: 1.3252298831939697\n",
      "Seen so far: 126976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1984: 0.9961069226264954\n",
      "Seen so far: 127040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1985: 1.1242237091064453\n",
      "Seen so far: 127104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1986: 0.5851473808288574\n",
      "Seen so far: 127168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1987: 1.1791200637817383\n",
      "Seen so far: 127232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1988: 1.2714320421218872\n",
      "Seen so far: 127296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1989: 0.762693464756012\n",
      "Seen so far: 127360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1990: 0.8149016499519348\n",
      "Seen so far: 127424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1991: 1.3887012004852295\n",
      "Seen so far: 127488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1992: 1.1401610374450684\n",
      "Seen so far: 127552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1993: 0.8544625043869019\n",
      "Seen so far: 127616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1994: 1.0857900381088257\n",
      "Seen so far: 127680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1995: 0.6088268756866455\n",
      "Seen so far: 127744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1996: 0.9411289691925049\n",
      "Seen so far: 127808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1997: 1.0651233196258545\n",
      "Seen so far: 127872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1998: 0.8448134660720825\n",
      "Seen so far: 127936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1999: 0.8757797479629517\n",
      "Seen so far: 128000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2000: 0.9566908478736877\n",
      "Seen so far: 128064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2001: 0.7937818169593811\n",
      "Seen so far: 128128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2002: 1.2419991493225098\n",
      "Seen so far: 128192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2003: 0.7047371864318848\n",
      "Seen so far: 128256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2004: 1.0691155195236206\n",
      "Seen so far: 128320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2005: 1.0466768741607666\n",
      "Seen so far: 128384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2006: 1.1159976720809937\n",
      "Seen so far: 128448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2007: 0.7797942161560059\n",
      "Seen so far: 128512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2008: 0.951075553894043\n",
      "Seen so far: 128576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2009: 0.9193459749221802\n",
      "Seen so far: 128640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2010: 1.4356228113174438\n",
      "Seen so far: 128704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2011: 1.1739850044250488\n",
      "Seen so far: 128768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2012: 0.9687451124191284\n",
      "Seen so far: 128832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2013: 1.2040185928344727\n",
      "Seen so far: 128896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2014: 0.937962532043457\n",
      "Seen so far: 128960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2015: 0.848191499710083\n",
      "Seen so far: 129024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2016: 0.7668905854225159\n",
      "Seen so far: 129088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2017: 0.9881058931350708\n",
      "Seen so far: 129152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2018: 0.6079494953155518\n",
      "Seen so far: 129216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2019: 1.1583645343780518\n",
      "Seen so far: 129280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2020: 0.5820773839950562\n",
      "Seen so far: 129344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2021: 1.0669087171554565\n",
      "Seen so far: 129408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2022: 1.3517365455627441\n",
      "Seen so far: 129472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2023: 0.8344894647598267\n",
      "Seen so far: 129536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2024: 0.7583086490631104\n",
      "Seen so far: 129600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2025: 1.0758320093154907\n",
      "Seen so far: 129664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2026: 1.0138728618621826\n",
      "Seen so far: 129728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2027: 1.1785650253295898\n",
      "Seen so far: 129792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2028: 0.7352021932601929\n",
      "Seen so far: 129856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2029: 0.9992625117301941\n",
      "Seen so far: 129920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2030: 1.482553482055664\n",
      "Seen so far: 129984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2031: 1.517090082168579\n",
      "Seen so far: 130048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2032: 1.0655571222305298\n",
      "Seen so far: 130112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2033: 1.2901010513305664\n",
      "Seen so far: 130176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2034: 1.2908024787902832\n",
      "Seen so far: 130240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2035: 0.8717026710510254\n",
      "Seen so far: 130304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2036: 0.7327889204025269\n",
      "Seen so far: 130368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2037: 0.8165983557701111\n",
      "Seen so far: 130432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2038: 0.9475873112678528\n",
      "Seen so far: 130496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2039: 1.0692713260650635\n",
      "Seen so far: 130560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2040: 0.5590544939041138\n",
      "Seen so far: 130624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2041: 0.8092148303985596\n",
      "Seen so far: 130688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2042: 1.0441646575927734\n",
      "Seen so far: 130752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2043: 0.818152904510498\n",
      "Seen so far: 130816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2044: 1.028939962387085\n",
      "Seen so far: 130880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2045: 0.7830238342285156\n",
      "Seen so far: 130944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2046: 0.9911383390426636\n",
      "Seen so far: 131008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2047: 0.868546724319458\n",
      "Seen so far: 131072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2048: 0.8143112659454346\n",
      "Seen so far: 131136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2049: 1.016493320465088\n",
      "Seen so far: 131200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2050: 0.8632901310920715\n",
      "Seen so far: 131264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2051: 1.1795828342437744\n",
      "Seen so far: 131328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2052: 1.029571771621704\n",
      "Seen so far: 131392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2053: 1.0185134410858154\n",
      "Seen so far: 131456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2054: 1.0002485513687134\n",
      "Seen so far: 131520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2055: 0.4493618607521057\n",
      "Seen so far: 131584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2056: 0.6097351908683777\n",
      "Seen so far: 131648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2057: 0.930264949798584\n",
      "Seen so far: 131712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2058: 0.9058648347854614\n",
      "Seen so far: 131776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2059: 0.8426560759544373\n",
      "Seen so far: 131840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2060: 1.0255290269851685\n",
      "Seen so far: 131904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2061: 1.210619330406189\n",
      "Seen so far: 131968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2062: 1.0095491409301758\n",
      "Seen so far: 132032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2063: 0.8908371925354004\n",
      "Seen so far: 132096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2064: 0.9939982295036316\n",
      "Seen so far: 132160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2065: 0.7840127944946289\n",
      "Seen so far: 132224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2066: 1.1320593357086182\n",
      "Seen so far: 132288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2067: 0.9072195291519165\n",
      "Seen so far: 132352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2068: 1.2643461227416992\n",
      "Seen so far: 132416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2069: 1.2046067714691162\n",
      "Seen so far: 132480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2070: 0.7173020839691162\n",
      "Seen so far: 132544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2071: 0.5336253643035889\n",
      "Seen so far: 132608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2072: 0.9943897128105164\n",
      "Seen so far: 132672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2073: 0.9191614389419556\n",
      "Seen so far: 132736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2074: 0.7831544280052185\n",
      "Seen so far: 132800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2075: 1.0041544437408447\n",
      "Seen so far: 132864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2076: 0.7587876319885254\n",
      "Seen so far: 132928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2077: 0.9336811304092407\n",
      "Seen so far: 132992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2078: 1.1046370267868042\n",
      "Seen so far: 133056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2079: 0.9366955757141113\n",
      "Seen so far: 133120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2080: 0.5079647898674011\n",
      "Seen so far: 133184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2081: 1.2339811325073242\n",
      "Seen so far: 133248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2082: 0.8298314809799194\n",
      "Seen so far: 133312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2083: 0.9894899129867554\n",
      "Seen so far: 133376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2084: 0.9223018884658813\n",
      "Seen so far: 133440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2085: 0.5696623921394348\n",
      "Seen so far: 133504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2086: 0.4795834422111511\n",
      "Seen so far: 133568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2087: 1.1001133918762207\n",
      "Seen so far: 133632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2088: 0.8175638318061829\n",
      "Seen so far: 133696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2089: 0.9304207563400269\n",
      "Seen so far: 133760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2090: 0.8851640820503235\n",
      "Seen so far: 133824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2091: 0.8637260794639587\n",
      "Seen so far: 133888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2092: 0.8851065039634705\n",
      "Seen so far: 133952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2093: 0.7084068059921265\n",
      "Seen so far: 134016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2094: 0.9396563768386841\n",
      "Seen so far: 134080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2095: 1.0644009113311768\n",
      "Seen so far: 134144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2096: 0.988406240940094\n",
      "Seen so far: 134208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2097: 0.6473375558853149\n",
      "Seen so far: 134272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2098: 0.9280977249145508\n",
      "Seen so far: 134336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2099: 0.7568197846412659\n",
      "Seen so far: 134400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2100: 0.8177773356437683\n",
      "Seen so far: 134464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2101: 0.6020118594169617\n",
      "Seen so far: 134528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2102: 1.0704748630523682\n",
      "Seen so far: 134592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2103: 0.8043035268783569\n",
      "Seen so far: 134656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2104: 0.9085197448730469\n",
      "Seen so far: 134720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2105: 0.6419098377227783\n",
      "Seen so far: 134784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2106: 0.9171515107154846\n",
      "Seen so far: 134848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2107: 0.9875568151473999\n",
      "Seen so far: 134912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2108: 0.46560654044151306\n",
      "Seen so far: 134976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2109: 0.7250827550888062\n",
      "Seen so far: 135040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2110: 1.1027287244796753\n",
      "Seen so far: 135104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2111: 0.6627776622772217\n",
      "Seen so far: 135168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2112: 0.7017191052436829\n",
      "Seen so far: 135232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2113: 1.1307345628738403\n",
      "Seen so far: 135296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2114: 0.9244856834411621\n",
      "Seen so far: 135360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2115: 0.9973082542419434\n",
      "Seen so far: 135424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2116: 0.6776247024536133\n",
      "Seen so far: 135488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2117: 0.7924146056175232\n",
      "Seen so far: 135552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2118: 1.4117488861083984\n",
      "Seen so far: 135616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2119: 0.9834494590759277\n",
      "Seen so far: 135680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2120: 1.263502836227417\n",
      "Seen so far: 135744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2121: 0.8204125165939331\n",
      "Seen so far: 135808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2122: 0.8539534211158752\n",
      "Seen so far: 135872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2123: 0.918628454208374\n",
      "Seen so far: 135936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2124: 0.9652924537658691\n",
      "Seen so far: 136000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2125: 1.0436742305755615\n",
      "Seen so far: 136064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2126: 1.124915361404419\n",
      "Seen so far: 136128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2127: 1.0856444835662842\n",
      "Seen so far: 136192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2128: 0.9204081892967224\n",
      "Seen so far: 136256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2129: 1.036637306213379\n",
      "Seen so far: 136320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2130: 0.8319783210754395\n",
      "Seen so far: 136384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2131: 0.9619983434677124\n",
      "Seen so far: 136448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2132: 0.8841379880905151\n",
      "Seen so far: 136512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2133: 0.7127324342727661\n",
      "Seen so far: 136576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2134: 0.3699161410331726\n",
      "Seen so far: 136640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2135: 0.6173925399780273\n",
      "Seen so far: 136704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2136: 0.6469129323959351\n",
      "Seen so far: 136768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2137: 1.0262057781219482\n",
      "Seen so far: 136832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2138: 0.908124566078186\n",
      "Seen so far: 136896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2139: 1.1370065212249756\n",
      "Seen so far: 136960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2140: 1.1210532188415527\n",
      "Seen so far: 137024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2141: 1.5463677644729614\n",
      "Seen so far: 137088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2142: 0.7053232192993164\n",
      "Seen so far: 137152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2143: 0.9094852209091187\n",
      "Seen so far: 137216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2144: 0.8136727809906006\n",
      "Seen so far: 137280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2145: 1.198798418045044\n",
      "Seen so far: 137344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2146: 1.2920223474502563\n",
      "Seen so far: 137408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2147: 0.6684963703155518\n",
      "Seen so far: 137472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2148: 1.0971639156341553\n",
      "Seen so far: 137536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2149: 1.0298054218292236\n",
      "Seen so far: 137600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2150: 0.6216391324996948\n",
      "Seen so far: 137664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2151: 0.8211972713470459\n",
      "Seen so far: 137728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2152: 1.140126347541809\n",
      "Seen so far: 137792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2153: 0.7132730484008789\n",
      "Seen so far: 137856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2154: 1.1193689107894897\n",
      "Seen so far: 137920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2155: 0.829864501953125\n",
      "Seen so far: 137984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2156: 0.724000096321106\n",
      "Seen so far: 138048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2157: 0.5259420871734619\n",
      "Seen so far: 138112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2158: 0.8494665622711182\n",
      "Seen so far: 138176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2159: 0.6475793719291687\n",
      "Seen so far: 138240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2160: 1.0031312704086304\n",
      "Seen so far: 138304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2161: 0.7750343680381775\n",
      "Seen so far: 138368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2162: 0.8912521600723267\n",
      "Seen so far: 138432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2163: 0.6596277356147766\n",
      "Seen so far: 138496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2164: 1.3427762985229492\n",
      "Seen so far: 138560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2165: 1.0279663801193237\n",
      "Seen so far: 138624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2166: 0.6439043283462524\n",
      "Seen so far: 138688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2167: 0.9986647367477417\n",
      "Seen so far: 138752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2168: 0.7086513042449951\n",
      "Seen so far: 138816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2169: 0.7220334410667419\n",
      "Seen so far: 138880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2170: 1.0631548166275024\n",
      "Seen so far: 138944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2171: 1.1103136539459229\n",
      "Seen so far: 139008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2172: 0.8352674841880798\n",
      "Seen so far: 139072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2173: 0.7418950796127319\n",
      "Seen so far: 139136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2174: 1.464891791343689\n",
      "Seen so far: 139200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2175: 0.8886028528213501\n",
      "Seen so far: 139264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2176: 1.0057388544082642\n",
      "Seen so far: 139328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2177: 0.8735663890838623\n",
      "Seen so far: 139392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2178: 0.5215224027633667\n",
      "Seen so far: 139456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2179: 0.5558290481567383\n",
      "Seen so far: 139520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2180: 0.7786569595336914\n",
      "Seen so far: 139584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2181: 1.1095688343048096\n",
      "Seen so far: 139648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2182: 1.297688603401184\n",
      "Seen so far: 139712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2183: 0.7064076066017151\n",
      "Seen so far: 139776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2184: 1.2423667907714844\n",
      "Seen so far: 139840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2185: 1.052013874053955\n",
      "Seen so far: 139904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2186: 0.8583575487136841\n",
      "Seen so far: 139968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2187: 0.8665339946746826\n",
      "Seen so far: 140032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2188: 0.7495673894882202\n",
      "Seen so far: 140096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2189: 1.080216646194458\n",
      "Seen so far: 140160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2190: 0.8479931354522705\n",
      "Seen so far: 140224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2191: 0.7839310765266418\n",
      "Seen so far: 140288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2192: 0.8516932725906372\n",
      "Seen so far: 140352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2193: 0.8502981066703796\n",
      "Seen so far: 140416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2194: 0.648714542388916\n",
      "Seen so far: 140480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2195: 1.285426378250122\n",
      "Seen so far: 140544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2196: 0.6776517629623413\n",
      "Seen so far: 140608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2197: 0.6366971731185913\n",
      "Seen so far: 140672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2198: 1.053222417831421\n",
      "Seen so far: 140736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2199: 0.7367120981216431\n",
      "Seen so far: 140800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2200: 1.2540974617004395\n",
      "Seen so far: 140864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2201: 0.9862102270126343\n",
      "Seen so far: 140928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2202: 0.8135865926742554\n",
      "Seen so far: 140992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2203: 1.3234124183654785\n",
      "Seen so far: 141056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2204: 0.7715728282928467\n",
      "Seen so far: 141120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2205: 0.6308478116989136\n",
      "Seen so far: 141184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2206: 1.2113362550735474\n",
      "Seen so far: 141248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2207: 1.0115934610366821\n",
      "Seen so far: 141312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2208: 1.8308738470077515\n",
      "Seen so far: 141376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2209: 0.8157809376716614\n",
      "Seen so far: 141440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2210: 0.7306321859359741\n",
      "Seen so far: 141504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2211: 1.0119247436523438\n",
      "Seen so far: 141568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2212: 0.8265900611877441\n",
      "Seen so far: 141632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2213: 0.7306852340698242\n",
      "Seen so far: 141696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2214: 1.0794425010681152\n",
      "Seen so far: 141760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2215: 0.9653102159500122\n",
      "Seen so far: 141824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2216: 0.7193483710289001\n",
      "Seen so far: 141888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2217: 1.0149222612380981\n",
      "Seen so far: 141952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2218: 0.9512523412704468\n",
      "Seen so far: 142016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2219: 0.9668760299682617\n",
      "Seen so far: 142080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2220: 1.0490543842315674\n",
      "Seen so far: 142144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2221: 1.1663331985473633\n",
      "Seen so far: 142208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2222: 1.3883135318756104\n",
      "Seen so far: 142272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2223: 0.7655510902404785\n",
      "Seen so far: 142336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2224: 1.189018964767456\n",
      "Seen so far: 142400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2225: 0.9613020420074463\n",
      "Seen so far: 142464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2226: 1.1562813520431519\n",
      "Seen so far: 142528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2227: 0.8095835447311401\n",
      "Seen so far: 142592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2228: 1.1063799858093262\n",
      "Seen so far: 142656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2229: 1.0565009117126465\n",
      "Seen so far: 142720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2230: 0.934095561504364\n",
      "Seen so far: 142784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2231: 0.9787766933441162\n",
      "Seen so far: 142848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2232: 1.2052727937698364\n",
      "Seen so far: 142912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2233: 0.8456661105155945\n",
      "Seen so far: 142976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2234: 1.1103023290634155\n",
      "Seen so far: 143040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2235: 1.1064982414245605\n",
      "Seen so far: 143104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2236: 1.0743982791900635\n",
      "Seen so far: 143168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2237: 1.1479283571243286\n",
      "Seen so far: 143232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2238: 0.9374381303787231\n",
      "Seen so far: 143296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2239: 0.9929584264755249\n",
      "Seen so far: 143360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2240: 0.6316561102867126\n",
      "Seen so far: 143424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2241: 1.1940929889678955\n",
      "Seen so far: 143488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2242: 1.0485270023345947\n",
      "Seen so far: 143552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2243: 1.0481611490249634\n",
      "Seen so far: 143616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2244: 1.0178600549697876\n",
      "Seen so far: 143680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2245: 0.7073251008987427\n",
      "Seen so far: 143744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2246: 0.7839497327804565\n",
      "Seen so far: 143808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2247: 1.4462134838104248\n",
      "Seen so far: 143872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2248: 0.5852227807044983\n",
      "Seen so far: 143936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2249: 1.1738488674163818\n",
      "Seen so far: 144000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2250: 0.8186759948730469\n",
      "Seen so far: 144064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2251: 0.9696654081344604\n",
      "Seen so far: 144128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2252: 0.8099813461303711\n",
      "Seen so far: 144192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2253: 1.1423609256744385\n",
      "Seen so far: 144256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2254: 0.9017469882965088\n",
      "Seen so far: 144320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2255: 0.7659170031547546\n",
      "Seen so far: 144384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2256: 1.0798931121826172\n",
      "Seen so far: 144448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2257: 1.2495611906051636\n",
      "Seen so far: 144512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2258: 1.4926633834838867\n",
      "Seen so far: 144576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2259: 0.860224187374115\n",
      "Seen so far: 144640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2260: 0.9095704555511475\n",
      "Seen so far: 144704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2261: 1.282464861869812\n",
      "Seen so far: 144768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2262: 0.8551077842712402\n",
      "Seen so far: 144832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2263: 1.0071666240692139\n",
      "Seen so far: 144896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2264: 1.2495989799499512\n",
      "Seen so far: 144960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2265: 0.8025404810905457\n",
      "Seen so far: 145024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2266: 0.7739138603210449\n",
      "Seen so far: 145088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2267: 0.8560236096382141\n",
      "Seen so far: 145152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2268: 0.9053481817245483\n",
      "Seen so far: 145216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2269: 0.7704989910125732\n",
      "Seen so far: 145280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2270: 0.8126518726348877\n",
      "Seen so far: 145344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2271: 0.6564537882804871\n",
      "Seen so far: 145408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2272: 0.9901443719863892\n",
      "Seen so far: 145472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2273: 1.093650460243225\n",
      "Seen so far: 145536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2274: 1.0032916069030762\n",
      "Seen so far: 145600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2275: 1.1817097663879395\n",
      "Seen so far: 145664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2276: 0.7937028408050537\n",
      "Seen so far: 145728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2277: 0.9072434902191162\n",
      "Seen so far: 145792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2278: 1.3547308444976807\n",
      "Seen so far: 145856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2279: 0.6601302623748779\n",
      "Seen so far: 145920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2280: 1.374685525894165\n",
      "Seen so far: 145984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2281: 0.8941221833229065\n",
      "Seen so far: 146048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2282: 1.1440911293029785\n",
      "Seen so far: 146112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2283: 0.9803422689437866\n",
      "Seen so far: 146176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2284: 0.7451030015945435\n",
      "Seen so far: 146240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2285: 1.2192680835723877\n",
      "Seen so far: 146304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2286: 1.3686673641204834\n",
      "Seen so far: 146368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2287: 0.7477973699569702\n",
      "Seen so far: 146432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2288: 1.0985164642333984\n",
      "Seen so far: 146496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2289: 0.9321996569633484\n",
      "Seen so far: 146560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2290: 1.0459353923797607\n",
      "Seen so far: 146624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2291: 0.7639840245246887\n",
      "Seen so far: 146688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2292: 0.7474981546401978\n",
      "Seen so far: 146752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2293: 1.0464067459106445\n",
      "Seen so far: 146816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2294: 1.514560341835022\n",
      "Seen so far: 146880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2295: 1.0391900539398193\n",
      "Seen so far: 146944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2296: 1.089245319366455\n",
      "Seen so far: 147008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2297: 1.3731859922409058\n",
      "Seen so far: 147072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2298: 0.7589715123176575\n",
      "Seen so far: 147136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2299: 0.7063271999359131\n",
      "Seen so far: 147200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2300: 1.133387804031372\n",
      "Seen so far: 147264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2301: 1.026940107345581\n",
      "Seen so far: 147328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2302: 1.006464958190918\n",
      "Seen so far: 147392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2303: 1.3188567161560059\n",
      "Seen so far: 147456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2304: 0.714432954788208\n",
      "Seen so far: 147520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2305: 0.9751973152160645\n",
      "Seen so far: 147584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2306: 0.8364589810371399\n",
      "Seen so far: 147648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2307: 0.8089819550514221\n",
      "Seen so far: 147712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2308: 0.9118245840072632\n",
      "Seen so far: 147776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2309: 1.2373895645141602\n",
      "Seen so far: 147840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2310: 0.7733106017112732\n",
      "Seen so far: 147904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2311: 0.7826862335205078\n",
      "Seen so far: 147968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2312: 0.7336535453796387\n",
      "Seen so far: 148032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2313: 1.0215996503829956\n",
      "Seen so far: 148096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2314: 1.3132121562957764\n",
      "Seen so far: 148160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2315: 0.9229050874710083\n",
      "Seen so far: 148224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2316: 1.168239951133728\n",
      "Seen so far: 148288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2317: 0.752574622631073\n",
      "Seen so far: 148352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2318: 0.6677278280258179\n",
      "Seen so far: 148416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2319: 1.20975661277771\n",
      "Seen so far: 148480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2320: 0.9150538444519043\n",
      "Seen so far: 148544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2321: 0.6707625389099121\n",
      "Seen so far: 148608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2322: 0.6239932775497437\n",
      "Seen so far: 148672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2323: 0.8067377805709839\n",
      "Seen so far: 148736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2324: 1.1101133823394775\n",
      "Seen so far: 148800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2325: 0.745917797088623\n",
      "Seen so far: 148864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2326: 1.0028514862060547\n",
      "Seen so far: 148928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2327: 1.1416810750961304\n",
      "Seen so far: 148992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2328: 0.6952791213989258\n",
      "Seen so far: 149056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2329: 0.9781907200813293\n",
      "Seen so far: 149120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2330: 0.9137839674949646\n",
      "Seen so far: 149184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2331: 0.7177809476852417\n",
      "Seen so far: 149248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2332: 1.094130039215088\n",
      "Seen so far: 149312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2333: 0.9768456220626831\n",
      "Seen so far: 149376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2334: 1.1304211616516113\n",
      "Seen so far: 149440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2335: 1.1714314222335815\n",
      "Seen so far: 149504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2336: 1.0804443359375\n",
      "Seen so far: 149568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2337: 1.0597777366638184\n",
      "Seen so far: 149632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2338: 0.8266404867172241\n",
      "Seen so far: 149696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2339: 1.1332566738128662\n",
      "Seen so far: 149760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2340: 1.112837553024292\n",
      "Seen so far: 149824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2341: 1.2123966217041016\n",
      "Seen so far: 149888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2342: 0.518312931060791\n",
      "Seen so far: 149952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2343: 0.5884655714035034\n",
      "Seen so far: 150016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2344: 0.9362711906433105\n",
      "Seen so far: 150080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2345: 1.0273386240005493\n",
      "Seen so far: 150144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2346: 0.8825022578239441\n",
      "Seen so far: 150208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2347: 0.7160570025444031\n",
      "Seen so far: 150272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2348: 1.0957427024841309\n",
      "Seen so far: 150336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2349: 0.810187578201294\n",
      "Seen so far: 150400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2350: 0.9740837812423706\n",
      "Seen so far: 150464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2351: 1.195013165473938\n",
      "Seen so far: 150528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2352: 1.0717648267745972\n",
      "Seen so far: 150592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2353: 0.9426311254501343\n",
      "Seen so far: 150656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2354: 0.8738477826118469\n",
      "Seen so far: 150720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2355: 0.8544735908508301\n",
      "Seen so far: 150784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2356: 0.7039051055908203\n",
      "Seen so far: 150848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2357: 1.226698398590088\n",
      "Seen so far: 150912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2358: 1.135877251625061\n",
      "Seen so far: 150976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2359: 1.0300967693328857\n",
      "Seen so far: 151040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2360: 1.2715545892715454\n",
      "Seen so far: 151104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2361: 0.9292902946472168\n",
      "Seen so far: 151168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2362: 1.1218154430389404\n",
      "Seen so far: 151232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2363: 0.9521653652191162\n",
      "Seen so far: 151296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2364: 0.8068979382514954\n",
      "Seen so far: 151360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2365: 1.5363558530807495\n",
      "Seen so far: 151424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2366: 1.0169179439544678\n",
      "Seen so far: 151488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2367: 0.9656080007553101\n",
      "Seen so far: 151552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2368: 1.0969970226287842\n",
      "Seen so far: 151616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2369: 1.2140007019042969\n",
      "Seen so far: 151680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2370: 0.9586396813392639\n",
      "Seen so far: 151744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2371: 1.0306713581085205\n",
      "Seen so far: 151808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2372: 1.02765691280365\n",
      "Seen so far: 151872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2373: 1.095597505569458\n",
      "Seen so far: 151936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2374: 0.9310322999954224\n",
      "Seen so far: 152000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2375: 1.0345327854156494\n",
      "Seen so far: 152064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2376: 1.4435322284698486\n",
      "Seen so far: 152128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2377: 0.9601190090179443\n",
      "Seen so far: 152192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2378: 0.7409954071044922\n",
      "Seen so far: 152256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2379: 1.0361977815628052\n",
      "Seen so far: 152320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2380: 0.7943514585494995\n",
      "Seen so far: 152384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2381: 0.6974779367446899\n",
      "Seen so far: 152448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2382: 0.538076639175415\n",
      "Seen so far: 152512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2383: 0.7248774766921997\n",
      "Seen so far: 152576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2384: 1.2677658796310425\n",
      "Seen so far: 152640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2385: 0.9770812392234802\n",
      "Seen so far: 152704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2386: 0.9753085374832153\n",
      "Seen so far: 152768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2387: 0.7942593097686768\n",
      "Seen so far: 152832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2388: 0.8447425365447998\n",
      "Seen so far: 152896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2389: 0.953839123249054\n",
      "Seen so far: 152960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2390: 1.2743031978607178\n",
      "Seen so far: 153024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2391: 0.9674595594406128\n",
      "Seen so far: 153088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2392: 0.611765444278717\n",
      "Seen so far: 153152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2393: 1.087928056716919\n",
      "Seen so far: 153216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2394: 0.7778183817863464\n",
      "Seen so far: 153280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2395: 1.2011362314224243\n",
      "Seen so far: 153344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2396: 0.7883045673370361\n",
      "Seen so far: 153408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2397: 1.1372555494308472\n",
      "Seen so far: 153472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2398: 0.9253280162811279\n",
      "Seen so far: 153536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2399: 0.7284791469573975\n",
      "Seen so far: 153600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2400: 0.8305691480636597\n",
      "Seen so far: 153664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2401: 0.7650139927864075\n",
      "Seen so far: 153728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2402: 1.0299129486083984\n",
      "Seen so far: 153792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2403: 1.187562108039856\n",
      "Seen so far: 153856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2404: 0.9633304476737976\n",
      "Seen so far: 153920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2405: 1.0289397239685059\n",
      "Seen so far: 153984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2406: 0.6397861242294312\n",
      "Seen so far: 154048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2407: 1.5725963115692139\n",
      "Seen so far: 154112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2408: 0.580763578414917\n",
      "Seen so far: 154176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2409: 1.256798267364502\n",
      "Seen so far: 154240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2410: 0.7407572865486145\n",
      "Seen so far: 154304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2411: 1.2547600269317627\n",
      "Seen so far: 154368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2412: 1.0918787717819214\n",
      "Seen so far: 154432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2413: 1.2100633382797241\n",
      "Seen so far: 154496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2414: 0.9894275665283203\n",
      "Seen so far: 154560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2415: 1.3082194328308105\n",
      "Seen so far: 154624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2416: 0.9369937181472778\n",
      "Seen so far: 154688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2417: 1.1684623956680298\n",
      "Seen so far: 154752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2418: 1.065125823020935\n",
      "Seen so far: 154816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2419: 0.8169494271278381\n",
      "Seen so far: 154880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2420: 1.1519272327423096\n",
      "Seen so far: 154944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2421: 0.9236142635345459\n",
      "Seen so far: 155008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2422: 0.8618869781494141\n",
      "Seen so far: 155072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2423: 0.9877451658248901\n",
      "Seen so far: 155136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2424: 0.9545686841011047\n",
      "Seen so far: 155200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2425: 1.2815189361572266\n",
      "Seen so far: 155264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2426: 1.0926107168197632\n",
      "Seen so far: 155328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2427: 1.3700687885284424\n",
      "Seen so far: 155392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2428: 1.2314144372940063\n",
      "Seen so far: 155456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2429: 0.8866505026817322\n",
      "Seen so far: 155520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2430: 1.0144211053848267\n",
      "Seen so far: 155584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2431: 1.3452622890472412\n",
      "Seen so far: 155648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2432: 0.7944530248641968\n",
      "Seen so far: 155712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2433: 0.7644393444061279\n",
      "Seen so far: 155776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2434: 0.9097603559494019\n",
      "Seen so far: 155840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2435: 1.3456792831420898\n",
      "Seen so far: 155904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2436: 1.1212098598480225\n",
      "Seen so far: 155968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2437: 0.5653965473175049\n",
      "Seen so far: 156032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2438: 0.9792224168777466\n",
      "Seen so far: 156096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2439: 1.0069832801818848\n",
      "Seen so far: 156160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2440: 1.0677711963653564\n",
      "Seen so far: 156224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2441: 0.6117668151855469\n",
      "Seen so far: 156288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2442: 1.1538589000701904\n",
      "Seen so far: 156352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2443: 1.0015250444412231\n",
      "Seen so far: 156416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2444: 0.8447219729423523\n",
      "Seen so far: 156480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2445: 1.0506393909454346\n",
      "Seen so far: 156544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2446: 0.8684105277061462\n",
      "Seen so far: 156608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2447: 0.6036814451217651\n",
      "Seen so far: 156672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2448: 1.240875244140625\n",
      "Seen so far: 156736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2449: 0.6845219135284424\n",
      "Seen so far: 156800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2450: 0.8119326829910278\n",
      "Seen so far: 156864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2451: 1.00245201587677\n",
      "Seen so far: 156928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2452: 1.00905442237854\n",
      "Seen so far: 156992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2453: 0.8029186725616455\n",
      "Seen so far: 157056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2454: 1.3116172552108765\n",
      "Seen so far: 157120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2455: 1.1713348627090454\n",
      "Seen so far: 157184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2456: 0.6801748871803284\n",
      "Seen so far: 157248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2457: 1.1220998764038086\n",
      "Seen so far: 157312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2458: 0.8918642997741699\n",
      "Seen so far: 157376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2459: 0.962202787399292\n",
      "Seen so far: 157440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2460: 0.8228622674942017\n",
      "Seen so far: 157504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2461: 0.851624608039856\n",
      "Seen so far: 157568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2462: 0.9726612567901611\n",
      "Seen so far: 157632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2463: 0.7079598903656006\n",
      "Seen so far: 157696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2464: 0.8958359956741333\n",
      "Seen so far: 157760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2465: 0.8633086681365967\n",
      "Seen so far: 157824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2466: 1.5216031074523926\n",
      "Seen so far: 157888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2467: 1.2215731143951416\n",
      "Seen so far: 157952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2468: 1.1528130769729614\n",
      "Seen so far: 158016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2469: 0.8266407251358032\n",
      "Seen so far: 158080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2470: 0.7813839316368103\n",
      "Seen so far: 158144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2471: 1.3351894617080688\n",
      "Seen so far: 158208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2472: 1.1028708219528198\n",
      "Seen so far: 158272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2473: 0.8632888793945312\n",
      "Seen so far: 158336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2474: 1.4887821674346924\n",
      "Seen so far: 158400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2475: 0.9878490567207336\n",
      "Seen so far: 158464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2476: 0.7765933871269226\n",
      "Seen so far: 158528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2477: 0.9256664514541626\n",
      "Seen so far: 158592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2478: 1.1755521297454834\n",
      "Seen so far: 158656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2479: 1.1594452857971191\n",
      "Seen so far: 158720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2480: 0.8681278228759766\n",
      "Seen so far: 158784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2481: 0.8724945187568665\n",
      "Seen so far: 158848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2482: 1.1654865741729736\n",
      "Seen so far: 158912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2483: 1.0851178169250488\n",
      "Seen so far: 158976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2484: 0.7676327228546143\n",
      "Seen so far: 159040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2485: 0.6776692867279053\n",
      "Seen so far: 159104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2486: 1.0922183990478516\n",
      "Seen so far: 159168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2487: 1.0050170421600342\n",
      "Seen so far: 159232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2488: 1.0807685852050781\n",
      "Seen so far: 159296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2489: 0.7241616249084473\n",
      "Seen so far: 159360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2490: 0.7742384672164917\n",
      "Seen so far: 159424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2491: 0.8972797393798828\n",
      "Seen so far: 159488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2492: 0.899939775466919\n",
      "Seen so far: 159552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2493: 0.679972767829895\n",
      "Seen so far: 159616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2494: 0.7668437957763672\n",
      "Seen so far: 159680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2495: 0.5835450887680054\n",
      "Seen so far: 159744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2496: 0.8041174411773682\n",
      "Seen so far: 159808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2497: 1.0714387893676758\n",
      "Seen so far: 159872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2498: 0.6448124647140503\n",
      "Seen so far: 159936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2499: 1.1919922828674316\n",
      "Seen so far: 160000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2500: 1.237534761428833\n",
      "Seen so far: 160064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2501: 0.8573501110076904\n",
      "Seen so far: 160128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2502: 0.7448385953903198\n",
      "Seen so far: 160192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2503: 1.027956485748291\n",
      "Seen so far: 160256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2504: 1.1681221723556519\n",
      "Seen so far: 160320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2505: 1.4103795289993286\n",
      "Seen so far: 160384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2506: 0.9166748523712158\n",
      "Seen so far: 160448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2507: 0.8360729217529297\n",
      "Seen so far: 160512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2508: 0.8973160982131958\n",
      "Seen so far: 160576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2509: 1.1180956363677979\n",
      "Seen so far: 160640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2510: 1.3575963973999023\n",
      "Seen so far: 160704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2511: 1.1563212871551514\n",
      "Seen so far: 160768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2512: 0.713822066783905\n",
      "Seen so far: 160832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2513: 0.8992385268211365\n",
      "Seen so far: 160896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2514: 0.9036862254142761\n",
      "Seen so far: 160960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2515: 0.7050149440765381\n",
      "Seen so far: 161024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2516: 1.0309631824493408\n",
      "Seen so far: 161088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2517: 0.9796087741851807\n",
      "Seen so far: 161152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2518: 1.2276629209518433\n",
      "Seen so far: 161216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2519: 0.9088147878646851\n",
      "Seen so far: 161280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2520: 0.7477998733520508\n",
      "Seen so far: 161344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2521: 0.9324566125869751\n",
      "Seen so far: 161408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2522: 0.741881787776947\n",
      "Seen so far: 161472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2523: 0.9989582300186157\n",
      "Seen so far: 161536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2524: 0.8594454526901245\n",
      "Seen so far: 161600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2525: 0.897849440574646\n",
      "Seen so far: 161664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2526: 0.8089374303817749\n",
      "Seen so far: 161728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2527: 0.9265016913414001\n",
      "Seen so far: 161792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2528: 1.4105098247528076\n",
      "Seen so far: 161856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2529: 0.930673360824585\n",
      "Seen so far: 161920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2530: 0.5998836755752563\n",
      "Seen so far: 161984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2531: 0.8418400287628174\n",
      "Seen so far: 162048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2532: 0.6106265783309937\n",
      "Seen so far: 162112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2533: 1.1746900081634521\n",
      "Seen so far: 162176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2534: 1.1046624183654785\n",
      "Seen so far: 162240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2535: 0.842566967010498\n",
      "Seen so far: 162304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2536: 0.8434398174285889\n",
      "Seen so far: 162368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2537: 1.0757267475128174\n",
      "Seen so far: 162432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2538: 0.7061625719070435\n",
      "Seen so far: 162496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2539: 1.1882820129394531\n",
      "Seen so far: 162560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2540: 1.3967076539993286\n",
      "Seen so far: 162624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2541: 1.6175408363342285\n",
      "Seen so far: 162688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2542: 0.8531363606452942\n",
      "Seen so far: 162752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2543: 1.0948741436004639\n",
      "Seen so far: 162816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2544: 1.0640524625778198\n",
      "Seen so far: 162880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2545: 1.2127944231033325\n",
      "Seen so far: 162944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2546: 0.6495524644851685\n",
      "Seen so far: 163008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2547: 1.2555333375930786\n",
      "Seen so far: 163072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2548: 1.2172513008117676\n",
      "Seen so far: 163136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2549: 1.2521111965179443\n",
      "Seen so far: 163200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2550: 1.1380380392074585\n",
      "Seen so far: 163264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2551: 0.7305713295936584\n",
      "Seen so far: 163328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2552: 0.5336001515388489\n",
      "Seen so far: 163392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2553: 1.168684720993042\n",
      "Seen so far: 163456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2554: 0.8937866687774658\n",
      "Seen so far: 163520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2555: 0.8123053908348083\n",
      "Seen so far: 163584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2556: 1.245957851409912\n",
      "Seen so far: 163648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2557: 0.651170551776886\n",
      "Seen so far: 163712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2558: 0.6278483867645264\n",
      "Seen so far: 163776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2559: 1.2139569520950317\n",
      "Seen so far: 163840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2560: 1.1902954578399658\n",
      "Seen so far: 163904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2561: 1.0673232078552246\n",
      "Seen so far: 163968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2562: 0.702049732208252\n",
      "Seen so far: 164032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2563: 0.9595709443092346\n",
      "Seen so far: 164096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2564: 1.0338150262832642\n",
      "Seen so far: 164160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2565: 0.6430667042732239\n",
      "Seen so far: 164224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2566: 1.046472430229187\n",
      "Seen so far: 164288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2567: 1.2346978187561035\n",
      "Seen so far: 164352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2568: 1.3361852169036865\n",
      "Seen so far: 164416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2569: 0.8884813785552979\n",
      "Seen so far: 164480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2570: 1.0099610090255737\n",
      "Seen so far: 164544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2571: 0.7223465442657471\n",
      "Seen so far: 164608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2572: 1.3507623672485352\n",
      "Seen so far: 164672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2573: 0.708568811416626\n",
      "Seen so far: 164736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2574: 0.9232535362243652\n",
      "Seen so far: 164800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2575: 0.7823461890220642\n",
      "Seen so far: 164864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2576: 0.9110259413719177\n",
      "Seen so far: 164928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2577: 0.7568455934524536\n",
      "Seen so far: 164992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2578: 0.6946620941162109\n",
      "Seen so far: 165056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2579: 0.8014222383499146\n",
      "Seen so far: 165120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2580: 0.8166563510894775\n",
      "Seen so far: 165184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2581: 0.8730109930038452\n",
      "Seen so far: 165248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2582: 1.263535976409912\n",
      "Seen so far: 165312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2583: 0.8138601183891296\n",
      "Seen so far: 165376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2584: 0.39872580766677856\n",
      "Seen so far: 165440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2585: 0.8386896848678589\n",
      "Seen so far: 165504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2586: 0.8854050636291504\n",
      "Seen so far: 165568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2587: 0.7159754037857056\n",
      "Seen so far: 165632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2588: 0.82582688331604\n",
      "Seen so far: 165696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2589: 0.9525175094604492\n",
      "Seen so far: 165760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2590: 1.0693120956420898\n",
      "Seen so far: 165824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2591: 0.9769030809402466\n",
      "Seen so far: 165888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2592: 0.8592100143432617\n",
      "Seen so far: 165952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2593: 1.14920973777771\n",
      "Seen so far: 166016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2594: 0.9743074178695679\n",
      "Seen so far: 166080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2595: 0.8866405487060547\n",
      "Seen so far: 166144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2596: 1.010490894317627\n",
      "Seen so far: 166208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2597: 0.7793794870376587\n",
      "Seen so far: 166272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2598: 1.215044379234314\n",
      "Seen so far: 166336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2599: 0.8218015432357788\n",
      "Seen so far: 166400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2600: 0.9067642092704773\n",
      "Seen so far: 166464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2601: 0.7201789021492004\n",
      "Seen so far: 166528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2602: 0.7298378944396973\n",
      "Seen so far: 166592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2603: 0.7687644958496094\n",
      "Seen so far: 166656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2604: 0.9447696208953857\n",
      "Seen so far: 166720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2605: 0.9015157222747803\n",
      "Seen so far: 166784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2606: 1.108548879623413\n",
      "Seen so far: 166848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2607: 1.6145851612091064\n",
      "Seen so far: 166912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2608: 0.7097656726837158\n",
      "Seen so far: 166976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2609: 0.7286394834518433\n",
      "Seen so far: 167040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2610: 1.0510965585708618\n",
      "Seen so far: 167104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2611: 0.8877172470092773\n",
      "Seen so far: 167168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2612: 1.0385172367095947\n",
      "Seen so far: 167232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2613: 0.6297711730003357\n",
      "Seen so far: 167296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2614: 1.1743528842926025\n",
      "Seen so far: 167360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2615: 0.9342010617256165\n",
      "Seen so far: 167424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2616: 0.7134499549865723\n",
      "Seen so far: 167488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2617: 0.9105240106582642\n",
      "Seen so far: 167552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2618: 0.9928269982337952\n",
      "Seen so far: 167616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2619: 1.483750581741333\n",
      "Seen so far: 167680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2620: 0.718066930770874\n",
      "Seen so far: 167744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2621: 1.1622657775878906\n",
      "Seen so far: 167808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2622: 1.0502002239227295\n",
      "Seen so far: 167872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2623: 0.9166102409362793\n",
      "Seen so far: 167936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2624: 1.0270687341690063\n",
      "Seen so far: 168000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2625: 0.8013418912887573\n",
      "Seen so far: 168064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2626: 0.789270281791687\n",
      "Seen so far: 168128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2627: 1.1495672464370728\n",
      "Seen so far: 168192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2628: 0.5439480543136597\n",
      "Seen so far: 168256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2629: 0.9221601486206055\n",
      "Seen so far: 168320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2630: 0.9673047065734863\n",
      "Seen so far: 168384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2631: 0.955274224281311\n",
      "Seen so far: 168448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2632: 0.9160550832748413\n",
      "Seen so far: 168512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2633: 0.827525794506073\n",
      "Seen so far: 168576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2634: 0.951904296875\n",
      "Seen so far: 168640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2635: 1.1546597480773926\n",
      "Seen so far: 168704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2636: 1.2424774169921875\n",
      "Seen so far: 168768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2637: 0.8733397722244263\n",
      "Seen so far: 168832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2638: 1.672258973121643\n",
      "Seen so far: 168896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2639: 1.0716583728790283\n",
      "Seen so far: 168960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2640: 0.8036543130874634\n",
      "Seen so far: 169024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2641: 0.7030890583992004\n",
      "Seen so far: 169088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2642: 0.8544526696205139\n",
      "Seen so far: 169152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2643: 1.0815646648406982\n",
      "Seen so far: 169216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2644: 0.8548402786254883\n",
      "Seen so far: 169280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2645: 0.9811572432518005\n",
      "Seen so far: 169344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2646: 0.8242907524108887\n",
      "Seen so far: 169408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2647: 0.7869706153869629\n",
      "Seen so far: 169472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2648: 0.8463338613510132\n",
      "Seen so far: 169536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2649: 0.8557885885238647\n",
      "Seen so far: 169600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2650: 0.8626288175582886\n",
      "Seen so far: 169664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2651: 1.0204555988311768\n",
      "Seen so far: 169728 samples\n",
      "Training acc over epoch: 0.6761429905891418\n",
      "Start of epoch 4\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 0: 0.864467442035675\n",
      "Seen so far: 64 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1: 0.7910534739494324\n",
      "Seen so far: 128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2: 0.7512263059616089\n",
      "Seen so far: 192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 3: 0.7244428992271423\n",
      "Seen so far: 256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 4: 0.8405486345291138\n",
      "Seen so far: 320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 5: 1.3542035818099976\n",
      "Seen so far: 384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 6: 1.1894218921661377\n",
      "Seen so far: 448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 7: 0.9501230716705322\n",
      "Seen so far: 512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 8: 1.3163819313049316\n",
      "Seen so far: 576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 9: 0.8868709802627563\n",
      "Seen so far: 640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 10: 0.7159808874130249\n",
      "Seen so far: 704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 11: 0.6230747699737549\n",
      "Seen so far: 768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 12: 0.6510008573532104\n",
      "Seen so far: 832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 13: 0.6734177470207214\n",
      "Seen so far: 896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 14: 1.240744709968567\n",
      "Seen so far: 960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 15: 0.6698243618011475\n",
      "Seen so far: 1024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 16: 0.9409233331680298\n",
      "Seen so far: 1088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 17: 1.4116302728652954\n",
      "Seen so far: 1152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 18: 1.196993112564087\n",
      "Seen so far: 1216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 19: 1.224931001663208\n",
      "Seen so far: 1280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 20: 1.0768787860870361\n",
      "Seen so far: 1344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 21: 1.1948869228363037\n",
      "Seen so far: 1408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 22: 1.1042386293411255\n",
      "Seen so far: 1472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 23: 1.6353014707565308\n",
      "Seen so far: 1536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 24: 0.6765769720077515\n",
      "Seen so far: 1600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 25: 0.9796189665794373\n",
      "Seen so far: 1664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 26: 0.9409339427947998\n",
      "Seen so far: 1728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 27: 1.449425458908081\n",
      "Seen so far: 1792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 28: 0.9765146970748901\n",
      "Seen so far: 1856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 29: 1.0116069316864014\n",
      "Seen so far: 1920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 30: 1.020267128944397\n",
      "Seen so far: 1984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 31: 0.962019145488739\n",
      "Seen so far: 2048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 32: 1.3264824151992798\n",
      "Seen so far: 2112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 33: 0.8154654502868652\n",
      "Seen so far: 2176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 34: 1.0093202590942383\n",
      "Seen so far: 2240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 35: 1.073420763015747\n",
      "Seen so far: 2304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 36: 0.6979446411132812\n",
      "Seen so far: 2368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 37: 1.163403868675232\n",
      "Seen so far: 2432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 38: 1.0173346996307373\n",
      "Seen so far: 2496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 39: 0.9369024038314819\n",
      "Seen so far: 2560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 40: 0.893122136592865\n",
      "Seen so far: 2624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 41: 1.34690260887146\n",
      "Seen so far: 2688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 42: 1.0393903255462646\n",
      "Seen so far: 2752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 43: 0.8426144123077393\n",
      "Seen so far: 2816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 44: 1.0034631490707397\n",
      "Seen so far: 2880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 45: 1.142699122428894\n",
      "Seen so far: 2944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 46: 0.8958428502082825\n",
      "Seen so far: 3008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 47: 0.6519299745559692\n",
      "Seen so far: 3072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 48: 1.0379353761672974\n",
      "Seen so far: 3136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 49: 0.7394347786903381\n",
      "Seen so far: 3200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 50: 1.1235547065734863\n",
      "Seen so far: 3264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 51: 1.0627617835998535\n",
      "Seen so far: 3328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 52: 0.8577996492385864\n",
      "Seen so far: 3392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 53: 0.7220175862312317\n",
      "Seen so far: 3456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 54: 0.5776200294494629\n",
      "Seen so far: 3520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 55: 1.135756015777588\n",
      "Seen so far: 3584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 56: 1.25563645362854\n",
      "Seen so far: 3648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 57: 1.4500081539154053\n",
      "Seen so far: 3712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 58: 0.6341355443000793\n",
      "Seen so far: 3776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 59: 0.6865335702896118\n",
      "Seen so far: 3840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 60: 0.453995019197464\n",
      "Seen so far: 3904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 61: 0.5754928588867188\n",
      "Seen so far: 3968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 62: 1.0484329462051392\n",
      "Seen so far: 4032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 63: 0.8924691081047058\n",
      "Seen so far: 4096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 64: 0.8024160861968994\n",
      "Seen so far: 4160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 65: 0.8468549251556396\n",
      "Seen so far: 4224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 66: 1.6153972148895264\n",
      "Seen so far: 4288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 67: 1.4608694314956665\n",
      "Seen so far: 4352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 68: 1.0677517652511597\n",
      "Seen so far: 4416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 69: 0.7079870700836182\n",
      "Seen so far: 4480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 70: 0.7780344486236572\n",
      "Seen so far: 4544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 71: 1.157903790473938\n",
      "Seen so far: 4608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 72: 1.285236120223999\n",
      "Seen so far: 4672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 73: 0.8213229775428772\n",
      "Seen so far: 4736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 74: 1.0380654335021973\n",
      "Seen so far: 4800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 75: 1.0062124729156494\n",
      "Seen so far: 4864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 76: 1.2973241806030273\n",
      "Seen so far: 4928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 77: 0.7341715097427368\n",
      "Seen so far: 4992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 78: 0.7235276103019714\n",
      "Seen so far: 5056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 79: 1.3369568586349487\n",
      "Seen so far: 5120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 80: 0.6325199604034424\n",
      "Seen so far: 5184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 81: 1.086250901222229\n",
      "Seen so far: 5248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 82: 1.2577767372131348\n",
      "Seen so far: 5312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 83: 1.003448247909546\n",
      "Seen so far: 5376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 84: 0.9883908033370972\n",
      "Seen so far: 5440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 85: 1.0868995189666748\n",
      "Seen so far: 5504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 86: 0.9772868156433105\n",
      "Seen so far: 5568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 87: 0.9969284534454346\n",
      "Seen so far: 5632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 88: 1.0041007995605469\n",
      "Seen so far: 5696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 89: 1.0072661638259888\n",
      "Seen so far: 5760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 90: 1.1242763996124268\n",
      "Seen so far: 5824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 91: 1.2746613025665283\n",
      "Seen so far: 5888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 92: 0.8065004348754883\n",
      "Seen so far: 5952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 93: 1.0517265796661377\n",
      "Seen so far: 6016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 94: 0.9757426381111145\n",
      "Seen so far: 6080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 95: 0.5882226228713989\n",
      "Seen so far: 6144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 96: 1.0336748361587524\n",
      "Seen so far: 6208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 97: 1.1106250286102295\n",
      "Seen so far: 6272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 98: 0.8798055648803711\n",
      "Seen so far: 6336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 99: 1.0157463550567627\n",
      "Seen so far: 6400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 100: 0.892242968082428\n",
      "Seen so far: 6464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 101: 0.6186363101005554\n",
      "Seen so far: 6528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 102: 0.7765481472015381\n",
      "Seen so far: 6592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 103: 0.8025283217430115\n",
      "Seen so far: 6656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 104: 1.0034505128860474\n",
      "Seen so far: 6720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 105: 1.0573936700820923\n",
      "Seen so far: 6784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 106: 0.7512117624282837\n",
      "Seen so far: 6848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 107: 1.072266936302185\n",
      "Seen so far: 6912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 108: 0.9490624666213989\n",
      "Seen so far: 6976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 109: 1.0992465019226074\n",
      "Seen so far: 7040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 110: 0.7997187376022339\n",
      "Seen so far: 7104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 111: 0.8839817643165588\n",
      "Seen so far: 7168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 112: 0.6699525713920593\n",
      "Seen so far: 7232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 113: 1.044930100440979\n",
      "Seen so far: 7296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 114: 1.165694236755371\n",
      "Seen so far: 7360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 115: 0.7512556314468384\n",
      "Seen so far: 7424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 116: 1.1026082038879395\n",
      "Seen so far: 7488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 117: 1.266775131225586\n",
      "Seen so far: 7552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 118: 1.0933581590652466\n",
      "Seen so far: 7616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 119: 0.7479122877120972\n",
      "Seen so far: 7680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 120: 1.120152473449707\n",
      "Seen so far: 7744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 121: 1.2045996189117432\n",
      "Seen so far: 7808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 122: 1.2764246463775635\n",
      "Seen so far: 7872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 123: 0.7290297150611877\n",
      "Seen so far: 7936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 124: 1.183158040046692\n",
      "Seen so far: 8000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 125: 1.0890053510665894\n",
      "Seen so far: 8064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 126: 0.6977412104606628\n",
      "Seen so far: 8128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 127: 1.271648645401001\n",
      "Seen so far: 8192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 128: 0.6402485370635986\n",
      "Seen so far: 8256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 129: 1.0420743227005005\n",
      "Seen so far: 8320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 130: 1.0525267124176025\n",
      "Seen so far: 8384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 131: 1.4154281616210938\n",
      "Seen so far: 8448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 132: 0.7575650215148926\n",
      "Seen so far: 8512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 133: 0.8096372485160828\n",
      "Seen so far: 8576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 134: 1.0069600343704224\n",
      "Seen so far: 8640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 135: 1.2906535863876343\n",
      "Seen so far: 8704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 136: 1.0977153778076172\n",
      "Seen so far: 8768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 137: 1.3984074592590332\n",
      "Seen so far: 8832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 138: 0.6681909561157227\n",
      "Seen so far: 8896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 139: 1.1089444160461426\n",
      "Seen so far: 8960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 140: 0.9776086807250977\n",
      "Seen so far: 9024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 141: 1.0884766578674316\n",
      "Seen so far: 9088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 142: 0.7380920052528381\n",
      "Seen so far: 9152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 143: 1.0181636810302734\n",
      "Seen so far: 9216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 144: 1.1471025943756104\n",
      "Seen so far: 9280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 145: 0.8176909685134888\n",
      "Seen so far: 9344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 146: 0.802548885345459\n",
      "Seen so far: 9408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 147: 1.0947461128234863\n",
      "Seen so far: 9472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 148: 1.507636308670044\n",
      "Seen so far: 9536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 149: 0.9809507727622986\n",
      "Seen so far: 9600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 150: 0.6688158512115479\n",
      "Seen so far: 9664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 151: 0.7311254739761353\n",
      "Seen so far: 9728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 152: 1.3584424257278442\n",
      "Seen so far: 9792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 153: 1.267019271850586\n",
      "Seen so far: 9856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 154: 1.7436888217926025\n",
      "Seen so far: 9920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 155: 1.00221586227417\n",
      "Seen so far: 9984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 156: 1.1840484142303467\n",
      "Seen so far: 10048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 157: 1.0724482536315918\n",
      "Seen so far: 10112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 158: 1.5268357992172241\n",
      "Seen so far: 10176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 159: 1.306760311126709\n",
      "Seen so far: 10240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 160: 0.936043381690979\n",
      "Seen so far: 10304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 161: 1.0391846895217896\n",
      "Seen so far: 10368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 162: 1.1079336404800415\n",
      "Seen so far: 10432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 163: 0.9559465050697327\n",
      "Seen so far: 10496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 164: 1.0803871154785156\n",
      "Seen so far: 10560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 165: 1.0425243377685547\n",
      "Seen so far: 10624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 166: 0.8927642107009888\n",
      "Seen so far: 10688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 167: 0.8086444735527039\n",
      "Seen so far: 10752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 168: 1.163468599319458\n",
      "Seen so far: 10816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 169: 0.6442430019378662\n",
      "Seen so far: 10880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 170: 1.0916941165924072\n",
      "Seen so far: 10944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 171: 1.1185646057128906\n",
      "Seen so far: 11008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 172: 1.2100863456726074\n",
      "Seen so far: 11072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 173: 0.9183547496795654\n",
      "Seen so far: 11136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 174: 1.1544524431228638\n",
      "Seen so far: 11200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 175: 0.9323617815971375\n",
      "Seen so far: 11264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 176: 1.1451821327209473\n",
      "Seen so far: 11328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 177: 0.6867986917495728\n",
      "Seen so far: 11392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 178: 0.9394115209579468\n",
      "Seen so far: 11456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 179: 0.915744423866272\n",
      "Seen so far: 11520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 180: 0.9654887914657593\n",
      "Seen so far: 11584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 181: 0.8465063571929932\n",
      "Seen so far: 11648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 182: 0.8617968559265137\n",
      "Seen so far: 11712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 183: 1.2025654315948486\n",
      "Seen so far: 11776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 184: 1.019525408744812\n",
      "Seen so far: 11840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 185: 1.178142786026001\n",
      "Seen so far: 11904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 186: 1.0288165807724\n",
      "Seen so far: 11968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 187: 1.3071293830871582\n",
      "Seen so far: 12032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 188: 1.3909152746200562\n",
      "Seen so far: 12096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 189: 0.9976180195808411\n",
      "Seen so far: 12160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 190: 1.1391799449920654\n",
      "Seen so far: 12224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 191: 0.4969654083251953\n",
      "Seen so far: 12288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 192: 1.047454595565796\n",
      "Seen so far: 12352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 193: 1.1174416542053223\n",
      "Seen so far: 12416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 194: 1.1696863174438477\n",
      "Seen so far: 12480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 195: 1.0336321592330933\n",
      "Seen so far: 12544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 196: 0.54783034324646\n",
      "Seen so far: 12608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 197: 0.7868742942810059\n",
      "Seen so far: 12672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 198: 1.3388986587524414\n",
      "Seen so far: 12736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 199: 0.8826781511306763\n",
      "Seen so far: 12800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 200: 0.919938862323761\n",
      "Seen so far: 12864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 201: 0.7956212759017944\n",
      "Seen so far: 12928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 202: 1.1365407705307007\n",
      "Seen so far: 12992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 203: 0.8813253045082092\n",
      "Seen so far: 13056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 204: 1.0741910934448242\n",
      "Seen so far: 13120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 205: 0.6916579008102417\n",
      "Seen so far: 13184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 206: 1.356181025505066\n",
      "Seen so far: 13248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 207: 0.8934390544891357\n",
      "Seen so far: 13312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 208: 1.2120611667633057\n",
      "Seen so far: 13376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 209: 0.9105790853500366\n",
      "Seen so far: 13440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 210: 1.1554057598114014\n",
      "Seen so far: 13504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 211: 0.904948353767395\n",
      "Seen so far: 13568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 212: 1.378751516342163\n",
      "Seen so far: 13632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 213: 1.0668087005615234\n",
      "Seen so far: 13696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 214: 1.1764590740203857\n",
      "Seen so far: 13760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 215: 0.9988255500793457\n",
      "Seen so far: 13824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 216: 0.7532186508178711\n",
      "Seen so far: 13888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 217: 0.9115098118782043\n",
      "Seen so far: 13952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 218: 0.7948883771896362\n",
      "Seen so far: 14016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 219: 0.643440842628479\n",
      "Seen so far: 14080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 220: 0.9829018712043762\n",
      "Seen so far: 14144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 221: 0.8133205771446228\n",
      "Seen so far: 14208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 222: 1.1318731307983398\n",
      "Seen so far: 14272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 223: 0.965054988861084\n",
      "Seen so far: 14336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 224: 0.6670122742652893\n",
      "Seen so far: 14400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 225: 0.9521778225898743\n",
      "Seen so far: 14464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 226: 0.5956650376319885\n",
      "Seen so far: 14528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 227: 0.8838632106781006\n",
      "Seen so far: 14592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 228: 0.8790614008903503\n",
      "Seen so far: 14656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 229: 1.1877505779266357\n",
      "Seen so far: 14720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 230: 0.6987512111663818\n",
      "Seen so far: 14784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 231: 0.8604871034622192\n",
      "Seen so far: 14848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 232: 1.0080413818359375\n",
      "Seen so far: 14912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 233: 1.2789249420166016\n",
      "Seen so far: 14976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 234: 0.9509276151657104\n",
      "Seen so far: 15040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 235: 0.6034371852874756\n",
      "Seen so far: 15104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 236: 0.9709195494651794\n",
      "Seen so far: 15168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 237: 0.9347125291824341\n",
      "Seen so far: 15232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 238: 1.277416706085205\n",
      "Seen so far: 15296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 239: 1.030447006225586\n",
      "Seen so far: 15360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 240: 1.1834514141082764\n",
      "Seen so far: 15424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 241: 0.9926679134368896\n",
      "Seen so far: 15488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 242: 1.2231231927871704\n",
      "Seen so far: 15552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 243: 0.8283450603485107\n",
      "Seen so far: 15616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 244: 1.182420015335083\n",
      "Seen so far: 15680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 245: 1.425110936164856\n",
      "Seen so far: 15744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 246: 1.2507456541061401\n",
      "Seen so far: 15808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 247: 1.1852176189422607\n",
      "Seen so far: 15872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 248: 0.7948600053787231\n",
      "Seen so far: 15936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 249: 0.7892980575561523\n",
      "Seen so far: 16000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 250: 1.175418496131897\n",
      "Seen so far: 16064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 251: 1.2934083938598633\n",
      "Seen so far: 16128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 252: 1.1694567203521729\n",
      "Seen so far: 16192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 253: 0.8867801427841187\n",
      "Seen so far: 16256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 254: 0.8675734996795654\n",
      "Seen so far: 16320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 255: 1.1510783433914185\n",
      "Seen so far: 16384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 256: 1.1216357946395874\n",
      "Seen so far: 16448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 257: 1.4617931842803955\n",
      "Seen so far: 16512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 258: 0.7301276326179504\n",
      "Seen so far: 16576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 259: 0.9667592644691467\n",
      "Seen so far: 16640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 260: 0.43442636728286743\n",
      "Seen so far: 16704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 261: 1.1167352199554443\n",
      "Seen so far: 16768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 262: 1.3834489583969116\n",
      "Seen so far: 16832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 263: 1.0176959037780762\n",
      "Seen so far: 16896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 264: 0.7249137163162231\n",
      "Seen so far: 16960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 265: 1.036624550819397\n",
      "Seen so far: 17024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 266: 0.7090919017791748\n",
      "Seen so far: 17088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 267: 1.0281168222427368\n",
      "Seen so far: 17152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 268: 1.004334807395935\n",
      "Seen so far: 17216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 269: 0.9156081080436707\n",
      "Seen so far: 17280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 270: 0.5487030148506165\n",
      "Seen so far: 17344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 271: 1.3038928508758545\n",
      "Seen so far: 17408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 272: 0.7265663146972656\n",
      "Seen so far: 17472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 273: 1.0757237672805786\n",
      "Seen so far: 17536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 274: 1.1343932151794434\n",
      "Seen so far: 17600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 275: 0.7811076641082764\n",
      "Seen so far: 17664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 276: 1.274751901626587\n",
      "Seen so far: 17728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 277: 1.35471510887146\n",
      "Seen so far: 17792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 278: 0.7722424268722534\n",
      "Seen so far: 17856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 279: 1.354065179824829\n",
      "Seen so far: 17920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 280: 0.626594066619873\n",
      "Seen so far: 17984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 281: 0.9098176956176758\n",
      "Seen so far: 18048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 282: 0.8871319890022278\n",
      "Seen so far: 18112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 283: 0.6123724579811096\n",
      "Seen so far: 18176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 284: 0.5108214616775513\n",
      "Seen so far: 18240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 285: 0.7395952939987183\n",
      "Seen so far: 18304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 286: 0.7775545716285706\n",
      "Seen so far: 18368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 287: 0.6619459390640259\n",
      "Seen so far: 18432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 288: 1.0317046642303467\n",
      "Seen so far: 18496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 289: 0.9201165437698364\n",
      "Seen so far: 18560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 290: 1.1729533672332764\n",
      "Seen so far: 18624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 291: 0.565526008605957\n",
      "Seen so far: 18688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 292: 1.225294828414917\n",
      "Seen so far: 18752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 293: 1.2554066181182861\n",
      "Seen so far: 18816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 294: 0.6324245929718018\n",
      "Seen so far: 18880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 295: 1.1122255325317383\n",
      "Seen so far: 18944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 296: 0.9104614853858948\n",
      "Seen so far: 19008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 297: 0.6870492100715637\n",
      "Seen so far: 19072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 298: 0.7285020351409912\n",
      "Seen so far: 19136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 299: 1.3348636627197266\n",
      "Seen so far: 19200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 300: 0.6798640489578247\n",
      "Seen so far: 19264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 301: 0.8115917444229126\n",
      "Seen so far: 19328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 302: 0.8569706082344055\n",
      "Seen so far: 19392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 303: 0.6898689270019531\n",
      "Seen so far: 19456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 304: 1.034877061843872\n",
      "Seen so far: 19520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 305: 0.8537918329238892\n",
      "Seen so far: 19584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 306: 1.10610032081604\n",
      "Seen so far: 19648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 307: 0.9893728494644165\n",
      "Seen so far: 19712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 308: 1.0916951894760132\n",
      "Seen so far: 19776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 309: 0.7263805866241455\n",
      "Seen so far: 19840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 310: 0.9957473278045654\n",
      "Seen so far: 19904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 311: 1.0701824426651\n",
      "Seen so far: 19968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 312: 1.0665698051452637\n",
      "Seen so far: 20032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 313: 0.9314533472061157\n",
      "Seen so far: 20096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 314: 1.064866304397583\n",
      "Seen so far: 20160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 315: 0.6786878705024719\n",
      "Seen so far: 20224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 316: 0.9568724036216736\n",
      "Seen so far: 20288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 317: 1.0326030254364014\n",
      "Seen so far: 20352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 318: 1.1787316799163818\n",
      "Seen so far: 20416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 319: 0.9497848749160767\n",
      "Seen so far: 20480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 320: 1.0436936616897583\n",
      "Seen so far: 20544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 321: 0.9168029427528381\n",
      "Seen so far: 20608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 322: 0.9508386850357056\n",
      "Seen so far: 20672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 323: 1.0750269889831543\n",
      "Seen so far: 20736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 324: 1.1125942468643188\n",
      "Seen so far: 20800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 325: 0.8746467232704163\n",
      "Seen so far: 20864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 326: 0.7743017077445984\n",
      "Seen so far: 20928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 327: 1.1701865196228027\n",
      "Seen so far: 20992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 328: 0.9707818031311035\n",
      "Seen so far: 21056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 329: 1.224552869796753\n",
      "Seen so far: 21120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 330: 0.8070584535598755\n",
      "Seen so far: 21184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 331: 0.9350867867469788\n",
      "Seen so far: 21248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 332: 1.0878052711486816\n",
      "Seen so far: 21312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 333: 1.1013139486312866\n",
      "Seen so far: 21376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 334: 0.9613863825798035\n",
      "Seen so far: 21440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 335: 1.2798476219177246\n",
      "Seen so far: 21504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 336: 1.102554202079773\n",
      "Seen so far: 21568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 337: 0.8519200086593628\n",
      "Seen so far: 21632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 338: 0.8015653491020203\n",
      "Seen so far: 21696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 339: 0.7811739444732666\n",
      "Seen so far: 21760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 340: 0.7914915084838867\n",
      "Seen so far: 21824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 341: 1.038325548171997\n",
      "Seen so far: 21888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 342: 1.0488951206207275\n",
      "Seen so far: 21952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 343: 1.2874789237976074\n",
      "Seen so far: 22016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 344: 1.0171284675598145\n",
      "Seen so far: 22080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 345: 0.7543091177940369\n",
      "Seen so far: 22144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 346: 0.7465876340866089\n",
      "Seen so far: 22208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 347: 1.2367053031921387\n",
      "Seen so far: 22272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 348: 0.361922025680542\n",
      "Seen so far: 22336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 349: 1.0052602291107178\n",
      "Seen so far: 22400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 350: 1.0983920097351074\n",
      "Seen so far: 22464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 351: 0.7298440933227539\n",
      "Seen so far: 22528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 352: 1.027093768119812\n",
      "Seen so far: 22592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 353: 1.0947844982147217\n",
      "Seen so far: 22656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 354: 0.9397890567779541\n",
      "Seen so far: 22720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 355: 0.9446384310722351\n",
      "Seen so far: 22784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 356: 0.6411280632019043\n",
      "Seen so far: 22848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 357: 1.02396821975708\n",
      "Seen so far: 22912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 358: 1.0263910293579102\n",
      "Seen so far: 22976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 359: 1.0596482753753662\n",
      "Seen so far: 23040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 360: 1.1638410091400146\n",
      "Seen so far: 23104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 361: 0.7475690841674805\n",
      "Seen so far: 23168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 362: 1.0438592433929443\n",
      "Seen so far: 23232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 363: 0.9768314957618713\n",
      "Seen so far: 23296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 364: 0.9838476181030273\n",
      "Seen so far: 23360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 365: 1.2249376773834229\n",
      "Seen so far: 23424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 366: 1.197211503982544\n",
      "Seen so far: 23488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 367: 0.9897087812423706\n",
      "Seen so far: 23552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 368: 0.9529602527618408\n",
      "Seen so far: 23616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 369: 1.1565237045288086\n",
      "Seen so far: 23680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 370: 0.6280665397644043\n",
      "Seen so far: 23744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 371: 1.027909755706787\n",
      "Seen so far: 23808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 372: 0.5462162494659424\n",
      "Seen so far: 23872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 373: 1.1127028465270996\n",
      "Seen so far: 23936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 374: 0.9420814514160156\n",
      "Seen so far: 24000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 375: 0.978740930557251\n",
      "Seen so far: 24064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 376: 0.8609087467193604\n",
      "Seen so far: 24128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 377: 1.3798131942749023\n",
      "Seen so far: 24192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 378: 0.857448160648346\n",
      "Seen so far: 24256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 379: 0.7801347970962524\n",
      "Seen so far: 24320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 380: 0.9791804552078247\n",
      "Seen so far: 24384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 381: 0.9062483906745911\n",
      "Seen so far: 24448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 382: 0.8271573781967163\n",
      "Seen so far: 24512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 383: 1.035233736038208\n",
      "Seen so far: 24576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 384: 0.9034948348999023\n",
      "Seen so far: 24640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 385: 1.1364758014678955\n",
      "Seen so far: 24704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 386: 1.4213855266571045\n",
      "Seen so far: 24768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 387: 0.907497763633728\n",
      "Seen so far: 24832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 388: 1.238353967666626\n",
      "Seen so far: 24896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 389: 0.7222528457641602\n",
      "Seen so far: 24960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 390: 1.2142846584320068\n",
      "Seen so far: 25024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 391: 0.6726496815681458\n",
      "Seen so far: 25088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 392: 0.9914073348045349\n",
      "Seen so far: 25152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 393: 1.05292546749115\n",
      "Seen so far: 25216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 394: 0.6155000925064087\n",
      "Seen so far: 25280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 395: 1.3694672584533691\n",
      "Seen so far: 25344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 396: 0.9759010672569275\n",
      "Seen so far: 25408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 397: 1.2525221109390259\n",
      "Seen so far: 25472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 398: 0.7341284155845642\n",
      "Seen so far: 25536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 399: 1.0536904335021973\n",
      "Seen so far: 25600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 400: 0.8869320154190063\n",
      "Seen so far: 25664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 401: 0.8593966364860535\n",
      "Seen so far: 25728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 402: 1.1587059497833252\n",
      "Seen so far: 25792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 403: 0.8554418087005615\n",
      "Seen so far: 25856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 404: 0.6908047199249268\n",
      "Seen so far: 25920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 405: 0.8469690084457397\n",
      "Seen so far: 25984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 406: 1.1719640493392944\n",
      "Seen so far: 26048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 407: 0.8275569677352905\n",
      "Seen so far: 26112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 408: 1.0874741077423096\n",
      "Seen so far: 26176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 409: 0.9095847606658936\n",
      "Seen so far: 26240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 410: 0.5935192108154297\n",
      "Seen so far: 26304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 411: 1.2407026290893555\n",
      "Seen so far: 26368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 412: 1.0898160934448242\n",
      "Seen so far: 26432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 413: 0.968286395072937\n",
      "Seen so far: 26496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 414: 0.45405057072639465\n",
      "Seen so far: 26560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 415: 0.8411022424697876\n",
      "Seen so far: 26624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 416: 1.0527653694152832\n",
      "Seen so far: 26688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 417: 1.073251724243164\n",
      "Seen so far: 26752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 418: 1.0087170600891113\n",
      "Seen so far: 26816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 419: 1.4822685718536377\n",
      "Seen so far: 26880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 420: 0.917998194694519\n",
      "Seen so far: 26944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 421: 1.5843802690505981\n",
      "Seen so far: 27008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 422: 0.7461666464805603\n",
      "Seen so far: 27072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 423: 0.995685875415802\n",
      "Seen so far: 27136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 424: 1.1483980417251587\n",
      "Seen so far: 27200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 425: 1.0567874908447266\n",
      "Seen so far: 27264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 426: 1.1993166208267212\n",
      "Seen so far: 27328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 427: 1.223169207572937\n",
      "Seen so far: 27392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 428: 1.0131832361221313\n",
      "Seen so far: 27456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 429: 0.9901362061500549\n",
      "Seen so far: 27520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 430: 0.947998046875\n",
      "Seen so far: 27584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 431: 0.9936296939849854\n",
      "Seen so far: 27648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 432: 1.2130497694015503\n",
      "Seen so far: 27712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 433: 0.6988662481307983\n",
      "Seen so far: 27776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 434: 0.8480901718139648\n",
      "Seen so far: 27840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 435: 1.0787701606750488\n",
      "Seen so far: 27904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 436: 0.8438551425933838\n",
      "Seen so far: 27968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 437: 0.9102120995521545\n",
      "Seen so far: 28032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 438: 1.192535638809204\n",
      "Seen so far: 28096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 439: 1.0041391849517822\n",
      "Seen so far: 28160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 440: 1.1372941732406616\n",
      "Seen so far: 28224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 441: 1.124003291130066\n",
      "Seen so far: 28288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 442: 0.9386729598045349\n",
      "Seen so far: 28352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 443: 0.5415802001953125\n",
      "Seen so far: 28416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 444: 1.2049235105514526\n",
      "Seen so far: 28480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 445: 1.1193337440490723\n",
      "Seen so far: 28544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 446: 0.7922374606132507\n",
      "Seen so far: 28608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 447: 0.929162859916687\n",
      "Seen so far: 28672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 448: 0.9089118838310242\n",
      "Seen so far: 28736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 449: 0.8674723505973816\n",
      "Seen so far: 28800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 450: 1.3136935234069824\n",
      "Seen so far: 28864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 451: 1.0139679908752441\n",
      "Seen so far: 28928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 452: 1.3294322490692139\n",
      "Seen so far: 28992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 453: 1.1517534255981445\n",
      "Seen so far: 29056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 454: 1.0248491764068604\n",
      "Seen so far: 29120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 455: 0.7508686780929565\n",
      "Seen so far: 29184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 456: 1.0252127647399902\n",
      "Seen so far: 29248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 457: 0.8107914924621582\n",
      "Seen so far: 29312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 458: 1.127811312675476\n",
      "Seen so far: 29376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 459: 0.8855772018432617\n",
      "Seen so far: 29440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 460: 1.2783825397491455\n",
      "Seen so far: 29504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 461: 1.1077873706817627\n",
      "Seen so far: 29568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 462: 0.9922123551368713\n",
      "Seen so far: 29632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 463: 0.9662961363792419\n",
      "Seen so far: 29696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 464: 0.9285392165184021\n",
      "Seen so far: 29760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 465: 0.770033597946167\n",
      "Seen so far: 29824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 466: 0.8687160015106201\n",
      "Seen so far: 29888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 467: 0.8802963495254517\n",
      "Seen so far: 29952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 468: 1.0457074642181396\n",
      "Seen so far: 30016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 469: 0.8672025799751282\n",
      "Seen so far: 30080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 470: 0.6753687858581543\n",
      "Seen so far: 30144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 471: 0.8820528984069824\n",
      "Seen so far: 30208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 472: 0.8537395000457764\n",
      "Seen so far: 30272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 473: 0.9498902559280396\n",
      "Seen so far: 30336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 474: 0.6474957466125488\n",
      "Seen so far: 30400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 475: 0.9955602288246155\n",
      "Seen so far: 30464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 476: 0.8847866058349609\n",
      "Seen so far: 30528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 477: 1.020437240600586\n",
      "Seen so far: 30592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 478: 0.8559831380844116\n",
      "Seen so far: 30656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 479: 1.174022912979126\n",
      "Seen so far: 30720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 480: 0.7420419454574585\n",
      "Seen so far: 30784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 481: 0.7946658134460449\n",
      "Seen so far: 30848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 482: 0.6079310178756714\n",
      "Seen so far: 30912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 483: 1.1181895732879639\n",
      "Seen so far: 30976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 484: 0.8078194856643677\n",
      "Seen so far: 31040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 485: 0.7809168696403503\n",
      "Seen so far: 31104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 486: 1.0814692974090576\n",
      "Seen so far: 31168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 487: 0.7995518445968628\n",
      "Seen so far: 31232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 488: 1.0830395221710205\n",
      "Seen so far: 31296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 489: 1.1868350505828857\n",
      "Seen so far: 31360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 490: 0.8188660740852356\n",
      "Seen so far: 31424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 491: 0.9568210244178772\n",
      "Seen so far: 31488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 492: 0.9956057071685791\n",
      "Seen so far: 31552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 493: 0.9138425588607788\n",
      "Seen so far: 31616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 494: 0.8267987966537476\n",
      "Seen so far: 31680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 495: 0.9241758584976196\n",
      "Seen so far: 31744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 496: 1.0924925804138184\n",
      "Seen so far: 31808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 497: 0.9155044555664062\n",
      "Seen so far: 31872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 498: 0.866888165473938\n",
      "Seen so far: 31936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 499: 1.1699316501617432\n",
      "Seen so far: 32000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 500: 0.7018698453903198\n",
      "Seen so far: 32064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 501: 0.8488821387290955\n",
      "Seen so far: 32128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 502: 0.7577077746391296\n",
      "Seen so far: 32192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 503: 0.7080692052841187\n",
      "Seen so far: 32256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 504: 1.4061222076416016\n",
      "Seen so far: 32320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 505: 1.0437088012695312\n",
      "Seen so far: 32384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 506: 1.0483318567276\n",
      "Seen so far: 32448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 507: 1.3754104375839233\n",
      "Seen so far: 32512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 508: 0.7977734208106995\n",
      "Seen so far: 32576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 509: 0.7622162103652954\n",
      "Seen so far: 32640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 510: 1.0194814205169678\n",
      "Seen so far: 32704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 511: 1.1673576831817627\n",
      "Seen so far: 32768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 512: 1.1327439546585083\n",
      "Seen so far: 32832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 513: 1.2091529369354248\n",
      "Seen so far: 32896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 514: 0.7747434377670288\n",
      "Seen so far: 32960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 515: 0.6614501476287842\n",
      "Seen so far: 33024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 516: 0.725001335144043\n",
      "Seen so far: 33088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 517: 1.026463508605957\n",
      "Seen so far: 33152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 518: 0.9701322913169861\n",
      "Seen so far: 33216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 519: 0.9289951324462891\n",
      "Seen so far: 33280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 520: 0.9749977588653564\n",
      "Seen so far: 33344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 521: 0.816710889339447\n",
      "Seen so far: 33408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 522: 0.7530907392501831\n",
      "Seen so far: 33472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 523: 1.050990343093872\n",
      "Seen so far: 33536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 524: 0.8721344470977783\n",
      "Seen so far: 33600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 525: 0.8772221803665161\n",
      "Seen so far: 33664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 526: 1.1512998342514038\n",
      "Seen so far: 33728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 527: 1.0733932256698608\n",
      "Seen so far: 33792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 528: 0.9205778241157532\n",
      "Seen so far: 33856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 529: 0.6186509132385254\n",
      "Seen so far: 33920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 530: 0.9070544242858887\n",
      "Seen so far: 33984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 531: 0.5280812978744507\n",
      "Seen so far: 34048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 532: 1.0083986520767212\n",
      "Seen so far: 34112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 533: 1.3614802360534668\n",
      "Seen so far: 34176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 534: 0.9112036824226379\n",
      "Seen so far: 34240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 535: 1.0798667669296265\n",
      "Seen so far: 34304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 536: 0.9564330577850342\n",
      "Seen so far: 34368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 537: 0.9468370079994202\n",
      "Seen so far: 34432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 538: 0.7011638879776001\n",
      "Seen so far: 34496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 539: 0.6254084706306458\n",
      "Seen so far: 34560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 540: 1.0285899639129639\n",
      "Seen so far: 34624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 541: 0.8406087756156921\n",
      "Seen so far: 34688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 542: 0.7378418445587158\n",
      "Seen so far: 34752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 543: 0.7330101728439331\n",
      "Seen so far: 34816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 544: 0.6253810524940491\n",
      "Seen so far: 34880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 545: 1.056654930114746\n",
      "Seen so far: 34944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 546: 0.9209065437316895\n",
      "Seen so far: 35008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 547: 1.001996397972107\n",
      "Seen so far: 35072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 548: 1.1797624826431274\n",
      "Seen so far: 35136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 549: 0.8761793375015259\n",
      "Seen so far: 35200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 550: 0.9453556537628174\n",
      "Seen so far: 35264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 551: 0.5350157022476196\n",
      "Seen so far: 35328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 552: 0.7922196388244629\n",
      "Seen so far: 35392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 553: 1.088931918144226\n",
      "Seen so far: 35456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 554: 0.9852211475372314\n",
      "Seen so far: 35520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 555: 1.1363751888275146\n",
      "Seen so far: 35584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 556: 0.916893482208252\n",
      "Seen so far: 35648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 557: 1.1022144556045532\n",
      "Seen so far: 35712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 558: 0.681705117225647\n",
      "Seen so far: 35776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 559: 1.0177942514419556\n",
      "Seen so far: 35840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 560: 0.9509748816490173\n",
      "Seen so far: 35904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 561: 0.7954992055892944\n",
      "Seen so far: 35968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 562: 1.1333131790161133\n",
      "Seen so far: 36032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 563: 1.0400187969207764\n",
      "Seen so far: 36096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 564: 0.6978049278259277\n",
      "Seen so far: 36160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 565: 0.8876722455024719\n",
      "Seen so far: 36224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 566: 0.6508548855781555\n",
      "Seen so far: 36288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 567: 0.8382056951522827\n",
      "Seen so far: 36352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 568: 0.8504624366760254\n",
      "Seen so far: 36416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 569: 0.7041701078414917\n",
      "Seen so far: 36480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 570: 1.084752082824707\n",
      "Seen so far: 36544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 571: 1.1508344411849976\n",
      "Seen so far: 36608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 572: 1.1556466817855835\n",
      "Seen so far: 36672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 573: 0.9589958190917969\n",
      "Seen so far: 36736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 574: 0.9050337672233582\n",
      "Seen so far: 36800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 575: 1.1452500820159912\n",
      "Seen so far: 36864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 576: 0.6619970798492432\n",
      "Seen so far: 36928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 577: 1.1853878498077393\n",
      "Seen so far: 36992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 578: 0.6952491998672485\n",
      "Seen so far: 37056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 579: 1.125295639038086\n",
      "Seen so far: 37120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 580: 0.6783877611160278\n",
      "Seen so far: 37184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 581: 0.8000211715698242\n",
      "Seen so far: 37248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 582: 1.3095982074737549\n",
      "Seen so far: 37312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 583: 0.756923496723175\n",
      "Seen so far: 37376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 584: 1.0491427183151245\n",
      "Seen so far: 37440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 585: 0.8373103141784668\n",
      "Seen so far: 37504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 586: 1.2045953273773193\n",
      "Seen so far: 37568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 587: 0.5814498662948608\n",
      "Seen so far: 37632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 588: 0.8820275068283081\n",
      "Seen so far: 37696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 589: 0.7899447679519653\n",
      "Seen so far: 37760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 590: 0.7773701548576355\n",
      "Seen so far: 37824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 591: 0.697026252746582\n",
      "Seen so far: 37888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 592: 0.9991052746772766\n",
      "Seen so far: 37952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 593: 1.0955427885055542\n",
      "Seen so far: 38016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 594: 0.607994019985199\n",
      "Seen so far: 38080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 595: 0.957379937171936\n",
      "Seen so far: 38144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 596: 0.9790364503860474\n",
      "Seen so far: 38208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 597: 0.773064374923706\n",
      "Seen so far: 38272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 598: 0.6866459846496582\n",
      "Seen so far: 38336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 599: 0.659752607345581\n",
      "Seen so far: 38400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 600: 0.6715506911277771\n",
      "Seen so far: 38464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 601: 0.5459334850311279\n",
      "Seen so far: 38528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 602: 1.139174222946167\n",
      "Seen so far: 38592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 603: 1.5488879680633545\n",
      "Seen so far: 38656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 604: 1.1135071516036987\n",
      "Seen so far: 38720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 605: 0.7756862640380859\n",
      "Seen so far: 38784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 606: 1.6326346397399902\n",
      "Seen so far: 38848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 607: 0.9272143840789795\n",
      "Seen so far: 38912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 608: 1.012143850326538\n",
      "Seen so far: 38976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 609: 0.9240396022796631\n",
      "Seen so far: 39040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 610: 0.6046878099441528\n",
      "Seen so far: 39104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 611: 0.6618722081184387\n",
      "Seen so far: 39168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 612: 0.7812001705169678\n",
      "Seen so far: 39232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 613: 0.9165641069412231\n",
      "Seen so far: 39296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 614: 1.2416858673095703\n",
      "Seen so far: 39360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 615: 0.8817562460899353\n",
      "Seen so far: 39424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 616: 0.7581832408905029\n",
      "Seen so far: 39488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 617: 1.160667896270752\n",
      "Seen so far: 39552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 618: 1.240529179573059\n",
      "Seen so far: 39616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 619: 0.9066404104232788\n",
      "Seen so far: 39680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 620: 1.0240119695663452\n",
      "Seen so far: 39744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 621: 0.9077416062355042\n",
      "Seen so far: 39808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 622: 0.9279831647872925\n",
      "Seen so far: 39872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 623: 0.7979606986045837\n",
      "Seen so far: 39936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 624: 0.9580010771751404\n",
      "Seen so far: 40000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 625: 0.8238496780395508\n",
      "Seen so far: 40064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 626: 0.7621920108795166\n",
      "Seen so far: 40128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 627: 0.587401270866394\n",
      "Seen so far: 40192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 628: 1.09610915184021\n",
      "Seen so far: 40256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 629: 1.0663065910339355\n",
      "Seen so far: 40320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 630: 0.9045137166976929\n",
      "Seen so far: 40384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 631: 0.8940544128417969\n",
      "Seen so far: 40448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 632: 0.9160115718841553\n",
      "Seen so far: 40512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 633: 0.9255740642547607\n",
      "Seen so far: 40576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 634: 0.590329110622406\n",
      "Seen so far: 40640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 635: 0.6896138191223145\n",
      "Seen so far: 40704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 636: 1.133209228515625\n",
      "Seen so far: 40768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 637: 0.4569163918495178\n",
      "Seen so far: 40832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 638: 0.8022675514221191\n",
      "Seen so far: 40896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 639: 0.9292566776275635\n",
      "Seen so far: 40960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 640: 0.6908793449401855\n",
      "Seen so far: 41024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 641: 0.4293859004974365\n",
      "Seen so far: 41088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 642: 0.6650775074958801\n",
      "Seen so far: 41152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 643: 0.7248497605323792\n",
      "Seen so far: 41216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 644: 1.0943377017974854\n",
      "Seen so far: 41280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 645: 1.0406473875045776\n",
      "Seen so far: 41344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 646: 0.9523640275001526\n",
      "Seen so far: 41408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 647: 0.9284157156944275\n",
      "Seen so far: 41472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 648: 0.8737500905990601\n",
      "Seen so far: 41536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 649: 1.1122632026672363\n",
      "Seen so far: 41600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 650: 1.247827172279358\n",
      "Seen so far: 41664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 651: 0.8697372674942017\n",
      "Seen so far: 41728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 652: 0.7794613838195801\n",
      "Seen so far: 41792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 653: 0.8670194745063782\n",
      "Seen so far: 41856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 654: 0.9189255833625793\n",
      "Seen so far: 41920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 655: 0.8520588874816895\n",
      "Seen so far: 41984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 656: 0.8149077892303467\n",
      "Seen so far: 42048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 657: 1.223874807357788\n",
      "Seen so far: 42112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 658: 0.7411506772041321\n",
      "Seen so far: 42176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 659: 0.8464011549949646\n",
      "Seen so far: 42240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 660: 1.0174918174743652\n",
      "Seen so far: 42304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 661: 0.8042072057723999\n",
      "Seen so far: 42368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 662: 0.9085317850112915\n",
      "Seen so far: 42432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 663: 1.1433523893356323\n",
      "Seen so far: 42496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 664: 0.8006188869476318\n",
      "Seen so far: 42560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 665: 1.0207545757293701\n",
      "Seen so far: 42624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 666: 0.8824793100357056\n",
      "Seen so far: 42688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 667: 0.6789160966873169\n",
      "Seen so far: 42752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 668: 0.6850690841674805\n",
      "Seen so far: 42816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 669: 1.027409553527832\n",
      "Seen so far: 42880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 670: 0.8597296476364136\n",
      "Seen so far: 42944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 671: 1.3792357444763184\n",
      "Seen so far: 43008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 672: 1.1918165683746338\n",
      "Seen so far: 43072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 673: 1.2721713781356812\n",
      "Seen so far: 43136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 674: 0.8204797506332397\n",
      "Seen so far: 43200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 675: 1.0178840160369873\n",
      "Seen so far: 43264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 676: 1.087101936340332\n",
      "Seen so far: 43328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 677: 0.9055586457252502\n",
      "Seen so far: 43392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 678: 1.0475194454193115\n",
      "Seen so far: 43456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 679: 1.2533223628997803\n",
      "Seen so far: 43520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 680: 0.9140831828117371\n",
      "Seen so far: 43584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 681: 1.1206523180007935\n",
      "Seen so far: 43648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 682: 1.079803466796875\n",
      "Seen so far: 43712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 683: 0.577422559261322\n",
      "Seen so far: 43776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 684: 0.8696228265762329\n",
      "Seen so far: 43840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 685: 0.7762896418571472\n",
      "Seen so far: 43904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 686: 1.2494416236877441\n",
      "Seen so far: 43968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 687: 1.1286050081253052\n",
      "Seen so far: 44032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 688: 0.8875651359558105\n",
      "Seen so far: 44096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 689: 0.836434006690979\n",
      "Seen so far: 44160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 690: 0.9268364310264587\n",
      "Seen so far: 44224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 691: 1.1394846439361572\n",
      "Seen so far: 44288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 692: 1.1071778535842896\n",
      "Seen so far: 44352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 693: 0.9722475409507751\n",
      "Seen so far: 44416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 694: 0.9496712684631348\n",
      "Seen so far: 44480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 695: 0.6707173585891724\n",
      "Seen so far: 44544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 696: 0.8959120512008667\n",
      "Seen so far: 44608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 697: 0.8828133344650269\n",
      "Seen so far: 44672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 698: 0.7806037664413452\n",
      "Seen so far: 44736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 699: 0.924023449420929\n",
      "Seen so far: 44800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 700: 1.2477619647979736\n",
      "Seen so far: 44864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 701: 1.0908615589141846\n",
      "Seen so far: 44928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 702: 0.8257852792739868\n",
      "Seen so far: 44992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 703: 0.6360520720481873\n",
      "Seen so far: 45056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 704: 0.9255563616752625\n",
      "Seen so far: 45120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 705: 0.5733383297920227\n",
      "Seen so far: 45184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 706: 0.9812246561050415\n",
      "Seen so far: 45248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 707: 0.6200047731399536\n",
      "Seen so far: 45312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 708: 0.8707449436187744\n",
      "Seen so far: 45376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 709: 1.41864812374115\n",
      "Seen so far: 45440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 710: 1.0073533058166504\n",
      "Seen so far: 45504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 711: 0.8142843842506409\n",
      "Seen so far: 45568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 712: 1.0425491333007812\n",
      "Seen so far: 45632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 713: 1.172407627105713\n",
      "Seen so far: 45696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 714: 0.9903610348701477\n",
      "Seen so far: 45760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 715: 1.1585534811019897\n",
      "Seen so far: 45824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 716: 0.566325843334198\n",
      "Seen so far: 45888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 717: 1.1460667848587036\n",
      "Seen so far: 45952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 718: 1.2961866855621338\n",
      "Seen so far: 46016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 719: 1.093263864517212\n",
      "Seen so far: 46080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 720: 1.04435133934021\n",
      "Seen so far: 46144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 721: 0.9429836273193359\n",
      "Seen so far: 46208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 722: 0.5742970705032349\n",
      "Seen so far: 46272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 723: 0.9111286401748657\n",
      "Seen so far: 46336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 724: 0.8892958164215088\n",
      "Seen so far: 46400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 725: 1.2482081651687622\n",
      "Seen so far: 46464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 726: 0.9864976406097412\n",
      "Seen so far: 46528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 727: 1.07257080078125\n",
      "Seen so far: 46592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 728: 1.2563802003860474\n",
      "Seen so far: 46656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 729: 0.7829317450523376\n",
      "Seen so far: 46720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 730: 0.8488328456878662\n",
      "Seen so far: 46784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 731: 1.2246406078338623\n",
      "Seen so far: 46848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 732: 1.509237289428711\n",
      "Seen so far: 46912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 733: 0.997877299785614\n",
      "Seen so far: 46976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 734: 0.752961277961731\n",
      "Seen so far: 47040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 735: 0.8077751398086548\n",
      "Seen so far: 47104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 736: 0.6864889860153198\n",
      "Seen so far: 47168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 737: 0.7141760587692261\n",
      "Seen so far: 47232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 738: 0.6491692066192627\n",
      "Seen so far: 47296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 739: 1.140434980392456\n",
      "Seen so far: 47360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 740: 0.8724658489227295\n",
      "Seen so far: 47424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 741: 0.6597840785980225\n",
      "Seen so far: 47488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 742: 0.7703216671943665\n",
      "Seen so far: 47552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 743: 1.2964355945587158\n",
      "Seen so far: 47616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 744: 0.6802234053611755\n",
      "Seen so far: 47680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 745: 0.9408818483352661\n",
      "Seen so far: 47744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 746: 1.1467912197113037\n",
      "Seen so far: 47808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 747: 1.1273024082183838\n",
      "Seen so far: 47872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 748: 0.6901048421859741\n",
      "Seen so far: 47936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 749: 1.3848530054092407\n",
      "Seen so far: 48000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 750: 0.7669508457183838\n",
      "Seen so far: 48064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 751: 0.8554965853691101\n",
      "Seen so far: 48128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 752: 1.1470592021942139\n",
      "Seen so far: 48192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 753: 1.2528645992279053\n",
      "Seen so far: 48256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 754: 1.0584771633148193\n",
      "Seen so far: 48320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 755: 0.7078173160552979\n",
      "Seen so far: 48384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 756: 1.1403323411941528\n",
      "Seen so far: 48448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 757: 1.339955449104309\n",
      "Seen so far: 48512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 758: 0.7109513878822327\n",
      "Seen so far: 48576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 759: 0.9657721519470215\n",
      "Seen so far: 48640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 760: 1.1086887121200562\n",
      "Seen so far: 48704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 761: 1.095908761024475\n",
      "Seen so far: 48768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 762: 0.8157301545143127\n",
      "Seen so far: 48832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 763: 1.1866190433502197\n",
      "Seen so far: 48896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 764: 1.0679079294204712\n",
      "Seen so far: 48960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 765: 1.0429201126098633\n",
      "Seen so far: 49024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 766: 1.1508963108062744\n",
      "Seen so far: 49088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 767: 0.947933554649353\n",
      "Seen so far: 49152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 768: 0.6153225302696228\n",
      "Seen so far: 49216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 769: 0.7566787600517273\n",
      "Seen so far: 49280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 770: 0.7757598757743835\n",
      "Seen so far: 49344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 771: 0.8810274600982666\n",
      "Seen so far: 49408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 772: 1.208085536956787\n",
      "Seen so far: 49472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 773: 0.8237309455871582\n",
      "Seen so far: 49536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 774: 0.8590885996818542\n",
      "Seen so far: 49600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 775: 0.9188680648803711\n",
      "Seen so far: 49664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 776: 0.9170143008232117\n",
      "Seen so far: 49728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 777: 1.0593360662460327\n",
      "Seen so far: 49792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 778: 0.7294939160346985\n",
      "Seen so far: 49856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 779: 0.5789377689361572\n",
      "Seen so far: 49920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 780: 1.272902250289917\n",
      "Seen so far: 49984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 781: 1.157065510749817\n",
      "Seen so far: 50048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 782: 1.0441656112670898\n",
      "Seen so far: 50112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 783: 1.0987884998321533\n",
      "Seen so far: 50176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 784: 1.2189345359802246\n",
      "Seen so far: 50240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 785: 1.0346486568450928\n",
      "Seen so far: 50304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 786: 1.0900346040725708\n",
      "Seen so far: 50368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 787: 1.1327987909317017\n",
      "Seen so far: 50432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 788: 0.6037755608558655\n",
      "Seen so far: 50496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 789: 1.2318977117538452\n",
      "Seen so far: 50560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 790: 1.2156641483306885\n",
      "Seen so far: 50624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 791: 0.6746171116828918\n",
      "Seen so far: 50688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 792: 0.7962139844894409\n",
      "Seen so far: 50752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 793: 0.8176433444023132\n",
      "Seen so far: 50816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 794: 1.233109474182129\n",
      "Seen so far: 50880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 795: 0.7573876976966858\n",
      "Seen so far: 50944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 796: 0.8257101774215698\n",
      "Seen so far: 51008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 797: 0.8562197685241699\n",
      "Seen so far: 51072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 798: 1.2903270721435547\n",
      "Seen so far: 51136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 799: 1.3043307065963745\n",
      "Seen so far: 51200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 800: 0.8250531554222107\n",
      "Seen so far: 51264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 801: 0.759577214717865\n",
      "Seen so far: 51328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 802: 0.9655413031578064\n",
      "Seen so far: 51392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 803: 0.8862423896789551\n",
      "Seen so far: 51456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 804: 0.6294670104980469\n",
      "Seen so far: 51520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 805: 1.013068675994873\n",
      "Seen so far: 51584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 806: 0.9471903443336487\n",
      "Seen so far: 51648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 807: 0.6586604118347168\n",
      "Seen so far: 51712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 808: 1.0515451431274414\n",
      "Seen so far: 51776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 809: 1.076371669769287\n",
      "Seen so far: 51840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 810: 0.8876405954360962\n",
      "Seen so far: 51904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 811: 0.8154811859130859\n",
      "Seen so far: 51968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 812: 1.1218711137771606\n",
      "Seen so far: 52032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 813: 0.7397698163986206\n",
      "Seen so far: 52096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 814: 0.6699913144111633\n",
      "Seen so far: 52160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 815: 1.2742081880569458\n",
      "Seen so far: 52224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 816: 0.9582916498184204\n",
      "Seen so far: 52288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 817: 0.6803837418556213\n",
      "Seen so far: 52352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 818: 1.4655497074127197\n",
      "Seen so far: 52416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 819: 0.39133596420288086\n",
      "Seen so far: 52480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 820: 1.4050614833831787\n",
      "Seen so far: 52544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 821: 0.9354669451713562\n",
      "Seen so far: 52608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 822: 0.8917009830474854\n",
      "Seen so far: 52672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 823: 0.9610289931297302\n",
      "Seen so far: 52736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 824: 1.0782126188278198\n",
      "Seen so far: 52800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 825: 0.9110615253448486\n",
      "Seen so far: 52864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 826: 1.1331398487091064\n",
      "Seen so far: 52928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 827: 1.1511119604110718\n",
      "Seen so far: 52992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 828: 0.7489582896232605\n",
      "Seen so far: 53056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 829: 0.9920954704284668\n",
      "Seen so far: 53120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 830: 0.8596878051757812\n",
      "Seen so far: 53184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 831: 1.1477972269058228\n",
      "Seen so far: 53248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 832: 0.9575716257095337\n",
      "Seen so far: 53312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 833: 1.0481902360916138\n",
      "Seen so far: 53376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 834: 0.7917282581329346\n",
      "Seen so far: 53440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 835: 0.7929202318191528\n",
      "Seen so far: 53504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 836: 0.8571339845657349\n",
      "Seen so far: 53568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 837: 0.8482570648193359\n",
      "Seen so far: 53632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 838: 0.49055951833724976\n",
      "Seen so far: 53696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 839: 0.5924403667449951\n",
      "Seen so far: 53760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 840: 0.7954344749450684\n",
      "Seen so far: 53824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 841: 1.3575001955032349\n",
      "Seen so far: 53888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 842: 0.7763334512710571\n",
      "Seen so far: 53952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 843: 0.9003466963768005\n",
      "Seen so far: 54016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 844: 1.0140044689178467\n",
      "Seen so far: 54080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 845: 0.9897555708885193\n",
      "Seen so far: 54144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 846: 1.141656517982483\n",
      "Seen so far: 54208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 847: 0.8772928714752197\n",
      "Seen so far: 54272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 848: 0.8914412260055542\n",
      "Seen so far: 54336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 849: 0.6540263891220093\n",
      "Seen so far: 54400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 850: 0.46120595932006836\n",
      "Seen so far: 54464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 851: 0.6056679487228394\n",
      "Seen so far: 54528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 852: 0.4614942669868469\n",
      "Seen so far: 54592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 853: 0.6640698909759521\n",
      "Seen so far: 54656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 854: 0.6654425859451294\n",
      "Seen so far: 54720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 855: 0.7366030216217041\n",
      "Seen so far: 54784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 856: 0.6544520854949951\n",
      "Seen so far: 54848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 857: 0.7325693368911743\n",
      "Seen so far: 54912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 858: 0.8329574465751648\n",
      "Seen so far: 54976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 859: 1.0977387428283691\n",
      "Seen so far: 55040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 860: 0.854407548904419\n",
      "Seen so far: 55104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 861: 0.8080046772956848\n",
      "Seen so far: 55168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 862: 0.6437687277793884\n",
      "Seen so far: 55232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 863: 1.3049578666687012\n",
      "Seen so far: 55296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 864: 0.8697656393051147\n",
      "Seen so far: 55360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 865: 0.6413305997848511\n",
      "Seen so far: 55424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 866: 0.6928051710128784\n",
      "Seen so far: 55488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 867: 0.8650896549224854\n",
      "Seen so far: 55552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 868: 1.0770697593688965\n",
      "Seen so far: 55616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 869: 0.9249069094657898\n",
      "Seen so far: 55680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 870: 1.1210925579071045\n",
      "Seen so far: 55744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 871: 1.0802682638168335\n",
      "Seen so far: 55808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 872: 0.7177492380142212\n",
      "Seen so far: 55872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 873: 1.0126750469207764\n",
      "Seen so far: 55936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 874: 1.047774076461792\n",
      "Seen so far: 56000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 875: 1.151869297027588\n",
      "Seen so far: 56064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 876: 1.0255627632141113\n",
      "Seen so far: 56128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 877: 1.0067241191864014\n",
      "Seen so far: 56192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 878: 0.9438579678535461\n",
      "Seen so far: 56256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 879: 0.670441746711731\n",
      "Seen so far: 56320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 880: 0.9733251929283142\n",
      "Seen so far: 56384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 881: 1.2491666078567505\n",
      "Seen so far: 56448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 882: 1.0545547008514404\n",
      "Seen so far: 56512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 883: 0.8312400579452515\n",
      "Seen so far: 56576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 884: 0.49590906500816345\n",
      "Seen so far: 56640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 885: 0.7902013063430786\n",
      "Seen so far: 56704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 886: 1.1708426475524902\n",
      "Seen so far: 56768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 887: 0.9237796068191528\n",
      "Seen so far: 56832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 888: 0.9228864312171936\n",
      "Seen so far: 56896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 889: 1.281461238861084\n",
      "Seen so far: 56960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 890: 0.9003016352653503\n",
      "Seen so far: 57024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 891: 1.1910649538040161\n",
      "Seen so far: 57088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 892: 0.6170592308044434\n",
      "Seen so far: 57152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 893: 1.1517307758331299\n",
      "Seen so far: 57216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 894: 1.1326663494110107\n",
      "Seen so far: 57280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 895: 0.9619224667549133\n",
      "Seen so far: 57344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 896: 1.348018765449524\n",
      "Seen so far: 57408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 897: 1.1231669187545776\n",
      "Seen so far: 57472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 898: 0.6939692497253418\n",
      "Seen so far: 57536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 899: 0.7110913395881653\n",
      "Seen so far: 57600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 900: 0.8040770292282104\n",
      "Seen so far: 57664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 901: 1.3150620460510254\n",
      "Seen so far: 57728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 902: 1.1078083515167236\n",
      "Seen so far: 57792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 903: 0.9954425692558289\n",
      "Seen so far: 57856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 904: 0.9671868085861206\n",
      "Seen so far: 57920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 905: 0.9906347990036011\n",
      "Seen so far: 57984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 906: 1.266546607017517\n",
      "Seen so far: 58048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 907: 0.9400345683097839\n",
      "Seen so far: 58112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 908: 0.6353370547294617\n",
      "Seen so far: 58176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 909: 1.0899473428726196\n",
      "Seen so far: 58240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 910: 0.7194958329200745\n",
      "Seen so far: 58304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 911: 0.9445194005966187\n",
      "Seen so far: 58368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 912: 0.7053816318511963\n",
      "Seen so far: 58432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 913: 1.3993091583251953\n",
      "Seen so far: 58496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 914: 0.5994182229042053\n",
      "Seen so far: 58560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 915: 0.5344905853271484\n",
      "Seen so far: 58624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 916: 1.0377306938171387\n",
      "Seen so far: 58688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 917: 0.6845433712005615\n",
      "Seen so far: 58752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 918: 1.0716803073883057\n",
      "Seen so far: 58816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 919: 0.8840803503990173\n",
      "Seen so far: 58880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 920: 0.9683440327644348\n",
      "Seen so far: 58944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 921: 0.8159998655319214\n",
      "Seen so far: 59008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 922: 1.0287753343582153\n",
      "Seen so far: 59072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 923: 0.9307057857513428\n",
      "Seen so far: 59136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 924: 0.8878229856491089\n",
      "Seen so far: 59200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 925: 0.9104833602905273\n",
      "Seen so far: 59264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 926: 1.2672030925750732\n",
      "Seen so far: 59328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 927: 0.9445973038673401\n",
      "Seen so far: 59392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 928: 0.8530042171478271\n",
      "Seen so far: 59456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 929: 0.6929148435592651\n",
      "Seen so far: 59520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 930: 0.8467365503311157\n",
      "Seen so far: 59584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 931: 1.1583220958709717\n",
      "Seen so far: 59648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 932: 1.2307016849517822\n",
      "Seen so far: 59712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 933: 0.8171166181564331\n",
      "Seen so far: 59776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 934: 1.1989891529083252\n",
      "Seen so far: 59840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 935: 0.6250656843185425\n",
      "Seen so far: 59904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 936: 0.8242261409759521\n",
      "Seen so far: 59968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 937: 1.079496145248413\n",
      "Seen so far: 60032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 938: 1.102083683013916\n",
      "Seen so far: 60096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 939: 0.8473395109176636\n",
      "Seen so far: 60160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 940: 0.6638855338096619\n",
      "Seen so far: 60224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 941: 0.7221716046333313\n",
      "Seen so far: 60288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 942: 0.9502872824668884\n",
      "Seen so far: 60352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 943: 1.127162218093872\n",
      "Seen so far: 60416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 944: 0.835646390914917\n",
      "Seen so far: 60480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 945: 0.9990370273590088\n",
      "Seen so far: 60544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 946: 0.8020490407943726\n",
      "Seen so far: 60608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 947: 1.1396496295928955\n",
      "Seen so far: 60672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 948: 0.6586392521858215\n",
      "Seen so far: 60736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 949: 0.9726226925849915\n",
      "Seen so far: 60800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 950: 1.0247766971588135\n",
      "Seen so far: 60864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 951: 0.9263306260108948\n",
      "Seen so far: 60928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 952: 1.0091735124588013\n",
      "Seen so far: 60992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 953: 1.1823457479476929\n",
      "Seen so far: 61056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 954: 1.0059951543807983\n",
      "Seen so far: 61120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 955: 0.8454759120941162\n",
      "Seen so far: 61184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 956: 1.3857131004333496\n",
      "Seen so far: 61248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 957: 1.2256830930709839\n",
      "Seen so far: 61312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 958: 1.0932209491729736\n",
      "Seen so far: 61376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 959: 0.7805380821228027\n",
      "Seen so far: 61440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 960: 0.9655088186264038\n",
      "Seen so far: 61504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 961: 0.9153056740760803\n",
      "Seen so far: 61568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 962: 0.790001630783081\n",
      "Seen so far: 61632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 963: 0.8612207770347595\n",
      "Seen so far: 61696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 964: 0.9904276132583618\n",
      "Seen so far: 61760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 965: 0.9474465847015381\n",
      "Seen so far: 61824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 966: 0.8941398859024048\n",
      "Seen so far: 61888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 967: 0.6574154496192932\n",
      "Seen so far: 61952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 968: 0.8928166627883911\n",
      "Seen so far: 62016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 969: 0.9175170660018921\n",
      "Seen so far: 62080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 970: 1.2140717506408691\n",
      "Seen so far: 62144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 971: 0.8245086073875427\n",
      "Seen so far: 62208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 972: 1.1639535427093506\n",
      "Seen so far: 62272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 973: 1.0502898693084717\n",
      "Seen so far: 62336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 974: 0.9001354575157166\n",
      "Seen so far: 62400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 975: 0.7891945838928223\n",
      "Seen so far: 62464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 976: 0.8334333896636963\n",
      "Seen so far: 62528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 977: 0.8762018084526062\n",
      "Seen so far: 62592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 978: 1.1186742782592773\n",
      "Seen so far: 62656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 979: 0.8880655765533447\n",
      "Seen so far: 62720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 980: 1.053757905960083\n",
      "Seen so far: 62784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 981: 1.0838475227355957\n",
      "Seen so far: 62848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 982: 0.9462697505950928\n",
      "Seen so far: 62912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 983: 0.7036235332489014\n",
      "Seen so far: 62976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 984: 0.9825621843338013\n",
      "Seen so far: 63040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 985: 1.1321555376052856\n",
      "Seen so far: 63104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 986: 0.8932128548622131\n",
      "Seen so far: 63168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 987: 1.046223521232605\n",
      "Seen so far: 63232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 988: 0.8780229091644287\n",
      "Seen so far: 63296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 989: 0.9711889028549194\n",
      "Seen so far: 63360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 990: 0.9350309371948242\n",
      "Seen so far: 63424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 991: 0.8755133152008057\n",
      "Seen so far: 63488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 992: 0.4681912958621979\n",
      "Seen so far: 63552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 993: 0.7309926748275757\n",
      "Seen so far: 63616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 994: 1.058253288269043\n",
      "Seen so far: 63680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 995: 0.8289806246757507\n",
      "Seen so far: 63744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 996: 1.2721303701400757\n",
      "Seen so far: 63808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 997: 0.5436941981315613\n",
      "Seen so far: 63872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 998: 0.9273393154144287\n",
      "Seen so far: 63936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 999: 0.7731436491012573\n",
      "Seen so far: 64000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1000: 0.8775730133056641\n",
      "Seen so far: 64064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1001: 0.841066837310791\n",
      "Seen so far: 64128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1002: 0.7885405421257019\n",
      "Seen so far: 64192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1003: 0.8539824485778809\n",
      "Seen so far: 64256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1004: 0.7422770261764526\n",
      "Seen so far: 64320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1005: 0.6718965768814087\n",
      "Seen so far: 64384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1006: 0.9385762214660645\n",
      "Seen so far: 64448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1007: 0.9061161279678345\n",
      "Seen so far: 64512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1008: 1.0112318992614746\n",
      "Seen so far: 64576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1009: 0.9563782215118408\n",
      "Seen so far: 64640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1010: 0.5928317308425903\n",
      "Seen so far: 64704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1011: 0.8082405924797058\n",
      "Seen so far: 64768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1012: 0.9850362539291382\n",
      "Seen so far: 64832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1013: 0.952595591545105\n",
      "Seen so far: 64896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1014: 1.0239306688308716\n",
      "Seen so far: 64960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1015: 0.44600582122802734\n",
      "Seen so far: 65024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1016: 0.9885861873626709\n",
      "Seen so far: 65088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1017: 1.1727612018585205\n",
      "Seen so far: 65152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1018: 0.6357138156890869\n",
      "Seen so far: 65216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1019: 1.1970970630645752\n",
      "Seen so far: 65280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1020: 0.5489619970321655\n",
      "Seen so far: 65344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1021: 0.6124550104141235\n",
      "Seen so far: 65408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1022: 0.7065160274505615\n",
      "Seen so far: 65472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1023: 1.6971964836120605\n",
      "Seen so far: 65536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1024: 0.8220223188400269\n",
      "Seen so far: 65600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1025: 1.1276954412460327\n",
      "Seen so far: 65664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1026: 0.8346036076545715\n",
      "Seen so far: 65728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1027: 1.1503336429595947\n",
      "Seen so far: 65792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1028: 0.5590925216674805\n",
      "Seen so far: 65856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1029: 1.0931544303894043\n",
      "Seen so far: 65920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1030: 1.0656083822250366\n",
      "Seen so far: 65984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1031: 0.6682584285736084\n",
      "Seen so far: 66048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1032: 0.8753825426101685\n",
      "Seen so far: 66112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1033: 1.3069469928741455\n",
      "Seen so far: 66176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1034: 1.2314101457595825\n",
      "Seen so far: 66240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1035: 1.2146497964859009\n",
      "Seen so far: 66304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1036: 0.5788769721984863\n",
      "Seen so far: 66368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1037: 1.0414671897888184\n",
      "Seen so far: 66432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1038: 1.0970450639724731\n",
      "Seen so far: 66496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1039: 0.7065240144729614\n",
      "Seen so far: 66560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1040: 1.1452863216400146\n",
      "Seen so far: 66624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1041: 1.269554853439331\n",
      "Seen so far: 66688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1042: 0.7247710227966309\n",
      "Seen so far: 66752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1043: 1.2302367687225342\n",
      "Seen so far: 66816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1044: 0.6044291257858276\n",
      "Seen so far: 66880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1045: 1.0291084051132202\n",
      "Seen so far: 66944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1046: 1.1060199737548828\n",
      "Seen so far: 67008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1047: 0.7556247115135193\n",
      "Seen so far: 67072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1048: 1.025683879852295\n",
      "Seen so far: 67136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1049: 0.6574161052703857\n",
      "Seen so far: 67200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1050: 1.416754961013794\n",
      "Seen so far: 67264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1051: 1.0927917957305908\n",
      "Seen so far: 67328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1052: 0.7313224673271179\n",
      "Seen so far: 67392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1053: 1.0562678575515747\n",
      "Seen so far: 67456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1054: 1.3667004108428955\n",
      "Seen so far: 67520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1055: 1.2036083936691284\n",
      "Seen so far: 67584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1056: 0.7228084802627563\n",
      "Seen so far: 67648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1057: 0.8026416301727295\n",
      "Seen so far: 67712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1058: 0.593508243560791\n",
      "Seen so far: 67776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1059: 0.6446877717971802\n",
      "Seen so far: 67840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1060: 0.8668346405029297\n",
      "Seen so far: 67904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1061: 0.9157270193099976\n",
      "Seen so far: 67968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1062: 1.2414836883544922\n",
      "Seen so far: 68032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1063: 0.48263150453567505\n",
      "Seen so far: 68096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1064: 1.1421589851379395\n",
      "Seen so far: 68160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1065: 0.8124557733535767\n",
      "Seen so far: 68224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1066: 0.9963188171386719\n",
      "Seen so far: 68288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1067: 0.745010495185852\n",
      "Seen so far: 68352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1068: 0.6860050559043884\n",
      "Seen so far: 68416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1069: 0.7954826354980469\n",
      "Seen so far: 68480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1070: 0.5895651578903198\n",
      "Seen so far: 68544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1071: 0.8167599439620972\n",
      "Seen so far: 68608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1072: 0.8093298077583313\n",
      "Seen so far: 68672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1073: 0.9987907409667969\n",
      "Seen so far: 68736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1074: 0.6422823667526245\n",
      "Seen so far: 68800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1075: 0.9555850028991699\n",
      "Seen so far: 68864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1076: 0.611976146697998\n",
      "Seen so far: 68928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1077: 1.1202658414840698\n",
      "Seen so far: 68992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1078: 1.2809033393859863\n",
      "Seen so far: 69056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1079: 1.0017497539520264\n",
      "Seen so far: 69120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1080: 0.877281904220581\n",
      "Seen so far: 69184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1081: 0.9520331621170044\n",
      "Seen so far: 69248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1082: 1.002938985824585\n",
      "Seen so far: 69312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1083: 0.9815516471862793\n",
      "Seen so far: 69376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1084: 1.0442664623260498\n",
      "Seen so far: 69440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1085: 0.839453935623169\n",
      "Seen so far: 69504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1086: 1.0320491790771484\n",
      "Seen so far: 69568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1087: 1.1867010593414307\n",
      "Seen so far: 69632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1088: 1.1029025316238403\n",
      "Seen so far: 69696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1089: 0.7820188999176025\n",
      "Seen so far: 69760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1090: 0.7232377529144287\n",
      "Seen so far: 69824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1091: 0.9965639710426331\n",
      "Seen so far: 69888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1092: 1.099537968635559\n",
      "Seen so far: 69952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1093: 0.594784140586853\n",
      "Seen so far: 70016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1094: 1.043715476989746\n",
      "Seen so far: 70080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1095: 0.8290457725524902\n",
      "Seen so far: 70144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1096: 0.6484698057174683\n",
      "Seen so far: 70208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1097: 0.8724303245544434\n",
      "Seen so far: 70272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1098: 1.4145753383636475\n",
      "Seen so far: 70336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1099: 0.8892332911491394\n",
      "Seen so far: 70400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1100: 1.4872854948043823\n",
      "Seen so far: 70464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1101: 1.252833604812622\n",
      "Seen so far: 70528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1102: 0.8898016214370728\n",
      "Seen so far: 70592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1103: 1.0080986022949219\n",
      "Seen so far: 70656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1104: 0.652957022190094\n",
      "Seen so far: 70720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1105: 1.2015563249588013\n",
      "Seen so far: 70784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1106: 0.9466423988342285\n",
      "Seen so far: 70848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1107: 0.7563232183456421\n",
      "Seen so far: 70912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1108: 0.9172502756118774\n",
      "Seen so far: 70976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1109: 0.811939537525177\n",
      "Seen so far: 71040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1110: 0.8322634696960449\n",
      "Seen so far: 71104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1111: 0.9233786463737488\n",
      "Seen so far: 71168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1112: 1.2119449377059937\n",
      "Seen so far: 71232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1113: 1.3093944787979126\n",
      "Seen so far: 71296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1114: 0.7583032846450806\n",
      "Seen so far: 71360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1115: 1.2455207109451294\n",
      "Seen so far: 71424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1116: 0.9367477297782898\n",
      "Seen so far: 71488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1117: 0.8547546863555908\n",
      "Seen so far: 71552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1118: 0.6064449548721313\n",
      "Seen so far: 71616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1119: 1.0795572996139526\n",
      "Seen so far: 71680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1120: 0.7627882361412048\n",
      "Seen so far: 71744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1121: 1.1102447509765625\n",
      "Seen so far: 71808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1122: 0.6515092253684998\n",
      "Seen so far: 71872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1123: 0.6854028701782227\n",
      "Seen so far: 71936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1124: 0.9874710440635681\n",
      "Seen so far: 72000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1125: 1.4181618690490723\n",
      "Seen so far: 72064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1126: 0.8859167098999023\n",
      "Seen so far: 72128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1127: 0.8560668230056763\n",
      "Seen so far: 72192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1128: 1.5531268119812012\n",
      "Seen so far: 72256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1129: 0.763176679611206\n",
      "Seen so far: 72320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1130: 0.7843176126480103\n",
      "Seen so far: 72384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1131: 1.1042803525924683\n",
      "Seen so far: 72448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1132: 0.816698431968689\n",
      "Seen so far: 72512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1133: 0.9898889064788818\n",
      "Seen so far: 72576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1134: 1.07196044921875\n",
      "Seen so far: 72640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1135: 1.1203901767730713\n",
      "Seen so far: 72704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1136: 0.956214189529419\n",
      "Seen so far: 72768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1137: 1.2610039710998535\n",
      "Seen so far: 72832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1138: 0.8314357995986938\n",
      "Seen so far: 72896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1139: 0.8202593326568604\n",
      "Seen so far: 72960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1140: 0.9006475806236267\n",
      "Seen so far: 73024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1141: 0.6513839960098267\n",
      "Seen so far: 73088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1142: 1.0673168897628784\n",
      "Seen so far: 73152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1143: 0.8054451942443848\n",
      "Seen so far: 73216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1144: 1.1167675256729126\n",
      "Seen so far: 73280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1145: 1.312709093093872\n",
      "Seen so far: 73344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1146: 1.1791727542877197\n",
      "Seen so far: 73408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1147: 1.1216521263122559\n",
      "Seen so far: 73472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1148: 1.413967490196228\n",
      "Seen so far: 73536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1149: 0.8399927616119385\n",
      "Seen so far: 73600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1150: 0.9528398513793945\n",
      "Seen so far: 73664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1151: 0.745395302772522\n",
      "Seen so far: 73728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1152: 0.7950681447982788\n",
      "Seen so far: 73792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1153: 0.7975519895553589\n",
      "Seen so far: 73856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1154: 0.6743156909942627\n",
      "Seen so far: 73920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1155: 1.0885992050170898\n",
      "Seen so far: 73984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1156: 0.8293874859809875\n",
      "Seen so far: 74048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1157: 0.9395931363105774\n",
      "Seen so far: 74112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1158: 0.9114918112754822\n",
      "Seen so far: 74176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1159: 0.9469267725944519\n",
      "Seen so far: 74240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1160: 1.0559053421020508\n",
      "Seen so far: 74304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1161: 0.8542911410331726\n",
      "Seen so far: 74368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1162: 0.5943587422370911\n",
      "Seen so far: 74432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1163: 0.8265212774276733\n",
      "Seen so far: 74496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1164: 1.0452141761779785\n",
      "Seen so far: 74560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1165: 0.9035770297050476\n",
      "Seen so far: 74624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1166: 1.1964689493179321\n",
      "Seen so far: 74688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1167: 0.7775245904922485\n",
      "Seen so far: 74752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1168: 0.47903457283973694\n",
      "Seen so far: 74816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1169: 0.8955300450325012\n",
      "Seen so far: 74880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1170: 1.1008875370025635\n",
      "Seen so far: 74944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1171: 0.8090319633483887\n",
      "Seen so far: 75008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1172: 1.477384090423584\n",
      "Seen so far: 75072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1173: 0.8296695351600647\n",
      "Seen so far: 75136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1174: 0.8807129859924316\n",
      "Seen so far: 75200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1175: 1.327678918838501\n",
      "Seen so far: 75264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1176: 1.057112216949463\n",
      "Seen so far: 75328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1177: 0.8233052492141724\n",
      "Seen so far: 75392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1178: 1.4466147422790527\n",
      "Seen so far: 75456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1179: 0.43198949098587036\n",
      "Seen so far: 75520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1180: 0.8863840103149414\n",
      "Seen so far: 75584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1181: 1.0032764673233032\n",
      "Seen so far: 75648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1182: 1.310323715209961\n",
      "Seen so far: 75712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1183: 0.9340697526931763\n",
      "Seen so far: 75776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1184: 0.7849816083908081\n",
      "Seen so far: 75840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1185: 0.8295817375183105\n",
      "Seen so far: 75904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1186: 0.7627063393592834\n",
      "Seen so far: 75968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1187: 0.9928088188171387\n",
      "Seen so far: 76032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1188: 0.9027062654495239\n",
      "Seen so far: 76096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1189: 0.6642875671386719\n",
      "Seen so far: 76160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1190: 0.7156451344490051\n",
      "Seen so far: 76224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1191: 0.6284341216087341\n",
      "Seen so far: 76288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1192: 1.3794045448303223\n",
      "Seen so far: 76352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1193: 0.8449716567993164\n",
      "Seen so far: 76416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1194: 1.6151223182678223\n",
      "Seen so far: 76480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1195: 0.6670483350753784\n",
      "Seen so far: 76544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1196: 0.7639718651771545\n",
      "Seen so far: 76608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1197: 1.3376870155334473\n",
      "Seen so far: 76672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1198: 1.2713261842727661\n",
      "Seen so far: 76736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1199: 1.2606360912322998\n",
      "Seen so far: 76800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1200: 0.9542869329452515\n",
      "Seen so far: 76864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1201: 0.9481385350227356\n",
      "Seen so far: 76928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1202: 1.0055837631225586\n",
      "Seen so far: 76992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1203: 0.6982141137123108\n",
      "Seen so far: 77056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1204: 1.0808426141738892\n",
      "Seen so far: 77120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1205: 0.702828049659729\n",
      "Seen so far: 77184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1206: 0.8333477973937988\n",
      "Seen so far: 77248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1207: 0.9967233538627625\n",
      "Seen so far: 77312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1208: 1.2689645290374756\n",
      "Seen so far: 77376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1209: 1.110087513923645\n",
      "Seen so far: 77440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1210: 0.9157657623291016\n",
      "Seen so far: 77504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1211: 0.9075081944465637\n",
      "Seen so far: 77568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1212: 0.7720264792442322\n",
      "Seen so far: 77632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1213: 0.7944555282592773\n",
      "Seen so far: 77696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1214: 1.603322148323059\n",
      "Seen so far: 77760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1215: 0.42152854800224304\n",
      "Seen so far: 77824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1216: 0.8349100351333618\n",
      "Seen so far: 77888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1217: 1.0349607467651367\n",
      "Seen so far: 77952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1218: 1.0114977359771729\n",
      "Seen so far: 78016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1219: 1.380613923072815\n",
      "Seen so far: 78080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1220: 0.7607116103172302\n",
      "Seen so far: 78144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1221: 0.8694744110107422\n",
      "Seen so far: 78208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1222: 0.9431019425392151\n",
      "Seen so far: 78272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1223: 0.7865315675735474\n",
      "Seen so far: 78336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1224: 0.5824328660964966\n",
      "Seen so far: 78400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1225: 0.9598678350448608\n",
      "Seen so far: 78464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1226: 0.8426786661148071\n",
      "Seen so far: 78528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1227: 0.8317694664001465\n",
      "Seen so far: 78592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1228: 0.8299647569656372\n",
      "Seen so far: 78656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1229: 0.933163046836853\n",
      "Seen so far: 78720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1230: 1.0433447360992432\n",
      "Seen so far: 78784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1231: 0.826963484287262\n",
      "Seen so far: 78848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1232: 1.0712854862213135\n",
      "Seen so far: 78912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1233: 0.9016947150230408\n",
      "Seen so far: 78976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1234: 1.129955768585205\n",
      "Seen so far: 79040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1235: 0.78858882188797\n",
      "Seen so far: 79104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1236: 0.9325554966926575\n",
      "Seen so far: 79168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1237: 0.9243286848068237\n",
      "Seen so far: 79232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1238: 1.090275764465332\n",
      "Seen so far: 79296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1239: 0.9450505971908569\n",
      "Seen so far: 79360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1240: 1.1332063674926758\n",
      "Seen so far: 79424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1241: 1.020831823348999\n",
      "Seen so far: 79488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1242: 0.7769569754600525\n",
      "Seen so far: 79552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1243: 1.0698215961456299\n",
      "Seen so far: 79616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1244: 0.8659560680389404\n",
      "Seen so far: 79680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1245: 1.0724058151245117\n",
      "Seen so far: 79744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1246: 0.8316752910614014\n",
      "Seen so far: 79808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1247: 0.7196817994117737\n",
      "Seen so far: 79872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1248: 0.742392897605896\n",
      "Seen so far: 79936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1249: 1.0989571809768677\n",
      "Seen so far: 80000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1250: 0.8224857449531555\n",
      "Seen so far: 80064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1251: 0.4748184382915497\n",
      "Seen so far: 80128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1252: 0.9901015758514404\n",
      "Seen so far: 80192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1253: 0.7426016330718994\n",
      "Seen so far: 80256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1254: 0.8287525773048401\n",
      "Seen so far: 80320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1255: 0.6975448131561279\n",
      "Seen so far: 80384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1256: 1.0605685710906982\n",
      "Seen so far: 80448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1257: 1.0612430572509766\n",
      "Seen so far: 80512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1258: 0.70018470287323\n",
      "Seen so far: 80576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1259: 0.5937149524688721\n",
      "Seen so far: 80640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1260: 0.7081577777862549\n",
      "Seen so far: 80704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1261: 0.5942540168762207\n",
      "Seen so far: 80768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1262: 0.8138190507888794\n",
      "Seen so far: 80832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1263: 0.6233482360839844\n",
      "Seen so far: 80896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1264: 0.9970387816429138\n",
      "Seen so far: 80960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1265: 0.8829188942909241\n",
      "Seen so far: 81024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1266: 0.6761593818664551\n",
      "Seen so far: 81088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1267: 0.7724514007568359\n",
      "Seen so far: 81152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1268: 0.744367241859436\n",
      "Seen so far: 81216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1269: 1.0575027465820312\n",
      "Seen so far: 81280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1270: 1.261348009109497\n",
      "Seen so far: 81344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1271: 0.6844145059585571\n",
      "Seen so far: 81408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1272: 1.1236004829406738\n",
      "Seen so far: 81472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1273: 0.9165530204772949\n",
      "Seen so far: 81536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1274: 0.6409152746200562\n",
      "Seen so far: 81600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1275: 0.7636723518371582\n",
      "Seen so far: 81664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1276: 0.6716000437736511\n",
      "Seen so far: 81728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1277: 0.8996372818946838\n",
      "Seen so far: 81792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1278: 1.1045751571655273\n",
      "Seen so far: 81856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1279: 1.0001776218414307\n",
      "Seen so far: 81920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1280: 1.0718231201171875\n",
      "Seen so far: 81984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1281: 0.768830418586731\n",
      "Seen so far: 82048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1282: 0.7788439393043518\n",
      "Seen so far: 82112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1283: 0.7547290325164795\n",
      "Seen so far: 82176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1284: 1.387452483177185\n",
      "Seen so far: 82240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1285: 0.9733307957649231\n",
      "Seen so far: 82304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1286: 0.7731637358665466\n",
      "Seen so far: 82368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1287: 0.9153781533241272\n",
      "Seen so far: 82432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1288: 0.6642485857009888\n",
      "Seen so far: 82496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1289: 1.0935741662979126\n",
      "Seen so far: 82560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1290: 0.5448745489120483\n",
      "Seen so far: 82624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1291: 1.1977715492248535\n",
      "Seen so far: 82688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1292: 0.3772205114364624\n",
      "Seen so far: 82752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1293: 0.8838935494422913\n",
      "Seen so far: 82816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1294: 1.045595407485962\n",
      "Seen so far: 82880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1295: 0.8268411755561829\n",
      "Seen so far: 82944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1296: 0.5785167217254639\n",
      "Seen so far: 83008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1297: 0.9237706661224365\n",
      "Seen so far: 83072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1298: 0.5762380361557007\n",
      "Seen so far: 83136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1299: 0.731361985206604\n",
      "Seen so far: 83200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1300: 1.1299259662628174\n",
      "Seen so far: 83264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1301: 0.8410936594009399\n",
      "Seen so far: 83328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1302: 1.0549423694610596\n",
      "Seen so far: 83392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1303: 1.0635935068130493\n",
      "Seen so far: 83456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1304: 0.5240430235862732\n",
      "Seen so far: 83520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1305: 0.6871729493141174\n",
      "Seen so far: 83584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1306: 0.9588907957077026\n",
      "Seen so far: 83648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1307: 0.8377506732940674\n",
      "Seen so far: 83712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1308: 0.9195518493652344\n",
      "Seen so far: 83776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1309: 0.8535815477371216\n",
      "Seen so far: 83840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1310: 0.7586334943771362\n",
      "Seen so far: 83904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1311: 0.8656624555587769\n",
      "Seen so far: 83968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1312: 0.752731204032898\n",
      "Seen so far: 84032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1313: 0.8574596643447876\n",
      "Seen so far: 84096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1314: 0.7977160811424255\n",
      "Seen so far: 84160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1315: 1.0168370008468628\n",
      "Seen so far: 84224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1316: 0.915654182434082\n",
      "Seen so far: 84288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1317: 1.2881603240966797\n",
      "Seen so far: 84352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1318: 0.8899824619293213\n",
      "Seen so far: 84416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1319: 1.0929462909698486\n",
      "Seen so far: 84480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1320: 0.9333409070968628\n",
      "Seen so far: 84544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1321: 1.430564522743225\n",
      "Seen so far: 84608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1322: 0.975605309009552\n",
      "Seen so far: 84672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1323: 0.7332888841629028\n",
      "Seen so far: 84736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1324: 0.8136694431304932\n",
      "Seen so far: 84800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1325: 0.9284172654151917\n",
      "Seen so far: 84864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1326: 0.9005331993103027\n",
      "Seen so far: 84928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1327: 0.7388191223144531\n",
      "Seen so far: 84992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1328: 1.1846516132354736\n",
      "Seen so far: 85056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1329: 0.8468753695487976\n",
      "Seen so far: 85120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1330: 0.7763299345970154\n",
      "Seen so far: 85184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1331: 1.1391141414642334\n",
      "Seen so far: 85248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1332: 1.051220417022705\n",
      "Seen so far: 85312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1333: 1.0724225044250488\n",
      "Seen so far: 85376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1334: 1.045111894607544\n",
      "Seen so far: 85440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1335: 0.8642017841339111\n",
      "Seen so far: 85504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1336: 0.8016613721847534\n",
      "Seen so far: 85568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1337: 0.9448726177215576\n",
      "Seen so far: 85632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1338: 1.1802217960357666\n",
      "Seen so far: 85696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1339: 0.919145941734314\n",
      "Seen so far: 85760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1340: 1.6677833795547485\n",
      "Seen so far: 85824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1341: 1.0820152759552002\n",
      "Seen so far: 85888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1342: 0.6925854682922363\n",
      "Seen so far: 85952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1343: 1.0268545150756836\n",
      "Seen so far: 86016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1344: 1.1583352088928223\n",
      "Seen so far: 86080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1345: 0.8590558171272278\n",
      "Seen so far: 86144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1346: 1.1774272918701172\n",
      "Seen so far: 86208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1347: 0.7046312093734741\n",
      "Seen so far: 86272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1348: 1.200574517250061\n",
      "Seen so far: 86336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1349: 1.3181750774383545\n",
      "Seen so far: 86400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1350: 1.1016812324523926\n",
      "Seen so far: 86464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1351: 0.7195338606834412\n",
      "Seen so far: 86528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1352: 1.304237961769104\n",
      "Seen so far: 86592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1353: 0.7581676244735718\n",
      "Seen so far: 86656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1354: 1.6351704597473145\n",
      "Seen so far: 86720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1355: 0.8147245645523071\n",
      "Seen so far: 86784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1356: 0.7026668190956116\n",
      "Seen so far: 86848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1357: 1.0248202085494995\n",
      "Seen so far: 86912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1358: 0.8150123953819275\n",
      "Seen so far: 86976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1359: 0.9331979751586914\n",
      "Seen so far: 87040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1360: 0.9642614126205444\n",
      "Seen so far: 87104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1361: 0.6930830478668213\n",
      "Seen so far: 87168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1362: 0.8407993316650391\n",
      "Seen so far: 87232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1363: 0.859502911567688\n",
      "Seen so far: 87296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1364: 0.9110943675041199\n",
      "Seen so far: 87360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1365: 0.7664384841918945\n",
      "Seen so far: 87424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1366: 1.0087788105010986\n",
      "Seen so far: 87488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1367: 1.2021371126174927\n",
      "Seen so far: 87552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1368: 1.0046159029006958\n",
      "Seen so far: 87616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1369: 0.5846861600875854\n",
      "Seen so far: 87680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1370: 0.7525392770767212\n",
      "Seen so far: 87744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1371: 0.9295789003372192\n",
      "Seen so far: 87808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1372: 1.1339552402496338\n",
      "Seen so far: 87872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1373: 0.8120005130767822\n",
      "Seen so far: 87936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1374: 0.9285615682601929\n",
      "Seen so far: 88000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1375: 1.106777548789978\n",
      "Seen so far: 88064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1376: 1.1122114658355713\n",
      "Seen so far: 88128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1377: 0.8768616914749146\n",
      "Seen so far: 88192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1378: 1.1791629791259766\n",
      "Seen so far: 88256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1379: 1.0077075958251953\n",
      "Seen so far: 88320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1380: 1.0971920490264893\n",
      "Seen so far: 88384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1381: 0.778266966342926\n",
      "Seen so far: 88448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1382: 0.8674294948577881\n",
      "Seen so far: 88512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1383: 1.0843758583068848\n",
      "Seen so far: 88576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1384: 0.6167564988136292\n",
      "Seen so far: 88640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1385: 0.7056647539138794\n",
      "Seen so far: 88704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1386: 0.9736646413803101\n",
      "Seen so far: 88768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1387: 0.8973010778427124\n",
      "Seen so far: 88832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1388: 1.0239177942276\n",
      "Seen so far: 88896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1389: 0.613655686378479\n",
      "Seen so far: 88960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1390: 0.6831822395324707\n",
      "Seen so far: 89024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1391: 1.1545746326446533\n",
      "Seen so far: 89088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1392: 1.112640142440796\n",
      "Seen so far: 89152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1393: 1.3776178359985352\n",
      "Seen so far: 89216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1394: 0.8549965023994446\n",
      "Seen so far: 89280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1395: 0.9737616777420044\n",
      "Seen so far: 89344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1396: 0.9920344352722168\n",
      "Seen so far: 89408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1397: 0.873658299446106\n",
      "Seen so far: 89472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1398: 0.7628941535949707\n",
      "Seen so far: 89536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1399: 1.0793120861053467\n",
      "Seen so far: 89600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1400: 1.1690367460250854\n",
      "Seen so far: 89664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1401: 0.7208709716796875\n",
      "Seen so far: 89728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1402: 0.972436785697937\n",
      "Seen so far: 89792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1403: 1.1161835193634033\n",
      "Seen so far: 89856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1404: 0.7927310466766357\n",
      "Seen so far: 89920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1405: 0.6875251531600952\n",
      "Seen so far: 89984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1406: 1.272322177886963\n",
      "Seen so far: 90048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1407: 0.7945542931556702\n",
      "Seen so far: 90112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1408: 0.6961742639541626\n",
      "Seen so far: 90176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1409: 0.7941066026687622\n",
      "Seen so far: 90240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1410: 0.8549256324768066\n",
      "Seen so far: 90304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1411: 0.7920448780059814\n",
      "Seen so far: 90368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1412: 1.0345531702041626\n",
      "Seen so far: 90432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1413: 0.938456654548645\n",
      "Seen so far: 90496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1414: 0.7965022325515747\n",
      "Seen so far: 90560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1415: 0.9502531886100769\n",
      "Seen so far: 90624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1416: 0.7964450716972351\n",
      "Seen so far: 90688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1417: 1.113555669784546\n",
      "Seen so far: 90752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1418: 0.8020132780075073\n",
      "Seen so far: 90816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1419: 0.8725523352622986\n",
      "Seen so far: 90880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1420: 0.6788100600242615\n",
      "Seen so far: 90944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1421: 0.5454494953155518\n",
      "Seen so far: 91008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1422: 0.9817767143249512\n",
      "Seen so far: 91072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1423: 0.8411071300506592\n",
      "Seen so far: 91136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1424: 0.6834920644760132\n",
      "Seen so far: 91200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1425: 0.7023085355758667\n",
      "Seen so far: 91264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1426: 0.7411755323410034\n",
      "Seen so far: 91328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1427: 0.9482946991920471\n",
      "Seen so far: 91392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1428: 1.1196002960205078\n",
      "Seen so far: 91456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1429: 0.8116747140884399\n",
      "Seen so far: 91520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1430: 0.749006986618042\n",
      "Seen so far: 91584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1431: 1.058324933052063\n",
      "Seen so far: 91648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1432: 0.4785272777080536\n",
      "Seen so far: 91712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1433: 0.924232006072998\n",
      "Seen so far: 91776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1434: 0.5755499601364136\n",
      "Seen so far: 91840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1435: 0.8651542067527771\n",
      "Seen so far: 91904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1436: 0.7068630456924438\n",
      "Seen so far: 91968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1437: 0.7332262992858887\n",
      "Seen so far: 92032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1438: 1.3261773586273193\n",
      "Seen so far: 92096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1439: 1.1100316047668457\n",
      "Seen so far: 92160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1440: 1.004541039466858\n",
      "Seen so far: 92224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1441: 0.6676543951034546\n",
      "Seen so far: 92288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1442: 1.0916279554367065\n",
      "Seen so far: 92352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1443: 1.140529751777649\n",
      "Seen so far: 92416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1444: 1.3147691488265991\n",
      "Seen so far: 92480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1445: 0.9739670753479004\n",
      "Seen so far: 92544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1446: 0.8503224849700928\n",
      "Seen so far: 92608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1447: 0.5383568406105042\n",
      "Seen so far: 92672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1448: 0.7003470659255981\n",
      "Seen so far: 92736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1449: 1.2086460590362549\n",
      "Seen so far: 92800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1450: 0.6290073394775391\n",
      "Seen so far: 92864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1451: 1.2005842924118042\n",
      "Seen so far: 92928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1452: 0.5401041507720947\n",
      "Seen so far: 92992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1453: 1.054038166999817\n",
      "Seen so far: 93056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1454: 0.7991738319396973\n",
      "Seen so far: 93120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1455: 1.2074811458587646\n",
      "Seen so far: 93184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1456: 0.8055030107498169\n",
      "Seen so far: 93248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1457: 1.0800845623016357\n",
      "Seen so far: 93312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1458: 0.8955150842666626\n",
      "Seen so far: 93376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1459: 0.9945895671844482\n",
      "Seen so far: 93440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1460: 1.0217926502227783\n",
      "Seen so far: 93504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1461: 0.7619856595993042\n",
      "Seen so far: 93568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1462: 0.8877481818199158\n",
      "Seen so far: 93632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1463: 1.208235502243042\n",
      "Seen so far: 93696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1464: 0.5323581099510193\n",
      "Seen so far: 93760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1465: 1.0901336669921875\n",
      "Seen so far: 93824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1466: 0.8257553577423096\n",
      "Seen so far: 93888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1467: 0.8685499429702759\n",
      "Seen so far: 93952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1468: 0.9892696738243103\n",
      "Seen so far: 94016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1469: 0.7961126565933228\n",
      "Seen so far: 94080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1470: 1.1139777898788452\n",
      "Seen so far: 94144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1471: 0.5114489197731018\n",
      "Seen so far: 94208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1472: 1.044144868850708\n",
      "Seen so far: 94272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1473: 0.9220342636108398\n",
      "Seen so far: 94336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1474: 0.6005040407180786\n",
      "Seen so far: 94400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1475: 1.3913636207580566\n",
      "Seen so far: 94464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1476: 0.4804234206676483\n",
      "Seen so far: 94528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1477: 0.7396791577339172\n",
      "Seen so far: 94592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1478: 1.3604741096496582\n",
      "Seen so far: 94656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1479: 1.0313870906829834\n",
      "Seen so far: 94720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1480: 0.6234309673309326\n",
      "Seen so far: 94784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1481: 1.0342087745666504\n",
      "Seen so far: 94848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1482: 0.5810935497283936\n",
      "Seen so far: 94912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1483: 1.0644553899765015\n",
      "Seen so far: 94976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1484: 0.6805521845817566\n",
      "Seen so far: 95040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1485: 0.7119781374931335\n",
      "Seen so far: 95104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1486: 0.6655904650688171\n",
      "Seen so far: 95168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1487: 0.6453040242195129\n",
      "Seen so far: 95232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1488: 0.9731554985046387\n",
      "Seen so far: 95296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1489: 0.9057235717773438\n",
      "Seen so far: 95360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1490: 0.8392143249511719\n",
      "Seen so far: 95424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1491: 0.5547447204589844\n",
      "Seen so far: 95488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1492: 0.872299075126648\n",
      "Seen so far: 95552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1493: 0.7978781461715698\n",
      "Seen so far: 95616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1494: 0.930100679397583\n",
      "Seen so far: 95680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1495: 1.3490498065948486\n",
      "Seen so far: 95744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1496: 0.69393390417099\n",
      "Seen so far: 95808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1497: 1.183754563331604\n",
      "Seen so far: 95872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1498: 0.7181100845336914\n",
      "Seen so far: 95936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1499: 1.1245152950286865\n",
      "Seen so far: 96000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1500: 0.7805342078208923\n",
      "Seen so far: 96064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1501: 1.1911005973815918\n",
      "Seen so far: 96128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1502: 0.790759265422821\n",
      "Seen so far: 96192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1503: 0.5992645025253296\n",
      "Seen so far: 96256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1504: 0.8294858336448669\n",
      "Seen so far: 96320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1505: 1.1222496032714844\n",
      "Seen so far: 96384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1506: 0.6600679159164429\n",
      "Seen so far: 96448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1507: 1.6188210248947144\n",
      "Seen so far: 96512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1508: 0.6478783488273621\n",
      "Seen so far: 96576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1509: 0.8708742260932922\n",
      "Seen so far: 96640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1510: 1.574315071105957\n",
      "Seen so far: 96704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1511: 0.8821693062782288\n",
      "Seen so far: 96768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1512: 0.8458579778671265\n",
      "Seen so far: 96832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1513: 0.9778995513916016\n",
      "Seen so far: 96896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1514: 0.7549257278442383\n",
      "Seen so far: 96960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1515: 1.4387714862823486\n",
      "Seen so far: 97024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1516: 0.8737568855285645\n",
      "Seen so far: 97088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1517: 1.4523173570632935\n",
      "Seen so far: 97152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1518: 1.0192546844482422\n",
      "Seen so far: 97216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1519: 0.5322012901306152\n",
      "Seen so far: 97280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1520: 0.8864481449127197\n",
      "Seen so far: 97344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1521: 0.8767238855361938\n",
      "Seen so far: 97408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1522: 1.0688271522521973\n",
      "Seen so far: 97472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1523: 1.3111770153045654\n",
      "Seen so far: 97536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1524: 1.0859410762786865\n",
      "Seen so far: 97600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1525: 1.1181538105010986\n",
      "Seen so far: 97664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1526: 1.183842420578003\n",
      "Seen so far: 97728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1527: 0.8547368049621582\n",
      "Seen so far: 97792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1528: 0.5823771953582764\n",
      "Seen so far: 97856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1529: 0.7537167072296143\n",
      "Seen so far: 97920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1530: 0.9207309484481812\n",
      "Seen so far: 97984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1531: 0.4905935525894165\n",
      "Seen so far: 98048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1532: 0.9717164635658264\n",
      "Seen so far: 98112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1533: 0.6650466918945312\n",
      "Seen so far: 98176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1534: 0.9712655544281006\n",
      "Seen so far: 98240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1535: 0.6665910482406616\n",
      "Seen so far: 98304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1536: 0.841139018535614\n",
      "Seen so far: 98368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1537: 0.8748297095298767\n",
      "Seen so far: 98432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1538: 1.0776311159133911\n",
      "Seen so far: 98496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1539: 0.7082487344741821\n",
      "Seen so far: 98560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1540: 0.7264624834060669\n",
      "Seen so far: 98624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1541: 0.5829638242721558\n",
      "Seen so far: 98688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1542: 0.9198849201202393\n",
      "Seen so far: 98752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1543: 1.0830559730529785\n",
      "Seen so far: 98816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1544: 0.6315980553627014\n",
      "Seen so far: 98880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1545: 0.5467836856842041\n",
      "Seen so far: 98944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1546: 0.9690123796463013\n",
      "Seen so far: 99008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1547: 0.9582039713859558\n",
      "Seen so far: 99072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1548: 0.7095069289207458\n",
      "Seen so far: 99136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1549: 0.7993214130401611\n",
      "Seen so far: 99200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1550: 1.1316380500793457\n",
      "Seen so far: 99264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1551: 1.1652114391326904\n",
      "Seen so far: 99328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1552: 0.723345935344696\n",
      "Seen so far: 99392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1553: 0.5095616579055786\n",
      "Seen so far: 99456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1554: 1.3222134113311768\n",
      "Seen so far: 99520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1555: 0.9768056869506836\n",
      "Seen so far: 99584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1556: 1.1989860534667969\n",
      "Seen so far: 99648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1557: 1.1170392036437988\n",
      "Seen so far: 99712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1558: 0.7740297317504883\n",
      "Seen so far: 99776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1559: 0.576337993144989\n",
      "Seen so far: 99840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1560: 1.3700661659240723\n",
      "Seen so far: 99904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1561: 0.9798658490180969\n",
      "Seen so far: 99968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1562: 0.8867775201797485\n",
      "Seen so far: 100032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1563: 0.8624333143234253\n",
      "Seen so far: 100096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1564: 1.1552088260650635\n",
      "Seen so far: 100160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1565: 1.1179876327514648\n",
      "Seen so far: 100224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1566: 0.8803972005844116\n",
      "Seen so far: 100288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1567: 0.6236884593963623\n",
      "Seen so far: 100352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1568: 0.7496481537818909\n",
      "Seen so far: 100416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1569: 0.7808021306991577\n",
      "Seen so far: 100480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1570: 1.2991986274719238\n",
      "Seen so far: 100544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1571: 1.1432503461837769\n",
      "Seen so far: 100608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1572: 0.6268998384475708\n",
      "Seen so far: 100672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1573: 1.2603896856307983\n",
      "Seen so far: 100736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1574: 0.7727484703063965\n",
      "Seen so far: 100800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1575: 1.041624903678894\n",
      "Seen so far: 100864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1576: 0.8532165288925171\n",
      "Seen so far: 100928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1577: 0.6913490295410156\n",
      "Seen so far: 100992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1578: 1.0046699047088623\n",
      "Seen so far: 101056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1579: 0.7701102495193481\n",
      "Seen so far: 101120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1580: 1.0597385168075562\n",
      "Seen so far: 101184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1581: 0.8436582088470459\n",
      "Seen so far: 101248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1582: 1.089599370956421\n",
      "Seen so far: 101312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1583: 0.832477331161499\n",
      "Seen so far: 101376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1584: 1.0237525701522827\n",
      "Seen so far: 101440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1585: 1.321850299835205\n",
      "Seen so far: 101504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1586: 0.8340195417404175\n",
      "Seen so far: 101568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1587: 0.5457872152328491\n",
      "Seen so far: 101632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1588: 0.6769463419914246\n",
      "Seen so far: 101696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1589: 1.0200042724609375\n",
      "Seen so far: 101760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1590: 0.8188033699989319\n",
      "Seen so far: 101824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1591: 1.0090287923812866\n",
      "Seen so far: 101888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1592: 0.9103979468345642\n",
      "Seen so far: 101952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1593: 0.8113138675689697\n",
      "Seen so far: 102016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1594: 0.5761216878890991\n",
      "Seen so far: 102080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1595: 1.0927464962005615\n",
      "Seen so far: 102144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1596: 0.7983500957489014\n",
      "Seen so far: 102208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1597: 1.176086187362671\n",
      "Seen so far: 102272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1598: 0.8417787551879883\n",
      "Seen so far: 102336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1599: 0.9391341209411621\n",
      "Seen so far: 102400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1600: 0.4287160634994507\n",
      "Seen so far: 102464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1601: 0.9407766461372375\n",
      "Seen so far: 102528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1602: 0.5186526775360107\n",
      "Seen so far: 102592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1603: 1.3153964281082153\n",
      "Seen so far: 102656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1604: 0.7613312602043152\n",
      "Seen so far: 102720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1605: 1.5426005125045776\n",
      "Seen so far: 102784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1606: 1.1153547763824463\n",
      "Seen so far: 102848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1607: 0.951628565788269\n",
      "Seen so far: 102912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1608: 0.8956726789474487\n",
      "Seen so far: 102976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1609: 0.9736093282699585\n",
      "Seen so far: 103040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1610: 1.0468404293060303\n",
      "Seen so far: 103104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1611: 0.8071938157081604\n",
      "Seen so far: 103168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1612: 1.1775548458099365\n",
      "Seen so far: 103232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1613: 1.1316484212875366\n",
      "Seen so far: 103296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1614: 0.6672471165657043\n",
      "Seen so far: 103360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1615: 0.7986364364624023\n",
      "Seen so far: 103424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1616: 0.8722352981567383\n",
      "Seen so far: 103488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1617: 1.0764801502227783\n",
      "Seen so far: 103552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1618: 0.7685246467590332\n",
      "Seen so far: 103616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1619: 0.8296030759811401\n",
      "Seen so far: 103680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1620: 0.7222084999084473\n",
      "Seen so far: 103744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1621: 0.752461314201355\n",
      "Seen so far: 103808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1622: 0.9427484273910522\n",
      "Seen so far: 103872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1623: 1.0404161214828491\n",
      "Seen so far: 103936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1624: 0.8320251703262329\n",
      "Seen so far: 104000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1625: 1.3664546012878418\n",
      "Seen so far: 104064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1626: 0.9318532943725586\n",
      "Seen so far: 104128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1627: 0.9038833379745483\n",
      "Seen so far: 104192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1628: 0.8789523839950562\n",
      "Seen so far: 104256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1629: 0.6699850559234619\n",
      "Seen so far: 104320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1630: 1.0650348663330078\n",
      "Seen so far: 104384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1631: 0.7870938777923584\n",
      "Seen so far: 104448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1632: 1.1617603302001953\n",
      "Seen so far: 104512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1633: 0.9314303398132324\n",
      "Seen so far: 104576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1634: 1.153065800666809\n",
      "Seen so far: 104640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1635: 0.8928906917572021\n",
      "Seen so far: 104704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1636: 0.8649339079856873\n",
      "Seen so far: 104768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1637: 0.7054091691970825\n",
      "Seen so far: 104832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1638: 0.9639290571212769\n",
      "Seen so far: 104896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1639: 0.578652024269104\n",
      "Seen so far: 104960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1640: 1.122131586074829\n",
      "Seen so far: 105024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1641: 0.7186712026596069\n",
      "Seen so far: 105088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1642: 0.9376801252365112\n",
      "Seen so far: 105152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1643: 1.3351919651031494\n",
      "Seen so far: 105216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1644: 0.867698609828949\n",
      "Seen so far: 105280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1645: 1.1500520706176758\n",
      "Seen so far: 105344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1646: 0.8030071258544922\n",
      "Seen so far: 105408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1647: 0.651235818862915\n",
      "Seen so far: 105472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1648: 0.8316025733947754\n",
      "Seen so far: 105536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1649: 1.1270456314086914\n",
      "Seen so far: 105600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1650: 0.7247787117958069\n",
      "Seen so far: 105664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1651: 1.2187550067901611\n",
      "Seen so far: 105728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1652: 0.7991136312484741\n",
      "Seen so far: 105792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1653: 0.8222616910934448\n",
      "Seen so far: 105856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1654: 0.9679995775222778\n",
      "Seen so far: 105920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1655: 0.8714706897735596\n",
      "Seen so far: 105984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1656: 0.7316939234733582\n",
      "Seen so far: 106048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1657: 0.8724791407585144\n",
      "Seen so far: 106112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1658: 0.6819003820419312\n",
      "Seen so far: 106176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1659: 0.9484328031539917\n",
      "Seen so far: 106240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1660: 0.962455153465271\n",
      "Seen so far: 106304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1661: 0.8909798860549927\n",
      "Seen so far: 106368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1662: 0.557543158531189\n",
      "Seen so far: 106432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1663: 0.8480640649795532\n",
      "Seen so far: 106496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1664: 1.1264829635620117\n",
      "Seen so far: 106560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1665: 1.19136643409729\n",
      "Seen so far: 106624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1666: 0.8647123575210571\n",
      "Seen so far: 106688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1667: 0.6897529363632202\n",
      "Seen so far: 106752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1668: 1.1788969039916992\n",
      "Seen so far: 106816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1669: 0.6550507545471191\n",
      "Seen so far: 106880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1670: 0.7581768035888672\n",
      "Seen so far: 106944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1671: 0.8838266134262085\n",
      "Seen so far: 107008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1672: 1.1575061082839966\n",
      "Seen so far: 107072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1673: 0.5728287696838379\n",
      "Seen so far: 107136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1674: 0.763542890548706\n",
      "Seen so far: 107200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1675: 1.1486982107162476\n",
      "Seen so far: 107264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1676: 0.8011629581451416\n",
      "Seen so far: 107328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1677: 0.770405113697052\n",
      "Seen so far: 107392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1678: 0.712333619594574\n",
      "Seen so far: 107456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1679: 0.8067723512649536\n",
      "Seen so far: 107520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1680: 0.9735579490661621\n",
      "Seen so far: 107584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1681: 1.484346866607666\n",
      "Seen so far: 107648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1682: 0.7974674701690674\n",
      "Seen so far: 107712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1683: 1.081730842590332\n",
      "Seen so far: 107776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1684: 1.0662753582000732\n",
      "Seen so far: 107840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1685: 0.8274881839752197\n",
      "Seen so far: 107904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1686: 1.0423176288604736\n",
      "Seen so far: 107968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1687: 1.1156234741210938\n",
      "Seen so far: 108032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1688: 1.2494287490844727\n",
      "Seen so far: 108096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1689: 0.7670215368270874\n",
      "Seen so far: 108160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1690: 1.2489780187606812\n",
      "Seen so far: 108224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1691: 0.6107361316680908\n",
      "Seen so far: 108288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1692: 0.7628015279769897\n",
      "Seen so far: 108352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1693: 1.0857675075531006\n",
      "Seen so far: 108416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1694: 1.0246328115463257\n",
      "Seen so far: 108480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1695: 0.9757142663002014\n",
      "Seen so far: 108544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1696: 1.1750524044036865\n",
      "Seen so far: 108608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1697: 1.1425467729568481\n",
      "Seen so far: 108672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1698: 0.6267734169960022\n",
      "Seen so far: 108736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1699: 0.6034187078475952\n",
      "Seen so far: 108800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1700: 0.7797107100486755\n",
      "Seen so far: 108864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1701: 1.025940179824829\n",
      "Seen so far: 108928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1702: 1.1805915832519531\n",
      "Seen so far: 108992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1703: 0.6599705815315247\n",
      "Seen so far: 109056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1704: 1.153566598892212\n",
      "Seen so far: 109120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1705: 1.0283105373382568\n",
      "Seen so far: 109184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1706: 1.2223811149597168\n",
      "Seen so far: 109248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1707: 0.9190082550048828\n",
      "Seen so far: 109312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1708: 1.1339622735977173\n",
      "Seen so far: 109376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1709: 1.3979172706604004\n",
      "Seen so far: 109440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1710: 0.8078740835189819\n",
      "Seen so far: 109504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1711: 0.7455368041992188\n",
      "Seen so far: 109568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1712: 0.7476462721824646\n",
      "Seen so far: 109632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1713: 0.5124887228012085\n",
      "Seen so far: 109696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1714: 0.8768937587738037\n",
      "Seen so far: 109760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1715: 0.7665162682533264\n",
      "Seen so far: 109824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1716: 1.1982358694076538\n",
      "Seen so far: 109888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1717: 0.6178203821182251\n",
      "Seen so far: 109952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1718: 0.8572683930397034\n",
      "Seen so far: 110016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1719: 0.6165187358856201\n",
      "Seen so far: 110080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1720: 1.0295422077178955\n",
      "Seen so far: 110144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1721: 0.9743395447731018\n",
      "Seen so far: 110208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1722: 0.8067218065261841\n",
      "Seen so far: 110272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1723: 0.6489487886428833\n",
      "Seen so far: 110336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1724: 1.1060881614685059\n",
      "Seen so far: 110400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1725: 0.838353157043457\n",
      "Seen so far: 110464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1726: 1.481994390487671\n",
      "Seen so far: 110528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1727: 0.9330632090568542\n",
      "Seen so far: 110592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1728: 0.8392608761787415\n",
      "Seen so far: 110656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1729: 1.0256632566452026\n",
      "Seen so far: 110720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1730: 0.7380846738815308\n",
      "Seen so far: 110784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1731: 0.5835859775543213\n",
      "Seen so far: 110848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1732: 1.1167702674865723\n",
      "Seen so far: 110912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1733: 1.2775208950042725\n",
      "Seen so far: 110976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1734: 0.82051682472229\n",
      "Seen so far: 111040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1735: 0.8108818531036377\n",
      "Seen so far: 111104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1736: 0.9258548021316528\n",
      "Seen so far: 111168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1737: 1.1419122219085693\n",
      "Seen so far: 111232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1738: 0.81276535987854\n",
      "Seen so far: 111296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1739: 0.7990496158599854\n",
      "Seen so far: 111360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1740: 1.034989833831787\n",
      "Seen so far: 111424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1741: 0.8371080160140991\n",
      "Seen so far: 111488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1742: 0.9499962329864502\n",
      "Seen so far: 111552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1743: 0.44024765491485596\n",
      "Seen so far: 111616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1744: 0.8682151436805725\n",
      "Seen so far: 111680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1745: 1.064692497253418\n",
      "Seen so far: 111744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1746: 1.2176141738891602\n",
      "Seen so far: 111808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1747: 1.4249597787857056\n",
      "Seen so far: 111872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1748: 0.9326955080032349\n",
      "Seen so far: 111936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1749: 0.7407521605491638\n",
      "Seen so far: 112000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1750: 0.9703278541564941\n",
      "Seen so far: 112064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1751: 1.073600172996521\n",
      "Seen so far: 112128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1752: 1.1148834228515625\n",
      "Seen so far: 112192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1753: 1.1620304584503174\n",
      "Seen so far: 112256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1754: 1.3627896308898926\n",
      "Seen so far: 112320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1755: 0.7619288563728333\n",
      "Seen so far: 112384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1756: 1.2756439447402954\n",
      "Seen so far: 112448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1757: 0.7713706493377686\n",
      "Seen so far: 112512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1758: 1.281891942024231\n",
      "Seen so far: 112576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1759: 0.7201601266860962\n",
      "Seen so far: 112640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1760: 0.9111305475234985\n",
      "Seen so far: 112704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1761: 0.8541994094848633\n",
      "Seen so far: 112768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1762: 1.0661497116088867\n",
      "Seen so far: 112832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1763: 1.2130231857299805\n",
      "Seen so far: 112896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1764: 0.9750422835350037\n",
      "Seen so far: 112960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1765: 0.6280298233032227\n",
      "Seen so far: 113024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1766: 0.828540027141571\n",
      "Seen so far: 113088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1767: 1.090075969696045\n",
      "Seen so far: 113152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1768: 1.0951588153839111\n",
      "Seen so far: 113216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1769: 0.7475132942199707\n",
      "Seen so far: 113280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1770: 0.732540488243103\n",
      "Seen so far: 113344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1771: 0.873693585395813\n",
      "Seen so far: 113408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1772: 1.167805790901184\n",
      "Seen so far: 113472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1773: 0.9386220574378967\n",
      "Seen so far: 113536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1774: 0.595219612121582\n",
      "Seen so far: 113600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1775: 1.1127934455871582\n",
      "Seen so far: 113664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1776: 1.258264183998108\n",
      "Seen so far: 113728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1777: 0.9916371703147888\n",
      "Seen so far: 113792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1778: 0.8470363020896912\n",
      "Seen so far: 113856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1779: 1.473954677581787\n",
      "Seen so far: 113920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1780: 1.220284342765808\n",
      "Seen so far: 113984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1781: 1.1706068515777588\n",
      "Seen so far: 114048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1782: 0.5648940205574036\n",
      "Seen so far: 114112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1783: 1.116612195968628\n",
      "Seen so far: 114176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1784: 1.0372955799102783\n",
      "Seen so far: 114240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1785: 0.9974668622016907\n",
      "Seen so far: 114304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1786: 1.0679210424423218\n",
      "Seen so far: 114368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1787: 1.002819538116455\n",
      "Seen so far: 114432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1788: 0.9027122259140015\n",
      "Seen so far: 114496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1789: 0.8711260557174683\n",
      "Seen so far: 114560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1790: 0.9142269492149353\n",
      "Seen so far: 114624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1791: 0.8189871311187744\n",
      "Seen so far: 114688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1792: 0.827620804309845\n",
      "Seen so far: 114752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1793: 0.9881956577301025\n",
      "Seen so far: 114816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1794: 0.848415732383728\n",
      "Seen so far: 114880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1795: 0.8586227893829346\n",
      "Seen so far: 114944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1796: 0.8009799122810364\n",
      "Seen so far: 115008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1797: 0.5247961282730103\n",
      "Seen so far: 115072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1798: 0.7722079753875732\n",
      "Seen so far: 115136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1799: 0.7941168546676636\n",
      "Seen so far: 115200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1800: 0.9000251293182373\n",
      "Seen so far: 115264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1801: 0.7625554800033569\n",
      "Seen so far: 115328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1802: 0.5577116012573242\n",
      "Seen so far: 115392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1803: 0.8916804790496826\n",
      "Seen so far: 115456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1804: 0.6081047058105469\n",
      "Seen so far: 115520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1805: 0.5671964883804321\n",
      "Seen so far: 115584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1806: 0.8749508857727051\n",
      "Seen so far: 115648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1807: 0.8334497213363647\n",
      "Seen so far: 115712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1808: 1.0845428705215454\n",
      "Seen so far: 115776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1809: 0.8819708824157715\n",
      "Seen so far: 115840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1810: 0.7296883463859558\n",
      "Seen so far: 115904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1811: 0.8755514025688171\n",
      "Seen so far: 115968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1812: 0.6827139258384705\n",
      "Seen so far: 116032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1813: 1.0681886672973633\n",
      "Seen so far: 116096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1814: 0.9283949732780457\n",
      "Seen so far: 116160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1815: 1.375665307044983\n",
      "Seen so far: 116224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1816: 0.8913882970809937\n",
      "Seen so far: 116288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1817: 0.8888353109359741\n",
      "Seen so far: 116352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1818: 0.8433360457420349\n",
      "Seen so far: 116416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1819: 0.6224885582923889\n",
      "Seen so far: 116480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1820: 0.8698972463607788\n",
      "Seen so far: 116544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1821: 1.1427137851715088\n",
      "Seen so far: 116608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1822: 1.2734317779541016\n",
      "Seen so far: 116672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1823: 1.3157960176467896\n",
      "Seen so far: 116736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1824: 1.1309664249420166\n",
      "Seen so far: 116800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1825: 0.831450343132019\n",
      "Seen so far: 116864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1826: 1.1456997394561768\n",
      "Seen so far: 116928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1827: 1.1145200729370117\n",
      "Seen so far: 116992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1828: 1.1351183652877808\n",
      "Seen so far: 117056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1829: 0.9658986330032349\n",
      "Seen so far: 117120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1830: 0.8988122940063477\n",
      "Seen so far: 117184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1831: 0.8966503143310547\n",
      "Seen so far: 117248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1832: 1.2458103895187378\n",
      "Seen so far: 117312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1833: 0.8599814772605896\n",
      "Seen so far: 117376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1834: 1.4080049991607666\n",
      "Seen so far: 117440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1835: 0.7153308391571045\n",
      "Seen so far: 117504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1836: 0.8462338447570801\n",
      "Seen so far: 117568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1837: 0.6515309810638428\n",
      "Seen so far: 117632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1838: 0.9645625948905945\n",
      "Seen so far: 117696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1839: 0.6797679662704468\n",
      "Seen so far: 117760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1840: 1.3619801998138428\n",
      "Seen so far: 117824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1841: 0.7922354340553284\n",
      "Seen so far: 117888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1842: 0.5659208297729492\n",
      "Seen so far: 117952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1843: 0.9541558027267456\n",
      "Seen so far: 118016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1844: 0.9495888948440552\n",
      "Seen so far: 118080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1845: 0.9454143047332764\n",
      "Seen so far: 118144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1846: 1.1349787712097168\n",
      "Seen so far: 118208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1847: 0.9915083050727844\n",
      "Seen so far: 118272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1848: 0.8541580438613892\n",
      "Seen so far: 118336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1849: 1.2000271081924438\n",
      "Seen so far: 118400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1850: 0.6935045123100281\n",
      "Seen so far: 118464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1851: 1.2515654563903809\n",
      "Seen so far: 118528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1852: 0.959165096282959\n",
      "Seen so far: 118592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1853: 0.5398741960525513\n",
      "Seen so far: 118656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1854: 1.1774349212646484\n",
      "Seen so far: 118720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1855: 1.2365440130233765\n",
      "Seen so far: 118784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1856: 0.8033144474029541\n",
      "Seen so far: 118848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1857: 0.737128734588623\n",
      "Seen so far: 118912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1858: 1.014485478401184\n",
      "Seen so far: 118976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1859: 0.5028342008590698\n",
      "Seen so far: 119040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1860: 0.7192076444625854\n",
      "Seen so far: 119104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1861: 1.1571626663208008\n",
      "Seen so far: 119168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1862: 0.7143864035606384\n",
      "Seen so far: 119232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1863: 0.7504585981369019\n",
      "Seen so far: 119296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1864: 0.722005307674408\n",
      "Seen so far: 119360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1865: 0.8008420467376709\n",
      "Seen so far: 119424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1866: 0.9795769453048706\n",
      "Seen so far: 119488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1867: 0.7782870531082153\n",
      "Seen so far: 119552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1868: 0.7199389934539795\n",
      "Seen so far: 119616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1869: 0.6940752267837524\n",
      "Seen so far: 119680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1870: 0.7271418571472168\n",
      "Seen so far: 119744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1871: 0.8271032571792603\n",
      "Seen so far: 119808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1872: 0.87563157081604\n",
      "Seen so far: 119872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1873: 1.1678252220153809\n",
      "Seen so far: 119936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1874: 1.0469279289245605\n",
      "Seen so far: 120000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1875: 0.7260719537734985\n",
      "Seen so far: 120064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1876: 0.7033743262290955\n",
      "Seen so far: 120128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1877: 0.6808799505233765\n",
      "Seen so far: 120192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1878: 1.0286059379577637\n",
      "Seen so far: 120256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1879: 0.8614529371261597\n",
      "Seen so far: 120320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1880: 0.8798816800117493\n",
      "Seen so far: 120384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1881: 0.5396311283111572\n",
      "Seen so far: 120448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1882: 1.076746940612793\n",
      "Seen so far: 120512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1883: 0.5424401760101318\n",
      "Seen so far: 120576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1884: 0.9722567796707153\n",
      "Seen so far: 120640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1885: 0.9632155299186707\n",
      "Seen so far: 120704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1886: 0.7983368635177612\n",
      "Seen so far: 120768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1887: 0.744871973991394\n",
      "Seen so far: 120832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1888: 0.49914583563804626\n",
      "Seen so far: 120896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1889: 1.071448802947998\n",
      "Seen so far: 120960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1890: 1.3172855377197266\n",
      "Seen so far: 121024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1891: 1.06001615524292\n",
      "Seen so far: 121088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1892: 0.7835248708724976\n",
      "Seen so far: 121152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1893: 1.0014322996139526\n",
      "Seen so far: 121216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1894: 1.0307369232177734\n",
      "Seen so far: 121280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1895: 0.9303950071334839\n",
      "Seen so far: 121344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1896: 0.4294189214706421\n",
      "Seen so far: 121408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1897: 1.054634928703308\n",
      "Seen so far: 121472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1898: 0.7832963466644287\n",
      "Seen so far: 121536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1899: 1.020462989807129\n",
      "Seen so far: 121600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1900: 0.9816319942474365\n",
      "Seen so far: 121664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1901: 0.6563443541526794\n",
      "Seen so far: 121728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1902: 1.322700023651123\n",
      "Seen so far: 121792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1903: 1.0267541408538818\n",
      "Seen so far: 121856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1904: 1.0209991931915283\n",
      "Seen so far: 121920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1905: 0.8910404443740845\n",
      "Seen so far: 121984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1906: 0.6373262405395508\n",
      "Seen so far: 122048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1907: 1.0951056480407715\n",
      "Seen so far: 122112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1908: 1.0005321502685547\n",
      "Seen so far: 122176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1909: 0.8873800039291382\n",
      "Seen so far: 122240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1910: 0.8366530537605286\n",
      "Seen so far: 122304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1911: 0.7357133030891418\n",
      "Seen so far: 122368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1912: 1.1938055753707886\n",
      "Seen so far: 122432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1913: 0.7060456275939941\n",
      "Seen so far: 122496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1914: 0.7966339588165283\n",
      "Seen so far: 122560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1915: 0.750213623046875\n",
      "Seen so far: 122624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1916: 0.862306535243988\n",
      "Seen so far: 122688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1917: 1.0115710496902466\n",
      "Seen so far: 122752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1918: 1.0577045679092407\n",
      "Seen so far: 122816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1919: 0.9767091274261475\n",
      "Seen so far: 122880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1920: 1.1821024417877197\n",
      "Seen so far: 122944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1921: 0.9392422437667847\n",
      "Seen so far: 123008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1922: 0.9878823757171631\n",
      "Seen so far: 123072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1923: 0.9258569478988647\n",
      "Seen so far: 123136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1924: 0.9179301261901855\n",
      "Seen so far: 123200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1925: 0.7727164626121521\n",
      "Seen so far: 123264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1926: 1.0295249223709106\n",
      "Seen so far: 123328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1927: 1.059799075126648\n",
      "Seen so far: 123392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1928: 0.6676685810089111\n",
      "Seen so far: 123456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1929: 0.7993445992469788\n",
      "Seen so far: 123520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1930: 1.1956007480621338\n",
      "Seen so far: 123584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1931: 1.0556522607803345\n",
      "Seen so far: 123648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1932: 1.328701138496399\n",
      "Seen so far: 123712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1933: 0.892625093460083\n",
      "Seen so far: 123776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1934: 1.014664888381958\n",
      "Seen so far: 123840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1935: 1.4302006959915161\n",
      "Seen so far: 123904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1936: 1.3878859281539917\n",
      "Seen so far: 123968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1937: 1.1155177354812622\n",
      "Seen so far: 124032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1938: 0.6743422150611877\n",
      "Seen so far: 124096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1939: 1.1337966918945312\n",
      "Seen so far: 124160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1940: 0.8446131944656372\n",
      "Seen so far: 124224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1941: 0.8266537189483643\n",
      "Seen so far: 124288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1942: 1.0033267736434937\n",
      "Seen so far: 124352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1943: 0.6744616031646729\n",
      "Seen so far: 124416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1944: 1.1696795225143433\n",
      "Seen so far: 124480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1945: 1.1038458347320557\n",
      "Seen so far: 124544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1946: 0.8560116291046143\n",
      "Seen so far: 124608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1947: 0.7519834041595459\n",
      "Seen so far: 124672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1948: 1.1792278289794922\n",
      "Seen so far: 124736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1949: 0.7930610179901123\n",
      "Seen so far: 124800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1950: 1.206560492515564\n",
      "Seen so far: 124864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1951: 0.601762056350708\n",
      "Seen so far: 124928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1952: 0.5348807573318481\n",
      "Seen so far: 124992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1953: 0.6576398611068726\n",
      "Seen so far: 125056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1954: 0.974094808101654\n",
      "Seen so far: 125120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1955: 0.9298062324523926\n",
      "Seen so far: 125184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1956: 0.9069281816482544\n",
      "Seen so far: 125248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1957: 0.9092569351196289\n",
      "Seen so far: 125312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1958: 0.5188308954238892\n",
      "Seen so far: 125376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1959: 0.7171319723129272\n",
      "Seen so far: 125440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1960: 1.0657551288604736\n",
      "Seen so far: 125504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1961: 0.8957785367965698\n",
      "Seen so far: 125568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1962: 0.7365002632141113\n",
      "Seen so far: 125632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1963: 0.8135203123092651\n",
      "Seen so far: 125696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1964: 0.6845501661300659\n",
      "Seen so far: 125760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1965: 1.1405200958251953\n",
      "Seen so far: 125824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1966: 0.7474137544631958\n",
      "Seen so far: 125888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1967: 0.9632986783981323\n",
      "Seen so far: 125952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1968: 0.6398664712905884\n",
      "Seen so far: 126016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1969: 0.9182672500610352\n",
      "Seen so far: 126080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1970: 0.9799091815948486\n",
      "Seen so far: 126144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1971: 0.819464921951294\n",
      "Seen so far: 126208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1972: 0.8919118642807007\n",
      "Seen so far: 126272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1973: 1.0084831714630127\n",
      "Seen so far: 126336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1974: 0.9012172222137451\n",
      "Seen so far: 126400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1975: 1.2998113632202148\n",
      "Seen so far: 126464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1976: 0.619004487991333\n",
      "Seen so far: 126528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1977: 0.7384946942329407\n",
      "Seen so far: 126592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1978: 1.0478745698928833\n",
      "Seen so far: 126656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1979: 0.6066144704818726\n",
      "Seen so far: 126720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1980: 1.1055406332015991\n",
      "Seen so far: 126784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1981: 0.7389488816261292\n",
      "Seen so far: 126848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1982: 0.7394388318061829\n",
      "Seen so far: 126912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1983: 1.2361286878585815\n",
      "Seen so far: 126976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1984: 0.9672454595565796\n",
      "Seen so far: 127040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1985: 1.1093648672103882\n",
      "Seen so far: 127104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1986: 0.5963071584701538\n",
      "Seen so far: 127168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1987: 1.0992487668991089\n",
      "Seen so far: 127232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1988: 1.119389533996582\n",
      "Seen so far: 127296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1989: 0.7885879278182983\n",
      "Seen so far: 127360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1990: 0.7605063915252686\n",
      "Seen so far: 127424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1991: 1.2140729427337646\n",
      "Seen so far: 127488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1992: 1.0599311590194702\n",
      "Seen so far: 127552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1993: 0.9026603698730469\n",
      "Seen so far: 127616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1994: 1.1431630849838257\n",
      "Seen so far: 127680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1995: 0.6414346694946289\n",
      "Seen so far: 127744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1996: 0.8723074197769165\n",
      "Seen so far: 127808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1997: 1.0646681785583496\n",
      "Seen so far: 127872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1998: 0.7606459856033325\n",
      "Seen so far: 127936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1999: 0.8524997234344482\n",
      "Seen so far: 128000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2000: 0.8759686350822449\n",
      "Seen so far: 128064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2001: 0.8807617425918579\n",
      "Seen so far: 128128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2002: 1.174904704093933\n",
      "Seen so far: 128192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2003: 0.5525810718536377\n",
      "Seen so far: 128256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2004: 1.0448285341262817\n",
      "Seen so far: 128320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2005: 1.0671197175979614\n",
      "Seen so far: 128384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2006: 1.3297085762023926\n",
      "Seen so far: 128448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2007: 0.7432163953781128\n",
      "Seen so far: 128512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2008: 0.9296379089355469\n",
      "Seen so far: 128576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2009: 0.966606080532074\n",
      "Seen so far: 128640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2010: 1.4166016578674316\n",
      "Seen so far: 128704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2011: 1.0052458047866821\n",
      "Seen so far: 128768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2012: 0.8824238777160645\n",
      "Seen so far: 128832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2013: 1.0434610843658447\n",
      "Seen so far: 128896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2014: 0.8064858913421631\n",
      "Seen so far: 128960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2015: 0.8066468834877014\n",
      "Seen so far: 129024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2016: 0.6269747018814087\n",
      "Seen so far: 129088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2017: 0.9493056535720825\n",
      "Seen so far: 129152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2018: 0.6463096141815186\n",
      "Seen so far: 129216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2019: 1.1855502128601074\n",
      "Seen so far: 129280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2020: 0.5187901258468628\n",
      "Seen so far: 129344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2021: 0.9284276962280273\n",
      "Seen so far: 129408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2022: 1.234114408493042\n",
      "Seen so far: 129472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2023: 0.7674805521965027\n",
      "Seen so far: 129536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2024: 0.6605925559997559\n",
      "Seen so far: 129600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2025: 0.9151567220687866\n",
      "Seen so far: 129664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2026: 0.7888163328170776\n",
      "Seen so far: 129728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2027: 1.2678864002227783\n",
      "Seen so far: 129792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2028: 0.7411209344863892\n",
      "Seen so far: 129856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2029: 0.8686355352401733\n",
      "Seen so far: 129920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2030: 1.3524866104125977\n",
      "Seen so far: 129984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2031: 1.2670094966888428\n",
      "Seen so far: 130048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2032: 0.9858183264732361\n",
      "Seen so far: 130112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2033: 1.244004726409912\n",
      "Seen so far: 130176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2034: 1.295342206954956\n",
      "Seen so far: 130240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2035: 0.7878110408782959\n",
      "Seen so far: 130304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2036: 0.676351010799408\n",
      "Seen so far: 130368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2037: 0.6824288368225098\n",
      "Seen so far: 130432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2038: 0.9325709342956543\n",
      "Seen so far: 130496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2039: 1.0245840549468994\n",
      "Seen so far: 130560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2040: 0.5287637114524841\n",
      "Seen so far: 130624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2041: 0.7294516563415527\n",
      "Seen so far: 130688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2042: 0.8680262565612793\n",
      "Seen so far: 130752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2043: 0.8104385733604431\n",
      "Seen so far: 130816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2044: 0.9418917894363403\n",
      "Seen so far: 130880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2045: 0.6980984210968018\n",
      "Seen so far: 130944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2046: 0.9050306677818298\n",
      "Seen so far: 131008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2047: 0.7266395688056946\n",
      "Seen so far: 131072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2048: 0.7484923601150513\n",
      "Seen so far: 131136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2049: 1.0511553287506104\n",
      "Seen so far: 131200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2050: 0.8942409753799438\n",
      "Seen so far: 131264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2051: 1.1405346393585205\n",
      "Seen so far: 131328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2052: 0.8286734223365784\n",
      "Seen so far: 131392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2053: 0.9832620620727539\n",
      "Seen so far: 131456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2054: 0.854029655456543\n",
      "Seen so far: 131520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2055: 0.3683488368988037\n",
      "Seen so far: 131584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2056: 0.5491682291030884\n",
      "Seen so far: 131648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2057: 0.8644508719444275\n",
      "Seen so far: 131712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2058: 0.8224166631698608\n",
      "Seen so far: 131776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2059: 0.9658890962600708\n",
      "Seen so far: 131840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2060: 0.8832917809486389\n",
      "Seen so far: 131904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2061: 1.0105791091918945\n",
      "Seen so far: 131968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2062: 1.0124143362045288\n",
      "Seen so far: 132032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2063: 0.8507975339889526\n",
      "Seen so far: 132096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2064: 1.0166351795196533\n",
      "Seen so far: 132160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2065: 0.7136182188987732\n",
      "Seen so far: 132224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2066: 1.0369837284088135\n",
      "Seen so far: 132288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2067: 0.8181531429290771\n",
      "Seen so far: 132352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2068: 1.088350534439087\n",
      "Seen so far: 132416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2069: 1.0101292133331299\n",
      "Seen so far: 132480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2070: 0.5605819821357727\n",
      "Seen so far: 132544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2071: 0.4792253375053406\n",
      "Seen so far: 132608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2072: 1.1330360174179077\n",
      "Seen so far: 132672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2073: 0.8347817063331604\n",
      "Seen so far: 132736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2074: 0.8479633331298828\n",
      "Seen so far: 132800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2075: 0.9152601957321167\n",
      "Seen so far: 132864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2076: 0.6697632074356079\n",
      "Seen so far: 132928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2077: 0.9190253615379333\n",
      "Seen so far: 132992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2078: 1.021612286567688\n",
      "Seen so far: 133056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2079: 0.991427481174469\n",
      "Seen so far: 133120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2080: 0.47469478845596313\n",
      "Seen so far: 133184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2081: 1.0987826585769653\n",
      "Seen so far: 133248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2082: 0.689590573310852\n",
      "Seen so far: 133312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2083: 0.7373767495155334\n",
      "Seen so far: 133376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2084: 0.8164529800415039\n",
      "Seen so far: 133440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2085: 0.5313392877578735\n",
      "Seen so far: 133504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2086: 0.4782555103302002\n",
      "Seen so far: 133568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2087: 1.035306692123413\n",
      "Seen so far: 133632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2088: 0.7780250906944275\n",
      "Seen so far: 133696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2089: 1.043766736984253\n",
      "Seen so far: 133760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2090: 0.7533890008926392\n",
      "Seen so far: 133824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2091: 0.7971073985099792\n",
      "Seen so far: 133888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2092: 0.8190480470657349\n",
      "Seen so far: 133952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2093: 0.7260870933532715\n",
      "Seen so far: 134016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2094: 0.9093852043151855\n",
      "Seen so far: 134080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2095: 1.0859944820404053\n",
      "Seen so far: 134144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2096: 0.888299822807312\n",
      "Seen so far: 134208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2097: 0.6020915508270264\n",
      "Seen so far: 134272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2098: 0.877112865447998\n",
      "Seen so far: 134336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2099: 0.7501567602157593\n",
      "Seen so far: 134400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2100: 0.92979896068573\n",
      "Seen so far: 134464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2101: 0.5701881647109985\n",
      "Seen so far: 134528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2102: 0.9130076169967651\n",
      "Seen so far: 134592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2103: 0.8427997827529907\n",
      "Seen so far: 134656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2104: 0.8568994998931885\n",
      "Seen so far: 134720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2105: 0.5567228198051453\n",
      "Seen so far: 134784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2106: 0.7820392847061157\n",
      "Seen so far: 134848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2107: 0.8720227479934692\n",
      "Seen so far: 134912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2108: 0.41935214400291443\n",
      "Seen so far: 134976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2109: 0.6121413707733154\n",
      "Seen so far: 135040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2110: 1.0116699934005737\n",
      "Seen so far: 135104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2111: 0.7076147794723511\n",
      "Seen so far: 135168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2112: 0.5657642483711243\n",
      "Seen so far: 135232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2113: 0.9880360960960388\n",
      "Seen so far: 135296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2114: 0.8023446202278137\n",
      "Seen so far: 135360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2115: 0.8860336542129517\n",
      "Seen so far: 135424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2116: 0.667798638343811\n",
      "Seen so far: 135488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2117: 0.6800435781478882\n",
      "Seen so far: 135552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2118: 1.2914268970489502\n",
      "Seen so far: 135616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2119: 0.9336605072021484\n",
      "Seen so far: 135680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2120: 1.065460205078125\n",
      "Seen so far: 135744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2121: 0.7471916079521179\n",
      "Seen so far: 135808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2122: 0.9045435190200806\n",
      "Seen so far: 135872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2123: 0.8144776821136475\n",
      "Seen so far: 135936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2124: 0.9846156239509583\n",
      "Seen so far: 136000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2125: 1.135547161102295\n",
      "Seen so far: 136064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2126: 0.9027218818664551\n",
      "Seen so far: 136128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2127: 1.068812608718872\n",
      "Seen so far: 136192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2128: 1.0591351985931396\n",
      "Seen so far: 136256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2129: 0.93721604347229\n",
      "Seen so far: 136320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2130: 0.7688692212104797\n",
      "Seen so far: 136384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2131: 0.9345365762710571\n",
      "Seen so far: 136448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2132: 0.9310990571975708\n",
      "Seen so far: 136512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2133: 0.6841834187507629\n",
      "Seen so far: 136576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2134: 0.319896399974823\n",
      "Seen so far: 136640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2135: 0.5120608806610107\n",
      "Seen so far: 136704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2136: 0.6087713241577148\n",
      "Seen so far: 136768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2137: 1.0085049867630005\n",
      "Seen so far: 136832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2138: 0.9114384055137634\n",
      "Seen so far: 136896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2139: 1.0253798961639404\n",
      "Seen so far: 136960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2140: 1.041926622390747\n",
      "Seen so far: 137024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2141: 1.5774853229522705\n",
      "Seen so far: 137088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2142: 0.5577509999275208\n",
      "Seen so far: 137152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2143: 0.9199545383453369\n",
      "Seen so far: 137216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2144: 0.7197463512420654\n",
      "Seen so far: 137280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2145: 1.1810122728347778\n",
      "Seen so far: 137344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2146: 1.248884916305542\n",
      "Seen so far: 137408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2147: 0.6040602326393127\n",
      "Seen so far: 137472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2148: 1.0188920497894287\n",
      "Seen so far: 137536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2149: 1.0440993309020996\n",
      "Seen so far: 137600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2150: 0.6000078916549683\n",
      "Seen so far: 137664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2151: 0.7522896528244019\n",
      "Seen so far: 137728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2152: 1.0692927837371826\n",
      "Seen so far: 137792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2153: 0.6243608593940735\n",
      "Seen so far: 137856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2154: 0.9941296577453613\n",
      "Seen so far: 137920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2155: 0.8757182359695435\n",
      "Seen so far: 137984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2156: 0.7096525430679321\n",
      "Seen so far: 138048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2157: 0.4526973366737366\n",
      "Seen so far: 138112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2158: 0.7458209991455078\n",
      "Seen so far: 138176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2159: 0.5503637790679932\n",
      "Seen so far: 138240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2160: 1.0257458686828613\n",
      "Seen so far: 138304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2161: 0.692252516746521\n",
      "Seen so far: 138368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2162: 0.7242621183395386\n",
      "Seen so far: 138432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2163: 0.5935879945755005\n",
      "Seen so far: 138496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2164: 1.3116066455841064\n",
      "Seen so far: 138560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2165: 0.9304434061050415\n",
      "Seen so far: 138624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2166: 0.6204980611801147\n",
      "Seen so far: 138688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2167: 1.031480073928833\n",
      "Seen so far: 138752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2168: 0.7227683663368225\n",
      "Seen so far: 138816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2169: 0.6511592268943787\n",
      "Seen so far: 138880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2170: 1.118408441543579\n",
      "Seen so far: 138944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2171: 0.9760087728500366\n",
      "Seen so far: 139008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2172: 0.7564113140106201\n",
      "Seen so far: 139072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2173: 0.7578835487365723\n",
      "Seen so far: 139136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2174: 1.3626255989074707\n",
      "Seen so far: 139200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2175: 0.9216941595077515\n",
      "Seen so far: 139264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2176: 0.9183286428451538\n",
      "Seen so far: 139328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2177: 0.8130403757095337\n",
      "Seen so far: 139392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2178: 0.5607165098190308\n",
      "Seen so far: 139456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2179: 0.5323081612586975\n",
      "Seen so far: 139520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2180: 0.7981663942337036\n",
      "Seen so far: 139584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2181: 1.124214768409729\n",
      "Seen so far: 139648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2182: 1.0930559635162354\n",
      "Seen so far: 139712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2183: 0.7136220932006836\n",
      "Seen so far: 139776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2184: 1.078273057937622\n",
      "Seen so far: 139840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2185: 0.9905369281768799\n",
      "Seen so far: 139904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2186: 0.784050464630127\n",
      "Seen so far: 139968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2187: 0.7582045197486877\n",
      "Seen so far: 140032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2188: 0.6072916388511658\n",
      "Seen so far: 140096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2189: 0.9379159808158875\n",
      "Seen so far: 140160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2190: 0.7640739679336548\n",
      "Seen so far: 140224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2191: 0.6776697635650635\n",
      "Seen so far: 140288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2192: 0.6992977857589722\n",
      "Seen so far: 140352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2193: 0.7395446300506592\n",
      "Seen so far: 140416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2194: 0.5444942116737366\n",
      "Seen so far: 140480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2195: 1.2232966423034668\n",
      "Seen so far: 140544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2196: 0.6588963270187378\n",
      "Seen so far: 140608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2197: 0.6516776084899902\n",
      "Seen so far: 140672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2198: 1.1161785125732422\n",
      "Seen so far: 140736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2199: 0.7015585899353027\n",
      "Seen so far: 140800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2200: 1.121732473373413\n",
      "Seen so far: 140864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2201: 0.9632771015167236\n",
      "Seen so far: 140928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2202: 0.7483170032501221\n",
      "Seen so far: 140992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2203: 1.277082085609436\n",
      "Seen so far: 141056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2204: 0.7179950475692749\n",
      "Seen so far: 141120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2205: 0.5935683846473694\n",
      "Seen so far: 141184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2206: 1.1743712425231934\n",
      "Seen so far: 141248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2207: 0.8607400059700012\n",
      "Seen so far: 141312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2208: 1.8314746618270874\n",
      "Seen so far: 141376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2209: 0.9342136383056641\n",
      "Seen so far: 141440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2210: 0.9053878784179688\n",
      "Seen so far: 141504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2211: 0.8480584621429443\n",
      "Seen so far: 141568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2212: 0.6768165826797485\n",
      "Seen so far: 141632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2213: 0.6293188333511353\n",
      "Seen so far: 141696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2214: 1.125473141670227\n",
      "Seen so far: 141760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2215: 0.9439985752105713\n",
      "Seen so far: 141824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2216: 0.6668002605438232\n",
      "Seen so far: 141888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2217: 0.9090442061424255\n",
      "Seen so far: 141952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2218: 0.9991136193275452\n",
      "Seen so far: 142016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2219: 1.0220584869384766\n",
      "Seen so far: 142080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2220: 0.9269846677780151\n",
      "Seen so far: 142144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2221: 1.1117219924926758\n",
      "Seen so far: 142208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2222: 1.3890255689620972\n",
      "Seen so far: 142272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2223: 0.681723952293396\n",
      "Seen so far: 142336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2224: 1.1066296100616455\n",
      "Seen so far: 142400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2225: 0.922522783279419\n",
      "Seen so far: 142464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2226: 1.1478238105773926\n",
      "Seen so far: 142528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2227: 0.7022279500961304\n",
      "Seen so far: 142592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2228: 0.9354711174964905\n",
      "Seen so far: 142656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2229: 1.046429991722107\n",
      "Seen so far: 142720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2230: 0.8655467629432678\n",
      "Seen so far: 142784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2231: 0.8942209482192993\n",
      "Seen so far: 142848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2232: 1.1508018970489502\n",
      "Seen so far: 142912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2233: 0.8853508830070496\n",
      "Seen so far: 142976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2234: 0.8931189775466919\n",
      "Seen so far: 143040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2235: 1.0227560997009277\n",
      "Seen so far: 143104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2236: 0.9166151285171509\n",
      "Seen so far: 143168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2237: 1.1020599603652954\n",
      "Seen so far: 143232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2238: 0.801332414150238\n",
      "Seen so far: 143296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2239: 1.1118431091308594\n",
      "Seen so far: 143360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2240: 0.6771535277366638\n",
      "Seen so far: 143424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2241: 1.0771727561950684\n",
      "Seen so far: 143488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2242: 0.7904579639434814\n",
      "Seen so far: 143552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2243: 1.0042048692703247\n",
      "Seen so far: 143616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2244: 1.0364656448364258\n",
      "Seen so far: 143680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2245: 0.6906893253326416\n",
      "Seen so far: 143744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2246: 0.7606183886528015\n",
      "Seen so far: 143808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2247: 1.27566659450531\n",
      "Seen so far: 143872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2248: 0.6539825201034546\n",
      "Seen so far: 143936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2249: 1.2166448831558228\n",
      "Seen so far: 144000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2250: 0.8751442432403564\n",
      "Seen so far: 144064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2251: 0.8681163787841797\n",
      "Seen so far: 144128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2252: 0.8338696956634521\n",
      "Seen so far: 144192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2253: 1.0336079597473145\n",
      "Seen so far: 144256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2254: 0.8676142692565918\n",
      "Seen so far: 144320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2255: 0.8071804046630859\n",
      "Seen so far: 144384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2256: 1.0491466522216797\n",
      "Seen so far: 144448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2257: 1.1416765451431274\n",
      "Seen so far: 144512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2258: 1.390594244003296\n",
      "Seen so far: 144576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2259: 0.9343206882476807\n",
      "Seen so far: 144640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2260: 0.894917368888855\n",
      "Seen so far: 144704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2261: 1.2107000350952148\n",
      "Seen so far: 144768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2262: 0.8693372011184692\n",
      "Seen so far: 144832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2263: 1.0885323286056519\n",
      "Seen so far: 144896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2264: 1.1125664710998535\n",
      "Seen so far: 144960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2265: 0.6762732267379761\n",
      "Seen so far: 145024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2266: 0.9657338261604309\n",
      "Seen so far: 145088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2267: 0.8259429335594177\n",
      "Seen so far: 145152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2268: 0.8011384010314941\n",
      "Seen so far: 145216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2269: 0.654540479183197\n",
      "Seen so far: 145280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2270: 0.702491283416748\n",
      "Seen so far: 145344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2271: 0.677727997303009\n",
      "Seen so far: 145408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2272: 0.9604861736297607\n",
      "Seen so far: 145472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2273: 0.9838341474533081\n",
      "Seen so far: 145536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2274: 1.0265216827392578\n",
      "Seen so far: 145600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2275: 1.2717760801315308\n",
      "Seen so far: 145664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2276: 0.7741200923919678\n",
      "Seen so far: 145728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2277: 0.8456805348396301\n",
      "Seen so far: 145792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2278: 1.2227458953857422\n",
      "Seen so far: 145856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2279: 0.6202198266983032\n",
      "Seen so far: 145920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2280: 1.1623585224151611\n",
      "Seen so far: 145984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2281: 0.7638797760009766\n",
      "Seen so far: 146048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2282: 1.0024529695510864\n",
      "Seen so far: 146112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2283: 0.9138773679733276\n",
      "Seen so far: 146176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2284: 0.7017508745193481\n",
      "Seen so far: 146240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2285: 0.9987611770629883\n",
      "Seen so far: 146304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2286: 1.2219575643539429\n",
      "Seen so far: 146368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2287: 0.6468329429626465\n",
      "Seen so far: 146432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2288: 0.7420974969863892\n",
      "Seen so far: 146496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2289: 0.8002320528030396\n",
      "Seen so far: 146560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2290: 0.9236094355583191\n",
      "Seen so far: 146624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2291: 0.7578006386756897\n",
      "Seen so far: 146688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2292: 0.6470459699630737\n",
      "Seen so far: 146752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2293: 0.9772456288337708\n",
      "Seen so far: 146816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2294: 1.3808823823928833\n",
      "Seen so far: 146880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2295: 1.0227043628692627\n",
      "Seen so far: 146944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2296: 0.9009581804275513\n",
      "Seen so far: 147008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2297: 1.3870155811309814\n",
      "Seen so far: 147072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2298: 0.8838217854499817\n",
      "Seen so far: 147136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2299: 0.6284884214401245\n",
      "Seen so far: 147200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2300: 0.96526038646698\n",
      "Seen so far: 147264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2301: 0.8725020885467529\n",
      "Seen so far: 147328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2302: 0.9356123208999634\n",
      "Seen so far: 147392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2303: 1.2171630859375\n",
      "Seen so far: 147456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2304: 0.7115408182144165\n",
      "Seen so far: 147520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2305: 0.9377300143241882\n",
      "Seen so far: 147584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2306: 0.700732409954071\n",
      "Seen so far: 147648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2307: 0.8389922380447388\n",
      "Seen so far: 147712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2308: 0.8926948308944702\n",
      "Seen so far: 147776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2309: 1.0785115957260132\n",
      "Seen so far: 147840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2310: 0.7233238220214844\n",
      "Seen so far: 147904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2311: 0.7117108702659607\n",
      "Seen so far: 147968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2312: 0.5538694858551025\n",
      "Seen so far: 148032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2313: 0.9266030788421631\n",
      "Seen so far: 148096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2314: 1.164017915725708\n",
      "Seen so far: 148160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2315: 0.7539293766021729\n",
      "Seen so far: 148224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2316: 0.9355574250221252\n",
      "Seen so far: 148288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2317: 0.5754703283309937\n",
      "Seen so far: 148352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2318: 0.5064585208892822\n",
      "Seen so far: 148416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2319: 1.072327971458435\n",
      "Seen so far: 148480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2320: 0.8453735113143921\n",
      "Seen so far: 148544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2321: 0.6730719208717346\n",
      "Seen so far: 148608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2322: 0.5985311269760132\n",
      "Seen so far: 148672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2323: 0.5940486192703247\n",
      "Seen so far: 148736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2324: 1.1156165599822998\n",
      "Seen so far: 148800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2325: 0.576616644859314\n",
      "Seen so far: 148864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2326: 0.9307103753089905\n",
      "Seen so far: 148928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2327: 1.2524572610855103\n",
      "Seen so far: 148992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2328: 0.6220297813415527\n",
      "Seen so far: 149056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2329: 0.809488832950592\n",
      "Seen so far: 149120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2330: 0.8511167764663696\n",
      "Seen so far: 149184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2331: 0.6088171005249023\n",
      "Seen so far: 149248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2332: 1.0920302867889404\n",
      "Seen so far: 149312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2333: 0.8181522488594055\n",
      "Seen so far: 149376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2334: 0.9555336236953735\n",
      "Seen so far: 149440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2335: 1.0501141548156738\n",
      "Seen so far: 149504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2336: 1.015178918838501\n",
      "Seen so far: 149568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2337: 0.963175892829895\n",
      "Seen so far: 149632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2338: 0.6619356870651245\n",
      "Seen so far: 149696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2339: 1.0719733238220215\n",
      "Seen so far: 149760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2340: 1.1159782409667969\n",
      "Seen so far: 149824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2341: 1.2284376621246338\n",
      "Seen so far: 149888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2342: 0.6363950371742249\n",
      "Seen so far: 149952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2343: 0.5486903786659241\n",
      "Seen so far: 150016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2344: 0.9541311264038086\n",
      "Seen so far: 150080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2345: 0.8792252540588379\n",
      "Seen so far: 150144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2346: 0.8068549633026123\n",
      "Seen so far: 150208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2347: 0.6670222282409668\n",
      "Seen so far: 150272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2348: 0.9840487241744995\n",
      "Seen so far: 150336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2349: 0.7801792621612549\n",
      "Seen so far: 150400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2350: 0.9509512782096863\n",
      "Seen so far: 150464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2351: 1.0678843259811401\n",
      "Seen so far: 150528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2352: 1.013305425643921\n",
      "Seen so far: 150592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2353: 0.9280484914779663\n",
      "Seen so far: 150656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2354: 0.9009451866149902\n",
      "Seen so far: 150720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2355: 0.8170867562294006\n",
      "Seen so far: 150784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2356: 0.6663258671760559\n",
      "Seen so far: 150848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2357: 1.2680988311767578\n",
      "Seen so far: 150912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2358: 0.9701187014579773\n",
      "Seen so far: 150976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2359: 0.9027880430221558\n",
      "Seen so far: 151040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2360: 1.1614844799041748\n",
      "Seen so far: 151104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2361: 0.7894504070281982\n",
      "Seen so far: 151168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2362: 1.0217766761779785\n",
      "Seen so far: 151232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2363: 0.9349229335784912\n",
      "Seen so far: 151296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2364: 0.7053180932998657\n",
      "Seen so far: 151360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2365: 1.3687571287155151\n",
      "Seen so far: 151424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2366: 0.8471775650978088\n",
      "Seen so far: 151488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2367: 0.9034531116485596\n",
      "Seen so far: 151552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2368: 0.9559773206710815\n",
      "Seen so far: 151616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2369: 1.1661466360092163\n",
      "Seen so far: 151680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2370: 0.9666840434074402\n",
      "Seen so far: 151744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2371: 0.9606746435165405\n",
      "Seen so far: 151808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2372: 0.9609109163284302\n",
      "Seen so far: 151872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2373: 1.2092534303665161\n",
      "Seen so far: 151936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2374: 0.900295615196228\n",
      "Seen so far: 152000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2375: 0.9138579368591309\n",
      "Seen so far: 152064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2376: 1.3996715545654297\n",
      "Seen so far: 152128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2377: 0.995941162109375\n",
      "Seen so far: 152192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2378: 0.6368433237075806\n",
      "Seen so far: 152256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2379: 0.9978145360946655\n",
      "Seen so far: 152320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2380: 0.8320897221565247\n",
      "Seen so far: 152384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2381: 0.5937067866325378\n",
      "Seen so far: 152448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2382: 0.5441057682037354\n",
      "Seen so far: 152512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2383: 0.7329509258270264\n",
      "Seen so far: 152576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2384: 1.2372328042984009\n",
      "Seen so far: 152640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2385: 0.9961968660354614\n",
      "Seen so far: 152704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2386: 0.8378217220306396\n",
      "Seen so far: 152768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2387: 0.7233824729919434\n",
      "Seen so far: 152832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2388: 0.8791379928588867\n",
      "Seen so far: 152896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2389: 0.9108865261077881\n",
      "Seen so far: 152960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2390: 1.1851041316986084\n",
      "Seen so far: 153024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2391: 0.9213089942932129\n",
      "Seen so far: 153088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2392: 0.634732186794281\n",
      "Seen so far: 153152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2393: 0.923386812210083\n",
      "Seen so far: 153216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2394: 0.7649853229522705\n",
      "Seen so far: 153280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2395: 1.1111459732055664\n",
      "Seen so far: 153344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2396: 0.7826741337776184\n",
      "Seen so far: 153408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2397: 1.142761468887329\n",
      "Seen so far: 153472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2398: 0.9238340854644775\n",
      "Seen so far: 153536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2399: 0.7258238792419434\n",
      "Seen so far: 153600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2400: 0.7339043617248535\n",
      "Seen so far: 153664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2401: 0.6800450682640076\n",
      "Seen so far: 153728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2402: 1.07920503616333\n",
      "Seen so far: 153792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2403: 1.2590866088867188\n",
      "Seen so far: 153856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2404: 0.8699809312820435\n",
      "Seen so far: 153920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2405: 1.1352920532226562\n",
      "Seen so far: 153984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2406: 0.6276736259460449\n",
      "Seen so far: 154048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2407: 1.5494532585144043\n",
      "Seen so far: 154112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2408: 0.4616125822067261\n",
      "Seen so far: 154176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2409: 1.0596981048583984\n",
      "Seen so far: 154240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2410: 0.7243694067001343\n",
      "Seen so far: 154304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2411: 1.3015773296356201\n",
      "Seen so far: 154368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2412: 1.117600440979004\n",
      "Seen so far: 154432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2413: 1.089676856994629\n",
      "Seen so far: 154496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2414: 1.0992757081985474\n",
      "Seen so far: 154560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2415: 1.1979811191558838\n",
      "Seen so far: 154624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2416: 0.976313591003418\n",
      "Seen so far: 154688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2417: 1.043749451637268\n",
      "Seen so far: 154752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2418: 1.0392131805419922\n",
      "Seen so far: 154816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2419: 0.8051046133041382\n",
      "Seen so far: 154880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2420: 1.1411144733428955\n",
      "Seen so far: 154944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2421: 0.8962185978889465\n",
      "Seen so far: 155008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2422: 0.7710744142532349\n",
      "Seen so far: 155072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2423: 0.9449045658111572\n",
      "Seen so far: 155136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2424: 0.9226210713386536\n",
      "Seen so far: 155200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2425: 1.2381950616836548\n",
      "Seen so far: 155264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2426: 0.9961098432540894\n",
      "Seen so far: 155328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2427: 1.2787060737609863\n",
      "Seen so far: 155392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2428: 1.1246812343597412\n",
      "Seen so far: 155456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2429: 0.8835768699645996\n",
      "Seen so far: 155520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2430: 1.003584384918213\n",
      "Seen so far: 155584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2431: 1.2028980255126953\n",
      "Seen so far: 155648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2432: 0.738845705986023\n",
      "Seen so far: 155712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2433: 0.745377779006958\n",
      "Seen so far: 155776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2434: 0.7746759057044983\n",
      "Seen so far: 155840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2435: 1.2258399724960327\n",
      "Seen so far: 155904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2436: 1.109987497329712\n",
      "Seen so far: 155968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2437: 0.49794715642929077\n",
      "Seen so far: 156032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2438: 1.020297646522522\n",
      "Seen so far: 156096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2439: 0.8373035192489624\n",
      "Seen so far: 156160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2440: 0.821190357208252\n",
      "Seen so far: 156224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2441: 0.47093868255615234\n",
      "Seen so far: 156288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2442: 1.089650273323059\n",
      "Seen so far: 156352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2443: 0.8965483903884888\n",
      "Seen so far: 156416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2444: 0.8143801689147949\n",
      "Seen so far: 156480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2445: 1.0310466289520264\n",
      "Seen so far: 156544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2446: 0.816195547580719\n",
      "Seen so far: 156608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2447: 0.5043516159057617\n",
      "Seen so far: 156672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2448: 1.3180890083312988\n",
      "Seen so far: 156736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2449: 0.6591204404830933\n",
      "Seen so far: 156800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2450: 0.8448682427406311\n",
      "Seen so far: 156864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2451: 0.9411570429801941\n",
      "Seen so far: 156928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2452: 1.0295988321304321\n",
      "Seen so far: 156992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2453: 0.7024202346801758\n",
      "Seen so far: 157056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2454: 1.2301430702209473\n",
      "Seen so far: 157120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2455: 0.8884817957878113\n",
      "Seen so far: 157184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2456: 0.5901699066162109\n",
      "Seen so far: 157248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2457: 1.0831202268600464\n",
      "Seen so far: 157312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2458: 0.7059997320175171\n",
      "Seen so far: 157376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2459: 0.9799010753631592\n",
      "Seen so far: 157440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2460: 0.8713387846946716\n",
      "Seen so far: 157504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2461: 0.7207759022712708\n",
      "Seen so far: 157568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2462: 1.0392333269119263\n",
      "Seen so far: 157632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2463: 0.552020788192749\n",
      "Seen so far: 157696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2464: 0.8188973665237427\n",
      "Seen so far: 157760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2465: 0.9332025051116943\n",
      "Seen so far: 157824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2466: 1.5130201578140259\n",
      "Seen so far: 157888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2467: 1.2130377292633057\n",
      "Seen so far: 157952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2468: 0.9951668977737427\n",
      "Seen so far: 158016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2469: 0.7999485731124878\n",
      "Seen so far: 158080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2470: 0.7676455974578857\n",
      "Seen so far: 158144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2471: 1.241358995437622\n",
      "Seen so far: 158208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2472: 1.1013821363449097\n",
      "Seen so far: 158272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2473: 0.8129523396492004\n",
      "Seen so far: 158336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2474: 1.479280710220337\n",
      "Seen so far: 158400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2475: 0.9620804190635681\n",
      "Seen so far: 158464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2476: 0.7475258111953735\n",
      "Seen so far: 158528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2477: 0.874975323677063\n",
      "Seen so far: 158592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2478: 1.246401309967041\n",
      "Seen so far: 158656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2479: 1.1383004188537598\n",
      "Seen so far: 158720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2480: 0.8856570720672607\n",
      "Seen so far: 158784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2481: 0.903308629989624\n",
      "Seen so far: 158848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2482: 0.9414618015289307\n",
      "Seen so far: 158912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2483: 0.9117639064788818\n",
      "Seen so far: 158976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2484: 0.8250883221626282\n",
      "Seen so far: 159040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2485: 0.7219672203063965\n",
      "Seen so far: 159104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2486: 1.171507477760315\n",
      "Seen so far: 159168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2487: 0.9828183054924011\n",
      "Seen so far: 159232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2488: 1.0906453132629395\n",
      "Seen so far: 159296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2489: 0.7685935497283936\n",
      "Seen so far: 159360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2490: 0.7499701976776123\n",
      "Seen so far: 159424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2491: 0.8749615550041199\n",
      "Seen so far: 159488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2492: 0.8794620037078857\n",
      "Seen so far: 159552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2493: 0.5685225129127502\n",
      "Seen so far: 159616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2494: 0.5983319878578186\n",
      "Seen so far: 159680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2495: 0.5676438212394714\n",
      "Seen so far: 159744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2496: 0.7598425149917603\n",
      "Seen so far: 159808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2497: 0.9960971474647522\n",
      "Seen so far: 159872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2498: 0.5999583005905151\n",
      "Seen so far: 159936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2499: 1.3745396137237549\n",
      "Seen so far: 160000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2500: 1.047410249710083\n",
      "Seen so far: 160064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2501: 0.8836947083473206\n",
      "Seen so far: 160128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2502: 0.7877268195152283\n",
      "Seen so far: 160192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2503: 0.9036495089530945\n",
      "Seen so far: 160256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2504: 1.1808353662490845\n",
      "Seen so far: 160320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2505: 1.3843841552734375\n",
      "Seen so far: 160384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2506: 0.8349874019622803\n",
      "Seen so far: 160448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2507: 0.8258578777313232\n",
      "Seen so far: 160512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2508: 0.8778893947601318\n",
      "Seen so far: 160576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2509: 1.0256001949310303\n",
      "Seen so far: 160640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2510: 1.1485695838928223\n",
      "Seen so far: 160704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2511: 1.1028276681900024\n",
      "Seen so far: 160768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2512: 0.6938813924789429\n",
      "Seen so far: 160832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2513: 0.8862618207931519\n",
      "Seen so far: 160896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2514: 0.8841485977172852\n",
      "Seen so far: 160960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2515: 0.8597036004066467\n",
      "Seen so far: 161024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2516: 0.9736734628677368\n",
      "Seen so far: 161088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2517: 0.946529746055603\n",
      "Seen so far: 161152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2518: 1.1493871212005615\n",
      "Seen so far: 161216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2519: 0.9133498072624207\n",
      "Seen so far: 161280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2520: 0.7233770489692688\n",
      "Seen so far: 161344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2521: 0.8547593355178833\n",
      "Seen so far: 161408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2522: 0.8135952949523926\n",
      "Seen so far: 161472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2523: 1.119604468345642\n",
      "Seen so far: 161536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2524: 0.8727264404296875\n",
      "Seen so far: 161600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2525: 0.876697838306427\n",
      "Seen so far: 161664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2526: 0.7199590802192688\n",
      "Seen so far: 161728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2527: 0.8453189134597778\n",
      "Seen so far: 161792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2528: 1.2058727741241455\n",
      "Seen so far: 161856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2529: 0.8837376236915588\n",
      "Seen so far: 161920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2530: 0.6955955028533936\n",
      "Seen so far: 161984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2531: 0.9029259085655212\n",
      "Seen so far: 162048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2532: 0.6096069812774658\n",
      "Seen so far: 162112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2533: 1.3335031270980835\n",
      "Seen so far: 162176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2534: 0.9729614853858948\n",
      "Seen so far: 162240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2535: 0.6960822939872742\n",
      "Seen so far: 162304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2536: 0.8806570768356323\n",
      "Seen so far: 162368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2537: 0.9969408512115479\n",
      "Seen so far: 162432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2538: 0.713545560836792\n",
      "Seen so far: 162496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2539: 1.1298381090164185\n",
      "Seen so far: 162560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2540: 1.3014907836914062\n",
      "Seen so far: 162624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2541: 1.6411032676696777\n",
      "Seen so far: 162688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2542: 0.7366452217102051\n",
      "Seen so far: 162752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2543: 1.0631103515625\n",
      "Seen so far: 162816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2544: 0.944865345954895\n",
      "Seen so far: 162880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2545: 1.1921586990356445\n",
      "Seen so far: 162944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2546: 0.5734581351280212\n",
      "Seen so far: 163008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2547: 1.1704944372177124\n",
      "Seen so far: 163072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2548: 1.190012812614441\n",
      "Seen so far: 163136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2549: 1.2662990093231201\n",
      "Seen so far: 163200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2550: 1.413602590560913\n",
      "Seen so far: 163264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2551: 0.8040840029716492\n",
      "Seen so far: 163328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2552: 0.4638950228691101\n",
      "Seen so far: 163392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2553: 1.030454158782959\n",
      "Seen so far: 163456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2554: 0.7442581653594971\n",
      "Seen so far: 163520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2555: 0.6884403228759766\n",
      "Seen so far: 163584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2556: 1.226436734199524\n",
      "Seen so far: 163648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2557: 0.6855202913284302\n",
      "Seen so far: 163712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2558: 0.6322250366210938\n",
      "Seen so far: 163776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2559: 1.1447107791900635\n",
      "Seen so far: 163840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2560: 1.1430741548538208\n",
      "Seen so far: 163904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2561: 1.0511996746063232\n",
      "Seen so far: 163968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2562: 0.6555310487747192\n",
      "Seen so far: 164032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2563: 0.8433291912078857\n",
      "Seen so far: 164096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2564: 1.0291156768798828\n",
      "Seen so far: 164160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2565: 0.5713632106781006\n",
      "Seen so far: 164224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2566: 1.1058269739151\n",
      "Seen so far: 164288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2567: 1.115450143814087\n",
      "Seen so far: 164352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2568: 1.2706125974655151\n",
      "Seen so far: 164416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2569: 0.8866157531738281\n",
      "Seen so far: 164480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2570: 0.8938968181610107\n",
      "Seen so far: 164544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2571: 0.704196572303772\n",
      "Seen so far: 164608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2572: 1.3794749975204468\n",
      "Seen so far: 164672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2573: 0.6810258626937866\n",
      "Seen so far: 164736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2574: 0.8706990480422974\n",
      "Seen so far: 164800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2575: 0.6273984313011169\n",
      "Seen so far: 164864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2576: 0.8225771188735962\n",
      "Seen so far: 164928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2577: 0.7169094085693359\n",
      "Seen so far: 164992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2578: 0.7487370371818542\n",
      "Seen so far: 165056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2579: 0.7422652840614319\n",
      "Seen so far: 165120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2580: 0.9111294746398926\n",
      "Seen so far: 165184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2581: 0.8114787340164185\n",
      "Seen so far: 165248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2582: 1.1404701471328735\n",
      "Seen so far: 165312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2583: 0.8122485280036926\n",
      "Seen so far: 165376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2584: 0.4379855990409851\n",
      "Seen so far: 165440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2585: 0.7934398651123047\n",
      "Seen so far: 165504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2586: 0.8667364120483398\n",
      "Seen so far: 165568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2587: 0.6884008049964905\n",
      "Seen so far: 165632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2588: 0.692642092704773\n",
      "Seen so far: 165696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2589: 0.9519643187522888\n",
      "Seen so far: 165760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2590: 0.9928487539291382\n",
      "Seen so far: 165824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2591: 0.9767943620681763\n",
      "Seen so far: 165888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2592: 0.8212593197822571\n",
      "Seen so far: 165952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2593: 1.0145783424377441\n",
      "Seen so far: 166016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2594: 1.0177069902420044\n",
      "Seen so far: 166080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2595: 0.9151118993759155\n",
      "Seen so far: 166144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2596: 0.860996663570404\n",
      "Seen so far: 166208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2597: 0.710384726524353\n",
      "Seen so far: 166272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2598: 1.0423805713653564\n",
      "Seen so far: 166336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2599: 0.8003484010696411\n",
      "Seen so far: 166400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2600: 0.9193856716156006\n",
      "Seen so far: 166464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2601: 0.6286717653274536\n",
      "Seen so far: 166528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2602: 0.6777567863464355\n",
      "Seen so far: 166592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2603: 0.7854283452033997\n",
      "Seen so far: 166656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2604: 0.8198500871658325\n",
      "Seen so far: 166720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2605: 0.7456918954849243\n",
      "Seen so far: 166784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2606: 0.8117181062698364\n",
      "Seen so far: 166848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2607: 1.490151047706604\n",
      "Seen so far: 166912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2608: 0.6692320108413696\n",
      "Seen so far: 166976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2609: 0.8141200542449951\n",
      "Seen so far: 167040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2610: 1.0456130504608154\n",
      "Seen so far: 167104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2611: 0.8717211484909058\n",
      "Seen so far: 167168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2612: 1.0813770294189453\n",
      "Seen so far: 167232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2613: 0.57765793800354\n",
      "Seen so far: 167296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2614: 1.0246589183807373\n",
      "Seen so far: 167360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2615: 0.7845464944839478\n",
      "Seen so far: 167424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2616: 0.6199219226837158\n",
      "Seen so far: 167488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2617: 0.8228071928024292\n",
      "Seen so far: 167552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2618: 0.8793748021125793\n",
      "Seen so far: 167616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2619: 1.3942034244537354\n",
      "Seen so far: 167680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2620: 0.693211555480957\n",
      "Seen so far: 167744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2621: 0.7858936786651611\n",
      "Seen so far: 167808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2622: 0.9827845096588135\n",
      "Seen so far: 167872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2623: 1.0581368207931519\n",
      "Seen so far: 167936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2624: 0.9897191524505615\n",
      "Seen so far: 168000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2625: 0.6971033215522766\n",
      "Seen so far: 168064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2626: 0.6141612529754639\n",
      "Seen so far: 168128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2627: 1.0719006061553955\n",
      "Seen so far: 168192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2628: 0.5640522241592407\n",
      "Seen so far: 168256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2629: 0.8667505979537964\n",
      "Seen so far: 168320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2630: 1.0240459442138672\n",
      "Seen so far: 168384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2631: 0.9341442584991455\n",
      "Seen so far: 168448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2632: 0.7530505657196045\n",
      "Seen so far: 168512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2633: 0.5934581756591797\n",
      "Seen so far: 168576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2634: 0.8522709608078003\n",
      "Seen so far: 168640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2635: 1.0392135381698608\n",
      "Seen so far: 168704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2636: 1.2834962606430054\n",
      "Seen so far: 168768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2637: 0.8109408020973206\n",
      "Seen so far: 168832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2638: 1.5963878631591797\n",
      "Seen so far: 168896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2639: 0.992255449295044\n",
      "Seen so far: 168960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2640: 0.7748408317565918\n",
      "Seen so far: 169024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2641: 0.6254576444625854\n",
      "Seen so far: 169088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2642: 0.6771076917648315\n",
      "Seen so far: 169152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2643: 1.2054510116577148\n",
      "Seen so far: 169216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2644: 0.6573693752288818\n",
      "Seen so far: 169280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2645: 1.1123749017715454\n",
      "Seen so far: 169344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2646: 0.675864577293396\n",
      "Seen so far: 169408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2647: 0.7750872373580933\n",
      "Seen so far: 169472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2648: 0.8997794389724731\n",
      "Seen so far: 169536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2649: 0.9858244061470032\n",
      "Seen so far: 169600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2650: 0.8943836092948914\n",
      "Seen so far: 169664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2651: 1.0911240577697754\n",
      "Seen so far: 169728 samples\n",
      "Training acc over epoch: 0.6978772282600403\n",
      "Start of epoch 5\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 0: 0.786419153213501\n",
      "Seen so far: 64 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1: 0.6110638380050659\n",
      "Seen so far: 128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2: 0.7211785912513733\n",
      "Seen so far: 192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 3: 0.8193231821060181\n",
      "Seen so far: 256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 4: 0.8043414354324341\n",
      "Seen so far: 320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 5: 1.40648353099823\n",
      "Seen so far: 384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 6: 1.173159122467041\n",
      "Seen so far: 448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 7: 0.9699591994285583\n",
      "Seen so far: 512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 8: 1.1738110780715942\n",
      "Seen so far: 576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 9: 0.8022081851959229\n",
      "Seen so far: 640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 10: 0.6947287321090698\n",
      "Seen so far: 704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 11: 0.54194575548172\n",
      "Seen so far: 768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 12: 0.5471407175064087\n",
      "Seen so far: 832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 13: 0.6516530513763428\n",
      "Seen so far: 896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 14: 1.2508087158203125\n",
      "Seen so far: 960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 15: 0.7112482190132141\n",
      "Seen so far: 1024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 16: 0.9714875221252441\n",
      "Seen so far: 1088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 17: 1.206718921661377\n",
      "Seen so far: 1152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 18: 0.9384346008300781\n",
      "Seen so far: 1216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 19: 1.0413687229156494\n",
      "Seen so far: 1280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 20: 0.9337895512580872\n",
      "Seen so far: 1344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 21: 1.1801528930664062\n",
      "Seen so far: 1408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 22: 1.0772695541381836\n",
      "Seen so far: 1472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 23: 1.4130929708480835\n",
      "Seen so far: 1536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 24: 0.6992053389549255\n",
      "Seen so far: 1600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 25: 0.7465164661407471\n",
      "Seen so far: 1664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 26: 0.9260717630386353\n",
      "Seen so far: 1728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 27: 1.438650131225586\n",
      "Seen so far: 1792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 28: 0.9026004076004028\n",
      "Seen so far: 1856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 29: 0.998154878616333\n",
      "Seen so far: 1920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 30: 0.8584599494934082\n",
      "Seen so far: 1984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 31: 0.9313809871673584\n",
      "Seen so far: 2048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 32: 1.1568806171417236\n",
      "Seen so far: 2112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 33: 0.8265269994735718\n",
      "Seen so far: 2176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 34: 1.037408709526062\n",
      "Seen so far: 2240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 35: 0.9433435797691345\n",
      "Seen so far: 2304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 36: 0.6208497881889343\n",
      "Seen so far: 2368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 37: 1.044204831123352\n",
      "Seen so far: 2432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 38: 1.026407241821289\n",
      "Seen so far: 2496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 39: 0.9173809289932251\n",
      "Seen so far: 2560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 40: 0.8477323651313782\n",
      "Seen so far: 2624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 41: 1.1766999959945679\n",
      "Seen so far: 2688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 42: 0.9778164625167847\n",
      "Seen so far: 2752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 43: 0.730482816696167\n",
      "Seen so far: 2816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 44: 1.0168824195861816\n",
      "Seen so far: 2880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 45: 1.0624723434448242\n",
      "Seen so far: 2944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 46: 0.8243799209594727\n",
      "Seen so far: 3008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 47: 0.5762672424316406\n",
      "Seen so far: 3072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 48: 1.0750415325164795\n",
      "Seen so far: 3136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 49: 0.6451470851898193\n",
      "Seen so far: 3200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 50: 1.0755053758621216\n",
      "Seen so far: 3264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 51: 1.0432448387145996\n",
      "Seen so far: 3328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 52: 0.7099519371986389\n",
      "Seen so far: 3392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 53: 0.7249684929847717\n",
      "Seen so far: 3456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 54: 0.5375062227249146\n",
      "Seen so far: 3520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 55: 1.0269787311553955\n",
      "Seen so far: 3584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 56: 1.1559852361679077\n",
      "Seen so far: 3648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 57: 1.4400588274002075\n",
      "Seen so far: 3712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 58: 0.48262184858322144\n",
      "Seen so far: 3776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 59: 0.6434576511383057\n",
      "Seen so far: 3840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 60: 0.3661959171295166\n",
      "Seen so far: 3904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 61: 0.4927366375923157\n",
      "Seen so far: 3968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 62: 1.0615143775939941\n",
      "Seen so far: 4032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 63: 1.0100152492523193\n",
      "Seen so far: 4096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 64: 0.6322957873344421\n",
      "Seen so far: 4160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 65: 0.8476494550704956\n",
      "Seen so far: 4224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 66: 1.6014811992645264\n",
      "Seen so far: 4288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 67: 1.3157761096954346\n",
      "Seen so far: 4352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 68: 1.1481096744537354\n",
      "Seen so far: 4416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 69: 0.6151424646377563\n",
      "Seen so far: 4480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 70: 0.6597088575363159\n",
      "Seen so far: 4544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 71: 0.9749864339828491\n",
      "Seen so far: 4608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 72: 1.0732251405715942\n",
      "Seen so far: 4672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 73: 0.7765699028968811\n",
      "Seen so far: 4736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 74: 1.0934823751449585\n",
      "Seen so far: 4800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 75: 0.9616525173187256\n",
      "Seen so far: 4864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 76: 1.245286226272583\n",
      "Seen so far: 4928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 77: 0.6478592157363892\n",
      "Seen so far: 4992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 78: 0.6509466171264648\n",
      "Seen so far: 5056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 79: 1.2825828790664673\n",
      "Seen so far: 5120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 80: 0.5483901500701904\n",
      "Seen so far: 5184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 81: 0.9774395823478699\n",
      "Seen so far: 5248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 82: 1.1913235187530518\n",
      "Seen so far: 5312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 83: 1.0048222541809082\n",
      "Seen so far: 5376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 84: 1.0127592086791992\n",
      "Seen so far: 5440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 85: 1.0155086517333984\n",
      "Seen so far: 5504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 86: 0.9165068864822388\n",
      "Seen so far: 5568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 87: 0.9582498073577881\n",
      "Seen so far: 5632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 88: 0.8396203517913818\n",
      "Seen so far: 5696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 89: 1.0234354734420776\n",
      "Seen so far: 5760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 90: 0.9576058983802795\n",
      "Seen so far: 5824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 91: 1.189345121383667\n",
      "Seen so far: 5888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 92: 0.7773165702819824\n",
      "Seen so far: 5952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 93: 0.9968684315681458\n",
      "Seen so far: 6016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 94: 1.0015568733215332\n",
      "Seen so far: 6080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 95: 0.5234618186950684\n",
      "Seen so far: 6144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 96: 0.9963507652282715\n",
      "Seen so far: 6208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 97: 0.9674798846244812\n",
      "Seen so far: 6272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 98: 0.7995181083679199\n",
      "Seen so far: 6336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 99: 0.9871129989624023\n",
      "Seen so far: 6400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 100: 0.8305959701538086\n",
      "Seen so far: 6464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 101: 0.6336047053337097\n",
      "Seen so far: 6528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 102: 0.8355961441993713\n",
      "Seen so far: 6592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 103: 0.7950723171234131\n",
      "Seen so far: 6656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 104: 0.9284030199050903\n",
      "Seen so far: 6720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 105: 1.0101925134658813\n",
      "Seen so far: 6784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 106: 0.7230302095413208\n",
      "Seen so far: 6848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 107: 0.9077420830726624\n",
      "Seen so far: 6912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 108: 0.8734689354896545\n",
      "Seen so far: 6976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 109: 0.9899294376373291\n",
      "Seen so far: 7040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 110: 0.6853452920913696\n",
      "Seen so far: 7104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 111: 0.8350021839141846\n",
      "Seen so far: 7168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 112: 0.7484437227249146\n",
      "Seen so far: 7232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 113: 1.1132142543792725\n",
      "Seen so far: 7296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 114: 1.0824048519134521\n",
      "Seen so far: 7360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 115: 0.6844726800918579\n",
      "Seen so far: 7424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 116: 1.0235326290130615\n",
      "Seen so far: 7488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 117: 1.2272628545761108\n",
      "Seen so far: 7552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 118: 1.0843777656555176\n",
      "Seen so far: 7616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 119: 0.6223602294921875\n",
      "Seen so far: 7680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 120: 0.9867849349975586\n",
      "Seen so far: 7744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 121: 1.129634976387024\n",
      "Seen so far: 7808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 122: 1.2231309413909912\n",
      "Seen so far: 7872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 123: 0.6895877122879028\n",
      "Seen so far: 7936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 124: 1.0556690692901611\n",
      "Seen so far: 8000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 125: 0.9779001474380493\n",
      "Seen so far: 8064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 126: 0.6416381597518921\n",
      "Seen so far: 8128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 127: 1.2447290420532227\n",
      "Seen so far: 8192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 128: 0.6233295798301697\n",
      "Seen so far: 8256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 129: 1.0200549364089966\n",
      "Seen so far: 8320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 130: 1.0690404176712036\n",
      "Seen so far: 8384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 131: 1.2481331825256348\n",
      "Seen so far: 8448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 132: 0.7130609154701233\n",
      "Seen so far: 8512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 133: 0.7878808975219727\n",
      "Seen so far: 8576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 134: 0.8861780166625977\n",
      "Seen so far: 8640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 135: 1.1331579685211182\n",
      "Seen so far: 8704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 136: 1.1915943622589111\n",
      "Seen so far: 8768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 137: 1.3028876781463623\n",
      "Seen so far: 8832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 138: 0.6173310279846191\n",
      "Seen so far: 8896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 139: 1.0167309045791626\n",
      "Seen so far: 8960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 140: 0.9407285451889038\n",
      "Seen so far: 9024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 141: 1.0801101922988892\n",
      "Seen so far: 9088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 142: 0.6357599496841431\n",
      "Seen so far: 9152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 143: 1.0007778406143188\n",
      "Seen so far: 9216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 144: 0.9967442750930786\n",
      "Seen so far: 9280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 145: 0.7581547498703003\n",
      "Seen so far: 9344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 146: 0.77605140209198\n",
      "Seen so far: 9408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 147: 1.0911426544189453\n",
      "Seen so far: 9472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 148: 1.3873180150985718\n",
      "Seen so far: 9536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 149: 0.8336919546127319\n",
      "Seen so far: 9600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 150: 0.5939401388168335\n",
      "Seen so far: 9664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 151: 0.6806526184082031\n",
      "Seen so far: 9728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 152: 1.3498268127441406\n",
      "Seen so far: 9792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 153: 1.1501502990722656\n",
      "Seen so far: 9856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 154: 1.6119378805160522\n",
      "Seen so far: 9920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 155: 0.9663819074630737\n",
      "Seen so far: 9984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 156: 1.1029034852981567\n",
      "Seen so far: 10048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 157: 0.9341752529144287\n",
      "Seen so far: 10112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 158: 1.4025001525878906\n",
      "Seen so far: 10176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 159: 1.200242042541504\n",
      "Seen so far: 10240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 160: 0.8778793811798096\n",
      "Seen so far: 10304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 161: 0.9830922484397888\n",
      "Seen so far: 10368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 162: 1.1132460832595825\n",
      "Seen so far: 10432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 163: 0.9843084812164307\n",
      "Seen so far: 10496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 164: 1.047248125076294\n",
      "Seen so far: 10560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 165: 0.9521533846855164\n",
      "Seen so far: 10624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 166: 0.8430590629577637\n",
      "Seen so far: 10688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 167: 0.7953795194625854\n",
      "Seen so far: 10752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 168: 0.9965804815292358\n",
      "Seen so far: 10816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 169: 0.6499330997467041\n",
      "Seen so far: 10880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 170: 1.0622286796569824\n",
      "Seen so far: 10944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 171: 1.0221905708312988\n",
      "Seen so far: 11008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 172: 1.068105936050415\n",
      "Seen so far: 11072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 173: 0.9045419692993164\n",
      "Seen so far: 11136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 174: 1.0010170936584473\n",
      "Seen so far: 11200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 175: 0.9053877592086792\n",
      "Seen so far: 11264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 176: 1.0713562965393066\n",
      "Seen so far: 11328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 177: 0.6320308446884155\n",
      "Seen so far: 11392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 178: 0.8151469826698303\n",
      "Seen so far: 11456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 179: 0.857527494430542\n",
      "Seen so far: 11520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 180: 0.9366863965988159\n",
      "Seen so far: 11584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 181: 0.8118269443511963\n",
      "Seen so far: 11648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 182: 0.8110603094100952\n",
      "Seen so far: 11712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 183: 1.1230463981628418\n",
      "Seen so far: 11776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 184: 0.9753066301345825\n",
      "Seen so far: 11840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 185: 1.0152087211608887\n",
      "Seen so far: 11904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 186: 0.9653868675231934\n",
      "Seen so far: 11968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 187: 1.1728765964508057\n",
      "Seen so far: 12032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 188: 1.3169901371002197\n",
      "Seen so far: 12096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 189: 0.9708151817321777\n",
      "Seen so far: 12160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 190: 1.0730897188186646\n",
      "Seen so far: 12224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 191: 0.46901458501815796\n",
      "Seen so far: 12288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 192: 0.9466581344604492\n",
      "Seen so far: 12352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 193: 1.1100547313690186\n",
      "Seen so far: 12416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 194: 1.1454490423202515\n",
      "Seen so far: 12480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 195: 0.8782327175140381\n",
      "Seen so far: 12544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 196: 0.4749886989593506\n",
      "Seen so far: 12608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 197: 0.8369172811508179\n",
      "Seen so far: 12672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 198: 1.2898848056793213\n",
      "Seen so far: 12736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 199: 0.7587676048278809\n",
      "Seen so far: 12800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 200: 0.8527991771697998\n",
      "Seen so far: 12864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 201: 0.723340630531311\n",
      "Seen so far: 12928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 202: 1.0200837850570679\n",
      "Seen so far: 12992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 203: 0.836940348148346\n",
      "Seen so far: 13056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 204: 1.0642778873443604\n",
      "Seen so far: 13120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 205: 0.6015665531158447\n",
      "Seen so far: 13184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 206: 1.316904902458191\n",
      "Seen so far: 13248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 207: 0.8218116760253906\n",
      "Seen so far: 13312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 208: 1.0970218181610107\n",
      "Seen so far: 13376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 209: 0.8560640215873718\n",
      "Seen so far: 13440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 210: 1.0603327751159668\n",
      "Seen so far: 13504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 211: 0.8751157522201538\n",
      "Seen so far: 13568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 212: 1.3788671493530273\n",
      "Seen so far: 13632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 213: 0.9463374018669128\n",
      "Seen so far: 13696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 214: 1.0122158527374268\n",
      "Seen so far: 13760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 215: 0.9098665714263916\n",
      "Seen so far: 13824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 216: 0.6563381552696228\n",
      "Seen so far: 13888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 217: 0.8724819421768188\n",
      "Seen so far: 13952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 218: 0.7892593741416931\n",
      "Seen so far: 14016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 219: 0.5244377851486206\n",
      "Seen so far: 14080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 220: 0.86241614818573\n",
      "Seen so far: 14144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 221: 0.782791793346405\n",
      "Seen so far: 14208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 222: 0.8440696597099304\n",
      "Seen so far: 14272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 223: 0.9370430707931519\n",
      "Seen so far: 14336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 224: 0.5468730926513672\n",
      "Seen so far: 14400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 225: 0.8914755582809448\n",
      "Seen so far: 14464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 226: 0.5675431489944458\n",
      "Seen so far: 14528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 227: 0.8445305824279785\n",
      "Seen so far: 14592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 228: 0.8484697937965393\n",
      "Seen so far: 14656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 229: 1.1329429149627686\n",
      "Seen so far: 14720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 230: 0.7701950669288635\n",
      "Seen so far: 14784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 231: 0.9394121766090393\n",
      "Seen so far: 14848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 232: 0.8899081945419312\n",
      "Seen so far: 14912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 233: 1.1796202659606934\n",
      "Seen so far: 14976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 234: 0.8274002075195312\n",
      "Seen so far: 15040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 235: 0.43808722496032715\n",
      "Seen so far: 15104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 236: 0.8341571092605591\n",
      "Seen so far: 15168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 237: 0.9151824116706848\n",
      "Seen so far: 15232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 238: 1.0921705961227417\n",
      "Seen so far: 15296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 239: 1.0007672309875488\n",
      "Seen so far: 15360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 240: 1.1577098369598389\n",
      "Seen so far: 15424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 241: 1.0528943538665771\n",
      "Seen so far: 15488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 242: 1.3355638980865479\n",
      "Seen so far: 15552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 243: 0.9118095636367798\n",
      "Seen so far: 15616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 244: 0.9545737504959106\n",
      "Seen so far: 15680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 245: 1.1421513557434082\n",
      "Seen so far: 15744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 246: 1.1384243965148926\n",
      "Seen so far: 15808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 247: 1.1547966003417969\n",
      "Seen so far: 15872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 248: 0.7280157804489136\n",
      "Seen so far: 15936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 249: 0.5819028615951538\n",
      "Seen so far: 16000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 250: 1.1407490968704224\n",
      "Seen so far: 16064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 251: 1.2187535762786865\n",
      "Seen so far: 16128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 252: 1.0379666090011597\n",
      "Seen so far: 16192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 253: 0.8972702026367188\n",
      "Seen so far: 16256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 254: 0.8475610613822937\n",
      "Seen so far: 16320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 255: 1.1153770685195923\n",
      "Seen so far: 16384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 256: 1.0463539361953735\n",
      "Seen so far: 16448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 257: 1.3525128364562988\n",
      "Seen so far: 16512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 258: 0.7083008289337158\n",
      "Seen so far: 16576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 259: 0.8316495418548584\n",
      "Seen so far: 16640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 260: 0.44065260887145996\n",
      "Seen so far: 16704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 261: 1.0182586908340454\n",
      "Seen so far: 16768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 262: 1.3508678674697876\n",
      "Seen so far: 16832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 263: 0.9915543794631958\n",
      "Seen so far: 16896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 264: 0.6246979832649231\n",
      "Seen so far: 16960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 265: 1.0070676803588867\n",
      "Seen so far: 17024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 266: 0.6863946318626404\n",
      "Seen so far: 17088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 267: 0.9789401292800903\n",
      "Seen so far: 17152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 268: 0.9310910701751709\n",
      "Seen so far: 17216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 269: 0.8673477172851562\n",
      "Seen so far: 17280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 270: 0.5415141582489014\n",
      "Seen so far: 17344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 271: 1.1865582466125488\n",
      "Seen so far: 17408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 272: 0.7313463687896729\n",
      "Seen so far: 17472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 273: 1.1046693325042725\n",
      "Seen so far: 17536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 274: 1.2040421962738037\n",
      "Seen so far: 17600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 275: 0.6633592844009399\n",
      "Seen so far: 17664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 276: 1.135221004486084\n",
      "Seen so far: 17728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 277: 1.201709508895874\n",
      "Seen so far: 17792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 278: 0.7774409055709839\n",
      "Seen so far: 17856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 279: 1.3863747119903564\n",
      "Seen so far: 17920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 280: 0.6055694818496704\n",
      "Seen so far: 17984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 281: 0.8330821990966797\n",
      "Seen so far: 18048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 282: 0.7839794754981995\n",
      "Seen so far: 18112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 283: 0.5162566900253296\n",
      "Seen so far: 18176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 284: 0.4009689390659332\n",
      "Seen so far: 18240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 285: 0.5850588083267212\n",
      "Seen so far: 18304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 286: 0.739942193031311\n",
      "Seen so far: 18368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 287: 0.6261072158813477\n",
      "Seen so far: 18432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 288: 0.8789424300193787\n",
      "Seen so far: 18496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 289: 0.9680648446083069\n",
      "Seen so far: 18560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 290: 1.1478540897369385\n",
      "Seen so far: 18624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 291: 0.5321836471557617\n",
      "Seen so far: 18688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 292: 1.1284348964691162\n",
      "Seen so far: 18752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 293: 1.316498041152954\n",
      "Seen so far: 18816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 294: 0.5646331310272217\n",
      "Seen so far: 18880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 295: 1.030088186264038\n",
      "Seen so far: 18944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 296: 0.8401298522949219\n",
      "Seen so far: 19008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 297: 0.6856076121330261\n",
      "Seen so far: 19072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 298: 0.7369793653488159\n",
      "Seen so far: 19136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 299: 1.395850419998169\n",
      "Seen so far: 19200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 300: 0.717469334602356\n",
      "Seen so far: 19264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 301: 0.738548219203949\n",
      "Seen so far: 19328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 302: 0.8405617475509644\n",
      "Seen so far: 19392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 303: 0.6565154790878296\n",
      "Seen so far: 19456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 304: 0.9751842021942139\n",
      "Seen so far: 19520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 305: 0.81029212474823\n",
      "Seen so far: 19584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 306: 1.094287395477295\n",
      "Seen so far: 19648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 307: 0.9196107387542725\n",
      "Seen so far: 19712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 308: 1.1483118534088135\n",
      "Seen so far: 19776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 309: 0.6546950340270996\n",
      "Seen so far: 19840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 310: 0.9211703538894653\n",
      "Seen so far: 19904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 311: 0.9040275812149048\n",
      "Seen so far: 19968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 312: 1.021968126296997\n",
      "Seen so far: 20032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 313: 1.0292422771453857\n",
      "Seen so far: 20096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 314: 0.9286289811134338\n",
      "Seen so far: 20160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 315: 0.6778243184089661\n",
      "Seen so far: 20224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 316: 0.9415270686149597\n",
      "Seen so far: 20288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 317: 0.9810853600502014\n",
      "Seen so far: 20352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 318: 1.046425223350525\n",
      "Seen so far: 20416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 319: 0.929783046245575\n",
      "Seen so far: 20480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 320: 0.9810971021652222\n",
      "Seen so far: 20544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 321: 0.8765774965286255\n",
      "Seen so far: 20608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 322: 1.0223119258880615\n",
      "Seen so far: 20672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 323: 1.0036696195602417\n",
      "Seen so far: 20736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 324: 1.0152294635772705\n",
      "Seen so far: 20800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 325: 0.7190802097320557\n",
      "Seen so far: 20864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 326: 0.9040488600730896\n",
      "Seen so far: 20928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 327: 1.1431865692138672\n",
      "Seen so far: 20992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 328: 0.9919667840003967\n",
      "Seen so far: 21056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 329: 1.0833196640014648\n",
      "Seen so far: 21120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 330: 0.7575064897537231\n",
      "Seen so far: 21184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 331: 0.7899370193481445\n",
      "Seen so far: 21248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 332: 0.9665514826774597\n",
      "Seen so far: 21312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 333: 1.1994192600250244\n",
      "Seen so far: 21376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 334: 0.9826473593711853\n",
      "Seen so far: 21440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 335: 1.2204530239105225\n",
      "Seen so far: 21504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 336: 0.9287561178207397\n",
      "Seen so far: 21568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 337: 0.803541898727417\n",
      "Seen so far: 21632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 338: 0.797203779220581\n",
      "Seen so far: 21696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 339: 0.630888819694519\n",
      "Seen so far: 21760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 340: 0.6368640661239624\n",
      "Seen so far: 21824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 341: 1.0203163623809814\n",
      "Seen so far: 21888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 342: 1.0067521333694458\n",
      "Seen so far: 21952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 343: 1.409624457359314\n",
      "Seen so far: 22016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 344: 0.9709451794624329\n",
      "Seen so far: 22080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 345: 0.8092962503433228\n",
      "Seen so far: 22144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 346: 0.5780249834060669\n",
      "Seen so far: 22208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 347: 1.2375227212905884\n",
      "Seen so far: 22272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 348: 0.4416291415691376\n",
      "Seen so far: 22336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 349: 0.8419799208641052\n",
      "Seen so far: 22400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 350: 1.2044720649719238\n",
      "Seen so far: 22464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 351: 0.6128344535827637\n",
      "Seen so far: 22528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 352: 0.9729395508766174\n",
      "Seen so far: 22592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 353: 1.060813546180725\n",
      "Seen so far: 22656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 354: 0.8906495571136475\n",
      "Seen so far: 22720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 355: 1.0104812383651733\n",
      "Seen so far: 22784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 356: 0.5409160256385803\n",
      "Seen so far: 22848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 357: 0.9131147861480713\n",
      "Seen so far: 22912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 358: 0.9004091620445251\n",
      "Seen so far: 22976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 359: 0.9824069738388062\n",
      "Seen so far: 23040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 360: 1.063976764678955\n",
      "Seen so far: 23104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 361: 0.7525403499603271\n",
      "Seen so far: 23168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 362: 1.0325353145599365\n",
      "Seen so far: 23232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 363: 0.9611263871192932\n",
      "Seen so far: 23296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 364: 1.078921914100647\n",
      "Seen so far: 23360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 365: 1.1694624423980713\n",
      "Seen so far: 23424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 366: 1.1702773571014404\n",
      "Seen so far: 23488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 367: 0.8626389503479004\n",
      "Seen so far: 23552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 368: 0.9824017882347107\n",
      "Seen so far: 23616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 369: 1.0920732021331787\n",
      "Seen so far: 23680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 370: 0.5711972713470459\n",
      "Seen so far: 23744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 371: 1.048069953918457\n",
      "Seen so far: 23808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 372: 0.5079743266105652\n",
      "Seen so far: 23872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 373: 1.0453349351882935\n",
      "Seen so far: 23936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 374: 0.8399642705917358\n",
      "Seen so far: 24000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 375: 0.8596808314323425\n",
      "Seen so far: 24064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 376: 0.7553616762161255\n",
      "Seen so far: 24128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 377: 1.4255238771438599\n",
      "Seen so far: 24192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 378: 0.6804731488227844\n",
      "Seen so far: 24256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 379: 0.7286727428436279\n",
      "Seen so far: 24320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 380: 0.9714405536651611\n",
      "Seen so far: 24384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 381: 0.8786171674728394\n",
      "Seen so far: 24448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 382: 0.7721701264381409\n",
      "Seen so far: 24512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 383: 0.9930551052093506\n",
      "Seen so far: 24576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 384: 0.8866169452667236\n",
      "Seen so far: 24640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 385: 1.0827994346618652\n",
      "Seen so far: 24704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 386: 1.406114101409912\n",
      "Seen so far: 24768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 387: 0.8145448565483093\n",
      "Seen so far: 24832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 388: 1.319106936454773\n",
      "Seen so far: 24896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 389: 0.7700588703155518\n",
      "Seen so far: 24960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 390: 1.157528281211853\n",
      "Seen so far: 25024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 391: 0.529390811920166\n",
      "Seen so far: 25088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 392: 1.0003902912139893\n",
      "Seen so far: 25152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 393: 1.04935622215271\n",
      "Seen so far: 25216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 394: 0.5615846514701843\n",
      "Seen so far: 25280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 395: 1.34759521484375\n",
      "Seen so far: 25344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 396: 1.0008423328399658\n",
      "Seen so far: 25408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 397: 1.235620379447937\n",
      "Seen so far: 25472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 398: 0.7097189426422119\n",
      "Seen so far: 25536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 399: 1.0546891689300537\n",
      "Seen so far: 25600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 400: 0.8357789516448975\n",
      "Seen so far: 25664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 401: 0.7730778455734253\n",
      "Seen so far: 25728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 402: 1.0054535865783691\n",
      "Seen so far: 25792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 403: 0.8541166186332703\n",
      "Seen so far: 25856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 404: 0.7350115776062012\n",
      "Seen so far: 25920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 405: 0.9360199570655823\n",
      "Seen so far: 25984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 406: 1.044592261314392\n",
      "Seen so far: 26048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 407: 0.8515860438346863\n",
      "Seen so far: 26112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 408: 1.0190149545669556\n",
      "Seen so far: 26176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 409: 1.003676176071167\n",
      "Seen so far: 26240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 410: 0.5467760562896729\n",
      "Seen so far: 26304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 411: 1.1867254972457886\n",
      "Seen so far: 26368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 412: 1.146494746208191\n",
      "Seen so far: 26432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 413: 0.8484805226325989\n",
      "Seen so far: 26496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 414: 0.46299809217453003\n",
      "Seen so far: 26560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 415: 0.9185418486595154\n",
      "Seen so far: 26624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 416: 0.9948269128799438\n",
      "Seen so far: 26688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 417: 0.9817126989364624\n",
      "Seen so far: 26752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 418: 1.0339840650558472\n",
      "Seen so far: 26816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 419: 1.6150457859039307\n",
      "Seen so far: 26880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 420: 0.9145013093948364\n",
      "Seen so far: 26944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 421: 1.4720818996429443\n",
      "Seen so far: 27008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 422: 0.7689241170883179\n",
      "Seen so far: 27072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 423: 0.9099494218826294\n",
      "Seen so far: 27136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 424: 0.9932500123977661\n",
      "Seen so far: 27200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 425: 1.0022032260894775\n",
      "Seen so far: 27264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 426: 1.070946216583252\n",
      "Seen so far: 27328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 427: 1.1478359699249268\n",
      "Seen so far: 27392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 428: 0.8905320167541504\n",
      "Seen so far: 27456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 429: 0.8134454488754272\n",
      "Seen so far: 27520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 430: 1.0828702449798584\n",
      "Seen so far: 27584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 431: 0.8074566125869751\n",
      "Seen so far: 27648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 432: 1.1378765106201172\n",
      "Seen so far: 27712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 433: 0.6177552938461304\n",
      "Seen so far: 27776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 434: 0.7693431377410889\n",
      "Seen so far: 27840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 435: 0.9879757761955261\n",
      "Seen so far: 27904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 436: 0.827866792678833\n",
      "Seen so far: 27968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 437: 0.8700652122497559\n",
      "Seen so far: 28032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 438: 1.1378121376037598\n",
      "Seen so far: 28096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 439: 0.8390873670578003\n",
      "Seen so far: 28160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 440: 0.9766338467597961\n",
      "Seen so far: 28224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 441: 1.1247172355651855\n",
      "Seen so far: 28288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 442: 0.929015040397644\n",
      "Seen so far: 28352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 443: 0.484348326921463\n",
      "Seen so far: 28416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 444: 1.1814374923706055\n",
      "Seen so far: 28480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 445: 1.117904782295227\n",
      "Seen so far: 28544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 446: 0.7634127140045166\n",
      "Seen so far: 28608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 447: 0.8461796641349792\n",
      "Seen so far: 28672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 448: 0.8600590229034424\n",
      "Seen so far: 28736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 449: 0.8020375967025757\n",
      "Seen so far: 28800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 450: 1.257825255393982\n",
      "Seen so far: 28864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 451: 0.9637731909751892\n",
      "Seen so far: 28928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 452: 1.129613995552063\n",
      "Seen so far: 28992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 453: 0.9371174573898315\n",
      "Seen so far: 29056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 454: 0.9058221578598022\n",
      "Seen so far: 29120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 455: 0.7221127152442932\n",
      "Seen so far: 29184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 456: 0.9355738162994385\n",
      "Seen so far: 29248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 457: 0.7281522750854492\n",
      "Seen so far: 29312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 458: 1.2942368984222412\n",
      "Seen so far: 29376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 459: 0.8862455487251282\n",
      "Seen so far: 29440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 460: 1.1126611232757568\n",
      "Seen so far: 29504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 461: 0.9167648553848267\n",
      "Seen so far: 29568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 462: 0.9452798366546631\n",
      "Seen so far: 29632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 463: 1.0137121677398682\n",
      "Seen so far: 29696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 464: 0.9411285519599915\n",
      "Seen so far: 29760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 465: 0.6762601137161255\n",
      "Seen so far: 29824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 466: 0.921872615814209\n",
      "Seen so far: 29888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 467: 0.8750624656677246\n",
      "Seen so far: 29952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 468: 0.9087415933609009\n",
      "Seen so far: 30016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 469: 0.7911514043807983\n",
      "Seen so far: 30080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 470: 0.561398983001709\n",
      "Seen so far: 30144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 471: 0.7427040934562683\n",
      "Seen so far: 30208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 472: 0.7937101125717163\n",
      "Seen so far: 30272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 473: 0.8631974458694458\n",
      "Seen so far: 30336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 474: 0.6441315412521362\n",
      "Seen so far: 30400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 475: 0.9883768558502197\n",
      "Seen so far: 30464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 476: 0.8765485286712646\n",
      "Seen so far: 30528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 477: 0.8087558746337891\n",
      "Seen so far: 30592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 478: 0.8578331470489502\n",
      "Seen so far: 30656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 479: 1.0116844177246094\n",
      "Seen so far: 30720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 480: 0.7156531810760498\n",
      "Seen so far: 30784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 481: 0.7698007822036743\n",
      "Seen so far: 30848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 482: 0.5983574390411377\n",
      "Seen so far: 30912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 483: 0.9689773917198181\n",
      "Seen so far: 30976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 484: 0.7023919224739075\n",
      "Seen so far: 31040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 485: 0.7585278749465942\n",
      "Seen so far: 31104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 486: 1.086438536643982\n",
      "Seen so far: 31168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 487: 0.836951494216919\n",
      "Seen so far: 31232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 488: 1.0787798166275024\n",
      "Seen so far: 31296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 489: 1.1172560453414917\n",
      "Seen so far: 31360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 490: 0.7735609412193298\n",
      "Seen so far: 31424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 491: 0.9215700626373291\n",
      "Seen so far: 31488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 492: 0.7869200706481934\n",
      "Seen so far: 31552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 493: 0.9204719066619873\n",
      "Seen so far: 31616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 494: 0.9412837028503418\n",
      "Seen so far: 31680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 495: 0.7927476167678833\n",
      "Seen so far: 31744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 496: 0.9458329677581787\n",
      "Seen so far: 31808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 497: 0.9632846117019653\n",
      "Seen so far: 31872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 498: 0.9086155891418457\n",
      "Seen so far: 31936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 499: 1.201468586921692\n",
      "Seen so far: 32000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 500: 0.6989138722419739\n",
      "Seen so far: 32064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 501: 0.8837589025497437\n",
      "Seen so far: 32128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 502: 0.6525363922119141\n",
      "Seen so far: 32192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 503: 0.6902377605438232\n",
      "Seen so far: 32256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 504: 1.3926124572753906\n",
      "Seen so far: 32320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 505: 0.9396877884864807\n",
      "Seen so far: 32384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 506: 1.242416262626648\n",
      "Seen so far: 32448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 507: 1.3783414363861084\n",
      "Seen so far: 32512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 508: 0.8871027827262878\n",
      "Seen so far: 32576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 509: 0.7662385702133179\n",
      "Seen so far: 32640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 510: 0.8494536876678467\n",
      "Seen so far: 32704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 511: 1.1000971794128418\n",
      "Seen so far: 32768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 512: 1.0783742666244507\n",
      "Seen so far: 32832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 513: 1.2458961009979248\n",
      "Seen so far: 32896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 514: 0.6755479574203491\n",
      "Seen so far: 32960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 515: 0.6879897117614746\n",
      "Seen so far: 33024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 516: 0.817176103591919\n",
      "Seen so far: 33088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 517: 1.0516047477722168\n",
      "Seen so far: 33152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 518: 0.9160643815994263\n",
      "Seen so far: 33216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 519: 0.9495077133178711\n",
      "Seen so far: 33280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 520: 0.9932931661605835\n",
      "Seen so far: 33344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 521: 0.7995206117630005\n",
      "Seen so far: 33408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 522: 0.7641188502311707\n",
      "Seen so far: 33472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 523: 0.8717166185379028\n",
      "Seen so far: 33536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 524: 0.9132457971572876\n",
      "Seen so far: 33600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 525: 0.8521251678466797\n",
      "Seen so far: 33664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 526: 1.0782105922698975\n",
      "Seen so far: 33728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 527: 1.0955476760864258\n",
      "Seen so far: 33792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 528: 0.8295338749885559\n",
      "Seen so far: 33856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 529: 0.6887884140014648\n",
      "Seen so far: 33920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 530: 0.9067260026931763\n",
      "Seen so far: 33984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 531: 0.4978715479373932\n",
      "Seen so far: 34048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 532: 1.0242942571640015\n",
      "Seen so far: 34112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 533: 1.3020597696304321\n",
      "Seen so far: 34176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 534: 0.7782158851623535\n",
      "Seen so far: 34240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 535: 1.0015109777450562\n",
      "Seen so far: 34304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 536: 0.8415371179580688\n",
      "Seen so far: 34368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 537: 0.9847524762153625\n",
      "Seen so far: 34432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 538: 0.6634965538978577\n",
      "Seen so far: 34496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 539: 0.6789946556091309\n",
      "Seen so far: 34560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 540: 1.003732442855835\n",
      "Seen so far: 34624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 541: 0.9003474712371826\n",
      "Seen so far: 34688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 542: 0.5762070417404175\n",
      "Seen so far: 34752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 543: 0.7161444425582886\n",
      "Seen so far: 34816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 544: 0.7148152589797974\n",
      "Seen so far: 34880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 545: 1.0495188236236572\n",
      "Seen so far: 34944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 546: 0.9505279064178467\n",
      "Seen so far: 35008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 547: 0.9797513484954834\n",
      "Seen so far: 35072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 548: 1.063051462173462\n",
      "Seen so far: 35136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 549: 0.7985475659370422\n",
      "Seen so far: 35200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 550: 0.8863559365272522\n",
      "Seen so far: 35264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 551: 0.5742106437683105\n",
      "Seen so far: 35328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 552: 0.8269947171211243\n",
      "Seen so far: 35392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 553: 1.084101915359497\n",
      "Seen so far: 35456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 554: 0.9303156137466431\n",
      "Seen so far: 35520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 555: 1.0403969287872314\n",
      "Seen so far: 35584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 556: 0.9045734405517578\n",
      "Seen so far: 35648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 557: 1.056091070175171\n",
      "Seen so far: 35712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 558: 0.610936164855957\n",
      "Seen so far: 35776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 559: 0.9822627305984497\n",
      "Seen so far: 35840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 560: 0.8270965814590454\n",
      "Seen so far: 35904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 561: 0.7121952772140503\n",
      "Seen so far: 35968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 562: 1.0740115642547607\n",
      "Seen so far: 36032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 563: 1.0438557863235474\n",
      "Seen so far: 36096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 564: 0.6719943284988403\n",
      "Seen so far: 36160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 565: 0.7871742248535156\n",
      "Seen so far: 36224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 566: 0.6601198315620422\n",
      "Seen so far: 36288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 567: 0.898488461971283\n",
      "Seen so far: 36352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 568: 0.7520625591278076\n",
      "Seen so far: 36416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 569: 0.6478440165519714\n",
      "Seen so far: 36480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 570: 1.0153168439865112\n",
      "Seen so far: 36544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 571: 1.143330693244934\n",
      "Seen so far: 36608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 572: 1.0774421691894531\n",
      "Seen so far: 36672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 573: 0.9375914335250854\n",
      "Seen so far: 36736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 574: 0.8460049033164978\n",
      "Seen so far: 36800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 575: 1.0256741046905518\n",
      "Seen so far: 36864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 576: 0.6128871440887451\n",
      "Seen so far: 36928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 577: 1.1375789642333984\n",
      "Seen so far: 36992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 578: 0.6097988486289978\n",
      "Seen so far: 37056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 579: 0.9933481812477112\n",
      "Seen so far: 37120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 580: 0.6251134872436523\n",
      "Seen so far: 37184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 581: 0.7665606141090393\n",
      "Seen so far: 37248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 582: 1.4668984413146973\n",
      "Seen so far: 37312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 583: 0.746519923210144\n",
      "Seen so far: 37376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 584: 1.0522481203079224\n",
      "Seen so far: 37440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 585: 0.7017887830734253\n",
      "Seen so far: 37504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 586: 0.9996306300163269\n",
      "Seen so far: 37568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 587: 0.5180153846740723\n",
      "Seen so far: 37632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 588: 0.7826407551765442\n",
      "Seen so far: 37696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 589: 0.8597854971885681\n",
      "Seen so far: 37760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 590: 0.6378719806671143\n",
      "Seen so far: 37824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 591: 0.7045575976371765\n",
      "Seen so far: 37888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 592: 0.8735930323600769\n",
      "Seen so far: 37952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 593: 1.0081634521484375\n",
      "Seen so far: 38016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 594: 0.5333927869796753\n",
      "Seen so far: 38080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 595: 0.7024556398391724\n",
      "Seen so far: 38144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 596: 0.775044322013855\n",
      "Seen so far: 38208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 597: 0.5737873911857605\n",
      "Seen so far: 38272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 598: 0.7060421705245972\n",
      "Seen so far: 38336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 599: 0.6796985864639282\n",
      "Seen so far: 38400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 600: 0.6218141317367554\n",
      "Seen so far: 38464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 601: 0.4289899170398712\n",
      "Seen so far: 38528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 602: 1.1203343868255615\n",
      "Seen so far: 38592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 603: 1.3264119625091553\n",
      "Seen so far: 38656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 604: 0.9888423085212708\n",
      "Seen so far: 38720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 605: 0.8155399560928345\n",
      "Seen so far: 38784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 606: 1.4984073638916016\n",
      "Seen so far: 38848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 607: 1.0310379266738892\n",
      "Seen so far: 38912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 608: 1.0189487934112549\n",
      "Seen so far: 38976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 609: 0.8393251299858093\n",
      "Seen so far: 39040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 610: 0.6313544511795044\n",
      "Seen so far: 39104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 611: 0.759739339351654\n",
      "Seen so far: 39168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 612: 0.8696669340133667\n",
      "Seen so far: 39232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 613: 0.6522026658058167\n",
      "Seen so far: 39296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 614: 1.2048245668411255\n",
      "Seen so far: 39360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 615: 0.9373842477798462\n",
      "Seen so far: 39424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 616: 0.7789660692214966\n",
      "Seen so far: 39488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 617: 1.1400752067565918\n",
      "Seen so far: 39552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 618: 1.2225234508514404\n",
      "Seen so far: 39616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 619: 0.9888024926185608\n",
      "Seen so far: 39680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 620: 0.9431533813476562\n",
      "Seen so far: 39744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 621: 0.8545961380004883\n",
      "Seen so far: 39808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 622: 1.0363882780075073\n",
      "Seen so far: 39872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 623: 0.7229571342468262\n",
      "Seen so far: 39936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 624: 0.9299149513244629\n",
      "Seen so far: 40000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 625: 0.8490517139434814\n",
      "Seen so far: 40064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 626: 0.876958429813385\n",
      "Seen so far: 40128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 627: 0.5125218629837036\n",
      "Seen so far: 40192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 628: 1.0716415643692017\n",
      "Seen so far: 40256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 629: 1.0276014804840088\n",
      "Seen so far: 40320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 630: 0.9214422106742859\n",
      "Seen so far: 40384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 631: 0.8201149702072144\n",
      "Seen so far: 40448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 632: 0.9042198657989502\n",
      "Seen so far: 40512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 633: 0.913468599319458\n",
      "Seen so far: 40576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 634: 0.5501560568809509\n",
      "Seen so far: 40640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 635: 0.7228364944458008\n",
      "Seen so far: 40704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 636: 1.1290704011917114\n",
      "Seen so far: 40768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 637: 0.44453883171081543\n",
      "Seen so far: 40832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 638: 0.7140883207321167\n",
      "Seen so far: 40896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 639: 0.8695558309555054\n",
      "Seen so far: 40960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 640: 0.802493155002594\n",
      "Seen so far: 41024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 641: 0.4281119108200073\n",
      "Seen so far: 41088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 642: 0.5899221897125244\n",
      "Seen so far: 41152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 643: 0.6142346858978271\n",
      "Seen so far: 41216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 644: 0.7863967418670654\n",
      "Seen so far: 41280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 645: 0.9068214297294617\n",
      "Seen so far: 41344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 646: 0.8295174837112427\n",
      "Seen so far: 41408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 647: 0.8105713129043579\n",
      "Seen so far: 41472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 648: 0.7721858024597168\n",
      "Seen so far: 41536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 649: 1.0086805820465088\n",
      "Seen so far: 41600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 650: 1.187117576599121\n",
      "Seen so far: 41664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 651: 0.7550781965255737\n",
      "Seen so far: 41728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 652: 0.7380554676055908\n",
      "Seen so far: 41792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 653: 0.7881395220756531\n",
      "Seen so far: 41856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 654: 0.9708660840988159\n",
      "Seen so far: 41920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 655: 0.6857864260673523\n",
      "Seen so far: 41984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 656: 0.8064334392547607\n",
      "Seen so far: 42048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 657: 1.3116002082824707\n",
      "Seen so far: 42112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 658: 0.724117636680603\n",
      "Seen so far: 42176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 659: 0.7741070985794067\n",
      "Seen so far: 42240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 660: 1.0108518600463867\n",
      "Seen so far: 42304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 661: 0.818504810333252\n",
      "Seen so far: 42368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 662: 0.909959614276886\n",
      "Seen so far: 42432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 663: 1.08359956741333\n",
      "Seen so far: 42496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 664: 0.8694338798522949\n",
      "Seen so far: 42560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 665: 1.0984009504318237\n",
      "Seen so far: 42624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 666: 0.8057770729064941\n",
      "Seen so far: 42688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 667: 0.6721605062484741\n",
      "Seen so far: 42752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 668: 0.6588913202285767\n",
      "Seen so far: 42816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 669: 1.0513352155685425\n",
      "Seen so far: 42880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 670: 0.83219313621521\n",
      "Seen so far: 42944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 671: 1.4405043125152588\n",
      "Seen so far: 43008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 672: 1.1031919717788696\n",
      "Seen so far: 43072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 673: 1.075516939163208\n",
      "Seen so far: 43136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 674: 0.7912181615829468\n",
      "Seen so far: 43200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 675: 0.9456846117973328\n",
      "Seen so far: 43264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 676: 0.9750747680664062\n",
      "Seen so far: 43328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 677: 0.9389487504959106\n",
      "Seen so far: 43392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 678: 0.9508539438247681\n",
      "Seen so far: 43456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 679: 1.1768734455108643\n",
      "Seen so far: 43520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 680: 0.8395907282829285\n",
      "Seen so far: 43584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 681: 1.1843435764312744\n",
      "Seen so far: 43648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 682: 0.9898487329483032\n",
      "Seen so far: 43712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 683: 0.5914079546928406\n",
      "Seen so far: 43776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 684: 0.9383293986320496\n",
      "Seen so far: 43840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 685: 0.6282711029052734\n",
      "Seen so far: 43904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 686: 1.1714434623718262\n",
      "Seen so far: 43968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 687: 0.9919617176055908\n",
      "Seen so far: 44032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 688: 0.7758758068084717\n",
      "Seen so far: 44096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 689: 0.6904542446136475\n",
      "Seen so far: 44160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 690: 0.9284108281135559\n",
      "Seen so far: 44224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 691: 1.0425629615783691\n",
      "Seen so far: 44288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 692: 1.0344879627227783\n",
      "Seen so far: 44352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 693: 0.9716088175773621\n",
      "Seen so far: 44416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 694: 0.906064510345459\n",
      "Seen so far: 44480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 695: 0.5850422382354736\n",
      "Seen so far: 44544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 696: 0.7825550436973572\n",
      "Seen so far: 44608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 697: 1.0645735263824463\n",
      "Seen so far: 44672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 698: 0.8107064366340637\n",
      "Seen so far: 44736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 699: 0.8672335147857666\n",
      "Seen so far: 44800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 700: 1.196126937866211\n",
      "Seen so far: 44864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 701: 0.9653987288475037\n",
      "Seen so far: 44928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 702: 0.775449275970459\n",
      "Seen so far: 44992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 703: 0.6713968515396118\n",
      "Seen so far: 45056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 704: 0.822616457939148\n",
      "Seen so far: 45120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 705: 0.5710618495941162\n",
      "Seen so far: 45184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 706: 0.8955011963844299\n",
      "Seen so far: 45248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 707: 0.5372707843780518\n",
      "Seen so far: 45312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 708: 0.7801629304885864\n",
      "Seen so far: 45376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 709: 1.3760470151901245\n",
      "Seen so far: 45440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 710: 0.9295756816864014\n",
      "Seen so far: 45504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 711: 0.7155804634094238\n",
      "Seen so far: 45568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 712: 1.012294054031372\n",
      "Seen so far: 45632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 713: 1.0589549541473389\n",
      "Seen so far: 45696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 714: 0.9721426963806152\n",
      "Seen so far: 45760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 715: 1.1644797325134277\n",
      "Seen so far: 45824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 716: 0.47882169485092163\n",
      "Seen so far: 45888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 717: 1.2983789443969727\n",
      "Seen so far: 45952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 718: 1.2340008020401\n",
      "Seen so far: 46016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 719: 0.9711651802062988\n",
      "Seen so far: 46080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 720: 0.9007281064987183\n",
      "Seen so far: 46144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 721: 0.9331243634223938\n",
      "Seen so far: 46208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 722: 0.433683842420578\n",
      "Seen so far: 46272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 723: 0.7857449054718018\n",
      "Seen so far: 46336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 724: 0.8752275705337524\n",
      "Seen so far: 46400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 725: 1.1642037630081177\n",
      "Seen so far: 46464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 726: 0.849342942237854\n",
      "Seen so far: 46528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 727: 0.9262235760688782\n",
      "Seen so far: 46592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 728: 1.0474412441253662\n",
      "Seen so far: 46656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 729: 0.667736828327179\n",
      "Seen so far: 46720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 730: 0.8264142274856567\n",
      "Seen so far: 46784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 731: 1.1264259815216064\n",
      "Seen so far: 46848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 732: 1.6465381383895874\n",
      "Seen so far: 46912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 733: 1.0283674001693726\n",
      "Seen so far: 46976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 734: 0.7626579999923706\n",
      "Seen so far: 47040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 735: 0.8218072056770325\n",
      "Seen so far: 47104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 736: 0.6105717420578003\n",
      "Seen so far: 47168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 737: 0.6419041156768799\n",
      "Seen so far: 47232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 738: 0.6109194755554199\n",
      "Seen so far: 47296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 739: 1.0242347717285156\n",
      "Seen so far: 47360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 740: 0.7134402990341187\n",
      "Seen so far: 47424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 741: 0.6813173890113831\n",
      "Seen so far: 47488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 742: 0.6500240564346313\n",
      "Seen so far: 47552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 743: 1.2451163530349731\n",
      "Seen so far: 47616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 744: 0.6566671133041382\n",
      "Seen so far: 47680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 745: 0.8505250215530396\n",
      "Seen so far: 47744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 746: 1.171696424484253\n",
      "Seen so far: 47808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 747: 1.0258965492248535\n",
      "Seen so far: 47872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 748: 0.6137405633926392\n",
      "Seen so far: 47936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 749: 1.2788959741592407\n",
      "Seen so far: 48000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 750: 0.6840112209320068\n",
      "Seen so far: 48064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 751: 0.825351357460022\n",
      "Seen so far: 48128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 752: 1.104299783706665\n",
      "Seen so far: 48192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 753: 1.1575100421905518\n",
      "Seen so far: 48256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 754: 0.9292358160018921\n",
      "Seen so far: 48320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 755: 0.7414239645004272\n",
      "Seen so far: 48384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 756: 1.151498556137085\n",
      "Seen so far: 48448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 757: 1.1509041786193848\n",
      "Seen so far: 48512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 758: 0.6831304430961609\n",
      "Seen so far: 48576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 759: 0.8503816723823547\n",
      "Seen so far: 48640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 760: 1.1320860385894775\n",
      "Seen so far: 48704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 761: 1.038751244544983\n",
      "Seen so far: 48768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 762: 0.7810447216033936\n",
      "Seen so far: 48832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 763: 1.1957581043243408\n",
      "Seen so far: 48896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 764: 0.9103481769561768\n",
      "Seen so far: 48960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 765: 0.9265801310539246\n",
      "Seen so far: 49024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 766: 1.0508921146392822\n",
      "Seen so far: 49088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 767: 0.8405642509460449\n",
      "Seen so far: 49152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 768: 0.5189580917358398\n",
      "Seen so far: 49216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 769: 0.6861575841903687\n",
      "Seen so far: 49280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 770: 0.7149521112442017\n",
      "Seen so far: 49344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 771: 0.8667587041854858\n",
      "Seen so far: 49408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 772: 1.049351692199707\n",
      "Seen so far: 49472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 773: 0.8375548124313354\n",
      "Seen so far: 49536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 774: 0.7178083062171936\n",
      "Seen so far: 49600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 775: 0.8819593787193298\n",
      "Seen so far: 49664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 776: 0.8621636629104614\n",
      "Seen so far: 49728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 777: 1.023984670639038\n",
      "Seen so far: 49792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 778: 0.6872163414955139\n",
      "Seen so far: 49856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 779: 0.4944548010826111\n",
      "Seen so far: 49920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 780: 1.1942306756973267\n",
      "Seen so far: 49984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 781: 1.1178027391433716\n",
      "Seen so far: 50048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 782: 0.8929885625839233\n",
      "Seen so far: 50112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 783: 0.9932518005371094\n",
      "Seen so far: 50176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 784: 1.1836059093475342\n",
      "Seen so far: 50240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 785: 0.865774393081665\n",
      "Seen so far: 50304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 786: 1.1737643480300903\n",
      "Seen so far: 50368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 787: 1.0474247932434082\n",
      "Seen so far: 50432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 788: 0.5022314786911011\n",
      "Seen so far: 50496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 789: 1.2366162538528442\n",
      "Seen so far: 50560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 790: 1.0454384088516235\n",
      "Seen so far: 50624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 791: 0.6464517116546631\n",
      "Seen so far: 50688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 792: 0.7319496870040894\n",
      "Seen so far: 50752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 793: 0.7549363374710083\n",
      "Seen so far: 50816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 794: 1.0961449146270752\n",
      "Seen so far: 50880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 795: 0.6915337443351746\n",
      "Seen so far: 50944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 796: 0.7954970598220825\n",
      "Seen so far: 51008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 797: 0.7508315443992615\n",
      "Seen so far: 51072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 798: 1.285104513168335\n",
      "Seen so far: 51136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 799: 1.2130975723266602\n",
      "Seen so far: 51200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 800: 0.8050539493560791\n",
      "Seen so far: 51264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 801: 0.7538453936576843\n",
      "Seen so far: 51328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 802: 1.0243010520935059\n",
      "Seen so far: 51392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 803: 0.9077852964401245\n",
      "Seen so far: 51456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 804: 0.5920525193214417\n",
      "Seen so far: 51520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 805: 0.9650390148162842\n",
      "Seen so far: 51584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 806: 0.9417992234230042\n",
      "Seen so far: 51648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 807: 0.5381168723106384\n",
      "Seen so far: 51712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 808: 0.9166398048400879\n",
      "Seen so far: 51776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 809: 0.9289926290512085\n",
      "Seen so far: 51840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 810: 0.9120656847953796\n",
      "Seen so far: 51904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 811: 0.7708879709243774\n",
      "Seen so far: 51968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 812: 0.9843301177024841\n",
      "Seen so far: 52032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 813: 0.742363452911377\n",
      "Seen so far: 52096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 814: 0.7043735980987549\n",
      "Seen so far: 52160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 815: 1.128115177154541\n",
      "Seen so far: 52224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 816: 0.9791163206100464\n",
      "Seen so far: 52288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 817: 0.5653663873672485\n",
      "Seen so far: 52352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 818: 1.383793592453003\n",
      "Seen so far: 52416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 819: 0.3459901809692383\n",
      "Seen so far: 52480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 820: 1.2123507261276245\n",
      "Seen so far: 52544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 821: 0.9397585391998291\n",
      "Seen so far: 52608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 822: 0.7326739430427551\n",
      "Seen so far: 52672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 823: 0.9456716775894165\n",
      "Seen so far: 52736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 824: 1.0604710578918457\n",
      "Seen so far: 52800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 825: 0.8911759257316589\n",
      "Seen so far: 52864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 826: 1.0038855075836182\n",
      "Seen so far: 52928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 827: 1.2505768537521362\n",
      "Seen so far: 52992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 828: 0.7831313610076904\n",
      "Seen so far: 53056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 829: 0.9871156215667725\n",
      "Seen so far: 53120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 830: 0.8926833868026733\n",
      "Seen so far: 53184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 831: 1.0962224006652832\n",
      "Seen so far: 53248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 832: 0.9219412803649902\n",
      "Seen so far: 53312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 833: 0.960655689239502\n",
      "Seen so far: 53376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 834: 0.6590208411216736\n",
      "Seen so far: 53440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 835: 0.7067232728004456\n",
      "Seen so far: 53504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 836: 0.8772082328796387\n",
      "Seen so far: 53568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 837: 0.8069747686386108\n",
      "Seen so far: 53632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 838: 0.45601555705070496\n",
      "Seen so far: 53696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 839: 0.5899943113327026\n",
      "Seen so far: 53760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 840: 0.6952679753303528\n",
      "Seen so far: 53824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 841: 1.2605924606323242\n",
      "Seen so far: 53888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 842: 0.8036842346191406\n",
      "Seen so far: 53952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 843: 0.7981506586074829\n",
      "Seen so far: 54016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 844: 1.071770191192627\n",
      "Seen so far: 54080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 845: 0.9668567180633545\n",
      "Seen so far: 54144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 846: 0.9255809783935547\n",
      "Seen so far: 54208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 847: 0.8189097046852112\n",
      "Seen so far: 54272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 848: 0.8411188125610352\n",
      "Seen so far: 54336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 849: 0.6420034766197205\n",
      "Seen so far: 54400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 850: 0.4295773506164551\n",
      "Seen so far: 54464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 851: 0.5461563467979431\n",
      "Seen so far: 54528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 852: 0.474060595035553\n",
      "Seen so far: 54592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 853: 0.68178790807724\n",
      "Seen so far: 54656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 854: 0.6791863441467285\n",
      "Seen so far: 54720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 855: 0.787779688835144\n",
      "Seen so far: 54784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 856: 0.6089029908180237\n",
      "Seen so far: 54848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 857: 0.6843709945678711\n",
      "Seen so far: 54912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 858: 0.86260986328125\n",
      "Seen so far: 54976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 859: 1.142439365386963\n",
      "Seen so far: 55040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 860: 0.7633234858512878\n",
      "Seen so far: 55104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 861: 0.7991099953651428\n",
      "Seen so far: 55168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 862: 0.6115704774856567\n",
      "Seen so far: 55232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 863: 1.1967254877090454\n",
      "Seen so far: 55296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 864: 0.9521322846412659\n",
      "Seen so far: 55360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 865: 0.5889697670936584\n",
      "Seen so far: 55424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 866: 0.6928583383560181\n",
      "Seen so far: 55488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 867: 0.8777183294296265\n",
      "Seen so far: 55552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 868: 0.9770606160163879\n",
      "Seen so far: 55616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 869: 0.9005305767059326\n",
      "Seen so far: 55680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 870: 1.1033656597137451\n",
      "Seen so far: 55744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 871: 1.0383532047271729\n",
      "Seen so far: 55808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 872: 0.6137534976005554\n",
      "Seen so far: 55872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 873: 1.1667484045028687\n",
      "Seen so far: 55936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 874: 1.0855138301849365\n",
      "Seen so far: 56000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 875: 1.1904720067977905\n",
      "Seen so far: 56064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 876: 0.8944412469863892\n",
      "Seen so far: 56128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 877: 0.9471724033355713\n",
      "Seen so far: 56192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 878: 0.8183748722076416\n",
      "Seen so far: 56256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 879: 0.497797429561615\n",
      "Seen so far: 56320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 880: 1.001394271850586\n",
      "Seen so far: 56384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 881: 1.0979547500610352\n",
      "Seen so far: 56448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 882: 0.9674443006515503\n",
      "Seen so far: 56512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 883: 0.7814846038818359\n",
      "Seen so far: 56576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 884: 0.4370739459991455\n",
      "Seen so far: 56640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 885: 0.809097409248352\n",
      "Seen so far: 56704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 886: 1.077429175376892\n",
      "Seen so far: 56768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 887: 0.8868634700775146\n",
      "Seen so far: 56832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 888: 0.8848699331283569\n",
      "Seen so far: 56896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 889: 1.22640860080719\n",
      "Seen so far: 56960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 890: 0.868888258934021\n",
      "Seen so far: 57024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 891: 1.1373684406280518\n",
      "Seen so far: 57088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 892: 0.6081414222717285\n",
      "Seen so far: 57152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 893: 1.109173059463501\n",
      "Seen so far: 57216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 894: 0.9899010062217712\n",
      "Seen so far: 57280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 895: 0.9751593470573425\n",
      "Seen so far: 57344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 896: 1.2258723974227905\n",
      "Seen so far: 57408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 897: 0.9275614023208618\n",
      "Seen so far: 57472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 898: 0.6626824736595154\n",
      "Seen so far: 57536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 899: 0.6119517087936401\n",
      "Seen so far: 57600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 900: 0.7457150220870972\n",
      "Seen so far: 57664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 901: 1.1541566848754883\n",
      "Seen so far: 57728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 902: 1.1208949089050293\n",
      "Seen so far: 57792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 903: 0.8754923343658447\n",
      "Seen so far: 57856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 904: 0.9490329027175903\n",
      "Seen so far: 57920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 905: 0.8909016847610474\n",
      "Seen so far: 57984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 906: 1.1934841871261597\n",
      "Seen so far: 58048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 907: 0.9349960684776306\n",
      "Seen so far: 58112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 908: 0.6359764337539673\n",
      "Seen so far: 58176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 909: 0.993481457233429\n",
      "Seen so far: 58240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 910: 0.7187156081199646\n",
      "Seen so far: 58304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 911: 0.8035581111907959\n",
      "Seen so far: 58368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 912: 0.8174022436141968\n",
      "Seen so far: 58432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 913: 1.365192174911499\n",
      "Seen so far: 58496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 914: 0.5694639682769775\n",
      "Seen so far: 58560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 915: 0.5973814129829407\n",
      "Seen so far: 58624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 916: 1.0391210317611694\n",
      "Seen so far: 58688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 917: 0.6807901263237\n",
      "Seen so far: 58752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 918: 1.0797076225280762\n",
      "Seen so far: 58816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 919: 0.8790998458862305\n",
      "Seen so far: 58880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 920: 0.9739222526550293\n",
      "Seen so far: 58944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 921: 0.7742630839347839\n",
      "Seen so far: 59008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 922: 0.9975858926773071\n",
      "Seen so far: 59072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 923: 0.8967515826225281\n",
      "Seen so far: 59136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 924: 0.9219077229499817\n",
      "Seen so far: 59200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 925: 0.8446887731552124\n",
      "Seen so far: 59264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 926: 1.11042320728302\n",
      "Seen so far: 59328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 927: 0.8509074449539185\n",
      "Seen so far: 59392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 928: 0.8325313329696655\n",
      "Seen so far: 59456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 929: 0.7415050268173218\n",
      "Seen so far: 59520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 930: 0.8233129382133484\n",
      "Seen so far: 59584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 931: 1.1028109788894653\n",
      "Seen so far: 59648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 932: 1.2580065727233887\n",
      "Seen so far: 59712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 933: 0.8387281894683838\n",
      "Seen so far: 59776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 934: 1.1486847400665283\n",
      "Seen so far: 59840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 935: 0.5759286880493164\n",
      "Seen so far: 59904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 936: 0.8252689838409424\n",
      "Seen so far: 59968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 937: 1.0883716344833374\n",
      "Seen so far: 60032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 938: 1.0103944540023804\n",
      "Seen so far: 60096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 939: 0.7425118088722229\n",
      "Seen so far: 60160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 940: 0.6474282145500183\n",
      "Seen so far: 60224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 941: 0.7799258232116699\n",
      "Seen so far: 60288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 942: 0.8923664093017578\n",
      "Seen so far: 60352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 943: 1.0129845142364502\n",
      "Seen so far: 60416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 944: 0.7476966381072998\n",
      "Seen so far: 60480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 945: 1.042081594467163\n",
      "Seen so far: 60544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 946: 0.6670055389404297\n",
      "Seen so far: 60608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 947: 0.99346524477005\n",
      "Seen so far: 60672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 948: 0.5662937164306641\n",
      "Seen so far: 60736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 949: 0.797080397605896\n",
      "Seen so far: 60800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 950: 0.8515917062759399\n",
      "Seen so far: 60864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 951: 0.8612503409385681\n",
      "Seen so far: 60928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 952: 1.0691401958465576\n",
      "Seen so far: 60992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 953: 1.1339919567108154\n",
      "Seen so far: 61056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 954: 0.9469643831253052\n",
      "Seen so far: 61120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 955: 0.8144187331199646\n",
      "Seen so far: 61184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 956: 1.2203205823898315\n",
      "Seen so far: 61248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 957: 1.092485785484314\n",
      "Seen so far: 61312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 958: 1.0945500135421753\n",
      "Seen so far: 61376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 959: 0.7377429008483887\n",
      "Seen so far: 61440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 960: 0.8657201528549194\n",
      "Seen so far: 61504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 961: 0.8402665853500366\n",
      "Seen so far: 61568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 962: 0.7677009701728821\n",
      "Seen so far: 61632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 963: 0.7988345623016357\n",
      "Seen so far: 61696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 964: 0.8740789294242859\n",
      "Seen so far: 61760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 965: 0.7969626188278198\n",
      "Seen so far: 61824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 966: 0.648037314414978\n",
      "Seen so far: 61888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 967: 0.7001651525497437\n",
      "Seen so far: 61952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 968: 0.7873245477676392\n",
      "Seen so far: 62016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 969: 0.9329355955123901\n",
      "Seen so far: 62080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 970: 1.1573309898376465\n",
      "Seen so far: 62144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 971: 0.7127273082733154\n",
      "Seen so far: 62208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 972: 1.1485247611999512\n",
      "Seen so far: 62272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 973: 0.9307537078857422\n",
      "Seen so far: 62336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 974: 0.8087469339370728\n",
      "Seen so far: 62400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 975: 0.7477818727493286\n",
      "Seen so far: 62464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 976: 0.7934237718582153\n",
      "Seen so far: 62528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 977: 0.7934174537658691\n",
      "Seen so far: 62592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 978: 1.0928008556365967\n",
      "Seen so far: 62656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 979: 0.771077036857605\n",
      "Seen so far: 62720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 980: 0.8434925675392151\n",
      "Seen so far: 62784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 981: 1.0620073080062866\n",
      "Seen so far: 62848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 982: 0.8539116978645325\n",
      "Seen so far: 62912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 983: 0.5504293441772461\n",
      "Seen so far: 62976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 984: 0.9299415349960327\n",
      "Seen so far: 63040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 985: 1.0340347290039062\n",
      "Seen so far: 63104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 986: 0.9126690626144409\n",
      "Seen so far: 63168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 987: 1.089577317237854\n",
      "Seen so far: 63232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 988: 0.8556941151618958\n",
      "Seen so far: 63296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 989: 0.9409633874893188\n",
      "Seen so far: 63360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 990: 0.7934465408325195\n",
      "Seen so far: 63424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 991: 0.8069857954978943\n",
      "Seen so far: 63488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 992: 0.3481028378009796\n",
      "Seen so far: 63552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 993: 0.8152507543563843\n",
      "Seen so far: 63616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 994: 1.1632936000823975\n",
      "Seen so far: 63680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 995: 0.7389518618583679\n",
      "Seen so far: 63744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 996: 1.0541051626205444\n",
      "Seen so far: 63808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 997: 0.42648667097091675\n",
      "Seen so far: 63872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 998: 0.8084391355514526\n",
      "Seen so far: 63936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 999: 0.82795250415802\n",
      "Seen so far: 64000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1000: 0.7427099943161011\n",
      "Seen so far: 64064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1001: 0.7614290714263916\n",
      "Seen so far: 64128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1002: 0.7550877928733826\n",
      "Seen so far: 64192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1003: 0.8163452744483948\n",
      "Seen so far: 64256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1004: 0.7702326774597168\n",
      "Seen so far: 64320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1005: 0.8535885810852051\n",
      "Seen so far: 64384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1006: 0.8954623937606812\n",
      "Seen so far: 64448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1007: 0.8679786920547485\n",
      "Seen so far: 64512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1008: 1.1145508289337158\n",
      "Seen so far: 64576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1009: 0.9246448278427124\n",
      "Seen so far: 64640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1010: 0.5963619947433472\n",
      "Seen so far: 64704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1011: 0.8093596696853638\n",
      "Seen so far: 64768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1012: 0.9337533116340637\n",
      "Seen so far: 64832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1013: 0.9664729237556458\n",
      "Seen so far: 64896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1014: 0.9609431028366089\n",
      "Seen so far: 64960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1015: 0.40118709206581116\n",
      "Seen so far: 65024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1016: 1.021047830581665\n",
      "Seen so far: 65088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1017: 1.0061805248260498\n",
      "Seen so far: 65152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1018: 0.6143152117729187\n",
      "Seen so far: 65216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1019: 1.1716138124465942\n",
      "Seen so far: 65280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1020: 0.45736613869667053\n",
      "Seen so far: 65344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1021: 0.5741819739341736\n",
      "Seen so far: 65408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1022: 0.5222806930541992\n",
      "Seen so far: 65472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1023: 1.4485920667648315\n",
      "Seen so far: 65536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1024: 0.628186821937561\n",
      "Seen so far: 65600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1025: 0.942950427532196\n",
      "Seen so far: 65664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1026: 0.9233169555664062\n",
      "Seen so far: 65728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1027: 1.196884274482727\n",
      "Seen so far: 65792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1028: 0.5146406888961792\n",
      "Seen so far: 65856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1029: 1.0980861186981201\n",
      "Seen so far: 65920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1030: 0.9247020483016968\n",
      "Seen so far: 65984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1031: 0.6430902481079102\n",
      "Seen so far: 66048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1032: 0.7825118899345398\n",
      "Seen so far: 66112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1033: 1.1803653240203857\n",
      "Seen so far: 66176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1034: 1.201106071472168\n",
      "Seen so far: 66240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1035: 1.1269521713256836\n",
      "Seen so far: 66304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1036: 0.5441434383392334\n",
      "Seen so far: 66368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1037: 0.8733447790145874\n",
      "Seen so far: 66432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1038: 0.8598139882087708\n",
      "Seen so far: 66496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1039: 0.6971011757850647\n",
      "Seen so far: 66560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1040: 1.0571070909500122\n",
      "Seen so far: 66624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1041: 1.0677006244659424\n",
      "Seen so far: 66688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1042: 0.6593843698501587\n",
      "Seen so far: 66752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1043: 1.0820621252059937\n",
      "Seen so far: 66816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1044: 0.47392570972442627\n",
      "Seen so far: 66880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1045: 0.9134777784347534\n",
      "Seen so far: 66944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1046: 0.9967362880706787\n",
      "Seen so far: 67008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1047: 0.7443128824234009\n",
      "Seen so far: 67072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1048: 1.0268734693527222\n",
      "Seen so far: 67136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1049: 0.6415384411811829\n",
      "Seen so far: 67200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1050: 1.2955057621002197\n",
      "Seen so far: 67264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1051: 1.0692112445831299\n",
      "Seen so far: 67328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1052: 0.7281848192214966\n",
      "Seen so far: 67392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1053: 0.90465247631073\n",
      "Seen so far: 67456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1054: 1.109118938446045\n",
      "Seen so far: 67520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1055: 1.0984909534454346\n",
      "Seen so far: 67584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1056: 0.7946726083755493\n",
      "Seen so far: 67648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1057: 0.6805704832077026\n",
      "Seen so far: 67712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1058: 0.6067063808441162\n",
      "Seen so far: 67776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1059: 0.7167220115661621\n",
      "Seen so far: 67840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1060: 0.7834279537200928\n",
      "Seen so far: 67904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1061: 0.8419417142868042\n",
      "Seen so far: 67968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1062: 1.2182996273040771\n",
      "Seen so far: 68032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1063: 0.4469463527202606\n",
      "Seen so far: 68096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1064: 0.981354832649231\n",
      "Seen so far: 68160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1065: 0.6419902443885803\n",
      "Seen so far: 68224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1066: 0.9385781288146973\n",
      "Seen so far: 68288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1067: 0.7255290150642395\n",
      "Seen so far: 68352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1068: 0.6261454820632935\n",
      "Seen so far: 68416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1069: 0.7760050296783447\n",
      "Seen so far: 68480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1070: 0.5275077819824219\n",
      "Seen so far: 68544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1071: 0.7015606164932251\n",
      "Seen so far: 68608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1072: 0.8011875152587891\n",
      "Seen so far: 68672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1073: 1.0999183654785156\n",
      "Seen so far: 68736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1074: 0.7171944379806519\n",
      "Seen so far: 68800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1075: 0.6989386081695557\n",
      "Seen so far: 68864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1076: 0.5557471513748169\n",
      "Seen so far: 68928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1077: 1.0458520650863647\n",
      "Seen so far: 68992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1078: 1.4562350511550903\n",
      "Seen so far: 69056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1079: 0.8723573684692383\n",
      "Seen so far: 69120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1080: 0.8009403944015503\n",
      "Seen so far: 69184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1081: 0.7595372796058655\n",
      "Seen so far: 69248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1082: 0.825319230556488\n",
      "Seen so far: 69312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1083: 0.925044059753418\n",
      "Seen so far: 69376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1084: 0.9956875443458557\n",
      "Seen so far: 69440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1085: 0.853209376335144\n",
      "Seen so far: 69504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1086: 1.001049518585205\n",
      "Seen so far: 69568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1087: 1.1030064821243286\n",
      "Seen so far: 69632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1088: 1.0035946369171143\n",
      "Seen so far: 69696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1089: 0.7623285055160522\n",
      "Seen so far: 69760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1090: 0.6322081089019775\n",
      "Seen so far: 69824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1091: 0.9993575811386108\n",
      "Seen so far: 69888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1092: 1.0673922300338745\n",
      "Seen so far: 69952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1093: 0.5988642573356628\n",
      "Seen so far: 70016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1094: 1.0145071744918823\n",
      "Seen so far: 70080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1095: 0.7566519975662231\n",
      "Seen so far: 70144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1096: 0.5220364332199097\n",
      "Seen so far: 70208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1097: 0.7773188948631287\n",
      "Seen so far: 70272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1098: 1.2967555522918701\n",
      "Seen so far: 70336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1099: 0.948090672492981\n",
      "Seen so far: 70400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1100: 1.3497474193572998\n",
      "Seen so far: 70464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1101: 1.1407394409179688\n",
      "Seen so far: 70528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1102: 0.7515769004821777\n",
      "Seen so far: 70592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1103: 0.9358524084091187\n",
      "Seen so far: 70656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1104: 0.619930624961853\n",
      "Seen so far: 70720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1105: 1.0499149560928345\n",
      "Seen so far: 70784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1106: 0.9283571243286133\n",
      "Seen so far: 70848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1107: 0.746009111404419\n",
      "Seen so far: 70912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1108: 0.9073443412780762\n",
      "Seen so far: 70976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1109: 0.7331017255783081\n",
      "Seen so far: 71040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1110: 0.7422378063201904\n",
      "Seen so far: 71104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1111: 0.7846853733062744\n",
      "Seen so far: 71168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1112: 1.1706403493881226\n",
      "Seen so far: 71232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1113: 1.302065134048462\n",
      "Seen so far: 71296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1114: 0.6433423757553101\n",
      "Seen so far: 71360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1115: 1.1564217805862427\n",
      "Seen so far: 71424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1116: 0.8859972953796387\n",
      "Seen so far: 71488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1117: 0.8784355521202087\n",
      "Seen so far: 71552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1118: 0.5827785134315491\n",
      "Seen so far: 71616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1119: 0.9434157609939575\n",
      "Seen so far: 71680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1120: 0.6433066129684448\n",
      "Seen so far: 71744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1121: 1.013429880142212\n",
      "Seen so far: 71808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1122: 0.6671977043151855\n",
      "Seen so far: 71872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1123: 0.6332085728645325\n",
      "Seen so far: 71936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1124: 0.8332863450050354\n",
      "Seen so far: 72000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1125: 1.288193941116333\n",
      "Seen so far: 72064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1126: 0.7241784930229187\n",
      "Seen so far: 72128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1127: 0.8691952228546143\n",
      "Seen so far: 72192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1128: 1.573969841003418\n",
      "Seen so far: 72256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1129: 0.6606669425964355\n",
      "Seen so far: 72320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1130: 0.790539026260376\n",
      "Seen so far: 72384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1131: 1.0151028633117676\n",
      "Seen so far: 72448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1132: 0.7909557819366455\n",
      "Seen so far: 72512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1133: 1.004105567932129\n",
      "Seen so far: 72576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1134: 1.0317909717559814\n",
      "Seen so far: 72640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1135: 1.0542097091674805\n",
      "Seen so far: 72704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1136: 0.9110777974128723\n",
      "Seen so far: 72768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1137: 1.249516248703003\n",
      "Seen so far: 72832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1138: 0.8118463754653931\n",
      "Seen so far: 72896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1139: 0.7608875632286072\n",
      "Seen so far: 72960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1140: 0.8961613178253174\n",
      "Seen so far: 73024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1141: 0.5829861164093018\n",
      "Seen so far: 73088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1142: 0.9679985046386719\n",
      "Seen so far: 73152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1143: 0.6588100790977478\n",
      "Seen so far: 73216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1144: 0.9275143146514893\n",
      "Seen so far: 73280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1145: 1.092556357383728\n",
      "Seen so far: 73344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1146: 0.8907263278961182\n",
      "Seen so far: 73408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1147: 0.9939651489257812\n",
      "Seen so far: 73472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1148: 1.3716249465942383\n",
      "Seen so far: 73536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1149: 0.7811972498893738\n",
      "Seen so far: 73600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1150: 0.8985795974731445\n",
      "Seen so far: 73664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1151: 0.6848540902137756\n",
      "Seen so far: 73728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1152: 0.8540457487106323\n",
      "Seen so far: 73792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1153: 0.7740894556045532\n",
      "Seen so far: 73856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1154: 0.6183915138244629\n",
      "Seen so far: 73920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1155: 0.9874434471130371\n",
      "Seen so far: 73984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1156: 0.7528318762779236\n",
      "Seen so far: 74048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1157: 1.0641463994979858\n",
      "Seen so far: 74112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1158: 1.0109238624572754\n",
      "Seen so far: 74176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1159: 0.8409885168075562\n",
      "Seen so far: 74240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1160: 0.9360028505325317\n",
      "Seen so far: 74304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1161: 0.7599544525146484\n",
      "Seen so far: 74368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1162: 0.6176657676696777\n",
      "Seen so far: 74432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1163: 0.6645725965499878\n",
      "Seen so far: 74496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1164: 0.9700643420219421\n",
      "Seen so far: 74560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1165: 0.7577378153800964\n",
      "Seen so far: 74624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1166: 1.174772024154663\n",
      "Seen so far: 74688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1167: 0.7478002309799194\n",
      "Seen so far: 74752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1168: 0.44123077392578125\n",
      "Seen so far: 74816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1169: 0.8176217079162598\n",
      "Seen so far: 74880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1170: 1.0465179681777954\n",
      "Seen so far: 74944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1171: 0.729360818862915\n",
      "Seen so far: 75008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1172: 1.314942717552185\n",
      "Seen so far: 75072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1173: 0.8140621781349182\n",
      "Seen so far: 75136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1174: 1.0519930124282837\n",
      "Seen so far: 75200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1175: 1.384706974029541\n",
      "Seen so far: 75264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1176: 1.0796022415161133\n",
      "Seen so far: 75328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1177: 0.9139869213104248\n",
      "Seen so far: 75392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1178: 1.2890173196792603\n",
      "Seen so far: 75456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1179: 0.4231552481651306\n",
      "Seen so far: 75520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1180: 0.7968324422836304\n",
      "Seen so far: 75584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1181: 1.0340222120285034\n",
      "Seen so far: 75648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1182: 1.3017771244049072\n",
      "Seen so far: 75712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1183: 0.9862163066864014\n",
      "Seen so far: 75776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1184: 0.9061151742935181\n",
      "Seen so far: 75840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1185: 0.7347731590270996\n",
      "Seen so far: 75904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1186: 0.6375057697296143\n",
      "Seen so far: 75968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1187: 0.9234025478363037\n",
      "Seen so far: 76032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1188: 0.807094931602478\n",
      "Seen so far: 76096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1189: 0.5843591690063477\n",
      "Seen so far: 76160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1190: 0.6306941509246826\n",
      "Seen so far: 76224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1191: 0.6044337749481201\n",
      "Seen so far: 76288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1192: 1.298677921295166\n",
      "Seen so far: 76352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1193: 0.7445173263549805\n",
      "Seen so far: 76416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1194: 1.3400218486785889\n",
      "Seen so far: 76480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1195: 0.6754900813102722\n",
      "Seen so far: 76544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1196: 0.6978483200073242\n",
      "Seen so far: 76608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1197: 1.3343002796173096\n",
      "Seen so far: 76672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1198: 1.159822702407837\n",
      "Seen so far: 76736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1199: 1.1703317165374756\n",
      "Seen so far: 76800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1200: 0.8629441261291504\n",
      "Seen so far: 76864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1201: 0.8850533366203308\n",
      "Seen so far: 76928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1202: 1.010613203048706\n",
      "Seen so far: 76992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1203: 0.7412113547325134\n",
      "Seen so far: 77056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1204: 0.9592620134353638\n",
      "Seen so far: 77120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1205: 0.6422311067581177\n",
      "Seen so far: 77184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1206: 0.7086018323898315\n",
      "Seen so far: 77248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1207: 0.9491731524467468\n",
      "Seen so far: 77312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1208: 1.1495671272277832\n",
      "Seen so far: 77376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1209: 1.084039568901062\n",
      "Seen so far: 77440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1210: 0.8038831949234009\n",
      "Seen so far: 77504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1211: 0.8011865615844727\n",
      "Seen so far: 77568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1212: 0.696270227432251\n",
      "Seen so far: 77632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1213: 0.7827802896499634\n",
      "Seen so far: 77696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1214: 1.5237219333648682\n",
      "Seen so far: 77760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1215: 0.3811843693256378\n",
      "Seen so far: 77824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1216: 0.7949267625808716\n",
      "Seen so far: 77888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1217: 0.872013509273529\n",
      "Seen so far: 77952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1218: 0.9293369054794312\n",
      "Seen so far: 78016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1219: 1.2607795000076294\n",
      "Seen so far: 78080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1220: 0.7535090446472168\n",
      "Seen so far: 78144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1221: 0.7338348627090454\n",
      "Seen so far: 78208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1222: 0.8975449800491333\n",
      "Seen so far: 78272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1223: 0.8174611330032349\n",
      "Seen so far: 78336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1224: 0.5688157081604004\n",
      "Seen so far: 78400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1225: 1.003481149673462\n",
      "Seen so far: 78464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1226: 0.8864037990570068\n",
      "Seen so far: 78528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1227: 0.7736164331436157\n",
      "Seen so far: 78592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1228: 0.8033890724182129\n",
      "Seen so far: 78656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1229: 0.8316264152526855\n",
      "Seen so far: 78720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1230: 0.9168957471847534\n",
      "Seen so far: 78784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1231: 0.6930621862411499\n",
      "Seen so far: 78848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1232: 1.0114023685455322\n",
      "Seen so far: 78912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1233: 0.917457103729248\n",
      "Seen so far: 78976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1234: 1.0306570529937744\n",
      "Seen so far: 79040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1235: 0.6911288499832153\n",
      "Seen so far: 79104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1236: 0.8496110439300537\n",
      "Seen so far: 79168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1237: 0.9407952427864075\n",
      "Seen so far: 79232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1238: 1.0158600807189941\n",
      "Seen so far: 79296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1239: 0.748083233833313\n",
      "Seen so far: 79360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1240: 1.0338064432144165\n",
      "Seen so far: 79424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1241: 0.9673309326171875\n",
      "Seen so far: 79488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1242: 0.7328314781188965\n",
      "Seen so far: 79552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1243: 1.0328551530838013\n",
      "Seen so far: 79616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1244: 0.81582111120224\n",
      "Seen so far: 79680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1245: 0.8608546257019043\n",
      "Seen so far: 79744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1246: 0.7948884963989258\n",
      "Seen so far: 79808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1247: 0.7163439989089966\n",
      "Seen so far: 79872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1248: 0.740397036075592\n",
      "Seen so far: 79936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1249: 1.0852960348129272\n",
      "Seen so far: 80000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1250: 0.8708369731903076\n",
      "Seen so far: 80064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1251: 0.48001450300216675\n",
      "Seen so far: 80128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1252: 0.9517028331756592\n",
      "Seen so far: 80192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1253: 0.665616512298584\n",
      "Seen so far: 80256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1254: 0.7257477045059204\n",
      "Seen so far: 80320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1255: 0.5918958187103271\n",
      "Seen so far: 80384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1256: 1.113640546798706\n",
      "Seen so far: 80448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1257: 1.006745457649231\n",
      "Seen so far: 80512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1258: 0.655534029006958\n",
      "Seen so far: 80576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1259: 0.6249950528144836\n",
      "Seen so far: 80640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1260: 0.6343783736228943\n",
      "Seen so far: 80704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1261: 0.5908650755882263\n",
      "Seen so far: 80768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1262: 0.7694689035415649\n",
      "Seen so far: 80832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1263: 0.5183528661727905\n",
      "Seen so far: 80896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1264: 0.9349257946014404\n",
      "Seen so far: 80960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1265: 0.9441894292831421\n",
      "Seen so far: 81024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1266: 0.6499730348587036\n",
      "Seen so far: 81088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1267: 0.7964178323745728\n",
      "Seen so far: 81152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1268: 0.7656270265579224\n",
      "Seen so far: 81216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1269: 0.9653075933456421\n",
      "Seen so far: 81280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1270: 1.1545103788375854\n",
      "Seen so far: 81344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1271: 0.6901500225067139\n",
      "Seen so far: 81408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1272: 0.989604651927948\n",
      "Seen so far: 81472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1273: 0.9278332591056824\n",
      "Seen so far: 81536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1274: 0.6176641583442688\n",
      "Seen so far: 81600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1275: 0.7539006471633911\n",
      "Seen so far: 81664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1276: 0.5731128454208374\n",
      "Seen so far: 81728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1277: 0.8531125783920288\n",
      "Seen so far: 81792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1278: 0.9807260632514954\n",
      "Seen so far: 81856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1279: 1.0232419967651367\n",
      "Seen so far: 81920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1280: 1.0197948217391968\n",
      "Seen so far: 81984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1281: 0.745049238204956\n",
      "Seen so far: 82048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1282: 0.7973371744155884\n",
      "Seen so far: 82112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1283: 0.7523065209388733\n",
      "Seen so far: 82176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1284: 1.1242029666900635\n",
      "Seen so far: 82240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1285: 0.9692266583442688\n",
      "Seen so far: 82304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1286: 0.696660041809082\n",
      "Seen so far: 82368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1287: 0.8482563495635986\n",
      "Seen so far: 82432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1288: 0.6556873321533203\n",
      "Seen so far: 82496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1289: 0.9334208965301514\n",
      "Seen so far: 82560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1290: 0.47979211807250977\n",
      "Seen so far: 82624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1291: 1.1950703859329224\n",
      "Seen so far: 82688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1292: 0.2976177930831909\n",
      "Seen so far: 82752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1293: 0.888459324836731\n",
      "Seen so far: 82816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1294: 0.928154468536377\n",
      "Seen so far: 82880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1295: 0.8302211761474609\n",
      "Seen so far: 82944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1296: 0.559975266456604\n",
      "Seen so far: 83008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1297: 0.7836731672286987\n",
      "Seen so far: 83072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1298: 0.6459930539131165\n",
      "Seen so far: 83136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1299: 0.7631369829177856\n",
      "Seen so far: 83200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1300: 1.1155273914337158\n",
      "Seen so far: 83264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1301: 0.6941896677017212\n",
      "Seen so far: 83328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1302: 0.992906391620636\n",
      "Seen so far: 83392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1303: 1.0477745532989502\n",
      "Seen so far: 83456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1304: 0.5309174060821533\n",
      "Seen so far: 83520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1305: 0.7517122626304626\n",
      "Seen so far: 83584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1306: 0.8921530246734619\n",
      "Seen so far: 83648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1307: 0.6216225624084473\n",
      "Seen so far: 83712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1308: 0.8826488256454468\n",
      "Seen so far: 83776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1309: 0.8413163423538208\n",
      "Seen so far: 83840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1310: 0.6765853762626648\n",
      "Seen so far: 83904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1311: 0.819564700126648\n",
      "Seen so far: 83968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1312: 0.6378548741340637\n",
      "Seen so far: 84032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1313: 0.779670238494873\n",
      "Seen so far: 84096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1314: 0.7116891741752625\n",
      "Seen so far: 84160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1315: 1.1115427017211914\n",
      "Seen so far: 84224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1316: 0.9526249766349792\n",
      "Seen so far: 84288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1317: 1.2462778091430664\n",
      "Seen so far: 84352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1318: 0.9316734075546265\n",
      "Seen so far: 84416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1319: 1.021511435508728\n",
      "Seen so far: 84480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1320: 0.9717114567756653\n",
      "Seen so far: 84544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1321: 1.4356300830841064\n",
      "Seen so far: 84608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1322: 0.9481220245361328\n",
      "Seen so far: 84672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1323: 0.8070894479751587\n",
      "Seen so far: 84736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1324: 0.8249862790107727\n",
      "Seen so far: 84800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1325: 0.9159009456634521\n",
      "Seen so far: 84864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1326: 0.8291365504264832\n",
      "Seen so far: 84928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1327: 0.6810756921768188\n",
      "Seen so far: 84992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1328: 1.0160177946090698\n",
      "Seen so far: 85056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1329: 0.8329533338546753\n",
      "Seen so far: 85120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1330: 0.755327582359314\n",
      "Seen so far: 85184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1331: 1.0273494720458984\n",
      "Seen so far: 85248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1332: 0.8108786344528198\n",
      "Seen so far: 85312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1333: 1.0961802005767822\n",
      "Seen so far: 85376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1334: 0.9627349972724915\n",
      "Seen so far: 85440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1335: 0.7953376173973083\n",
      "Seen so far: 85504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1336: 0.7566749453544617\n",
      "Seen so far: 85568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1337: 0.7411717176437378\n",
      "Seen so far: 85632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1338: 1.1599360704421997\n",
      "Seen so far: 85696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1339: 0.87635338306427\n",
      "Seen so far: 85760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1340: 1.5354087352752686\n",
      "Seen so far: 85824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1341: 1.085992693901062\n",
      "Seen so far: 85888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1342: 0.5934129953384399\n",
      "Seen so far: 85952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1343: 0.8397694826126099\n",
      "Seen so far: 86016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1344: 1.030737042427063\n",
      "Seen so far: 86080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1345: 0.7620031833648682\n",
      "Seen so far: 86144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1346: 1.1923667192459106\n",
      "Seen so far: 86208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1347: 0.6940927505493164\n",
      "Seen so far: 86272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1348: 1.1519161462783813\n",
      "Seen so far: 86336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1349: 1.253090739250183\n",
      "Seen so far: 86400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1350: 1.0608240365982056\n",
      "Seen so far: 86464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1351: 0.6220641136169434\n",
      "Seen so far: 86528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1352: 1.3816771507263184\n",
      "Seen so far: 86592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1353: 0.7030569314956665\n",
      "Seen so far: 86656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1354: 1.6316032409667969\n",
      "Seen so far: 86720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1355: 0.8482133150100708\n",
      "Seen so far: 86784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1356: 0.716340184211731\n",
      "Seen so far: 86848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1357: 1.0468873977661133\n",
      "Seen so far: 86912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1358: 0.7198757529258728\n",
      "Seen so far: 86976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1359: 0.8569777011871338\n",
      "Seen so far: 87040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1360: 0.922130823135376\n",
      "Seen so far: 87104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1361: 0.6842311024665833\n",
      "Seen so far: 87168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1362: 0.7812491059303284\n",
      "Seen so far: 87232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1363: 0.8495092391967773\n",
      "Seen so far: 87296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1364: 0.9154847264289856\n",
      "Seen so far: 87360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1365: 0.8047923445701599\n",
      "Seen so far: 87424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1366: 0.9542330503463745\n",
      "Seen so far: 87488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1367: 1.1477924585342407\n",
      "Seen so far: 87552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1368: 1.0328007936477661\n",
      "Seen so far: 87616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1369: 0.6581167578697205\n",
      "Seen so far: 87680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1370: 0.8071838021278381\n",
      "Seen so far: 87744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1371: 0.7926477193832397\n",
      "Seen so far: 87808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1372: 1.1952648162841797\n",
      "Seen so far: 87872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1373: 0.7488193511962891\n",
      "Seen so far: 87936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1374: 0.8553438782691956\n",
      "Seen so far: 88000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1375: 1.0267289876937866\n",
      "Seen so far: 88064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1376: 1.2744756937026978\n",
      "Seen so far: 88128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1377: 0.9007610082626343\n",
      "Seen so far: 88192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1378: 1.0928380489349365\n",
      "Seen so far: 88256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1379: 0.9390156269073486\n",
      "Seen so far: 88320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1380: 1.059393286705017\n",
      "Seen so far: 88384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1381: 0.7241631150245667\n",
      "Seen so far: 88448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1382: 0.9065917730331421\n",
      "Seen so far: 88512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1383: 1.072523832321167\n",
      "Seen so far: 88576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1384: 0.6325802803039551\n",
      "Seen so far: 88640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1385: 0.6730431914329529\n",
      "Seen so far: 88704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1386: 1.0400573015213013\n",
      "Seen so far: 88768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1387: 0.874163031578064\n",
      "Seen so far: 88832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1388: 1.0503709316253662\n",
      "Seen so far: 88896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1389: 0.536524772644043\n",
      "Seen so far: 88960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1390: 0.7876431941986084\n",
      "Seen so far: 89024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1391: 1.1489291191101074\n",
      "Seen so far: 89088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1392: 1.060362458229065\n",
      "Seen so far: 89152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1393: 1.4150274991989136\n",
      "Seen so far: 89216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1394: 0.779557466506958\n",
      "Seen so far: 89280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1395: 0.9203106164932251\n",
      "Seen so far: 89344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1396: 1.0504885911941528\n",
      "Seen so far: 89408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1397: 0.9545799493789673\n",
      "Seen so far: 89472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1398: 0.7992533445358276\n",
      "Seen so far: 89536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1399: 1.1201834678649902\n",
      "Seen so far: 89600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1400: 1.0486079454421997\n",
      "Seen so far: 89664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1401: 0.7112300992012024\n",
      "Seen so far: 89728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1402: 0.8380372524261475\n",
      "Seen so far: 89792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1403: 0.9913798570632935\n",
      "Seen so far: 89856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1404: 0.707499623298645\n",
      "Seen so far: 89920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1405: 0.6492264270782471\n",
      "Seen so far: 89984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1406: 1.3397347927093506\n",
      "Seen so far: 90048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1407: 0.6380405426025391\n",
      "Seen so far: 90112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1408: 0.6872586011886597\n",
      "Seen so far: 90176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1409: 0.6989518404006958\n",
      "Seen so far: 90240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1410: 0.9351899027824402\n",
      "Seen so far: 90304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1411: 0.963448703289032\n",
      "Seen so far: 90368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1412: 1.0111582279205322\n",
      "Seen so far: 90432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1413: 0.9824906587600708\n",
      "Seen so far: 90496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1414: 0.7156680822372437\n",
      "Seen so far: 90560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1415: 0.8062430024147034\n",
      "Seen so far: 90624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1416: 0.8407720327377319\n",
      "Seen so far: 90688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1417: 1.044421672821045\n",
      "Seen so far: 90752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1418: 0.8367769122123718\n",
      "Seen so far: 90816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1419: 0.9032584428787231\n",
      "Seen so far: 90880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1420: 0.6419703960418701\n",
      "Seen so far: 90944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1421: 0.5936852693557739\n",
      "Seen so far: 91008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1422: 0.9379621148109436\n",
      "Seen so far: 91072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1423: 0.9295923113822937\n",
      "Seen so far: 91136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1424: 0.7445884943008423\n",
      "Seen so far: 91200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1425: 0.5264467000961304\n",
      "Seen so far: 91264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1426: 0.8006738424301147\n",
      "Seen so far: 91328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1427: 0.8407118320465088\n",
      "Seen so far: 91392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1428: 1.0357346534729004\n",
      "Seen so far: 91456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1429: 0.7760441303253174\n",
      "Seen so far: 91520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1430: 0.695656955242157\n",
      "Seen so far: 91584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1431: 1.0588371753692627\n",
      "Seen so far: 91648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1432: 0.43929600715637207\n",
      "Seen so far: 91712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1433: 0.8887631893157959\n",
      "Seen so far: 91776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1434: 0.4742239713668823\n",
      "Seen so far: 91840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1435: 0.9008248448371887\n",
      "Seen so far: 91904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1436: 0.7377043962478638\n",
      "Seen so far: 91968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1437: 0.7899832725524902\n",
      "Seen so far: 92032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1438: 1.0833159685134888\n",
      "Seen so far: 92096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1439: 0.8892049789428711\n",
      "Seen so far: 92160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1440: 0.8930945992469788\n",
      "Seen so far: 92224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1441: 0.7125236988067627\n",
      "Seen so far: 92288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1442: 1.2409495115280151\n",
      "Seen so far: 92352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1443: 1.1190083026885986\n",
      "Seen so far: 92416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1444: 1.2949492931365967\n",
      "Seen so far: 92480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1445: 0.9660935401916504\n",
      "Seen so far: 92544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1446: 0.7579535245895386\n",
      "Seen so far: 92608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1447: 0.44844383001327515\n",
      "Seen so far: 92672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1448: 0.6469120383262634\n",
      "Seen so far: 92736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1449: 1.1167184114456177\n",
      "Seen so far: 92800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1450: 0.5117107033729553\n",
      "Seen so far: 92864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1451: 1.1264837980270386\n",
      "Seen so far: 92928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1452: 0.535490870475769\n",
      "Seen so far: 92992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1453: 1.1588311195373535\n",
      "Seen so far: 93056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1454: 0.7901759147644043\n",
      "Seen so far: 93120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1455: 1.0578685998916626\n",
      "Seen so far: 93184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1456: 0.7920838594436646\n",
      "Seen so far: 93248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1457: 1.0628688335418701\n",
      "Seen so far: 93312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1458: 1.0266749858856201\n",
      "Seen so far: 93376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1459: 1.0118498802185059\n",
      "Seen so far: 93440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1460: 1.0389381647109985\n",
      "Seen so far: 93504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1461: 0.8298164010047913\n",
      "Seen so far: 93568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1462: 0.9074957966804504\n",
      "Seen so far: 93632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1463: 1.12703275680542\n",
      "Seen so far: 93696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1464: 0.5048324465751648\n",
      "Seen so far: 93760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1465: 0.9801418781280518\n",
      "Seen so far: 93824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1466: 0.8443441390991211\n",
      "Seen so far: 93888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1467: 0.8015495538711548\n",
      "Seen so far: 93952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1468: 0.9254136085510254\n",
      "Seen so far: 94016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1469: 0.7346842885017395\n",
      "Seen so far: 94080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1470: 1.1238934993743896\n",
      "Seen so far: 94144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1471: 0.47612464427948\n",
      "Seen so far: 94208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1472: 0.9663870334625244\n",
      "Seen so far: 94272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1473: 0.836405873298645\n",
      "Seen so far: 94336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1474: 0.5539593696594238\n",
      "Seen so far: 94400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1475: 1.2299917936325073\n",
      "Seen so far: 94464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1476: 0.4528543949127197\n",
      "Seen so far: 94528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1477: 0.7041070461273193\n",
      "Seen so far: 94592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1478: 1.22324800491333\n",
      "Seen so far: 94656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1479: 0.9687214493751526\n",
      "Seen so far: 94720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1480: 0.6701470017433167\n",
      "Seen so far: 94784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1481: 1.0132304430007935\n",
      "Seen so far: 94848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1482: 0.5166893005371094\n",
      "Seen so far: 94912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1483: 0.9729233980178833\n",
      "Seen so far: 94976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1484: 0.728019654750824\n",
      "Seen so far: 95040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1485: 0.7369977235794067\n",
      "Seen so far: 95104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1486: 0.6190798282623291\n",
      "Seen so far: 95168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1487: 0.5464995503425598\n",
      "Seen so far: 95232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1488: 0.8350099325180054\n",
      "Seen so far: 95296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1489: 0.7968392372131348\n",
      "Seen so far: 95360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1490: 0.6463041305541992\n",
      "Seen so far: 95424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1491: 0.585952639579773\n",
      "Seen so far: 95488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1492: 0.8196049928665161\n",
      "Seen so far: 95552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1493: 0.8293425440788269\n",
      "Seen so far: 95616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1494: 0.8491986989974976\n",
      "Seen so far: 95680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1495: 1.3039028644561768\n",
      "Seen so far: 95744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1496: 0.7505667805671692\n",
      "Seen so far: 95808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1497: 1.0985137224197388\n",
      "Seen so far: 95872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1498: 0.6115216016769409\n",
      "Seen so far: 95936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1499: 0.9738458395004272\n",
      "Seen so far: 96000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1500: 0.7688038945198059\n",
      "Seen so far: 96064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1501: 1.1997913122177124\n",
      "Seen so far: 96128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1502: 0.887108564376831\n",
      "Seen so far: 96192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1503: 0.5407372713088989\n",
      "Seen so far: 96256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1504: 0.7553195953369141\n",
      "Seen so far: 96320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1505: 1.0784169435501099\n",
      "Seen so far: 96384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1506: 0.603608250617981\n",
      "Seen so far: 96448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1507: 1.5918588638305664\n",
      "Seen so far: 96512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1508: 0.6554925441741943\n",
      "Seen so far: 96576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1509: 1.1595070362091064\n",
      "Seen so far: 96640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1510: 1.7113584280014038\n",
      "Seen so far: 96704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1511: 0.8958012461662292\n",
      "Seen so far: 96768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1512: 0.8657057285308838\n",
      "Seen so far: 96832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1513: 0.9676923751831055\n",
      "Seen so far: 96896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1514: 0.8719417452812195\n",
      "Seen so far: 96960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1515: 1.2810237407684326\n",
      "Seen so far: 97024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1516: 0.8742533922195435\n",
      "Seen so far: 97088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1517: 1.4415382146835327\n",
      "Seen so far: 97152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1518: 1.057509183883667\n",
      "Seen so far: 97216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1519: 0.6019545793533325\n",
      "Seen so far: 97280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1520: 0.8508813381195068\n",
      "Seen so far: 97344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1521: 0.8564338684082031\n",
      "Seen so far: 97408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1522: 0.9783614873886108\n",
      "Seen so far: 97472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1523: 1.182465672492981\n",
      "Seen so far: 97536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1524: 1.050886631011963\n",
      "Seen so far: 97600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1525: 1.0777184963226318\n",
      "Seen so far: 97664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1526: 1.1912941932678223\n",
      "Seen so far: 97728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1527: 0.8026098012924194\n",
      "Seen so far: 97792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1528: 0.5776315331459045\n",
      "Seen so far: 97856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1529: 0.7176635265350342\n",
      "Seen so far: 97920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1530: 0.7755394577980042\n",
      "Seen so far: 97984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1531: 0.4175431728363037\n",
      "Seen so far: 98048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1532: 0.8286468386650085\n",
      "Seen so far: 98112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1533: 0.7417863607406616\n",
      "Seen so far: 98176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1534: 0.894160807132721\n",
      "Seen so far: 98240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1535: 0.6259322166442871\n",
      "Seen so far: 98304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1536: 0.7953686118125916\n",
      "Seen so far: 98368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1537: 0.7650789022445679\n",
      "Seen so far: 98432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1538: 1.0133060216903687\n",
      "Seen so far: 98496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1539: 0.6534369587898254\n",
      "Seen so far: 98560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1540: 0.6640818119049072\n",
      "Seen so far: 98624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1541: 0.5654861927032471\n",
      "Seen so far: 98688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1542: 0.862577497959137\n",
      "Seen so far: 98752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1543: 0.9814137816429138\n",
      "Seen so far: 98816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1544: 0.5522145628929138\n",
      "Seen so far: 98880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1545: 0.5295521020889282\n",
      "Seen so far: 98944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1546: 0.8707800507545471\n",
      "Seen so far: 99008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1547: 0.9383790493011475\n",
      "Seen so far: 99072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1548: 0.7081224918365479\n",
      "Seen so far: 99136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1549: 0.7053107023239136\n",
      "Seen so far: 99200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1550: 1.0005545616149902\n",
      "Seen so far: 99264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1551: 1.2123924493789673\n",
      "Seen so far: 99328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1552: 0.6339932680130005\n",
      "Seen so far: 99392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1553: 0.4950109124183655\n",
      "Seen so far: 99456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1554: 1.2777304649353027\n",
      "Seen so far: 99520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1555: 1.0596600770950317\n",
      "Seen so far: 99584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1556: 1.1281161308288574\n",
      "Seen so far: 99648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1557: 1.0411179065704346\n",
      "Seen so far: 99712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1558: 0.8076725602149963\n",
      "Seen so far: 99776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1559: 0.5280320644378662\n",
      "Seen so far: 99840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1560: 1.3585798740386963\n",
      "Seen so far: 99904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1561: 0.8400800228118896\n",
      "Seen so far: 99968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1562: 0.940356433391571\n",
      "Seen so far: 100032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1563: 0.7858982086181641\n",
      "Seen so far: 100096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1564: 1.0790596008300781\n",
      "Seen so far: 100160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1565: 1.0125553607940674\n",
      "Seen so far: 100224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1566: 0.9065145254135132\n",
      "Seen so far: 100288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1567: 0.6378831267356873\n",
      "Seen so far: 100352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1568: 0.7117295265197754\n",
      "Seen so far: 100416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1569: 0.7032463550567627\n",
      "Seen so far: 100480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1570: 1.1989498138427734\n",
      "Seen so far: 100544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1571: 1.1030925512313843\n",
      "Seen so far: 100608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1572: 0.5939540863037109\n",
      "Seen so far: 100672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1573: 1.1929261684417725\n",
      "Seen so far: 100736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1574: 0.8045768141746521\n",
      "Seen so far: 100800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1575: 0.9709311127662659\n",
      "Seen so far: 100864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1576: 0.7479979395866394\n",
      "Seen so far: 100928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1577: 0.6770042181015015\n",
      "Seen so far: 100992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1578: 0.9361974000930786\n",
      "Seen so far: 101056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1579: 0.7167824506759644\n",
      "Seen so far: 101120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1580: 0.886023759841919\n",
      "Seen so far: 101184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1581: 0.8445202112197876\n",
      "Seen so far: 101248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1582: 0.9673923850059509\n",
      "Seen so far: 101312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1583: 0.7738897800445557\n",
      "Seen so far: 101376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1584: 0.8873696327209473\n",
      "Seen so far: 101440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1585: 1.389298677444458\n",
      "Seen so far: 101504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1586: 0.7468356490135193\n",
      "Seen so far: 101568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1587: 0.5880280137062073\n",
      "Seen so far: 101632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1588: 0.5965871214866638\n",
      "Seen so far: 101696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1589: 0.9359039068222046\n",
      "Seen so far: 101760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1590: 0.8230626583099365\n",
      "Seen so far: 101824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1591: 0.9798756837844849\n",
      "Seen so far: 101888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1592: 0.8931833505630493\n",
      "Seen so far: 101952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1593: 0.7981234788894653\n",
      "Seen so far: 102016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1594: 0.5636111497879028\n",
      "Seen so far: 102080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1595: 1.076136827468872\n",
      "Seen so far: 102144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1596: 0.7708125114440918\n",
      "Seen so far: 102208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1597: 1.0032225847244263\n",
      "Seen so far: 102272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1598: 0.7560124397277832\n",
      "Seen so far: 102336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1599: 0.8159866333007812\n",
      "Seen so far: 102400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1600: 0.4296568036079407\n",
      "Seen so far: 102464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1601: 0.8903083801269531\n",
      "Seen so far: 102528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1602: 0.48274850845336914\n",
      "Seen so far: 102592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1603: 1.285238265991211\n",
      "Seen so far: 102656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1604: 0.7310742735862732\n",
      "Seen so far: 102720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1605: 1.4905998706817627\n",
      "Seen so far: 102784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1606: 1.0455386638641357\n",
      "Seen so far: 102848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1607: 0.7901487946510315\n",
      "Seen so far: 102912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1608: 0.8358476161956787\n",
      "Seen so far: 102976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1609: 0.9282057881355286\n",
      "Seen so far: 103040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1610: 0.9655612111091614\n",
      "Seen so far: 103104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1611: 0.8299612998962402\n",
      "Seen so far: 103168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1612: 1.0823888778686523\n",
      "Seen so far: 103232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1613: 1.1828975677490234\n",
      "Seen so far: 103296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1614: 0.7147595286369324\n",
      "Seen so far: 103360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1615: 0.7894196510314941\n",
      "Seen so far: 103424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1616: 0.8204411268234253\n",
      "Seen so far: 103488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1617: 0.9804494380950928\n",
      "Seen so far: 103552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1618: 0.6617496013641357\n",
      "Seen so far: 103616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1619: 0.791121244430542\n",
      "Seen so far: 103680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1620: 0.7372960448265076\n",
      "Seen so far: 103744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1621: 0.6794883012771606\n",
      "Seen so far: 103808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1622: 0.8213511109352112\n",
      "Seen so far: 103872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1623: 1.026383638381958\n",
      "Seen so far: 103936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1624: 0.7649767398834229\n",
      "Seen so far: 104000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1625: 1.3202762603759766\n",
      "Seen so far: 104064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1626: 0.8724236488342285\n",
      "Seen so far: 104128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1627: 0.910716712474823\n",
      "Seen so far: 104192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1628: 0.8143060803413391\n",
      "Seen so far: 104256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1629: 0.6799366474151611\n",
      "Seen so far: 104320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1630: 1.0299516916275024\n",
      "Seen so far: 104384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1631: 0.7774752974510193\n",
      "Seen so far: 104448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1632: 1.1400928497314453\n",
      "Seen so far: 104512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1633: 0.954535722732544\n",
      "Seen so far: 104576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1634: 1.1742138862609863\n",
      "Seen so far: 104640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1635: 0.7817391157150269\n",
      "Seen so far: 104704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1636: 0.7848160266876221\n",
      "Seen so far: 104768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1637: 0.5142449140548706\n",
      "Seen so far: 104832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1638: 0.9946185946464539\n",
      "Seen so far: 104896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1639: 0.6660933494567871\n",
      "Seen so far: 104960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1640: 0.9726074934005737\n",
      "Seen so far: 105024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1641: 0.7278541326522827\n",
      "Seen so far: 105088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1642: 0.855414867401123\n",
      "Seen so far: 105152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1643: 1.2626609802246094\n",
      "Seen so far: 105216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1644: 0.8653985261917114\n",
      "Seen so far: 105280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1645: 1.1232447624206543\n",
      "Seen so far: 105344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1646: 0.7817448377609253\n",
      "Seen so far: 105408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1647: 0.6247994303703308\n",
      "Seen so far: 105472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1648: 0.805902898311615\n",
      "Seen so far: 105536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1649: 1.0682504177093506\n",
      "Seen so far: 105600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1650: 0.7046966552734375\n",
      "Seen so far: 105664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1651: 1.0127606391906738\n",
      "Seen so far: 105728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1652: 0.8047431707382202\n",
      "Seen so far: 105792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1653: 0.6761274337768555\n",
      "Seen so far: 105856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1654: 0.8662540912628174\n",
      "Seen so far: 105920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1655: 0.7662128210067749\n",
      "Seen so far: 105984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1656: 0.6266958713531494\n",
      "Seen so far: 106048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1657: 0.8144506216049194\n",
      "Seen so far: 106112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1658: 0.5990699529647827\n",
      "Seen so far: 106176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1659: 0.9506248235702515\n",
      "Seen so far: 106240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1660: 0.9306961297988892\n",
      "Seen so far: 106304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1661: 0.8550770878791809\n",
      "Seen so far: 106368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1662: 0.522946834564209\n",
      "Seen so far: 106432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1663: 0.877461850643158\n",
      "Seen so far: 106496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1664: 1.1038357019424438\n",
      "Seen so far: 106560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1665: 1.1429779529571533\n",
      "Seen so far: 106624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1666: 0.8096235394477844\n",
      "Seen so far: 106688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1667: 0.7284348011016846\n",
      "Seen so far: 106752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1668: 1.129071831703186\n",
      "Seen so far: 106816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1669: 0.540280818939209\n",
      "Seen so far: 106880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1670: 0.7609524130821228\n",
      "Seen so far: 106944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1671: 0.8550009727478027\n",
      "Seen so far: 107008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1672: 0.9410664439201355\n",
      "Seen so far: 107072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1673: 0.5401259064674377\n",
      "Seen so far: 107136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1674: 0.7068842053413391\n",
      "Seen so far: 107200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1675: 1.1764329671859741\n",
      "Seen so far: 107264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1676: 0.6957769393920898\n",
      "Seen so far: 107328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1677: 0.7926781177520752\n",
      "Seen so far: 107392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1678: 0.7661876082420349\n",
      "Seen so far: 107456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1679: 0.7622648477554321\n",
      "Seen so far: 107520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1680: 1.0123026371002197\n",
      "Seen so far: 107584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1681: 1.3737894296646118\n",
      "Seen so far: 107648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1682: 0.8010399341583252\n",
      "Seen so far: 107712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1683: 1.0240013599395752\n",
      "Seen so far: 107776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1684: 1.0087800025939941\n",
      "Seen so far: 107840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1685: 0.8998985886573792\n",
      "Seen so far: 107904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1686: 1.0523438453674316\n",
      "Seen so far: 107968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1687: 1.0532448291778564\n",
      "Seen so far: 108032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1688: 1.1321580410003662\n",
      "Seen so far: 108096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1689: 0.7472450137138367\n",
      "Seen so far: 108160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1690: 1.1463253498077393\n",
      "Seen so far: 108224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1691: 0.530292809009552\n",
      "Seen so far: 108288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1692: 0.7201769351959229\n",
      "Seen so far: 108352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1693: 1.182004690170288\n",
      "Seen so far: 108416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1694: 0.920845627784729\n",
      "Seen so far: 108480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1695: 0.9364463686943054\n",
      "Seen so far: 108544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1696: 1.0355769395828247\n",
      "Seen so far: 108608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1697: 1.1495469808578491\n",
      "Seen so far: 108672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1698: 0.5139628648757935\n",
      "Seen so far: 108736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1699: 0.6296210885047913\n",
      "Seen so far: 108800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1700: 0.6249434947967529\n",
      "Seen so far: 108864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1701: 0.8602955341339111\n",
      "Seen so far: 108928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1702: 1.1416972875595093\n",
      "Seen so far: 108992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1703: 0.6171187162399292\n",
      "Seen so far: 109056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1704: 1.0252643823623657\n",
      "Seen so far: 109120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1705: 1.078334093093872\n",
      "Seen so far: 109184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1706: 1.1312651634216309\n",
      "Seen so far: 109248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1707: 0.6562595367431641\n",
      "Seen so far: 109312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1708: 0.9724992513656616\n",
      "Seen so far: 109376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1709: 1.3307836055755615\n",
      "Seen so far: 109440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1710: 0.7289677858352661\n",
      "Seen so far: 109504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1711: 0.6252362728118896\n",
      "Seen so far: 109568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1712: 0.6651724576950073\n",
      "Seen so far: 109632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1713: 0.4518747925758362\n",
      "Seen so far: 109696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1714: 0.8245776891708374\n",
      "Seen so far: 109760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1715: 0.5938556790351868\n",
      "Seen so far: 109824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1716: 1.108776330947876\n",
      "Seen so far: 109888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1717: 0.6205301284790039\n",
      "Seen so far: 109952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1718: 0.7806442975997925\n",
      "Seen so far: 110016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1719: 0.5872864723205566\n",
      "Seen so far: 110080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1720: 1.048284649848938\n",
      "Seen so far: 110144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1721: 1.0237154960632324\n",
      "Seen so far: 110208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1722: 0.8521366119384766\n",
      "Seen so far: 110272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1723: 0.65561842918396\n",
      "Seen so far: 110336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1724: 1.0029361248016357\n",
      "Seen so far: 110400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1725: 0.8764835596084595\n",
      "Seen so far: 110464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1726: 1.4525389671325684\n",
      "Seen so far: 110528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1727: 0.8749485015869141\n",
      "Seen so far: 110592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1728: 0.8021194338798523\n",
      "Seen so far: 110656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1729: 0.9303343296051025\n",
      "Seen so far: 110720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1730: 0.8610926866531372\n",
      "Seen so far: 110784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1731: 0.6385781764984131\n",
      "Seen so far: 110848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1732: 1.0520941019058228\n",
      "Seen so far: 110912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1733: 1.2468855381011963\n",
      "Seen so far: 110976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1734: 0.7770755290985107\n",
      "Seen so far: 111040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1735: 0.7135555148124695\n",
      "Seen so far: 111104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1736: 0.8308467864990234\n",
      "Seen so far: 111168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1737: 1.0408920049667358\n",
      "Seen so far: 111232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1738: 0.7913268804550171\n",
      "Seen so far: 111296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1739: 0.7534265518188477\n",
      "Seen so far: 111360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1740: 0.98080974817276\n",
      "Seen so far: 111424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1741: 0.9215977191925049\n",
      "Seen so far: 111488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1742: 0.8431727886199951\n",
      "Seen so far: 111552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1743: 0.5060149431228638\n",
      "Seen so far: 111616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1744: 0.8799462914466858\n",
      "Seen so far: 111680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1745: 0.9907000660896301\n",
      "Seen so far: 111744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1746: 1.2170472145080566\n",
      "Seen so far: 111808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1747: 1.3386520147323608\n",
      "Seen so far: 111872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1748: 0.9675092697143555\n",
      "Seen so far: 111936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1749: 0.6952307224273682\n",
      "Seen so far: 112000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1750: 0.9672180414199829\n",
      "Seen so far: 112064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1751: 1.0987000465393066\n",
      "Seen so far: 112128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1752: 1.0846807956695557\n",
      "Seen so far: 112192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1753: 1.2333929538726807\n",
      "Seen so far: 112256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1754: 1.2077133655548096\n",
      "Seen so far: 112320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1755: 0.71507728099823\n",
      "Seen so far: 112384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1756: 1.2773507833480835\n",
      "Seen so far: 112448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1757: 0.7465742230415344\n",
      "Seen so far: 112512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1758: 1.3339085578918457\n",
      "Seen so far: 112576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1759: 0.6637816429138184\n",
      "Seen so far: 112640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1760: 0.8668292760848999\n",
      "Seen so far: 112704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1761: 0.9472441673278809\n",
      "Seen so far: 112768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1762: 0.9455578923225403\n",
      "Seen so far: 112832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1763: 1.140071988105774\n",
      "Seen so far: 112896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1764: 0.9688547253608704\n",
      "Seen so far: 112960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1765: 0.5720685124397278\n",
      "Seen so far: 113024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1766: 0.8096307516098022\n",
      "Seen so far: 113088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1767: 0.9485836029052734\n",
      "Seen so far: 113152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1768: 1.1038212776184082\n",
      "Seen so far: 113216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1769: 0.7001551389694214\n",
      "Seen so far: 113280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1770: 0.7496993541717529\n",
      "Seen so far: 113344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1771: 0.9544961452484131\n",
      "Seen so far: 113408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1772: 1.0874583721160889\n",
      "Seen so far: 113472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1773: 0.9027256965637207\n",
      "Seen so far: 113536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1774: 0.5813187956809998\n",
      "Seen so far: 113600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1775: 0.9814820289611816\n",
      "Seen so far: 113664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1776: 1.2140977382659912\n",
      "Seen so far: 113728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1777: 0.8816523551940918\n",
      "Seen so far: 113792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1778: 0.7426223754882812\n",
      "Seen so far: 113856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1779: 1.3707382678985596\n",
      "Seen so far: 113920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1780: 1.1930383443832397\n",
      "Seen so far: 113984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1781: 1.1969881057739258\n",
      "Seen so far: 114048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1782: 0.5098108649253845\n",
      "Seen so far: 114112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1783: 0.9853676557540894\n",
      "Seen so far: 114176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1784: 0.9808955192565918\n",
      "Seen so far: 114240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1785: 0.8814610242843628\n",
      "Seen so far: 114304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1786: 1.0992774963378906\n",
      "Seen so far: 114368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1787: 0.8748725652694702\n",
      "Seen so far: 114432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1788: 0.7074300050735474\n",
      "Seen so far: 114496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1789: 0.7340207099914551\n",
      "Seen so far: 114560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1790: 0.8783247470855713\n",
      "Seen so far: 114624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1791: 0.7348311543464661\n",
      "Seen so far: 114688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1792: 0.6389131546020508\n",
      "Seen so far: 114752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1793: 0.9911612868309021\n",
      "Seen so far: 114816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1794: 0.6584599018096924\n",
      "Seen so far: 114880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1795: 0.7586839199066162\n",
      "Seen so far: 114944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1796: 0.8007501363754272\n",
      "Seen so far: 115008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1797: 0.48353147506713867\n",
      "Seen so far: 115072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1798: 0.5784834027290344\n",
      "Seen so far: 115136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1799: 0.6718820333480835\n",
      "Seen so far: 115200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1800: 0.8913574814796448\n",
      "Seen so far: 115264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1801: 0.724378228187561\n",
      "Seen so far: 115328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1802: 0.5371606349945068\n",
      "Seen so far: 115392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1803: 0.9162496328353882\n",
      "Seen so far: 115456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1804: 0.6739615201950073\n",
      "Seen so far: 115520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1805: 0.5324645042419434\n",
      "Seen so far: 115584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1806: 0.8225888013839722\n",
      "Seen so far: 115648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1807: 0.7754924297332764\n",
      "Seen so far: 115712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1808: 1.0006916522979736\n",
      "Seen so far: 115776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1809: 0.8049788475036621\n",
      "Seen so far: 115840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1810: 0.7200335264205933\n",
      "Seen so far: 115904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1811: 0.9385412335395813\n",
      "Seen so far: 115968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1812: 0.8125777244567871\n",
      "Seen so far: 116032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1813: 1.0645573139190674\n",
      "Seen so far: 116096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1814: 0.919896125793457\n",
      "Seen so far: 116160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1815: 1.3678293228149414\n",
      "Seen so far: 116224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1816: 0.8757988214492798\n",
      "Seen so far: 116288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1817: 0.8826277852058411\n",
      "Seen so far: 116352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1818: 0.8790302872657776\n",
      "Seen so far: 116416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1819: 0.6075981855392456\n",
      "Seen so far: 116480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1820: 0.7455852627754211\n",
      "Seen so far: 116544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1821: 1.1180187463760376\n",
      "Seen so far: 116608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1822: 1.2527961730957031\n",
      "Seen so far: 116672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1823: 1.0565862655639648\n",
      "Seen so far: 116736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1824: 1.128159523010254\n",
      "Seen so far: 116800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1825: 0.6953915953636169\n",
      "Seen so far: 116864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1826: 1.1948442459106445\n",
      "Seen so far: 116928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1827: 1.0762934684753418\n",
      "Seen so far: 116992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1828: 1.0295993089675903\n",
      "Seen so far: 117056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1829: 0.8630757331848145\n",
      "Seen so far: 117120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1830: 0.8330399990081787\n",
      "Seen so far: 117184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1831: 0.8169825077056885\n",
      "Seen so far: 117248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1832: 1.228476881980896\n",
      "Seen so far: 117312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1833: 0.832994818687439\n",
      "Seen so far: 117376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1834: 1.2538297176361084\n",
      "Seen so far: 117440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1835: 0.7561125159263611\n",
      "Seen so far: 117504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1836: 0.8182396292686462\n",
      "Seen so far: 117568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1837: 0.6498754024505615\n",
      "Seen so far: 117632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1838: 0.9489913582801819\n",
      "Seen so far: 117696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1839: 0.6709851026535034\n",
      "Seen so far: 117760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1840: 1.3482825756072998\n",
      "Seen so far: 117824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1841: 0.7882556915283203\n",
      "Seen so far: 117888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1842: 0.5410441160202026\n",
      "Seen so far: 117952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1843: 0.9544809460639954\n",
      "Seen so far: 118016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1844: 0.9205609560012817\n",
      "Seen so far: 118080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1845: 0.9651787281036377\n",
      "Seen so far: 118144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1846: 1.0605342388153076\n",
      "Seen so far: 118208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1847: 0.9588968753814697\n",
      "Seen so far: 118272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1848: 0.8135538101196289\n",
      "Seen so far: 118336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1849: 1.2103021144866943\n",
      "Seen so far: 118400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1850: 0.6784425973892212\n",
      "Seen so far: 118464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1851: 1.146618366241455\n",
      "Seen so far: 118528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1852: 0.8600786924362183\n",
      "Seen so far: 118592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1853: 0.5128440856933594\n",
      "Seen so far: 118656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1854: 1.125662922859192\n",
      "Seen so far: 118720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1855: 1.251917839050293\n",
      "Seen so far: 118784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1856: 0.8351583480834961\n",
      "Seen so far: 118848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1857: 0.7334169149398804\n",
      "Seen so far: 118912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1858: 0.9513859748840332\n",
      "Seen so far: 118976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1859: 0.5898000597953796\n",
      "Seen so far: 119040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1860: 0.6917139887809753\n",
      "Seen so far: 119104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1861: 1.0141305923461914\n",
      "Seen so far: 119168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1862: 0.7886067628860474\n",
      "Seen so far: 119232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1863: 0.6698720455169678\n",
      "Seen so far: 119296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1864: 0.8438506722450256\n",
      "Seen so far: 119360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1865: 0.7877548933029175\n",
      "Seen so far: 119424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1866: 1.0014958381652832\n",
      "Seen so far: 119488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1867: 0.7483969926834106\n",
      "Seen so far: 119552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1868: 0.6706326007843018\n",
      "Seen so far: 119616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1869: 0.6639618873596191\n",
      "Seen so far: 119680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1870: 0.6963456869125366\n",
      "Seen so far: 119744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1871: 0.8102643489837646\n",
      "Seen so far: 119808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1872: 0.8821094036102295\n",
      "Seen so far: 119872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1873: 1.1328513622283936\n",
      "Seen so far: 119936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1874: 0.8699694871902466\n",
      "Seen so far: 120000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1875: 0.7932920455932617\n",
      "Seen so far: 120064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1876: 0.5832617282867432\n",
      "Seen so far: 120128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1877: 0.593914270401001\n",
      "Seen so far: 120192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1878: 0.9143697023391724\n",
      "Seen so far: 120256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1879: 0.8207074999809265\n",
      "Seen so far: 120320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1880: 0.9062287211418152\n",
      "Seen so far: 120384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1881: 0.5283415913581848\n",
      "Seen so far: 120448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1882: 1.035243272781372\n",
      "Seen so far: 120512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1883: 0.5405191779136658\n",
      "Seen so far: 120576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1884: 0.9990118741989136\n",
      "Seen so far: 120640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1885: 0.9350813627243042\n",
      "Seen so far: 120704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1886: 0.7031227350234985\n",
      "Seen so far: 120768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1887: 0.7011122703552246\n",
      "Seen so far: 120832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1888: 0.5237968564033508\n",
      "Seen so far: 120896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1889: 1.1495361328125\n",
      "Seen so far: 120960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1890: 1.4309613704681396\n",
      "Seen so far: 121024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1891: 1.006494164466858\n",
      "Seen so far: 121088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1892: 0.7866982221603394\n",
      "Seen so far: 121152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1893: 0.9327794313430786\n",
      "Seen so far: 121216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1894: 0.8864669799804688\n",
      "Seen so far: 121280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1895: 0.7646992206573486\n",
      "Seen so far: 121344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1896: 0.3751324415206909\n",
      "Seen so far: 121408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1897: 0.9713663458824158\n",
      "Seen so far: 121472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1898: 0.668459415435791\n",
      "Seen so far: 121536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1899: 1.055757999420166\n",
      "Seen so far: 121600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1900: 0.9182324409484863\n",
      "Seen so far: 121664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1901: 0.765727698802948\n",
      "Seen so far: 121728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1902: 1.3564683198928833\n",
      "Seen so far: 121792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1903: 0.8953368663787842\n",
      "Seen so far: 121856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1904: 0.9857892394065857\n",
      "Seen so far: 121920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1905: 0.7938054800033569\n",
      "Seen so far: 121984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1906: 0.7267515063285828\n",
      "Seen so far: 122048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1907: 1.0674071311950684\n",
      "Seen so far: 122112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1908: 1.0194191932678223\n",
      "Seen so far: 122176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1909: 0.9326322078704834\n",
      "Seen so far: 122240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1910: 0.6623420715332031\n",
      "Seen so far: 122304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1911: 0.6764022707939148\n",
      "Seen so far: 122368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1912: 1.142148494720459\n",
      "Seen so far: 122432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1913: 0.7505949139595032\n",
      "Seen so far: 122496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1914: 0.7922703623771667\n",
      "Seen so far: 122560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1915: 0.7481141090393066\n",
      "Seen so far: 122624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1916: 0.7360396385192871\n",
      "Seen so far: 122688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1917: 1.0010164976119995\n",
      "Seen so far: 122752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1918: 1.0200932025909424\n",
      "Seen so far: 122816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1919: 0.976965069770813\n",
      "Seen so far: 122880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1920: 1.0734703540802002\n",
      "Seen so far: 122944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1921: 1.0516870021820068\n",
      "Seen so far: 123008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1922: 0.9618431925773621\n",
      "Seen so far: 123072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1923: 0.9328294992446899\n",
      "Seen so far: 123136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1924: 0.970644474029541\n",
      "Seen so far: 123200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1925: 0.7491124868392944\n",
      "Seen so far: 123264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1926: 0.9825431704521179\n",
      "Seen so far: 123328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1927: 0.9237841367721558\n",
      "Seen so far: 123392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1928: 0.5577466487884521\n",
      "Seen so far: 123456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1929: 0.7202497124671936\n",
      "Seen so far: 123520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1930: 1.2341346740722656\n",
      "Seen so far: 123584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1931: 1.0336703062057495\n",
      "Seen so far: 123648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1932: 1.1897003650665283\n",
      "Seen so far: 123712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1933: 0.8135276436805725\n",
      "Seen so far: 123776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1934: 0.8909067511558533\n",
      "Seen so far: 123840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1935: 1.2353214025497437\n",
      "Seen so far: 123904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1936: 1.3101022243499756\n",
      "Seen so far: 123968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1937: 0.9304330348968506\n",
      "Seen so far: 124032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1938: 0.6516997814178467\n",
      "Seen so far: 124096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1939: 1.1887238025665283\n",
      "Seen so far: 124160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1940: 0.8263137340545654\n",
      "Seen so far: 124224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1941: 0.8243730068206787\n",
      "Seen so far: 124288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1942: 0.825562596321106\n",
      "Seen so far: 124352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1943: 0.6245344877243042\n",
      "Seen so far: 124416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1944: 1.0363516807556152\n",
      "Seen so far: 124480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1945: 0.9890593886375427\n",
      "Seen so far: 124544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1946: 0.8875199556350708\n",
      "Seen so far: 124608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1947: 0.5762103796005249\n",
      "Seen so far: 124672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1948: 1.1184613704681396\n",
      "Seen so far: 124736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1949: 0.8232945203781128\n",
      "Seen so far: 124800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1950: 1.2159290313720703\n",
      "Seen so far: 124864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1951: 0.6463043093681335\n",
      "Seen so far: 124928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1952: 0.4395129084587097\n",
      "Seen so far: 124992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1953: 0.574527382850647\n",
      "Seen so far: 125056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1954: 0.8963271975517273\n",
      "Seen so far: 125120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1955: 0.9183027744293213\n",
      "Seen so far: 125184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1956: 0.8484091758728027\n",
      "Seen so far: 125248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1957: 0.8588280081748962\n",
      "Seen so far: 125312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1958: 0.5108624696731567\n",
      "Seen so far: 125376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1959: 0.618323564529419\n",
      "Seen so far: 125440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1960: 1.0226848125457764\n",
      "Seen so far: 125504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1961: 0.8644769787788391\n",
      "Seen so far: 125568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1962: 0.6617032289505005\n",
      "Seen so far: 125632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1963: 0.8422952890396118\n",
      "Seen so far: 125696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1964: 0.7170038223266602\n",
      "Seen so far: 125760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1965: 1.2107973098754883\n",
      "Seen so far: 125824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1966: 0.7790710926055908\n",
      "Seen so far: 125888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1967: 0.949341356754303\n",
      "Seen so far: 125952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1968: 0.653298020362854\n",
      "Seen so far: 126016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1969: 0.8404473066329956\n",
      "Seen so far: 126080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1970: 0.887976884841919\n",
      "Seen so far: 126144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1971: 0.7975054979324341\n",
      "Seen so far: 126208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1972: 0.7923074960708618\n",
      "Seen so far: 126272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1973: 1.0024664402008057\n",
      "Seen so far: 126336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1974: 0.8781331777572632\n",
      "Seen so far: 126400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1975: 1.2969651222229004\n",
      "Seen so far: 126464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1976: 0.6282613277435303\n",
      "Seen so far: 126528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1977: 0.7059051990509033\n",
      "Seen so far: 126592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1978: 0.9103927612304688\n",
      "Seen so far: 126656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1979: 0.474867045879364\n",
      "Seen so far: 126720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1980: 1.021134376525879\n",
      "Seen so far: 126784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1981: 0.7930120229721069\n",
      "Seen so far: 126848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1982: 0.5443331003189087\n",
      "Seen so far: 126912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1983: 1.1416826248168945\n",
      "Seen so far: 126976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1984: 0.9503689408302307\n",
      "Seen so far: 127040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1985: 1.2278650999069214\n",
      "Seen so far: 127104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1986: 0.5348247289657593\n",
      "Seen so far: 127168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1987: 1.17268967628479\n",
      "Seen so far: 127232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1988: 1.1127300262451172\n",
      "Seen so far: 127296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1989: 0.7766953706741333\n",
      "Seen so far: 127360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1990: 0.8282530307769775\n",
      "Seen so far: 127424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1991: 1.19533109664917\n",
      "Seen so far: 127488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1992: 1.1090928316116333\n",
      "Seen so far: 127552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1993: 0.8642920255661011\n",
      "Seen so far: 127616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1994: 1.0949819087982178\n",
      "Seen so far: 127680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1995: 0.6138037443161011\n",
      "Seen so far: 127744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1996: 0.8893508911132812\n",
      "Seen so far: 127808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1997: 1.0282459259033203\n",
      "Seen so far: 127872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1998: 0.7738604545593262\n",
      "Seen so far: 127936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1999: 0.8788527846336365\n",
      "Seen so far: 128000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2000: 0.811848521232605\n",
      "Seen so far: 128064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2001: 0.7588366270065308\n",
      "Seen so far: 128128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2002: 1.165926218032837\n",
      "Seen so far: 128192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2003: 0.5175774693489075\n",
      "Seen so far: 128256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2004: 1.0493806600570679\n",
      "Seen so far: 128320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2005: 1.0024185180664062\n",
      "Seen so far: 128384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2006: 1.2572338581085205\n",
      "Seen so far: 128448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2007: 0.6180278062820435\n",
      "Seen so far: 128512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2008: 0.7037227153778076\n",
      "Seen so far: 128576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2009: 0.9002686142921448\n",
      "Seen so far: 128640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2010: 1.3705978393554688\n",
      "Seen so far: 128704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2011: 0.9608656167984009\n",
      "Seen so far: 128768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2012: 0.7779273986816406\n",
      "Seen so far: 128832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2013: 0.8605896830558777\n",
      "Seen so far: 128896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2014: 0.7309712171554565\n",
      "Seen so far: 128960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2015: 0.7319138050079346\n",
      "Seen so far: 129024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2016: 0.6238592863082886\n",
      "Seen so far: 129088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2017: 0.9376153945922852\n",
      "Seen so far: 129152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2018: 0.5749563574790955\n",
      "Seen so far: 129216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2019: 1.0780433416366577\n",
      "Seen so far: 129280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2020: 0.5170432925224304\n",
      "Seen so far: 129344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2021: 0.9271062612533569\n",
      "Seen so far: 129408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2022: 1.1436519622802734\n",
      "Seen so far: 129472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2023: 0.7315746545791626\n",
      "Seen so far: 129536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2024: 0.6976585388183594\n",
      "Seen so far: 129600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2025: 0.8184726238250732\n",
      "Seen so far: 129664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2026: 0.6954007148742676\n",
      "Seen so far: 129728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2027: 1.2477130889892578\n",
      "Seen so far: 129792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2028: 0.7686601877212524\n",
      "Seen so far: 129856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2029: 0.8725138902664185\n",
      "Seen so far: 129920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2030: 1.3898378610610962\n",
      "Seen so far: 129984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2031: 1.2491302490234375\n",
      "Seen so far: 130048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2032: 0.9240014553070068\n",
      "Seen so far: 130112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2033: 1.1810309886932373\n",
      "Seen so far: 130176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2034: 1.1415011882781982\n",
      "Seen so far: 130240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2035: 0.690392255783081\n",
      "Seen so far: 130304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2036: 0.654393196105957\n",
      "Seen so far: 130368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2037: 0.6090525388717651\n",
      "Seen so far: 130432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2038: 0.9160207509994507\n",
      "Seen so far: 130496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2039: 0.9609750509262085\n",
      "Seen so far: 130560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2040: 0.5861091017723083\n",
      "Seen so far: 130624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2041: 0.6974887251853943\n",
      "Seen so far: 130688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2042: 0.8303835391998291\n",
      "Seen so far: 130752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2043: 0.7897245287895203\n",
      "Seen so far: 130816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2044: 0.8008970022201538\n",
      "Seen so far: 130880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2045: 0.6818954944610596\n",
      "Seen so far: 130944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2046: 0.9284950494766235\n",
      "Seen so far: 131008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2047: 0.6351653337478638\n",
      "Seen so far: 131072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2048: 0.7560087442398071\n",
      "Seen so far: 131136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2049: 1.0283762216567993\n",
      "Seen so far: 131200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2050: 0.8548468351364136\n",
      "Seen so far: 131264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2051: 1.0931246280670166\n",
      "Seen so far: 131328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2052: 0.8243928551673889\n",
      "Seen so far: 131392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2053: 0.9823752641677856\n",
      "Seen so far: 131456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2054: 0.8551883697509766\n",
      "Seen so far: 131520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2055: 0.34895893931388855\n",
      "Seen so far: 131584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2056: 0.6288517713546753\n",
      "Seen so far: 131648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2057: 0.8162825107574463\n",
      "Seen so far: 131712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2058: 0.8287644386291504\n",
      "Seen so far: 131776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2059: 0.9923616647720337\n",
      "Seen so far: 131840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2060: 0.893083930015564\n",
      "Seen so far: 131904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2061: 1.0016049146652222\n",
      "Seen so far: 131968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2062: 0.9922009110450745\n",
      "Seen so far: 132032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2063: 0.81745445728302\n",
      "Seen so far: 132096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2064: 0.9138429164886475\n",
      "Seen so far: 132160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2065: 0.7258424758911133\n",
      "Seen so far: 132224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2066: 1.0063568353652954\n",
      "Seen so far: 132288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2067: 0.8018556833267212\n",
      "Seen so far: 132352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2068: 1.08745539188385\n",
      "Seen so far: 132416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2069: 1.0412006378173828\n",
      "Seen so far: 132480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2070: 0.5993706583976746\n",
      "Seen so far: 132544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2071: 0.5089949369430542\n",
      "Seen so far: 132608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2072: 1.1888487339019775\n",
      "Seen so far: 132672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2073: 0.8336858749389648\n",
      "Seen so far: 132736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2074: 0.7850414514541626\n",
      "Seen so far: 132800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2075: 0.9122433662414551\n",
      "Seen so far: 132864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2076: 0.5560482740402222\n",
      "Seen so far: 132928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2077: 0.8585312366485596\n",
      "Seen so far: 132992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2078: 1.0970213413238525\n",
      "Seen so far: 133056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2079: 0.9814542531967163\n",
      "Seen so far: 133120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2080: 0.4537385106086731\n",
      "Seen so far: 133184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2081: 1.1054692268371582\n",
      "Seen so far: 133248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2082: 0.707262396812439\n",
      "Seen so far: 133312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2083: 0.7742115259170532\n",
      "Seen so far: 133376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2084: 0.8096101880073547\n",
      "Seen so far: 133440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2085: 0.43237030506134033\n",
      "Seen so far: 133504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2086: 0.40002718567848206\n",
      "Seen so far: 133568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2087: 0.959314227104187\n",
      "Seen so far: 133632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2088: 0.7334127426147461\n",
      "Seen so far: 133696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2089: 1.015962839126587\n",
      "Seen so far: 133760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2090: 0.6927053928375244\n",
      "Seen so far: 133824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2091: 0.7858841419219971\n",
      "Seen so far: 133888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2092: 0.7806329727172852\n",
      "Seen so far: 133952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2093: 0.6042273640632629\n",
      "Seen so far: 134016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2094: 0.8826550245285034\n",
      "Seen so far: 134080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2095: 1.075048804283142\n",
      "Seen so far: 134144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2096: 0.8339246511459351\n",
      "Seen so far: 134208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2097: 0.5981493592262268\n",
      "Seen so far: 134272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2098: 0.8038925528526306\n",
      "Seen so far: 134336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2099: 0.6990243792533875\n",
      "Seen so far: 134400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2100: 0.8870257139205933\n",
      "Seen so far: 134464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2101: 0.48444056510925293\n",
      "Seen so far: 134528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2102: 1.0868146419525146\n",
      "Seen so far: 134592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2103: 0.636827826499939\n",
      "Seen so far: 134656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2104: 0.7070454955101013\n",
      "Seen so far: 134720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2105: 0.5771781206130981\n",
      "Seen so far: 134784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2106: 0.7938977479934692\n",
      "Seen so far: 134848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2107: 0.7631322145462036\n",
      "Seen so far: 134912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2108: 0.414430171251297\n",
      "Seen so far: 134976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2109: 0.6170255541801453\n",
      "Seen so far: 135040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2110: 0.8666547536849976\n",
      "Seen so far: 135104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2111: 0.7235129475593567\n",
      "Seen so far: 135168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2112: 0.5996639728546143\n",
      "Seen so far: 135232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2113: 0.8894175291061401\n",
      "Seen so far: 135296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2114: 0.7762031555175781\n",
      "Seen so far: 135360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2115: 0.7508460879325867\n",
      "Seen so far: 135424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2116: 0.5982707738876343\n",
      "Seen so far: 135488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2117: 0.5532159805297852\n",
      "Seen so far: 135552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2118: 1.2144718170166016\n",
      "Seen so far: 135616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2119: 0.9212503433227539\n",
      "Seen so far: 135680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2120: 1.0484356880187988\n",
      "Seen so far: 135744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2121: 0.7931339740753174\n",
      "Seen so far: 135808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2122: 0.9768863916397095\n",
      "Seen so far: 135872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2123: 0.8157548308372498\n",
      "Seen so far: 135936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2124: 0.9202802181243896\n",
      "Seen so far: 136000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2125: 1.1150802373886108\n",
      "Seen so far: 136064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2126: 0.8738125562667847\n",
      "Seen so far: 136128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2127: 1.075854778289795\n",
      "Seen so far: 136192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2128: 1.0124218463897705\n",
      "Seen so far: 136256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2129: 0.979483962059021\n",
      "Seen so far: 136320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2130: 0.7877991795539856\n",
      "Seen so far: 136384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2131: 0.9935389757156372\n",
      "Seen so far: 136448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2132: 0.7783955335617065\n",
      "Seen so far: 136512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2133: 0.6748510003089905\n",
      "Seen so far: 136576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2134: 0.2720460295677185\n",
      "Seen so far: 136640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2135: 0.5125125646591187\n",
      "Seen so far: 136704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2136: 0.6299192905426025\n",
      "Seen so far: 136768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2137: 1.0348447561264038\n",
      "Seen so far: 136832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2138: 1.0303683280944824\n",
      "Seen so far: 136896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2139: 0.8823800086975098\n",
      "Seen so far: 136960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2140: 0.9685885906219482\n",
      "Seen so far: 137024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2141: 1.4478092193603516\n",
      "Seen so far: 137088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2142: 0.5078483819961548\n",
      "Seen so far: 137152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2143: 0.9225832223892212\n",
      "Seen so far: 137216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2144: 0.6559285521507263\n",
      "Seen so far: 137280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2145: 1.0644299983978271\n",
      "Seen so far: 137344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2146: 1.337416410446167\n",
      "Seen so far: 137408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2147: 0.5687638521194458\n",
      "Seen so far: 137472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2148: 0.8840154409408569\n",
      "Seen so far: 137536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2149: 0.9234017133712769\n",
      "Seen so far: 137600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2150: 0.6319975852966309\n",
      "Seen so far: 137664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2151: 0.6821516752243042\n",
      "Seen so far: 137728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2152: 1.071070671081543\n",
      "Seen so far: 137792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2153: 0.5968891382217407\n",
      "Seen so far: 137856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2154: 0.9701938629150391\n",
      "Seen so far: 137920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2155: 0.8637621402740479\n",
      "Seen so far: 137984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2156: 0.7314125299453735\n",
      "Seen so far: 138048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2157: 0.3639395236968994\n",
      "Seen so far: 138112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2158: 0.7043617963790894\n",
      "Seen so far: 138176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2159: 0.47987550497055054\n",
      "Seen so far: 138240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2160: 0.9544793963432312\n",
      "Seen so far: 138304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2161: 0.7397196888923645\n",
      "Seen so far: 138368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2162: 0.7335902452468872\n",
      "Seen so far: 138432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2163: 0.5772046446800232\n",
      "Seen so far: 138496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2164: 1.160793662071228\n",
      "Seen so far: 138560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2165: 0.9224846363067627\n",
      "Seen so far: 138624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2166: 0.5341553092002869\n",
      "Seen so far: 138688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2167: 0.8960932493209839\n",
      "Seen so far: 138752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2168: 0.6459149122238159\n",
      "Seen so far: 138816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2169: 0.5613388419151306\n",
      "Seen so far: 138880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2170: 0.9628108739852905\n",
      "Seen so far: 138944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2171: 0.8277398347854614\n",
      "Seen so far: 139008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2172: 0.618821382522583\n",
      "Seen so far: 139072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2173: 0.7851132154464722\n",
      "Seen so far: 139136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2174: 1.3313063383102417\n",
      "Seen so far: 139200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2175: 0.8143559694290161\n",
      "Seen so far: 139264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2176: 0.8618548512458801\n",
      "Seen so far: 139328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2177: 0.7636938095092773\n",
      "Seen so far: 139392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2178: 0.5112063884735107\n",
      "Seen so far: 139456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2179: 0.47420454025268555\n",
      "Seen so far: 139520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2180: 0.6398941874504089\n",
      "Seen so far: 139584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2181: 0.9665010571479797\n",
      "Seen so far: 139648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2182: 1.0681705474853516\n",
      "Seen so far: 139712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2183: 0.6874725818634033\n",
      "Seen so far: 139776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2184: 1.0845129489898682\n",
      "Seen so far: 139840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2185: 0.8389499187469482\n",
      "Seen so far: 139904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2186: 0.7199403643608093\n",
      "Seen so far: 139968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2187: 0.7151983976364136\n",
      "Seen so far: 140032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2188: 0.4941619038581848\n",
      "Seen so far: 140096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2189: 0.8753312230110168\n",
      "Seen so far: 140160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2190: 0.8075519800186157\n",
      "Seen so far: 140224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2191: 0.7289307117462158\n",
      "Seen so far: 140288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2192: 0.6616336107254028\n",
      "Seen so far: 140352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2193: 0.7138034105300903\n",
      "Seen so far: 140416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2194: 0.46646469831466675\n",
      "Seen so far: 140480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2195: 1.056174397468567\n",
      "Seen so far: 140544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2196: 0.6088130474090576\n",
      "Seen so far: 140608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2197: 0.7167159914970398\n",
      "Seen so far: 140672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2198: 1.1448050737380981\n",
      "Seen so far: 140736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2199: 0.59156733751297\n",
      "Seen so far: 140800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2200: 1.0652525424957275\n",
      "Seen so far: 140864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2201: 0.9018145799636841\n",
      "Seen so far: 140928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2202: 0.7378120422363281\n",
      "Seen so far: 140992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2203: 1.1575360298156738\n",
      "Seen so far: 141056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2204: 0.7483342885971069\n",
      "Seen so far: 141120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2205: 0.5031327605247498\n",
      "Seen so far: 141184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2206: 1.3299273252487183\n",
      "Seen so far: 141248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2207: 0.8347099423408508\n",
      "Seen so far: 141312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2208: 1.7269799709320068\n",
      "Seen so far: 141376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2209: 0.7387728691101074\n",
      "Seen so far: 141440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2210: 0.8010529279708862\n",
      "Seen so far: 141504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2211: 0.8241065144538879\n",
      "Seen so far: 141568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2212: 0.5947422385215759\n",
      "Seen so far: 141632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2213: 0.6857675313949585\n",
      "Seen so far: 141696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2214: 1.051984429359436\n",
      "Seen so far: 141760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2215: 0.8987826704978943\n",
      "Seen so far: 141824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2216: 0.6747478246688843\n",
      "Seen so far: 141888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2217: 0.7804085612297058\n",
      "Seen so far: 141952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2218: 0.9628922939300537\n",
      "Seen so far: 142016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2219: 0.9641874432563782\n",
      "Seen so far: 142080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2220: 0.9166110754013062\n",
      "Seen so far: 142144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2221: 1.0588676929473877\n",
      "Seen so far: 142208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2222: 1.2632042169570923\n",
      "Seen so far: 142272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2223: 0.6156134605407715\n",
      "Seen so far: 142336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2224: 0.9408601522445679\n",
      "Seen so far: 142400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2225: 0.8552566766738892\n",
      "Seen so far: 142464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2226: 1.042712688446045\n",
      "Seen so far: 142528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2227: 0.6871646046638489\n",
      "Seen so far: 142592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2228: 0.965722918510437\n",
      "Seen so far: 142656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2229: 1.0151331424713135\n",
      "Seen so far: 142720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2230: 0.8398312330245972\n",
      "Seen so far: 142784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2231: 0.9610238075256348\n",
      "Seen so far: 142848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2232: 1.1244428157806396\n",
      "Seen so far: 142912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2233: 0.751744270324707\n",
      "Seen so far: 142976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2234: 0.6678285598754883\n",
      "Seen so far: 143040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2235: 1.1532690525054932\n",
      "Seen so far: 143104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2236: 0.8739012479782104\n",
      "Seen so far: 143168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2237: 0.9756815433502197\n",
      "Seen so far: 143232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2238: 0.6681381464004517\n",
      "Seen so far: 143296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2239: 0.9811186790466309\n",
      "Seen so far: 143360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2240: 0.7501906752586365\n",
      "Seen so far: 143424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2241: 1.103635311126709\n",
      "Seen so far: 143488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2242: 0.7722461819648743\n",
      "Seen so far: 143552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2243: 1.0981743335723877\n",
      "Seen so far: 143616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2244: 0.9011275768280029\n",
      "Seen so far: 143680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2245: 0.595695972442627\n",
      "Seen so far: 143744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2246: 0.8562462329864502\n",
      "Seen so far: 143808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2247: 1.1837100982666016\n",
      "Seen so far: 143872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2248: 0.6717734932899475\n",
      "Seen so far: 143936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2249: 1.0885951519012451\n",
      "Seen so far: 144000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2250: 0.8676989078521729\n",
      "Seen so far: 144064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2251: 0.8426999449729919\n",
      "Seen so far: 144128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2252: 0.8246891498565674\n",
      "Seen so far: 144192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2253: 1.0468554496765137\n",
      "Seen so far: 144256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2254: 0.7301188707351685\n",
      "Seen so far: 144320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2255: 0.698571503162384\n",
      "Seen so far: 144384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2256: 0.9932167530059814\n",
      "Seen so far: 144448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2257: 1.096516728401184\n",
      "Seen so far: 144512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2258: 1.2791998386383057\n",
      "Seen so far: 144576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2259: 0.9720043540000916\n",
      "Seen so far: 144640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2260: 0.8658194541931152\n",
      "Seen so far: 144704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2261: 1.1193022727966309\n",
      "Seen so far: 144768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2262: 0.8989373445510864\n",
      "Seen so far: 144832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2263: 1.1400601863861084\n",
      "Seen so far: 144896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2264: 1.044341802597046\n",
      "Seen so far: 144960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2265: 0.6567198038101196\n",
      "Seen so far: 145024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2266: 0.8860059380531311\n",
      "Seen so far: 145088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2267: 0.885330080986023\n",
      "Seen so far: 145152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2268: 0.776829183101654\n",
      "Seen so far: 145216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2269: 0.5801900625228882\n",
      "Seen so far: 145280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2270: 0.6720238924026489\n",
      "Seen so far: 145344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2271: 0.6568339467048645\n",
      "Seen so far: 145408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2272: 1.0631506443023682\n",
      "Seen so far: 145472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2273: 0.9529850482940674\n",
      "Seen so far: 145536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2274: 0.8761045932769775\n",
      "Seen so far: 145600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2275: 1.1584126949310303\n",
      "Seen so far: 145664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2276: 0.7777882814407349\n",
      "Seen so far: 145728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2277: 0.7995312213897705\n",
      "Seen so far: 145792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2278: 1.0762910842895508\n",
      "Seen so far: 145856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2279: 0.5618658065795898\n",
      "Seen so far: 145920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2280: 1.0637547969818115\n",
      "Seen so far: 145984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2281: 0.7726577520370483\n",
      "Seen so far: 146048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2282: 0.8874720931053162\n",
      "Seen so far: 146112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2283: 0.9667235016822815\n",
      "Seen so far: 146176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2284: 0.7321269512176514\n",
      "Seen so far: 146240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2285: 0.8285183906555176\n",
      "Seen so far: 146304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2286: 1.0611971616744995\n",
      "Seen so far: 146368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2287: 0.6217183470726013\n",
      "Seen so far: 146432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2288: 0.5942569971084595\n",
      "Seen so far: 146496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2289: 0.8269221782684326\n",
      "Seen so far: 146560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2290: 0.8946084380149841\n",
      "Seen so far: 146624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2291: 0.7620047330856323\n",
      "Seen so far: 146688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2292: 0.7971057891845703\n",
      "Seen so far: 146752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2293: 1.0484068393707275\n",
      "Seen so far: 146816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2294: 1.236879587173462\n",
      "Seen so far: 146880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2295: 0.9614499807357788\n",
      "Seen so far: 146944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2296: 0.8018065094947815\n",
      "Seen so far: 147008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2297: 1.2670865058898926\n",
      "Seen so far: 147072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2298: 0.9773948192596436\n",
      "Seen so far: 147136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2299: 0.5675615072250366\n",
      "Seen so far: 147200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2300: 0.8448236584663391\n",
      "Seen so far: 147264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2301: 0.9123237133026123\n",
      "Seen so far: 147328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2302: 0.9868130683898926\n",
      "Seen so far: 147392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2303: 1.087499737739563\n",
      "Seen so far: 147456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2304: 0.5469879508018494\n",
      "Seen so far: 147520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2305: 1.0265235900878906\n",
      "Seen so far: 147584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2306: 0.6622964143753052\n",
      "Seen so far: 147648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2307: 0.9334902763366699\n",
      "Seen so far: 147712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2308: 1.007611632347107\n",
      "Seen so far: 147776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2309: 1.0731310844421387\n",
      "Seen so far: 147840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2310: 0.6679127216339111\n",
      "Seen so far: 147904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2311: 0.6359755396842957\n",
      "Seen so far: 147968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2312: 0.4941466748714447\n",
      "Seen so far: 148032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2313: 0.82927405834198\n",
      "Seen so far: 148096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2314: 1.1794979572296143\n",
      "Seen so far: 148160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2315: 0.9029071927070618\n",
      "Seen so far: 148224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2316: 0.9579547643661499\n",
      "Seen so far: 148288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2317: 0.5981219410896301\n",
      "Seen so far: 148352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2318: 0.589870810508728\n",
      "Seen so far: 148416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2319: 0.9694089889526367\n",
      "Seen so far: 148480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2320: 0.7909305691719055\n",
      "Seen so far: 148544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2321: 0.5814670920372009\n",
      "Seen so far: 148608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2322: 0.5785559415817261\n",
      "Seen so far: 148672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2323: 0.6174106597900391\n",
      "Seen so far: 148736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2324: 1.1141328811645508\n",
      "Seen so far: 148800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2325: 0.521713376045227\n",
      "Seen so far: 148864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2326: 0.7873557209968567\n",
      "Seen so far: 148928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2327: 1.114335536956787\n",
      "Seen so far: 148992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2328: 0.5010066032409668\n",
      "Seen so far: 149056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2329: 0.7279267907142639\n",
      "Seen so far: 149120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2330: 0.7700455188751221\n",
      "Seen so far: 149184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2331: 0.5126432180404663\n",
      "Seen so far: 149248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2332: 0.9528675079345703\n",
      "Seen so far: 149312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2333: 0.6890299916267395\n",
      "Seen so far: 149376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2334: 0.8562085032463074\n",
      "Seen so far: 149440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2335: 0.8898125886917114\n",
      "Seen so far: 149504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2336: 0.89504075050354\n",
      "Seen so far: 149568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2337: 0.9157530069351196\n",
      "Seen so far: 149632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2338: 0.7282094359397888\n",
      "Seen so far: 149696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2339: 0.9928725361824036\n",
      "Seen so far: 149760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2340: 1.0836472511291504\n",
      "Seen so far: 149824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2341: 1.0839719772338867\n",
      "Seen so far: 149888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2342: 0.5579970479011536\n",
      "Seen so far: 149952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2343: 0.5498451590538025\n",
      "Seen so far: 150016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2344: 1.0059458017349243\n",
      "Seen so far: 150080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2345: 0.8895602822303772\n",
      "Seen so far: 150144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2346: 0.7742640972137451\n",
      "Seen so far: 150208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2347: 0.573030412197113\n",
      "Seen so far: 150272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2348: 0.9831808805465698\n",
      "Seen so far: 150336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2349: 0.6496550440788269\n",
      "Seen so far: 150400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2350: 0.9564022421836853\n",
      "Seen so far: 150464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2351: 0.8758847713470459\n",
      "Seen so far: 150528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2352: 1.0073586702346802\n",
      "Seen so far: 150592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2353: 0.8387212753295898\n",
      "Seen so far: 150656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2354: 0.7785148024559021\n",
      "Seen so far: 150720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2355: 0.8215411901473999\n",
      "Seen so far: 150784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2356: 0.5926403403282166\n",
      "Seen so far: 150848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2357: 1.1690696477890015\n",
      "Seen so far: 150912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2358: 0.8519407510757446\n",
      "Seen so far: 150976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2359: 0.9418075084686279\n",
      "Seen so far: 151040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2360: 1.0923901796340942\n",
      "Seen so far: 151104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2361: 0.8342185020446777\n",
      "Seen so far: 151168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2362: 1.0684624910354614\n",
      "Seen so far: 151232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2363: 0.8919820785522461\n",
      "Seen so far: 151296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2364: 0.6502611041069031\n",
      "Seen so far: 151360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2365: 1.1461493968963623\n",
      "Seen so far: 151424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2366: 0.8482294678688049\n",
      "Seen so far: 151488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2367: 0.8912717700004578\n",
      "Seen so far: 151552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2368: 1.045907735824585\n",
      "Seen so far: 151616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2369: 1.1709017753601074\n",
      "Seen so far: 151680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2370: 0.8909643888473511\n",
      "Seen so far: 151744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2371: 0.9275747537612915\n",
      "Seen so far: 151808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2372: 0.8455500602722168\n",
      "Seen so far: 151872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2373: 1.1384379863739014\n",
      "Seen so far: 151936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2374: 0.8897632956504822\n",
      "Seen so far: 152000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2375: 0.8994002342224121\n",
      "Seen so far: 152064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2376: 1.5265592336654663\n",
      "Seen so far: 152128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2377: 0.8610838651657104\n",
      "Seen so far: 152192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2378: 0.5040247440338135\n",
      "Seen so far: 152256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2379: 0.9233473539352417\n",
      "Seen so far: 152320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2380: 0.7357715368270874\n",
      "Seen so far: 152384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2381: 0.5728591680526733\n",
      "Seen so far: 152448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2382: 0.5174348950386047\n",
      "Seen so far: 152512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2383: 0.8205900192260742\n",
      "Seen so far: 152576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2384: 1.0705926418304443\n",
      "Seen so far: 152640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2385: 1.0488859415054321\n",
      "Seen so far: 152704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2386: 0.8954613208770752\n",
      "Seen so far: 152768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2387: 0.6324079036712646\n",
      "Seen so far: 152832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2388: 0.8141293525695801\n",
      "Seen so far: 152896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2389: 0.9194521307945251\n",
      "Seen so far: 152960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2390: 1.0984926223754883\n",
      "Seen so far: 153024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2391: 0.8780708312988281\n",
      "Seen so far: 153088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2392: 0.5377274751663208\n",
      "Seen so far: 153152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2393: 0.9276363849639893\n",
      "Seen so far: 153216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2394: 0.7700331211090088\n",
      "Seen so far: 153280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2395: 1.0581068992614746\n",
      "Seen so far: 153344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2396: 0.8238214254379272\n",
      "Seen so far: 153408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2397: 1.0648103952407837\n",
      "Seen so far: 153472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2398: 0.8415954113006592\n",
      "Seen so far: 153536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2399: 0.683758020401001\n",
      "Seen so far: 153600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2400: 0.6642631888389587\n",
      "Seen so far: 153664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2401: 0.6793615818023682\n",
      "Seen so far: 153728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2402: 0.9726030230522156\n",
      "Seen so far: 153792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2403: 1.2025728225708008\n",
      "Seen so far: 153856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2404: 0.7876258492469788\n",
      "Seen so far: 153920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2405: 1.0171339511871338\n",
      "Seen so far: 153984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2406: 0.5094701051712036\n",
      "Seen so far: 154048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2407: 1.3450469970703125\n",
      "Seen so far: 154112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2408: 0.39497625827789307\n",
      "Seen so far: 154176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2409: 0.9256067276000977\n",
      "Seen so far: 154240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2410: 0.61187744140625\n",
      "Seen so far: 154304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2411: 1.2983348369598389\n",
      "Seen so far: 154368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2412: 1.1049894094467163\n",
      "Seen so far: 154432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2413: 1.0793778896331787\n",
      "Seen so far: 154496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2414: 0.9359668493270874\n",
      "Seen so far: 154560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2415: 1.121755838394165\n",
      "Seen so far: 154624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2416: 0.9507424831390381\n",
      "Seen so far: 154688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2417: 0.9831678867340088\n",
      "Seen so far: 154752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2418: 1.07794189453125\n",
      "Seen so far: 154816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2419: 0.6665235757827759\n",
      "Seen so far: 154880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2420: 0.9838945269584656\n",
      "Seen so far: 154944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2421: 0.792435884475708\n",
      "Seen so far: 155008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2422: 0.7409879565238953\n",
      "Seen so far: 155072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2423: 0.7956581711769104\n",
      "Seen so far: 155136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2424: 0.8311694264411926\n",
      "Seen so far: 155200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2425: 1.0802406072616577\n",
      "Seen so far: 155264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2426: 0.8478479385375977\n",
      "Seen so far: 155328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2427: 1.1082329750061035\n",
      "Seen so far: 155392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2428: 1.0106372833251953\n",
      "Seen so far: 155456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2429: 0.728851318359375\n",
      "Seen so far: 155520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2430: 0.9367597699165344\n",
      "Seen so far: 155584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2431: 1.1712446212768555\n",
      "Seen so far: 155648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2432: 0.7250935435295105\n",
      "Seen so far: 155712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2433: 0.7511811256408691\n",
      "Seen so far: 155776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2434: 0.7794356346130371\n",
      "Seen so far: 155840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2435: 1.2315528392791748\n",
      "Seen so far: 155904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2436: 1.2694967985153198\n",
      "Seen so far: 155968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2437: 0.5407536029815674\n",
      "Seen so far: 156032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2438: 0.9830206036567688\n",
      "Seen so far: 156096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2439: 0.7616592645645142\n",
      "Seen so far: 156160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2440: 0.7037397623062134\n",
      "Seen so far: 156224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2441: 0.38320890069007874\n",
      "Seen so far: 156288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2442: 1.0222983360290527\n",
      "Seen so far: 156352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2443: 0.9072399139404297\n",
      "Seen so far: 156416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2444: 0.8276709318161011\n",
      "Seen so far: 156480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2445: 0.9420902729034424\n",
      "Seen so far: 156544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2446: 0.7435743808746338\n",
      "Seen so far: 156608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2447: 0.4926448464393616\n",
      "Seen so far: 156672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2448: 1.3526904582977295\n",
      "Seen so far: 156736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2449: 0.7461376190185547\n",
      "Seen so far: 156800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2450: 0.8447920083999634\n",
      "Seen so far: 156864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2451: 0.8930895328521729\n",
      "Seen so far: 156928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2452: 0.8583617806434631\n",
      "Seen so far: 156992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2453: 0.6226052045822144\n",
      "Seen so far: 157056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2454: 1.1250330209732056\n",
      "Seen so far: 157120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2455: 0.8703500032424927\n",
      "Seen so far: 157184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2456: 0.6103723049163818\n",
      "Seen so far: 157248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2457: 1.0564509630203247\n",
      "Seen so far: 157312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2458: 0.6402772068977356\n",
      "Seen so far: 157376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2459: 0.9501591920852661\n",
      "Seen so far: 157440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2460: 0.8520249128341675\n",
      "Seen so far: 157504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2461: 0.618536651134491\n",
      "Seen so far: 157568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2462: 0.942071259021759\n",
      "Seen so far: 157632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2463: 0.5319581627845764\n",
      "Seen so far: 157696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2464: 0.8275919556617737\n",
      "Seen so far: 157760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2465: 0.9056495428085327\n",
      "Seen so far: 157824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2466: 1.3909814357757568\n",
      "Seen so far: 157888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2467: 1.0641703605651855\n",
      "Seen so far: 157952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2468: 0.9919177889823914\n",
      "Seen so far: 158016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2469: 0.7624655365943909\n",
      "Seen so far: 158080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2470: 0.8357694149017334\n",
      "Seen so far: 158144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2471: 1.2099634408950806\n",
      "Seen so far: 158208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2472: 0.9975429773330688\n",
      "Seen so far: 158272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2473: 0.7779000997543335\n",
      "Seen so far: 158336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2474: 1.4396483898162842\n",
      "Seen so far: 158400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2475: 0.8352054357528687\n",
      "Seen so far: 158464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2476: 0.7435622811317444\n",
      "Seen so far: 158528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2477: 0.8196879625320435\n",
      "Seen so far: 158592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2478: 1.0652390718460083\n",
      "Seen so far: 158656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2479: 0.9807978272438049\n",
      "Seen so far: 158720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2480: 0.9166431427001953\n",
      "Seen so far: 158784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2481: 0.8065433502197266\n",
      "Seen so far: 158848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2482: 0.9343676567077637\n",
      "Seen so far: 158912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2483: 1.0469545125961304\n",
      "Seen so far: 158976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2484: 0.7496338486671448\n",
      "Seen so far: 159040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2485: 0.5874209403991699\n",
      "Seen so far: 159104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2486: 1.1182763576507568\n",
      "Seen so far: 159168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2487: 0.9211680889129639\n",
      "Seen so far: 159232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2488: 1.113694667816162\n",
      "Seen so far: 159296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2489: 0.7037679553031921\n",
      "Seen so far: 159360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2490: 0.7881733179092407\n",
      "Seen so far: 159424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2491: 0.808271586894989\n",
      "Seen so far: 159488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2492: 0.7382316589355469\n",
      "Seen so far: 159552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2493: 0.5767692923545837\n",
      "Seen so far: 159616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2494: 0.6422714591026306\n",
      "Seen so far: 159680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2495: 0.576655387878418\n",
      "Seen so far: 159744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2496: 0.6781461238861084\n",
      "Seen so far: 159808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2497: 0.8593512773513794\n",
      "Seen so far: 159872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2498: 0.6297729015350342\n",
      "Seen so far: 159936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2499: 1.2416651248931885\n",
      "Seen so far: 160000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2500: 0.953058123588562\n",
      "Seen so far: 160064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2501: 0.8653755784034729\n",
      "Seen so far: 160128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2502: 0.6456160545349121\n",
      "Seen so far: 160192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2503: 0.7795103788375854\n",
      "Seen so far: 160256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2504: 1.0275659561157227\n",
      "Seen so far: 160320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2505: 1.2271397113800049\n",
      "Seen so far: 160384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2506: 0.7896841764450073\n",
      "Seen so far: 160448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2507: 0.8180301189422607\n",
      "Seen so far: 160512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2508: 0.8012799024581909\n",
      "Seen so far: 160576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2509: 0.9017807245254517\n",
      "Seen so far: 160640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2510: 1.162517786026001\n",
      "Seen so far: 160704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2511: 1.039419412612915\n",
      "Seen so far: 160768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2512: 0.6318405866622925\n",
      "Seen so far: 160832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2513: 0.7616379857063293\n",
      "Seen so far: 160896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2514: 0.8147728443145752\n",
      "Seen so far: 160960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2515: 0.8695009350776672\n",
      "Seen so far: 161024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2516: 0.9345048666000366\n",
      "Seen so far: 161088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2517: 0.9128139019012451\n",
      "Seen so far: 161152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2518: 0.9855830669403076\n",
      "Seen so far: 161216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2519: 0.870195746421814\n",
      "Seen so far: 161280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2520: 0.5930734872817993\n",
      "Seen so far: 161344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2521: 0.7997536659240723\n",
      "Seen so far: 161408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2522: 0.7891201376914978\n",
      "Seen so far: 161472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2523: 1.0363702774047852\n",
      "Seen so far: 161536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2524: 0.8568602800369263\n",
      "Seen so far: 161600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2525: 0.7561208605766296\n",
      "Seen so far: 161664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2526: 0.682248592376709\n",
      "Seen so far: 161728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2527: 0.8082720041275024\n",
      "Seen so far: 161792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2528: 1.097369909286499\n",
      "Seen so far: 161856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2529: 0.9222787022590637\n",
      "Seen so far: 161920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2530: 0.6711387634277344\n",
      "Seen so far: 161984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2531: 0.8277188539505005\n",
      "Seen so far: 162048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2532: 0.5448698401451111\n",
      "Seen so far: 162112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2533: 1.1279354095458984\n",
      "Seen so far: 162176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2534: 0.8929659724235535\n",
      "Seen so far: 162240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2535: 0.7381882667541504\n",
      "Seen so far: 162304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2536: 0.8281056880950928\n",
      "Seen so far: 162368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2537: 0.864543080329895\n",
      "Seen so far: 162432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2538: 0.6882113218307495\n",
      "Seen so far: 162496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2539: 1.1088029146194458\n",
      "Seen so far: 162560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2540: 1.1803960800170898\n",
      "Seen so far: 162624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2541: 1.6178240776062012\n",
      "Seen so far: 162688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2542: 0.680480420589447\n",
      "Seen so far: 162752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2543: 0.967502236366272\n",
      "Seen so far: 162816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2544: 0.889999508857727\n",
      "Seen so far: 162880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2545: 1.2325608730316162\n",
      "Seen so far: 162944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2546: 0.5152947902679443\n",
      "Seen so far: 163008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2547: 1.0891551971435547\n",
      "Seen so far: 163072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2548: 1.1472439765930176\n",
      "Seen so far: 163136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2549: 1.2188794612884521\n",
      "Seen so far: 163200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2550: 1.4593706130981445\n",
      "Seen so far: 163264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2551: 0.8523365259170532\n",
      "Seen so far: 163328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2552: 0.4709978997707367\n",
      "Seen so far: 163392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2553: 1.0672972202301025\n",
      "Seen so far: 163456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2554: 0.6827607750892639\n",
      "Seen so far: 163520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2555: 0.6500998735427856\n",
      "Seen so far: 163584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2556: 1.1944971084594727\n",
      "Seen so far: 163648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2557: 0.694743275642395\n",
      "Seen so far: 163712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2558: 0.6555193662643433\n",
      "Seen so far: 163776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2559: 0.9445503354072571\n",
      "Seen so far: 163840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2560: 1.1426233053207397\n",
      "Seen so far: 163904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2561: 1.015000343322754\n",
      "Seen so far: 163968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2562: 0.6218570470809937\n",
      "Seen so far: 164032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2563: 0.8304257988929749\n",
      "Seen so far: 164096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2564: 0.9724687933921814\n",
      "Seen so far: 164160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2565: 0.46508342027664185\n",
      "Seen so far: 164224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2566: 1.0650264024734497\n",
      "Seen so far: 164288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2567: 1.0858125686645508\n",
      "Seen so far: 164352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2568: 1.360471248626709\n",
      "Seen so far: 164416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2569: 0.9408351182937622\n",
      "Seen so far: 164480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2570: 0.8873180747032166\n",
      "Seen so far: 164544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2571: 0.6972280740737915\n",
      "Seen so far: 164608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2572: 1.3248683214187622\n",
      "Seen so far: 164672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2573: 0.6734845638275146\n",
      "Seen so far: 164736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2574: 0.8288537263870239\n",
      "Seen so far: 164800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2575: 0.5806866884231567\n",
      "Seen so far: 164864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2576: 0.798365592956543\n",
      "Seen so far: 164928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2577: 0.7040194272994995\n",
      "Seen so far: 164992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2578: 0.6084636449813843\n",
      "Seen so far: 165056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2579: 0.7282773852348328\n",
      "Seen so far: 165120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2580: 0.9175848960876465\n",
      "Seen so far: 165184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2581: 0.7973216772079468\n",
      "Seen so far: 165248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2582: 1.098473072052002\n",
      "Seen so far: 165312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2583: 0.6797667741775513\n",
      "Seen so far: 165376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2584: 0.43437057733535767\n",
      "Seen so far: 165440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2585: 0.7229872941970825\n",
      "Seen so far: 165504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2586: 0.7968761920928955\n",
      "Seen so far: 165568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2587: 0.6982711553573608\n",
      "Seen so far: 165632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2588: 0.7471026182174683\n",
      "Seen so far: 165696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2589: 0.9934957027435303\n",
      "Seen so far: 165760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2590: 0.9849300980567932\n",
      "Seen so far: 165824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2591: 0.9163983464241028\n",
      "Seen so far: 165888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2592: 0.803532600402832\n",
      "Seen so far: 165952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2593: 0.8593175411224365\n",
      "Seen so far: 166016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2594: 0.966495931148529\n",
      "Seen so far: 166080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2595: 0.8257873058319092\n",
      "Seen so far: 166144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2596: 0.8029935359954834\n",
      "Seen so far: 166208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2597: 0.7346598505973816\n",
      "Seen so far: 166272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2598: 1.0108553171157837\n",
      "Seen so far: 166336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2599: 0.8061220645904541\n",
      "Seen so far: 166400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2600: 0.8378831148147583\n",
      "Seen so far: 166464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2601: 0.6086783409118652\n",
      "Seen so far: 166528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2602: 0.6804856061935425\n",
      "Seen so far: 166592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2603: 0.7417022585868835\n",
      "Seen so far: 166656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2604: 0.828612744808197\n",
      "Seen so far: 166720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2605: 0.6261752843856812\n",
      "Seen so far: 166784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2606: 0.8068535327911377\n",
      "Seen so far: 166848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2607: 1.5376521348953247\n",
      "Seen so far: 166912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2608: 0.5950744152069092\n",
      "Seen so far: 166976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2609: 0.7676455974578857\n",
      "Seen so far: 167040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2610: 1.0232148170471191\n",
      "Seen so far: 167104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2611: 0.804924726486206\n",
      "Seen so far: 167168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2612: 1.0440210103988647\n",
      "Seen so far: 167232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2613: 0.5580155253410339\n",
      "Seen so far: 167296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2614: 0.8747127056121826\n",
      "Seen so far: 167360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2615: 0.7042744159698486\n",
      "Seen so far: 167424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2616: 0.633819043636322\n",
      "Seen so far: 167488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2617: 0.7469993829727173\n",
      "Seen so far: 167552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2618: 0.7104128003120422\n",
      "Seen so far: 167616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2619: 1.2727017402648926\n",
      "Seen so far: 167680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2620: 0.6575931310653687\n",
      "Seen so far: 167744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2621: 0.724403977394104\n",
      "Seen so far: 167808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2622: 0.9071336984634399\n",
      "Seen so far: 167872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2623: 0.9559369087219238\n",
      "Seen so far: 167936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2624: 0.8830140829086304\n",
      "Seen so far: 168000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2625: 0.634084939956665\n",
      "Seen so far: 168064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2626: 0.6034812331199646\n",
      "Seen so far: 168128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2627: 0.9309862852096558\n",
      "Seen so far: 168192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2628: 0.5611701011657715\n",
      "Seen so far: 168256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2629: 0.8263421654701233\n",
      "Seen so far: 168320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2630: 1.0196212530136108\n",
      "Seen so far: 168384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2631: 0.8699455261230469\n",
      "Seen so far: 168448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2632: 0.6989729404449463\n",
      "Seen so far: 168512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2633: 0.7316511273384094\n",
      "Seen so far: 168576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2634: 0.9380541443824768\n",
      "Seen so far: 168640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2635: 0.9302548170089722\n",
      "Seen so far: 168704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2636: 1.1112195253372192\n",
      "Seen so far: 168768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2637: 0.8284405469894409\n",
      "Seen so far: 168832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2638: 1.5399580001831055\n",
      "Seen so far: 168896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2639: 0.981865644454956\n",
      "Seen so far: 168960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2640: 0.726975679397583\n",
      "Seen so far: 169024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2641: 0.5798040628433228\n",
      "Seen so far: 169088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2642: 0.7263796329498291\n",
      "Seen so far: 169152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2643: 0.9869630336761475\n",
      "Seen so far: 169216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2644: 0.621633768081665\n",
      "Seen so far: 169280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2645: 0.8858239650726318\n",
      "Seen so far: 169344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2646: 0.708008885383606\n",
      "Seen so far: 169408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2647: 0.7379863858222961\n",
      "Seen so far: 169472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2648: 0.9725217819213867\n",
      "Seen so far: 169536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2649: 1.0967482328414917\n",
      "Seen so far: 169600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2650: 0.9036176204681396\n",
      "Seen so far: 169664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2651: 1.0561212301254272\n",
      "Seen so far: 169728 samples\n",
      "Training acc over epoch: 0.7128342986106873\n",
      "Start of epoch 6\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 0: 0.7837018966674805\n",
      "Seen so far: 64 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1: 0.6248582601547241\n",
      "Seen so far: 128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2: 0.6503624320030212\n",
      "Seen so far: 192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 3: 0.8094964027404785\n",
      "Seen so far: 256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 4: 0.7957267761230469\n",
      "Seen so far: 320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 5: 1.2350280284881592\n",
      "Seen so far: 384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 6: 1.2323038578033447\n",
      "Seen so far: 448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 7: 0.9270064830780029\n",
      "Seen so far: 512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 8: 1.2340154647827148\n",
      "Seen so far: 576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 9: 0.8587186336517334\n",
      "Seen so far: 640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 10: 0.662635087966919\n",
      "Seen so far: 704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 11: 0.5408909320831299\n",
      "Seen so far: 768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 12: 0.6650187969207764\n",
      "Seen so far: 832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 13: 0.6480523943901062\n",
      "Seen so far: 896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 14: 1.1291842460632324\n",
      "Seen so far: 960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 15: 0.7199221849441528\n",
      "Seen so far: 1024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 16: 1.0356194972991943\n",
      "Seen so far: 1088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 17: 1.3830668926239014\n",
      "Seen so far: 1152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 18: 0.9208364486694336\n",
      "Seen so far: 1216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 19: 1.0736780166625977\n",
      "Seen so far: 1280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 20: 0.9671435952186584\n",
      "Seen so far: 1344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 21: 1.1531782150268555\n",
      "Seen so far: 1408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 22: 1.0523066520690918\n",
      "Seen so far: 1472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 23: 1.3927346467971802\n",
      "Seen so far: 1536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 24: 0.6572562456130981\n",
      "Seen so far: 1600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 25: 0.7441811561584473\n",
      "Seen so far: 1664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 26: 1.141139268875122\n",
      "Seen so far: 1728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 27: 1.2723076343536377\n",
      "Seen so far: 1792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 28: 0.8694225549697876\n",
      "Seen so far: 1856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 29: 0.8720980882644653\n",
      "Seen so far: 1920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 30: 0.7001934051513672\n",
      "Seen so far: 1984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 31: 0.91753751039505\n",
      "Seen so far: 2048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 32: 1.122415542602539\n",
      "Seen so far: 2112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 33: 0.8835594654083252\n",
      "Seen so far: 2176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 34: 1.0313000679016113\n",
      "Seen so far: 2240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 35: 0.8809021711349487\n",
      "Seen so far: 2304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 36: 0.5793149471282959\n",
      "Seen so far: 2368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 37: 1.025712251663208\n",
      "Seen so far: 2432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 38: 0.9434425234794617\n",
      "Seen so far: 2496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 39: 0.7981551885604858\n",
      "Seen so far: 2560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 40: 0.9144502878189087\n",
      "Seen so far: 2624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 41: 1.1494636535644531\n",
      "Seen so far: 2688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 42: 0.9093314409255981\n",
      "Seen so far: 2752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 43: 0.6593809127807617\n",
      "Seen so far: 2816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 44: 0.9635710120201111\n",
      "Seen so far: 2880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 45: 1.1106505393981934\n",
      "Seen so far: 2944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 46: 0.7293275594711304\n",
      "Seen so far: 3008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 47: 0.6855083703994751\n",
      "Seen so far: 3072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 48: 1.048775553703308\n",
      "Seen so far: 3136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 49: 0.6027486324310303\n",
      "Seen so far: 3200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 50: 1.0169633626937866\n",
      "Seen so far: 3264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 51: 0.8754010796546936\n",
      "Seen so far: 3328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 52: 0.6885160207748413\n",
      "Seen so far: 3392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 53: 0.7233538031578064\n",
      "Seen so far: 3456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 54: 0.47748279571533203\n",
      "Seen so far: 3520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 55: 0.8683711290359497\n",
      "Seen so far: 3584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 56: 1.2550218105316162\n",
      "Seen so far: 3648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 57: 1.483057975769043\n",
      "Seen so far: 3712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 58: 0.4817860722541809\n",
      "Seen so far: 3776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 59: 0.7449474334716797\n",
      "Seen so far: 3840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 60: 0.2637261748313904\n",
      "Seen so far: 3904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 61: 0.5022608637809753\n",
      "Seen so far: 3968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 62: 0.9514549970626831\n",
      "Seen so far: 4032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 63: 0.8746420741081238\n",
      "Seen so far: 4096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 64: 0.669374942779541\n",
      "Seen so far: 4160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 65: 0.777431309223175\n",
      "Seen so far: 4224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 66: 1.4881985187530518\n",
      "Seen so far: 4288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 67: 1.336259365081787\n",
      "Seen so far: 4352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 68: 0.9341044425964355\n",
      "Seen so far: 4416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 69: 0.5387667417526245\n",
      "Seen so far: 4480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 70: 0.6418642997741699\n",
      "Seen so far: 4544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 71: 0.8652183413505554\n",
      "Seen so far: 4608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 72: 1.0500909090042114\n",
      "Seen so far: 4672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 73: 0.7793499231338501\n",
      "Seen so far: 4736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 74: 0.9398891925811768\n",
      "Seen so far: 4800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 75: 0.9190196990966797\n",
      "Seen so far: 4864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 76: 1.2156323194503784\n",
      "Seen so far: 4928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 77: 0.6188160181045532\n",
      "Seen so far: 4992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 78: 0.6207205057144165\n",
      "Seen so far: 5056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 79: 1.1741752624511719\n",
      "Seen so far: 5120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 80: 0.5506596565246582\n",
      "Seen so far: 5184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 81: 0.9321005940437317\n",
      "Seen so far: 5248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 82: 1.1259992122650146\n",
      "Seen so far: 5312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 83: 0.9211443662643433\n",
      "Seen so far: 5376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 84: 0.9487927556037903\n",
      "Seen so far: 5440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 85: 0.9215219616889954\n",
      "Seen so far: 5504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 86: 0.8603000640869141\n",
      "Seen so far: 5568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 87: 0.8653370141983032\n",
      "Seen so far: 5632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 88: 0.7799636721611023\n",
      "Seen so far: 5696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 89: 0.9894113540649414\n",
      "Seen so far: 5760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 90: 0.9379233121871948\n",
      "Seen so far: 5824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 91: 1.1163291931152344\n",
      "Seen so far: 5888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 92: 0.8347605466842651\n",
      "Seen so far: 5952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 93: 0.8535639643669128\n",
      "Seen so far: 6016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 94: 0.9888198375701904\n",
      "Seen so far: 6080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 95: 0.4812135696411133\n",
      "Seen so far: 6144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 96: 0.8926699161529541\n",
      "Seen so far: 6208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 97: 0.9150869846343994\n",
      "Seen so far: 6272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 98: 0.7189146280288696\n",
      "Seen so far: 6336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 99: 0.971082866191864\n",
      "Seen so far: 6400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 100: 0.8185592889785767\n",
      "Seen so far: 6464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 101: 0.5673757791519165\n",
      "Seen so far: 6528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 102: 0.7777054309844971\n",
      "Seen so far: 6592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 103: 0.7881991863250732\n",
      "Seen so far: 6656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 104: 0.9126044511795044\n",
      "Seen so far: 6720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 105: 0.9103412628173828\n",
      "Seen so far: 6784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 106: 0.7070026993751526\n",
      "Seen so far: 6848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 107: 0.8114979267120361\n",
      "Seen so far: 6912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 108: 0.9289951324462891\n",
      "Seen so far: 6976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 109: 0.9018442034721375\n",
      "Seen so far: 7040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 110: 0.7909868955612183\n",
      "Seen so far: 7104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 111: 0.802194356918335\n",
      "Seen so far: 7168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 112: 0.658983051776886\n",
      "Seen so far: 7232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 113: 1.0990716218948364\n",
      "Seen so far: 7296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 114: 1.0284292697906494\n",
      "Seen so far: 7360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 115: 0.5660567879676819\n",
      "Seen so far: 7424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 116: 1.1305325031280518\n",
      "Seen so far: 7488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 117: 1.0716078281402588\n",
      "Seen so far: 7552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 118: 1.080275535583496\n",
      "Seen so far: 7616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 119: 0.5905735492706299\n",
      "Seen so far: 7680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 120: 0.9282207489013672\n",
      "Seen so far: 7744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 121: 1.160395860671997\n",
      "Seen so far: 7808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 122: 1.0068743228912354\n",
      "Seen so far: 7872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 123: 0.5951483249664307\n",
      "Seen so far: 7936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 124: 0.971286416053772\n",
      "Seen so far: 8000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 125: 0.832122802734375\n",
      "Seen so far: 8064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 126: 0.6040440797805786\n",
      "Seen so far: 8128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 127: 1.2932400703430176\n",
      "Seen so far: 8192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 128: 0.5048680305480957\n",
      "Seen so far: 8256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 129: 0.9517016410827637\n",
      "Seen so far: 8320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 130: 1.008361577987671\n",
      "Seen so far: 8384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 131: 1.2427382469177246\n",
      "Seen so far: 8448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 132: 0.7077349424362183\n",
      "Seen so far: 8512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 133: 0.7336088418960571\n",
      "Seen so far: 8576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 134: 0.8760870099067688\n",
      "Seen so far: 8640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 135: 1.128949761390686\n",
      "Seen so far: 8704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 136: 1.0306518077850342\n",
      "Seen so far: 8768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 137: 1.3126041889190674\n",
      "Seen so far: 8832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 138: 0.6179563999176025\n",
      "Seen so far: 8896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 139: 0.9593263864517212\n",
      "Seen so far: 8960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 140: 0.9531217813491821\n",
      "Seen so far: 9024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 141: 0.9845860004425049\n",
      "Seen so far: 9088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 142: 0.558724045753479\n",
      "Seen so far: 9152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 143: 0.9200149178504944\n",
      "Seen so far: 9216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 144: 1.0242058038711548\n",
      "Seen so far: 9280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 145: 0.7655990123748779\n",
      "Seen so far: 9344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 146: 0.663371205329895\n",
      "Seen so far: 9408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 147: 1.100508689880371\n",
      "Seen so far: 9472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 148: 1.3646905422210693\n",
      "Seen so far: 9536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 149: 0.8244155049324036\n",
      "Seen so far: 9600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 150: 0.5893983244895935\n",
      "Seen so far: 9664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 151: 0.6247000694274902\n",
      "Seen so far: 9728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 152: 1.2637137174606323\n",
      "Seen so far: 9792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 153: 1.1262820959091187\n",
      "Seen so far: 9856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 154: 1.569148063659668\n",
      "Seen so far: 9920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 155: 0.9375069737434387\n",
      "Seen so far: 9984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 156: 1.0602335929870605\n",
      "Seen so far: 10048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 157: 0.8487086296081543\n",
      "Seen so far: 10112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 158: 1.381374478340149\n",
      "Seen so far: 10176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 159: 1.0489165782928467\n",
      "Seen so far: 10240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 160: 0.8259548544883728\n",
      "Seen so far: 10304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 161: 0.8986781239509583\n",
      "Seen so far: 10368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 162: 1.0205594301223755\n",
      "Seen so far: 10432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 163: 0.9082857370376587\n",
      "Seen so far: 10496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 164: 0.9821000099182129\n",
      "Seen so far: 10560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 165: 1.0201197862625122\n",
      "Seen so far: 10624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 166: 0.884231448173523\n",
      "Seen so far: 10688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 167: 0.6744175553321838\n",
      "Seen so far: 10752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 168: 0.9598063230514526\n",
      "Seen so far: 10816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 169: 0.6185019016265869\n",
      "Seen so far: 10880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 170: 0.9469335675239563\n",
      "Seen so far: 10944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 171: 0.9071241617202759\n",
      "Seen so far: 11008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 172: 1.0361521244049072\n",
      "Seen so far: 11072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 173: 0.8642687797546387\n",
      "Seen so far: 11136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 174: 0.9166736006736755\n",
      "Seen so far: 11200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 175: 0.8737648725509644\n",
      "Seen so far: 11264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 176: 1.0819249153137207\n",
      "Seen so far: 11328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 177: 0.6461461782455444\n",
      "Seen so far: 11392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 178: 0.7729181051254272\n",
      "Seen so far: 11456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 179: 0.9866223335266113\n",
      "Seen so far: 11520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 180: 1.0465092658996582\n",
      "Seen so far: 11584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 181: 0.7475723028182983\n",
      "Seen so far: 11648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 182: 0.8367477655410767\n",
      "Seen so far: 11712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 183: 1.1454145908355713\n",
      "Seen so far: 11776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 184: 1.0334804058074951\n",
      "Seen so far: 11840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 185: 1.02553129196167\n",
      "Seen so far: 11904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 186: 0.8546984791755676\n",
      "Seen so far: 11968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 187: 1.0895509719848633\n",
      "Seen so far: 12032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 188: 1.2320095300674438\n",
      "Seen so far: 12096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 189: 0.9290378093719482\n",
      "Seen so far: 12160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 190: 0.8819621801376343\n",
      "Seen so far: 12224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 191: 0.4346162676811218\n",
      "Seen so far: 12288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 192: 0.8109148740768433\n",
      "Seen so far: 12352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 193: 1.0121986865997314\n",
      "Seen so far: 12416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 194: 1.0772157907485962\n",
      "Seen so far: 12480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 195: 0.8810313940048218\n",
      "Seen so far: 12544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 196: 0.45244893431663513\n",
      "Seen so far: 12608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 197: 0.715285062789917\n",
      "Seen so far: 12672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 198: 1.4162545204162598\n",
      "Seen so far: 12736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 199: 0.7394483089447021\n",
      "Seen so far: 12800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 200: 0.8329002261161804\n",
      "Seen so far: 12864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 201: 0.6966015696525574\n",
      "Seen so far: 12928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 202: 0.944719672203064\n",
      "Seen so far: 12992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 203: 0.8291206359863281\n",
      "Seen so far: 13056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 204: 1.0505590438842773\n",
      "Seen so far: 13120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 205: 0.5539385080337524\n",
      "Seen so far: 13184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 206: 1.2477104663848877\n",
      "Seen so far: 13248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 207: 0.7606561183929443\n",
      "Seen so far: 13312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 208: 1.1244889497756958\n",
      "Seen so far: 13376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 209: 0.8826092481613159\n",
      "Seen so far: 13440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 210: 0.7870451211929321\n",
      "Seen so far: 13504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 211: 0.8469196557998657\n",
      "Seen so far: 13568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 212: 1.3473138809204102\n",
      "Seen so far: 13632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 213: 0.9562262892723083\n",
      "Seen so far: 13696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 214: 0.9835957288742065\n",
      "Seen so far: 13760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 215: 0.8989812731742859\n",
      "Seen so far: 13824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 216: 0.6791632175445557\n",
      "Seen so far: 13888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 217: 0.8385804891586304\n",
      "Seen so far: 13952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 218: 0.8145144581794739\n",
      "Seen so far: 14016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 219: 0.4895358085632324\n",
      "Seen so far: 14080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 220: 0.7962489128112793\n",
      "Seen so far: 14144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 221: 0.789570152759552\n",
      "Seen so far: 14208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 222: 0.7883950471878052\n",
      "Seen so far: 14272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 223: 0.9162689447402954\n",
      "Seen so far: 14336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 224: 0.5141017436981201\n",
      "Seen so far: 14400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 225: 0.8379029631614685\n",
      "Seen so far: 14464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 226: 0.5456726551055908\n",
      "Seen so far: 14528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 227: 0.8160585165023804\n",
      "Seen so far: 14592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 228: 0.8056424856185913\n",
      "Seen so far: 14656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 229: 1.0917932987213135\n",
      "Seen so far: 14720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 230: 0.6525163054466248\n",
      "Seen so far: 14784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 231: 1.0008002519607544\n",
      "Seen so far: 14848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 232: 0.8071333169937134\n",
      "Seen so far: 14912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 233: 1.206054925918579\n",
      "Seen so far: 14976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 234: 0.7153196930885315\n",
      "Seen so far: 15040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 235: 0.4798448383808136\n",
      "Seen so far: 15104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 236: 0.7122859954833984\n",
      "Seen so far: 15168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 237: 0.9348173141479492\n",
      "Seen so far: 15232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 238: 1.090131402015686\n",
      "Seen so far: 15296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 239: 0.9636393189430237\n",
      "Seen so far: 15360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 240: 1.231234073638916\n",
      "Seen so far: 15424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 241: 0.9818085432052612\n",
      "Seen so far: 15488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 242: 1.2350538969039917\n",
      "Seen so far: 15552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 243: 0.9596509337425232\n",
      "Seen so far: 15616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 244: 0.8184841871261597\n",
      "Seen so far: 15680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 245: 1.0481553077697754\n",
      "Seen so far: 15744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 246: 1.1640163660049438\n",
      "Seen so far: 15808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 247: 1.0579822063446045\n",
      "Seen so far: 15872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 248: 0.6403456926345825\n",
      "Seen so far: 15936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 249: 0.5139399766921997\n",
      "Seen so far: 16000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 250: 1.1970629692077637\n",
      "Seen so far: 16064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 251: 1.201000690460205\n",
      "Seen so far: 16128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 252: 0.9737058877944946\n",
      "Seen so far: 16192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 253: 0.8294743299484253\n",
      "Seen so far: 16256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 254: 0.8021768927574158\n",
      "Seen so far: 16320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 255: 1.0934864282608032\n",
      "Seen so far: 16384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 256: 1.1150308847427368\n",
      "Seen so far: 16448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 257: 1.3533787727355957\n",
      "Seen so far: 16512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 258: 0.6618666648864746\n",
      "Seen so far: 16576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 259: 0.8620332479476929\n",
      "Seen so far: 16640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 260: 0.46333736181259155\n",
      "Seen so far: 16704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 261: 0.9304831624031067\n",
      "Seen so far: 16768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 262: 1.1145124435424805\n",
      "Seen so far: 16832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 263: 0.9619870185852051\n",
      "Seen so far: 16896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 264: 0.635855495929718\n",
      "Seen so far: 16960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 265: 0.9799494743347168\n",
      "Seen so far: 17024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 266: 0.7798031568527222\n",
      "Seen so far: 17088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 267: 0.9016104936599731\n",
      "Seen so far: 17152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 268: 0.8936631679534912\n",
      "Seen so far: 17216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 269: 0.9353463053703308\n",
      "Seen so far: 17280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 270: 0.49704307317733765\n",
      "Seen so far: 17344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 271: 1.1877050399780273\n",
      "Seen so far: 17408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 272: 0.5764002799987793\n",
      "Seen so far: 17472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 273: 1.0730564594268799\n",
      "Seen so far: 17536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 274: 1.1044433116912842\n",
      "Seen so far: 17600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 275: 0.6306620240211487\n",
      "Seen so far: 17664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 276: 1.1910697221755981\n",
      "Seen so far: 17728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 277: 1.1428780555725098\n",
      "Seen so far: 17792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 278: 0.7363260984420776\n",
      "Seen so far: 17856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 279: 1.2415181398391724\n",
      "Seen so far: 17920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 280: 0.5210598707199097\n",
      "Seen so far: 17984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 281: 0.8203533887863159\n",
      "Seen so far: 18048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 282: 0.8321082592010498\n",
      "Seen so far: 18112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 283: 0.5254957675933838\n",
      "Seen so far: 18176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 284: 0.40239277482032776\n",
      "Seen so far: 18240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 285: 0.6077485084533691\n",
      "Seen so far: 18304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 286: 0.7500542402267456\n",
      "Seen so far: 18368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 287: 0.570563554763794\n",
      "Seen so far: 18432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 288: 0.746578574180603\n",
      "Seen so far: 18496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 289: 0.9152581095695496\n",
      "Seen so far: 18560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 290: 1.0838686227798462\n",
      "Seen so far: 18624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 291: 0.44432488083839417\n",
      "Seen so far: 18688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 292: 1.1049578189849854\n",
      "Seen so far: 18752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 293: 1.3778622150421143\n",
      "Seen so far: 18816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 294: 0.5528767108917236\n",
      "Seen so far: 18880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 295: 1.0254276990890503\n",
      "Seen so far: 18944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 296: 0.8677511215209961\n",
      "Seen so far: 19008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 297: 0.6254400014877319\n",
      "Seen so far: 19072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 298: 0.7181423902511597\n",
      "Seen so far: 19136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 299: 1.4111192226409912\n",
      "Seen so far: 19200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 300: 0.7729535698890686\n",
      "Seen so far: 19264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 301: 0.7150706648826599\n",
      "Seen so far: 19328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 302: 0.8518802523612976\n",
      "Seen so far: 19392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 303: 0.6456373929977417\n",
      "Seen so far: 19456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 304: 0.9077091217041016\n",
      "Seen so far: 19520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 305: 0.8156598806381226\n",
      "Seen so far: 19584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 306: 0.9958467483520508\n",
      "Seen so far: 19648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 307: 0.9618936777114868\n",
      "Seen so far: 19712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 308: 1.076523780822754\n",
      "Seen so far: 19776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 309: 0.6835237741470337\n",
      "Seen so far: 19840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 310: 0.8891571760177612\n",
      "Seen so far: 19904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 311: 0.8605705499649048\n",
      "Seen so far: 19968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 312: 0.9898467063903809\n",
      "Seen so far: 20032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 313: 0.9616521000862122\n",
      "Seen so far: 20096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 314: 0.8714836835861206\n",
      "Seen so far: 20160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 315: 0.6562647819519043\n",
      "Seen so far: 20224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 316: 0.8760911226272583\n",
      "Seen so far: 20288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 317: 0.9586668014526367\n",
      "Seen so far: 20352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 318: 0.9252772331237793\n",
      "Seen so far: 20416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 319: 0.8487176895141602\n",
      "Seen so far: 20480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 320: 0.9344033002853394\n",
      "Seen so far: 20544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 321: 0.7756036520004272\n",
      "Seen so far: 20608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 322: 0.9698641300201416\n",
      "Seen so far: 20672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 323: 0.9906350374221802\n",
      "Seen so far: 20736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 324: 1.005993366241455\n",
      "Seen so far: 20800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 325: 0.6085951924324036\n",
      "Seen so far: 20864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 326: 0.7823070287704468\n",
      "Seen so far: 20928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 327: 1.0188333988189697\n",
      "Seen so far: 20992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 328: 1.062532663345337\n",
      "Seen so far: 21056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 329: 0.9895522594451904\n",
      "Seen so far: 21120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 330: 0.7881252765655518\n",
      "Seen so far: 21184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 331: 0.8586766719818115\n",
      "Seen so far: 21248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 332: 0.9958182573318481\n",
      "Seen so far: 21312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 333: 1.153498888015747\n",
      "Seen so far: 21376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 334: 0.863244891166687\n",
      "Seen so far: 21440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 335: 1.1410472393035889\n",
      "Seen so far: 21504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 336: 0.9082552790641785\n",
      "Seen so far: 21568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 337: 0.6512858271598816\n",
      "Seen so far: 21632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 338: 0.7556185722351074\n",
      "Seen so far: 21696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 339: 0.5489656925201416\n",
      "Seen so far: 21760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 340: 0.5955232381820679\n",
      "Seen so far: 21824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 341: 0.8285961151123047\n",
      "Seen so far: 21888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 342: 0.8784894347190857\n",
      "Seen so far: 21952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 343: 1.3573219776153564\n",
      "Seen so far: 22016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 344: 0.9784733057022095\n",
      "Seen so far: 22080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 345: 0.6984298229217529\n",
      "Seen so far: 22144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 346: 0.5572134256362915\n",
      "Seen so far: 22208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 347: 1.2535698413848877\n",
      "Seen so far: 22272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 348: 0.4285070300102234\n",
      "Seen so far: 22336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 349: 0.8374271392822266\n",
      "Seen so far: 22400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 350: 1.0056400299072266\n",
      "Seen so far: 22464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 351: 0.6652923822402954\n",
      "Seen so far: 22528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 352: 1.0487654209136963\n",
      "Seen so far: 22592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 353: 1.1355204582214355\n",
      "Seen so far: 22656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 354: 0.7820584774017334\n",
      "Seen so far: 22720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 355: 0.8666359782218933\n",
      "Seen so far: 22784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 356: 0.48869916796684265\n",
      "Seen so far: 22848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 357: 0.8403352499008179\n",
      "Seen so far: 22912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 358: 0.8443617820739746\n",
      "Seen so far: 22976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 359: 0.9108973145484924\n",
      "Seen so far: 23040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 360: 1.0015664100646973\n",
      "Seen so far: 23104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 361: 0.6517506837844849\n",
      "Seen so far: 23168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 362: 1.018471360206604\n",
      "Seen so far: 23232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 363: 0.9292924404144287\n",
      "Seen so far: 23296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 364: 0.9941563606262207\n",
      "Seen so far: 23360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 365: 0.9604357481002808\n",
      "Seen so far: 23424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 366: 1.1557730436325073\n",
      "Seen so far: 23488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 367: 0.837882936000824\n",
      "Seen so far: 23552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 368: 0.8332456350326538\n",
      "Seen so far: 23616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 369: 1.0190938711166382\n",
      "Seen so far: 23680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 370: 0.5899860262870789\n",
      "Seen so far: 23744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 371: 1.099854588508606\n",
      "Seen so far: 23808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 372: 0.5030347108840942\n",
      "Seen so far: 23872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 373: 0.8665316104888916\n",
      "Seen so far: 23936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 374: 0.9252525568008423\n",
      "Seen so far: 24000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 375: 0.7604669332504272\n",
      "Seen so far: 24064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 376: 0.6707174181938171\n",
      "Seen so far: 24128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 377: 1.3254154920578003\n",
      "Seen so far: 24192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 378: 0.6312863826751709\n",
      "Seen so far: 24256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 379: 0.7871081829071045\n",
      "Seen so far: 24320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 380: 0.9879034757614136\n",
      "Seen so far: 24384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 381: 0.7477332353591919\n",
      "Seen so far: 24448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 382: 0.6740376949310303\n",
      "Seen so far: 24512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 383: 1.0277338027954102\n",
      "Seen so far: 24576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 384: 0.8960565328598022\n",
      "Seen so far: 24640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 385: 0.8981227874755859\n",
      "Seen so far: 24704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 386: 1.3066704273223877\n",
      "Seen so far: 24768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 387: 0.8073936700820923\n",
      "Seen so far: 24832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 388: 1.2702045440673828\n",
      "Seen so far: 24896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 389: 0.7209979295730591\n",
      "Seen so far: 24960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 390: 1.0727832317352295\n",
      "Seen so far: 25024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 391: 0.5357916355133057\n",
      "Seen so far: 25088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 392: 1.0551338195800781\n",
      "Seen so far: 25152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 393: 1.026655912399292\n",
      "Seen so far: 25216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 394: 0.5700885057449341\n",
      "Seen so far: 25280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 395: 1.2154446840286255\n",
      "Seen so far: 25344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 396: 0.8470414280891418\n",
      "Seen so far: 25408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 397: 1.2180079221725464\n",
      "Seen so far: 25472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 398: 0.7314550876617432\n",
      "Seen so far: 25536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 399: 0.9789348840713501\n",
      "Seen so far: 25600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 400: 0.8314355611801147\n",
      "Seen so far: 25664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 401: 0.7263618111610413\n",
      "Seen so far: 25728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 402: 0.8456017971038818\n",
      "Seen so far: 25792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 403: 0.7525826096534729\n",
      "Seen so far: 25856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 404: 0.6092408895492554\n",
      "Seen so far: 25920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 405: 0.9140182137489319\n",
      "Seen so far: 25984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 406: 0.9230406880378723\n",
      "Seen so far: 26048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 407: 0.7679699659347534\n",
      "Seen so far: 26112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 408: 0.9886326193809509\n",
      "Seen so far: 26176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 409: 0.8575431108474731\n",
      "Seen so far: 26240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 410: 0.5280818939208984\n",
      "Seen so far: 26304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 411: 1.1110644340515137\n",
      "Seen so far: 26368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 412: 1.0857691764831543\n",
      "Seen so far: 26432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 413: 0.8364474177360535\n",
      "Seen so far: 26496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 414: 0.40398934483528137\n",
      "Seen so far: 26560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 415: 0.9159482717514038\n",
      "Seen so far: 26624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 416: 0.9127219319343567\n",
      "Seen so far: 26688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 417: 0.8681632280349731\n",
      "Seen so far: 26752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 418: 0.9346270561218262\n",
      "Seen so far: 26816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 419: 1.4362847805023193\n",
      "Seen so far: 26880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 420: 0.847173810005188\n",
      "Seen so far: 26944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 421: 1.4310050010681152\n",
      "Seen so far: 27008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 422: 0.7023860216140747\n",
      "Seen so far: 27072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 423: 0.7970050573348999\n",
      "Seen so far: 27136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 424: 0.8235574960708618\n",
      "Seen so far: 27200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 425: 0.8333609104156494\n",
      "Seen so far: 27264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 426: 1.0503261089324951\n",
      "Seen so far: 27328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 427: 1.0800846815109253\n",
      "Seen so far: 27392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 428: 0.8095294237136841\n",
      "Seen so far: 27456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 429: 0.7654927968978882\n",
      "Seen so far: 27520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 430: 1.0188297033309937\n",
      "Seen so far: 27584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 431: 0.7230654954910278\n",
      "Seen so far: 27648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 432: 1.1111464500427246\n",
      "Seen so far: 27712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 433: 0.5477151870727539\n",
      "Seen so far: 27776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 434: 0.7359418869018555\n",
      "Seen so far: 27840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 435: 1.0742913484573364\n",
      "Seen so far: 27904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 436: 0.8888498544692993\n",
      "Seen so far: 27968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 437: 0.8674123287200928\n",
      "Seen so far: 28032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 438: 0.976317822933197\n",
      "Seen so far: 28096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 439: 0.73509681224823\n",
      "Seen so far: 28160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 440: 0.9300040006637573\n",
      "Seen so far: 28224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 441: 1.1135292053222656\n",
      "Seen so far: 28288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 442: 0.8790342211723328\n",
      "Seen so far: 28352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 443: 0.4836066663265228\n",
      "Seen so far: 28416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 444: 1.0888252258300781\n",
      "Seen so far: 28480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 445: 1.0011568069458008\n",
      "Seen so far: 28544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 446: 0.7501388788223267\n",
      "Seen so far: 28608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 447: 0.7230339646339417\n",
      "Seen so far: 28672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 448: 0.7838352918624878\n",
      "Seen so far: 28736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 449: 0.7602065205574036\n",
      "Seen so far: 28800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 450: 1.2284966707229614\n",
      "Seen so far: 28864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 451: 0.907982587814331\n",
      "Seen so far: 28928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 452: 1.033826470375061\n",
      "Seen so far: 28992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 453: 0.8427719473838806\n",
      "Seen so far: 29056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 454: 0.8576351404190063\n",
      "Seen so far: 29120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 455: 0.684847891330719\n",
      "Seen so far: 29184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 456: 0.8710218667984009\n",
      "Seen so far: 29248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 457: 0.6501331329345703\n",
      "Seen so far: 29312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 458: 1.2638471126556396\n",
      "Seen so far: 29376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 459: 0.9020326733589172\n",
      "Seen so far: 29440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 460: 1.0016659498214722\n",
      "Seen so far: 29504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 461: 0.9781195521354675\n",
      "Seen so far: 29568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 462: 0.8244903683662415\n",
      "Seen so far: 29632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 463: 0.8936875462532043\n",
      "Seen so far: 29696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 464: 0.8856382369995117\n",
      "Seen so far: 29760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 465: 0.636748194694519\n",
      "Seen so far: 29824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 466: 0.8768401145935059\n",
      "Seen so far: 29888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 467: 0.8869473934173584\n",
      "Seen so far: 29952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 468: 0.9527809619903564\n",
      "Seen so far: 30016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 469: 0.8006305694580078\n",
      "Seen so far: 30080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 470: 0.5284596085548401\n",
      "Seen so far: 30144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 471: 0.7373527884483337\n",
      "Seen so far: 30208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 472: 0.6865073442459106\n",
      "Seen so far: 30272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 473: 0.7716939449310303\n",
      "Seen so far: 30336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 474: 0.6349256634712219\n",
      "Seen so far: 30400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 475: 0.9611257314682007\n",
      "Seen so far: 30464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 476: 0.8747549057006836\n",
      "Seen so far: 30528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 477: 0.6515949964523315\n",
      "Seen so far: 30592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 478: 0.8192712068557739\n",
      "Seen so far: 30656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 479: 0.9981987476348877\n",
      "Seen so far: 30720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 480: 0.6274759769439697\n",
      "Seen so far: 30784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 481: 0.797421395778656\n",
      "Seen so far: 30848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 482: 0.5897639989852905\n",
      "Seen so far: 30912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 483: 0.9417612552642822\n",
      "Seen so far: 30976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 484: 0.714680552482605\n",
      "Seen so far: 31040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 485: 0.7931191921234131\n",
      "Seen so far: 31104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 486: 0.9942464232444763\n",
      "Seen so far: 31168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 487: 0.861547589302063\n",
      "Seen so far: 31232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 488: 0.9777987003326416\n",
      "Seen so far: 31296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 489: 1.1250903606414795\n",
      "Seen so far: 31360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 490: 0.7138792872428894\n",
      "Seen so far: 31424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 491: 0.7881892323493958\n",
      "Seen so far: 31488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 492: 0.7871459722518921\n",
      "Seen so far: 31552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 493: 0.8262543678283691\n",
      "Seen so far: 31616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 494: 0.9462741613388062\n",
      "Seen so far: 31680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 495: 0.7382093667984009\n",
      "Seen so far: 31744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 496: 0.9802330732345581\n",
      "Seen so far: 31808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 497: 0.9056911468505859\n",
      "Seen so far: 31872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 498: 0.8404312133789062\n",
      "Seen so far: 31936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 499: 1.091916799545288\n",
      "Seen so far: 32000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 500: 0.6859827637672424\n",
      "Seen so far: 32064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 501: 0.9088281989097595\n",
      "Seen so far: 32128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 502: 0.5701589584350586\n",
      "Seen so far: 32192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 503: 0.6790052652359009\n",
      "Seen so far: 32256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 504: 1.325352430343628\n",
      "Seen so far: 32320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 505: 1.0148489475250244\n",
      "Seen so far: 32384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 506: 1.0936617851257324\n",
      "Seen so far: 32448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 507: 1.2775375843048096\n",
      "Seen so far: 32512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 508: 0.8985778093338013\n",
      "Seen so far: 32576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 509: 0.7383178472518921\n",
      "Seen so far: 32640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 510: 0.8992654085159302\n",
      "Seen so far: 32704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 511: 1.0324878692626953\n",
      "Seen so far: 32768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 512: 1.0802533626556396\n",
      "Seen so far: 32832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 513: 1.2419027090072632\n",
      "Seen so far: 32896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 514: 0.6706039905548096\n",
      "Seen so far: 32960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 515: 0.6627210378646851\n",
      "Seen so far: 33024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 516: 0.8491902351379395\n",
      "Seen so far: 33088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 517: 0.9971245527267456\n",
      "Seen so far: 33152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 518: 0.8474093675613403\n",
      "Seen so far: 33216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 519: 0.9168950915336609\n",
      "Seen so far: 33280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 520: 0.8209295272827148\n",
      "Seen so far: 33344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 521: 0.7322750091552734\n",
      "Seen so far: 33408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 522: 0.578973650932312\n",
      "Seen so far: 33472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 523: 0.8443436622619629\n",
      "Seen so far: 33536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 524: 0.8688706755638123\n",
      "Seen so far: 33600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 525: 0.9630335569381714\n",
      "Seen so far: 33664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 526: 1.1630847454071045\n",
      "Seen so far: 33728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 527: 0.9866726994514465\n",
      "Seen so far: 33792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 528: 0.7721157073974609\n",
      "Seen so far: 33856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 529: 0.7085142135620117\n",
      "Seen so far: 33920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 530: 0.9218621850013733\n",
      "Seen so far: 33984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 531: 0.5543655753135681\n",
      "Seen so far: 34048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 532: 0.9431718587875366\n",
      "Seen so far: 34112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 533: 1.1827772855758667\n",
      "Seen so far: 34176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 534: 0.80729740858078\n",
      "Seen so far: 34240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 535: 0.9497742652893066\n",
      "Seen so far: 34304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 536: 0.7436039447784424\n",
      "Seen so far: 34368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 537: 0.8436145186424255\n",
      "Seen so far: 34432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 538: 0.6091470718383789\n",
      "Seen so far: 34496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 539: 0.6606194376945496\n",
      "Seen so far: 34560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 540: 0.9878594875335693\n",
      "Seen so far: 34624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 541: 0.8220403790473938\n",
      "Seen so far: 34688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 542: 0.6468983888626099\n",
      "Seen so far: 34752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 543: 0.7058441638946533\n",
      "Seen so far: 34816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 544: 0.6524286270141602\n",
      "Seen so far: 34880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 545: 0.9985082745552063\n",
      "Seen so far: 34944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 546: 0.9034209847450256\n",
      "Seen so far: 35008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 547: 0.9648874402046204\n",
      "Seen so far: 35072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 548: 0.970874547958374\n",
      "Seen so far: 35136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 549: 0.8633697032928467\n",
      "Seen so far: 35200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 550: 0.8643990159034729\n",
      "Seen so far: 35264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 551: 0.5554420351982117\n",
      "Seen so far: 35328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 552: 0.8250232934951782\n",
      "Seen so far: 35392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 553: 1.0871262550354004\n",
      "Seen so far: 35456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 554: 0.8887918591499329\n",
      "Seen so far: 35520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 555: 0.9982268810272217\n",
      "Seen so far: 35584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 556: 0.8948709964752197\n",
      "Seen so far: 35648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 557: 1.1117005348205566\n",
      "Seen so far: 35712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 558: 0.6111849546432495\n",
      "Seen so far: 35776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 559: 0.898379921913147\n",
      "Seen so far: 35840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 560: 0.7654532194137573\n",
      "Seen so far: 35904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 561: 0.6477277874946594\n",
      "Seen so far: 35968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 562: 1.0360207557678223\n",
      "Seen so far: 36032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 563: 0.9735252261161804\n",
      "Seen so far: 36096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 564: 0.7226687669754028\n",
      "Seen so far: 36160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 565: 0.761317789554596\n",
      "Seen so far: 36224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 566: 0.6561148762702942\n",
      "Seen so far: 36288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 567: 0.783690869808197\n",
      "Seen so far: 36352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 568: 0.6869741678237915\n",
      "Seen so far: 36416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 569: 0.6325150728225708\n",
      "Seen so far: 36480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 570: 0.9797675609588623\n",
      "Seen so far: 36544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 571: 1.0014550685882568\n",
      "Seen so far: 36608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 572: 0.9804006218910217\n",
      "Seen so far: 36672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 573: 0.9802511930465698\n",
      "Seen so far: 36736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 574: 0.8532482385635376\n",
      "Seen so far: 36800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 575: 1.0679700374603271\n",
      "Seen so far: 36864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 576: 0.5718857049942017\n",
      "Seen so far: 36928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 577: 1.0642828941345215\n",
      "Seen so far: 36992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 578: 0.5136187076568604\n",
      "Seen so far: 37056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 579: 0.7966874837875366\n",
      "Seen so far: 37120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 580: 0.6244238018989563\n",
      "Seen so far: 37184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 581: 0.7706777453422546\n",
      "Seen so far: 37248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 582: 1.2951388359069824\n",
      "Seen so far: 37312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 583: 0.7640865445137024\n",
      "Seen so far: 37376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 584: 1.0529651641845703\n",
      "Seen so far: 37440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 585: 0.6682108640670776\n",
      "Seen so far: 37504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 586: 0.7689635157585144\n",
      "Seen so far: 37568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 587: 0.5499428510665894\n",
      "Seen so far: 37632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 588: 0.7583855986595154\n",
      "Seen so far: 37696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 589: 0.8056906461715698\n",
      "Seen so far: 37760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 590: 0.5694326162338257\n",
      "Seen so far: 37824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 591: 0.711182177066803\n",
      "Seen so far: 37888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 592: 0.9285035729408264\n",
      "Seen so far: 37952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 593: 0.8807641863822937\n",
      "Seen so far: 38016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 594: 0.573292076587677\n",
      "Seen so far: 38080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 595: 0.6966220140457153\n",
      "Seen so far: 38144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 596: 0.722338080406189\n",
      "Seen so far: 38208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 597: 0.5023728609085083\n",
      "Seen so far: 38272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 598: 0.7511959671974182\n",
      "Seen so far: 38336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 599: 0.6463791131973267\n",
      "Seen so far: 38400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 600: 0.5369203090667725\n",
      "Seen so far: 38464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 601: 0.4529385566711426\n",
      "Seen so far: 38528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 602: 1.0327115058898926\n",
      "Seen so far: 38592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 603: 1.3991695642471313\n",
      "Seen so far: 38656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 604: 1.042683720588684\n",
      "Seen so far: 38720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 605: 0.8647948503494263\n",
      "Seen so far: 38784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 606: 1.4292303323745728\n",
      "Seen so far: 38848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 607: 0.9586074352264404\n",
      "Seen so far: 38912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 608: 0.9376498460769653\n",
      "Seen so far: 38976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 609: 0.691064178943634\n",
      "Seen so far: 39040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 610: 0.5445663332939148\n",
      "Seen so far: 39104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 611: 0.6835581660270691\n",
      "Seen so far: 39168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 612: 0.7667451500892639\n",
      "Seen so far: 39232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 613: 0.6937175393104553\n",
      "Seen so far: 39296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 614: 1.0020583868026733\n",
      "Seen so far: 39360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 615: 0.8921414613723755\n",
      "Seen so far: 39424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 616: 0.6944668292999268\n",
      "Seen so far: 39488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 617: 1.1182730197906494\n",
      "Seen so far: 39552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 618: 1.2004220485687256\n",
      "Seen so far: 39616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 619: 0.8953365683555603\n",
      "Seen so far: 39680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 620: 1.0122942924499512\n",
      "Seen so far: 39744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 621: 0.9848816394805908\n",
      "Seen so far: 39808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 622: 0.9493961334228516\n",
      "Seen so far: 39872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 623: 0.7673047780990601\n",
      "Seen so far: 39936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 624: 0.8079527020454407\n",
      "Seen so far: 40000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 625: 0.7865156531333923\n",
      "Seen so far: 40064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 626: 0.8727314472198486\n",
      "Seen so far: 40128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 627: 0.5835375785827637\n",
      "Seen so far: 40192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 628: 0.9819289445877075\n",
      "Seen so far: 40256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 629: 0.9031092524528503\n",
      "Seen so far: 40320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 630: 0.777495265007019\n",
      "Seen so far: 40384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 631: 0.7800256013870239\n",
      "Seen so far: 40448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 632: 0.808385968208313\n",
      "Seen so far: 40512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 633: 0.9846954345703125\n",
      "Seen so far: 40576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 634: 0.5480397343635559\n",
      "Seen so far: 40640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 635: 0.6340734958648682\n",
      "Seen so far: 40704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 636: 1.0171289443969727\n",
      "Seen so far: 40768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 637: 0.40860867500305176\n",
      "Seen so far: 40832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 638: 0.6462222337722778\n",
      "Seen so far: 40896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 639: 0.8653475046157837\n",
      "Seen so far: 40960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 640: 0.7706242799758911\n",
      "Seen so far: 41024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 641: 0.3150855004787445\n",
      "Seen so far: 41088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 642: 0.6504820585250854\n",
      "Seen so far: 41152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 643: 0.5799773335456848\n",
      "Seen so far: 41216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 644: 0.7663036584854126\n",
      "Seen so far: 41280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 645: 0.9062076807022095\n",
      "Seen so far: 41344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 646: 0.7591193318367004\n",
      "Seen so far: 41408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 647: 0.7974172830581665\n",
      "Seen so far: 41472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 648: 0.7453540563583374\n",
      "Seen so far: 41536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 649: 1.0936585664749146\n",
      "Seen so far: 41600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 650: 1.2339931726455688\n",
      "Seen so far: 41664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 651: 0.7192132472991943\n",
      "Seen so far: 41728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 652: 0.7240732908248901\n",
      "Seen so far: 41792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 653: 0.7468340396881104\n",
      "Seen so far: 41856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 654: 1.0200934410095215\n",
      "Seen so far: 41920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 655: 0.5552334785461426\n",
      "Seen so far: 41984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 656: 0.8915525078773499\n",
      "Seen so far: 42048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 657: 1.3991378545761108\n",
      "Seen so far: 42112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 658: 0.6946237087249756\n",
      "Seen so far: 42176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 659: 0.7965649366378784\n",
      "Seen so far: 42240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 660: 0.9207841157913208\n",
      "Seen so far: 42304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 661: 0.7395260334014893\n",
      "Seen so far: 42368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 662: 0.9019399881362915\n",
      "Seen so far: 42432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 663: 0.9705918431282043\n",
      "Seen so far: 42496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 664: 0.8664833307266235\n",
      "Seen so far: 42560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 665: 1.0242788791656494\n",
      "Seen so far: 42624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 666: 0.7316396236419678\n",
      "Seen so far: 42688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 667: 0.6260116100311279\n",
      "Seen so far: 42752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 668: 0.6833302974700928\n",
      "Seen so far: 42816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 669: 0.9923029541969299\n",
      "Seen so far: 42880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 670: 0.8103830218315125\n",
      "Seen so far: 42944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 671: 1.4817557334899902\n",
      "Seen so far: 43008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 672: 0.987326443195343\n",
      "Seen so far: 43072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 673: 1.0696423053741455\n",
      "Seen so far: 43136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 674: 0.7550654411315918\n",
      "Seen so far: 43200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 675: 0.956169843673706\n",
      "Seen so far: 43264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 676: 1.069055438041687\n",
      "Seen so far: 43328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 677: 0.8192747235298157\n",
      "Seen so far: 43392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 678: 0.8459974527359009\n",
      "Seen so far: 43456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 679: 1.0643798112869263\n",
      "Seen so far: 43520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 680: 0.7594826221466064\n",
      "Seen so far: 43584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 681: 1.1725807189941406\n",
      "Seen so far: 43648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 682: 0.8955813646316528\n",
      "Seen so far: 43712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 683: 0.5687073469161987\n",
      "Seen so far: 43776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 684: 0.8630051612854004\n",
      "Seen so far: 43840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 685: 0.5996761322021484\n",
      "Seen so far: 43904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 686: 1.1229056119918823\n",
      "Seen so far: 43968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 687: 0.9865632057189941\n",
      "Seen so far: 44032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 688: 0.7497521638870239\n",
      "Seen so far: 44096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 689: 0.5851271748542786\n",
      "Seen so far: 44160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 690: 0.8593677878379822\n",
      "Seen so far: 44224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 691: 0.9686572551727295\n",
      "Seen so far: 44288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 692: 1.088568925857544\n",
      "Seen so far: 44352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 693: 0.9335352778434753\n",
      "Seen so far: 44416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 694: 0.7919625043869019\n",
      "Seen so far: 44480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 695: 0.4627975523471832\n",
      "Seen so far: 44544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 696: 0.753359317779541\n",
      "Seen so far: 44608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 697: 0.6647965312004089\n",
      "Seen so far: 44672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 698: 0.6888666152954102\n",
      "Seen so far: 44736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 699: 0.9042190909385681\n",
      "Seen so far: 44800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 700: 1.3142127990722656\n",
      "Seen so far: 44864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 701: 0.9387621283531189\n",
      "Seen so far: 44928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 702: 0.7159312963485718\n",
      "Seen so far: 44992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 703: 0.6116955280303955\n",
      "Seen so far: 45056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 704: 0.7074108719825745\n",
      "Seen so far: 45120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 705: 0.6112755537033081\n",
      "Seen so far: 45184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 706: 0.8352882266044617\n",
      "Seen so far: 45248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 707: 0.5386003851890564\n",
      "Seen so far: 45312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 708: 0.6997891664505005\n",
      "Seen so far: 45376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 709: 1.4034414291381836\n",
      "Seen so far: 45440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 710: 0.8453410863876343\n",
      "Seen so far: 45504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 711: 0.6836236715316772\n",
      "Seen so far: 45568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 712: 0.8908905386924744\n",
      "Seen so far: 45632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 713: 0.9733348488807678\n",
      "Seen so far: 45696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 714: 0.9842134118080139\n",
      "Seen so far: 45760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 715: 1.1119725704193115\n",
      "Seen so far: 45824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 716: 0.3956390917301178\n",
      "Seen so far: 45888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 717: 1.226414680480957\n",
      "Seen so far: 45952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 718: 1.2359421253204346\n",
      "Seen so far: 46016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 719: 1.0573660135269165\n",
      "Seen so far: 46080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 720: 0.9436060786247253\n",
      "Seen so far: 46144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 721: 0.951103687286377\n",
      "Seen so far: 46208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 722: 0.4374238848686218\n",
      "Seen so far: 46272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 723: 0.6923131942749023\n",
      "Seen so far: 46336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 724: 0.8199352622032166\n",
      "Seen so far: 46400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 725: 1.14824378490448\n",
      "Seen so far: 46464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 726: 0.923866868019104\n",
      "Seen so far: 46528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 727: 0.8344299793243408\n",
      "Seen so far: 46592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 728: 1.0431220531463623\n",
      "Seen so far: 46656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 729: 0.6699038743972778\n",
      "Seen so far: 46720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 730: 0.825951337814331\n",
      "Seen so far: 46784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 731: 0.9119157195091248\n",
      "Seen so far: 46848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 732: 1.622523307800293\n",
      "Seen so far: 46912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 733: 0.9814322590827942\n",
      "Seen so far: 46976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 734: 0.7406148314476013\n",
      "Seen so far: 47040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 735: 0.7470276355743408\n",
      "Seen so far: 47104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 736: 0.6855005621910095\n",
      "Seen so far: 47168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 737: 0.6687198877334595\n",
      "Seen so far: 47232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 738: 0.6368243098258972\n",
      "Seen so far: 47296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 739: 1.012905240058899\n",
      "Seen so far: 47360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 740: 0.6796791553497314\n",
      "Seen so far: 47424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 741: 0.8027365803718567\n",
      "Seen so far: 47488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 742: 0.6350854635238647\n",
      "Seen so far: 47552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 743: 1.2301521301269531\n",
      "Seen so far: 47616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 744: 0.6237919330596924\n",
      "Seen so far: 47680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 745: 0.7906854748725891\n",
      "Seen so far: 47744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 746: 1.0644888877868652\n",
      "Seen so far: 47808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 747: 0.9083875417709351\n",
      "Seen so far: 47872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 748: 0.6140434741973877\n",
      "Seen so far: 47936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 749: 1.2607383728027344\n",
      "Seen so far: 48000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 750: 0.6732744574546814\n",
      "Seen so far: 48064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 751: 0.6729897260665894\n",
      "Seen so far: 48128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 752: 0.9841982126235962\n",
      "Seen so far: 48192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 753: 1.3273645639419556\n",
      "Seen so far: 48256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 754: 1.0341660976409912\n",
      "Seen so far: 48320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 755: 0.7333588004112244\n",
      "Seen so far: 48384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 756: 1.1752063035964966\n",
      "Seen so far: 48448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 757: 0.9993767142295837\n",
      "Seen so far: 48512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 758: 0.7328662276268005\n",
      "Seen so far: 48576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 759: 0.8415107727050781\n",
      "Seen so far: 48640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 760: 1.1128922700881958\n",
      "Seen so far: 48704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 761: 1.0897562503814697\n",
      "Seen so far: 48768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 762: 0.7217026948928833\n",
      "Seen so far: 48832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 763: 1.118187665939331\n",
      "Seen so far: 48896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 764: 0.8318721055984497\n",
      "Seen so far: 48960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 765: 0.7975407838821411\n",
      "Seen so far: 49024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 766: 0.8857764601707458\n",
      "Seen so far: 49088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 767: 0.7306582927703857\n",
      "Seen so far: 49152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 768: 0.4883968234062195\n",
      "Seen so far: 49216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 769: 0.6887191534042358\n",
      "Seen so far: 49280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 770: 0.723287045955658\n",
      "Seen so far: 49344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 771: 0.7360042333602905\n",
      "Seen so far: 49408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 772: 1.1501189470291138\n",
      "Seen so far: 49472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 773: 0.8274739384651184\n",
      "Seen so far: 49536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 774: 0.716719925403595\n",
      "Seen so far: 49600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 775: 0.8470811247825623\n",
      "Seen so far: 49664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 776: 0.8105145692825317\n",
      "Seen so far: 49728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 777: 1.0431574583053589\n",
      "Seen so far: 49792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 778: 0.7451425790786743\n",
      "Seen so far: 49856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 779: 0.5119418501853943\n",
      "Seen so far: 49920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 780: 1.1812186241149902\n",
      "Seen so far: 49984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 781: 1.0861365795135498\n",
      "Seen so far: 50048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 782: 0.884032130241394\n",
      "Seen so far: 50112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 783: 0.8535634279251099\n",
      "Seen so far: 50176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 784: 1.0794419050216675\n",
      "Seen so far: 50240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 785: 0.8136032223701477\n",
      "Seen so far: 50304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 786: 1.0751612186431885\n",
      "Seen so far: 50368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 787: 0.9285968542098999\n",
      "Seen so far: 50432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 788: 0.46314793825149536\n",
      "Seen so far: 50496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 789: 1.1001594066619873\n",
      "Seen so far: 50560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 790: 1.099054217338562\n",
      "Seen so far: 50624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 791: 0.5992677211761475\n",
      "Seen so far: 50688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 792: 0.6092211008071899\n",
      "Seen so far: 50752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 793: 0.7898600697517395\n",
      "Seen so far: 50816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 794: 1.0399333238601685\n",
      "Seen so far: 50880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 795: 0.6520318984985352\n",
      "Seen so far: 50944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 796: 0.8285980820655823\n",
      "Seen so far: 51008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 797: 0.72002112865448\n",
      "Seen so far: 51072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 798: 1.19599449634552\n",
      "Seen so far: 51136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 799: 1.0169380903244019\n",
      "Seen so far: 51200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 800: 0.7167702913284302\n",
      "Seen so far: 51264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 801: 0.7200343608856201\n",
      "Seen so far: 51328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 802: 0.9522876143455505\n",
      "Seen so far: 51392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 803: 0.8888921737670898\n",
      "Seen so far: 51456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 804: 0.522259533405304\n",
      "Seen so far: 51520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 805: 0.8766964673995972\n",
      "Seen so far: 51584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 806: 0.983989417552948\n",
      "Seen so far: 51648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 807: 0.49299177527427673\n",
      "Seen so far: 51712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 808: 0.7966079711914062\n",
      "Seen so far: 51776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 809: 0.7754267454147339\n",
      "Seen so far: 51840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 810: 0.8775215148925781\n",
      "Seen so far: 51904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 811: 0.9760145545005798\n",
      "Seen so far: 51968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 812: 0.9364842176437378\n",
      "Seen so far: 52032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 813: 0.7778427004814148\n",
      "Seen so far: 52096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 814: 0.596771776676178\n",
      "Seen so far: 52160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 815: 1.1806375980377197\n",
      "Seen so far: 52224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 816: 0.9679357409477234\n",
      "Seen so far: 52288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 817: 0.5374552011489868\n",
      "Seen so far: 52352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 818: 1.3847428560256958\n",
      "Seen so far: 52416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 819: 0.3434871435165405\n",
      "Seen so far: 52480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 820: 1.1043550968170166\n",
      "Seen so far: 52544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 821: 0.8155815601348877\n",
      "Seen so far: 52608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 822: 0.6278862953186035\n",
      "Seen so far: 52672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 823: 0.8943592309951782\n",
      "Seen so far: 52736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 824: 1.031968116760254\n",
      "Seen so far: 52800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 825: 0.8668383359909058\n",
      "Seen so far: 52864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 826: 0.8646335601806641\n",
      "Seen so far: 52928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 827: 1.2396697998046875\n",
      "Seen so far: 52992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 828: 0.8306843042373657\n",
      "Seen so far: 53056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 829: 0.9260951280593872\n",
      "Seen so far: 53120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 830: 0.8794229030609131\n",
      "Seen so far: 53184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 831: 1.0244221687316895\n",
      "Seen so far: 53248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 832: 0.939476728439331\n",
      "Seen so far: 53312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 833: 0.9534760117530823\n",
      "Seen so far: 53376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 834: 0.6048243045806885\n",
      "Seen so far: 53440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 835: 0.6726338863372803\n",
      "Seen so far: 53504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 836: 0.8832734823226929\n",
      "Seen so far: 53568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 837: 0.8217552900314331\n",
      "Seen so far: 53632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 838: 0.4291190505027771\n",
      "Seen so far: 53696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 839: 0.6081310510635376\n",
      "Seen so far: 53760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 840: 0.5829702615737915\n",
      "Seen so far: 53824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 841: 1.214223027229309\n",
      "Seen so far: 53888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 842: 0.7339341044425964\n",
      "Seen so far: 53952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 843: 0.7527737021446228\n",
      "Seen so far: 54016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 844: 1.0379810333251953\n",
      "Seen so far: 54080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 845: 0.9435132145881653\n",
      "Seen so far: 54144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 846: 0.7943700551986694\n",
      "Seen so far: 54208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 847: 0.8455272912979126\n",
      "Seen so far: 54272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 848: 0.7548968195915222\n",
      "Seen so far: 54336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 849: 0.5839009284973145\n",
      "Seen so far: 54400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 850: 0.4796152412891388\n",
      "Seen so far: 54464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 851: 0.6200188398361206\n",
      "Seen so far: 54528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 852: 0.42549633979797363\n",
      "Seen so far: 54592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 853: 0.6956591010093689\n",
      "Seen so far: 54656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 854: 0.6011110544204712\n",
      "Seen so far: 54720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 855: 0.7436641454696655\n",
      "Seen so far: 54784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 856: 0.6067778468132019\n",
      "Seen so far: 54848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 857: 0.6049439907073975\n",
      "Seen so far: 54912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 858: 0.821083664894104\n",
      "Seen so far: 54976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 859: 1.1224315166473389\n",
      "Seen so far: 55040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 860: 0.6609909534454346\n",
      "Seen so far: 55104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 861: 0.7512741088867188\n",
      "Seen so far: 55168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 862: 0.7599223852157593\n",
      "Seen so far: 55232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 863: 1.0349209308624268\n",
      "Seen so far: 55296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 864: 0.9700064659118652\n",
      "Seen so far: 55360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 865: 0.5457997918128967\n",
      "Seen so far: 55424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 866: 0.669968843460083\n",
      "Seen so far: 55488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 867: 0.7696893215179443\n",
      "Seen so far: 55552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 868: 1.0687456130981445\n",
      "Seen so far: 55616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 869: 0.8494564890861511\n",
      "Seen so far: 55680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 870: 1.2000863552093506\n",
      "Seen so far: 55744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 871: 1.0664077997207642\n",
      "Seen so far: 55808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 872: 0.5997700691223145\n",
      "Seen so far: 55872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 873: 1.0270203351974487\n",
      "Seen so far: 55936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 874: 1.0750553607940674\n",
      "Seen so far: 56000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 875: 1.108130931854248\n",
      "Seen so far: 56064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 876: 0.8748378157615662\n",
      "Seen so far: 56128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 877: 1.0430488586425781\n",
      "Seen so far: 56192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 878: 0.9181675910949707\n",
      "Seen so far: 56256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 879: 0.4323112964630127\n",
      "Seen so far: 56320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 880: 0.9199329614639282\n",
      "Seen so far: 56384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 881: 1.1745270490646362\n",
      "Seen so far: 56448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 882: 0.9093572497367859\n",
      "Seen so far: 56512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 883: 0.8169209957122803\n",
      "Seen so far: 56576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 884: 0.4450000822544098\n",
      "Seen so far: 56640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 885: 0.8049719333648682\n",
      "Seen so far: 56704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 886: 0.9519325494766235\n",
      "Seen so far: 56768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 887: 0.9635619521141052\n",
      "Seen so far: 56832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 888: 0.8826612830162048\n",
      "Seen so far: 56896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 889: 1.1897183656692505\n",
      "Seen so far: 56960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 890: 0.8027985095977783\n",
      "Seen so far: 57024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 891: 1.1021971702575684\n",
      "Seen so far: 57088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 892: 0.5295528173446655\n",
      "Seen so far: 57152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 893: 1.2287379503250122\n",
      "Seen so far: 57216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 894: 0.9091457724571228\n",
      "Seen so far: 57280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 895: 0.8946440815925598\n",
      "Seen so far: 57344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 896: 1.2581114768981934\n",
      "Seen so far: 57408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 897: 0.9164588451385498\n",
      "Seen so far: 57472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 898: 0.5731194019317627\n",
      "Seen so far: 57536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 899: 0.645976185798645\n",
      "Seen so far: 57600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 900: 0.7950899004936218\n",
      "Seen so far: 57664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 901: 1.1786822080612183\n",
      "Seen so far: 57728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 902: 1.1097691059112549\n",
      "Seen so far: 57792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 903: 0.9156796336174011\n",
      "Seen so far: 57856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 904: 0.9334645867347717\n",
      "Seen so far: 57920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 905: 0.8886778950691223\n",
      "Seen so far: 57984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 906: 1.162400484085083\n",
      "Seen so far: 58048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 907: 0.866563618183136\n",
      "Seen so far: 58112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 908: 0.5679435133934021\n",
      "Seen so far: 58176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 909: 0.9458563327789307\n",
      "Seen so far: 58240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 910: 0.6419709920883179\n",
      "Seen so far: 58304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 911: 0.7080379724502563\n",
      "Seen so far: 58368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 912: 0.8163821697235107\n",
      "Seen so far: 58432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 913: 1.4807409048080444\n",
      "Seen so far: 58496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 914: 0.6559480428695679\n",
      "Seen so far: 58560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 915: 0.6482381820678711\n",
      "Seen so far: 58624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 916: 1.0870585441589355\n",
      "Seen so far: 58688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 917: 0.6948452591896057\n",
      "Seen so far: 58752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 918: 0.9614287614822388\n",
      "Seen so far: 58816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 919: 0.7602526545524597\n",
      "Seen so far: 58880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 920: 0.8559324741363525\n",
      "Seen so far: 58944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 921: 0.6219650506973267\n",
      "Seen so far: 59008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 922: 0.97796630859375\n",
      "Seen so far: 59072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 923: 0.8820384740829468\n",
      "Seen so far: 59136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 924: 0.8974967002868652\n",
      "Seen so far: 59200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 925: 0.7926578521728516\n",
      "Seen so far: 59264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 926: 1.0373375415802002\n",
      "Seen so far: 59328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 927: 0.7606896758079529\n",
      "Seen so far: 59392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 928: 0.7183570861816406\n",
      "Seen so far: 59456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 929: 0.8019951581954956\n",
      "Seen so far: 59520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 930: 0.8793033361434937\n",
      "Seen so far: 59584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 931: 1.1009052991867065\n",
      "Seen so far: 59648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 932: 1.2610104084014893\n",
      "Seen so far: 59712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 933: 0.9423224925994873\n",
      "Seen so far: 59776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 934: 1.1080671548843384\n",
      "Seen so far: 59840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 935: 0.612551748752594\n",
      "Seen so far: 59904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 936: 0.8605327606201172\n",
      "Seen so far: 59968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 937: 0.9974234104156494\n",
      "Seen so far: 60032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 938: 0.9722069501876831\n",
      "Seen so far: 60096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 939: 0.6317902207374573\n",
      "Seen so far: 60160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 940: 0.6031723022460938\n",
      "Seen so far: 60224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 941: 0.7199192047119141\n",
      "Seen so far: 60288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 942: 0.8995333909988403\n",
      "Seen so far: 60352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 943: 0.9403932094573975\n",
      "Seen so far: 60416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 944: 0.7542291879653931\n",
      "Seen so far: 60480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 945: 0.9826010465621948\n",
      "Seen so far: 60544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 946: 0.7855814695358276\n",
      "Seen so far: 60608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 947: 0.9841194152832031\n",
      "Seen so far: 60672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 948: 0.4938805103302002\n",
      "Seen so far: 60736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 949: 0.8439600467681885\n",
      "Seen so far: 60800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 950: 0.8916435241699219\n",
      "Seen so far: 60864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 951: 0.7701905369758606\n",
      "Seen so far: 60928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 952: 1.1535192728042603\n",
      "Seen so far: 60992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 953: 1.1607218980789185\n",
      "Seen so far: 61056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 954: 0.9206578731536865\n",
      "Seen so far: 61120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 955: 0.8676186203956604\n",
      "Seen so far: 61184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 956: 1.24832284450531\n",
      "Seen so far: 61248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 957: 1.0174980163574219\n",
      "Seen so far: 61312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 958: 1.0393539667129517\n",
      "Seen so far: 61376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 959: 0.6556578278541565\n",
      "Seen so far: 61440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 960: 0.7938680648803711\n",
      "Seen so far: 61504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 961: 0.739655613899231\n",
      "Seen so far: 61568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 962: 0.7990106344223022\n",
      "Seen so far: 61632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 963: 0.8689306378364563\n",
      "Seen so far: 61696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 964: 0.8129422068595886\n",
      "Seen so far: 61760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 965: 0.7919667959213257\n",
      "Seen so far: 61824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 966: 0.5530816316604614\n",
      "Seen so far: 61888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 967: 0.6350681781768799\n",
      "Seen so far: 61952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 968: 0.8241404294967651\n",
      "Seen so far: 62016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 969: 0.8094241619110107\n",
      "Seen so far: 62080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 970: 1.1046228408813477\n",
      "Seen so far: 62144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 971: 0.6918764114379883\n",
      "Seen so far: 62208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 972: 1.1571650505065918\n",
      "Seen so far: 62272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 973: 0.7613454461097717\n",
      "Seen so far: 62336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 974: 0.7585892677307129\n",
      "Seen so far: 62400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 975: 0.7832872867584229\n",
      "Seen so far: 62464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 976: 0.8569682836532593\n",
      "Seen so far: 62528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 977: 0.8624398112297058\n",
      "Seen so far: 62592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 978: 1.1736009120941162\n",
      "Seen so far: 62656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 979: 0.7856255173683167\n",
      "Seen so far: 62720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 980: 0.9336346387863159\n",
      "Seen so far: 62784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 981: 0.9846909046173096\n",
      "Seen so far: 62848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 982: 0.7335877418518066\n",
      "Seen so far: 62912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 983: 0.5456384420394897\n",
      "Seen so far: 62976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 984: 0.8001048564910889\n",
      "Seen so far: 63040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 985: 0.9647748470306396\n",
      "Seen so far: 63104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 986: 0.8452924489974976\n",
      "Seen so far: 63168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 987: 0.9789012670516968\n",
      "Seen so far: 63232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 988: 0.8119468092918396\n",
      "Seen so far: 63296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 989: 0.8616309762001038\n",
      "Seen so far: 63360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 990: 0.7689878940582275\n",
      "Seen so far: 63424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 991: 0.7878801822662354\n",
      "Seen so far: 63488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 992: 0.32464462518692017\n",
      "Seen so far: 63552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 993: 0.8704253435134888\n",
      "Seen so far: 63616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 994: 1.1972427368164062\n",
      "Seen so far: 63680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 995: 0.8175173401832581\n",
      "Seen so far: 63744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 996: 0.931241512298584\n",
      "Seen so far: 63808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 997: 0.4538947343826294\n",
      "Seen so far: 63872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 998: 0.7845708131790161\n",
      "Seen so far: 63936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 999: 0.7751765251159668\n",
      "Seen so far: 64000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1000: 0.7672803401947021\n",
      "Seen so far: 64064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1001: 0.7774125337600708\n",
      "Seen so far: 64128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1002: 0.855953574180603\n",
      "Seen so far: 64192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1003: 0.7203373312950134\n",
      "Seen so far: 64256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1004: 0.7907572388648987\n",
      "Seen so far: 64320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1005: 0.8353705406188965\n",
      "Seen so far: 64384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1006: 0.8561201095581055\n",
      "Seen so far: 64448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1007: 0.9188259840011597\n",
      "Seen so far: 64512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1008: 1.1179673671722412\n",
      "Seen so far: 64576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1009: 0.9042359590530396\n",
      "Seen so far: 64640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1010: 0.4915890395641327\n",
      "Seen so far: 64704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1011: 0.7591471672058105\n",
      "Seen so far: 64768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1012: 0.8653613328933716\n",
      "Seen so far: 64832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1013: 0.9140788912773132\n",
      "Seen so far: 64896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1014: 0.8370152711868286\n",
      "Seen so far: 64960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1015: 0.4635668992996216\n",
      "Seen so far: 65024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1016: 1.0000128746032715\n",
      "Seen so far: 65088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1017: 1.0384341478347778\n",
      "Seen so far: 65152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1018: 0.6270405650138855\n",
      "Seen so far: 65216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1019: 1.134509801864624\n",
      "Seen so far: 65280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1020: 0.43810737133026123\n",
      "Seen so far: 65344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1021: 0.5043752193450928\n",
      "Seen so far: 65408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1022: 0.5567614436149597\n",
      "Seen so far: 65472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1023: 1.3789079189300537\n",
      "Seen so far: 65536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1024: 0.6539385318756104\n",
      "Seen so far: 65600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1025: 0.9363999366760254\n",
      "Seen so far: 65664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1026: 0.8050937652587891\n",
      "Seen so far: 65728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1027: 1.1897454261779785\n",
      "Seen so far: 65792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1028: 0.5270450711250305\n",
      "Seen so far: 65856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1029: 1.0580586194992065\n",
      "Seen so far: 65920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1030: 0.8883352279663086\n",
      "Seen so far: 65984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1031: 0.6338440179824829\n",
      "Seen so far: 66048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1032: 0.7102681398391724\n",
      "Seen so far: 66112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1033: 1.1298868656158447\n",
      "Seen so far: 66176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1034: 1.145180583000183\n",
      "Seen so far: 66240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1035: 1.1753053665161133\n",
      "Seen so far: 66304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1036: 0.515299916267395\n",
      "Seen so far: 66368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1037: 0.8922758102416992\n",
      "Seen so far: 66432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1038: 0.8180434703826904\n",
      "Seen so far: 66496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1039: 0.6336855292320251\n",
      "Seen so far: 66560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1040: 0.9628020524978638\n",
      "Seen so far: 66624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1041: 1.057652235031128\n",
      "Seen so far: 66688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1042: 0.6813913583755493\n",
      "Seen so far: 66752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1043: 0.9863569736480713\n",
      "Seen so far: 66816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1044: 0.4515339732170105\n",
      "Seen so far: 66880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1045: 0.8203833103179932\n",
      "Seen so far: 66944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1046: 0.9030864238739014\n",
      "Seen so far: 67008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1047: 0.7430034279823303\n",
      "Seen so far: 67072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1048: 0.8921442031860352\n",
      "Seen so far: 67136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1049: 0.6479827165603638\n",
      "Seen so far: 67200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1050: 1.2632991075515747\n",
      "Seen so far: 67264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1051: 1.074230670928955\n",
      "Seen so far: 67328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1052: 0.6005959510803223\n",
      "Seen so far: 67392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1053: 0.8587042093276978\n",
      "Seen so far: 67456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1054: 1.1646428108215332\n",
      "Seen so far: 67520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1055: 0.9631175994873047\n",
      "Seen so far: 67584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1056: 0.6502639651298523\n",
      "Seen so far: 67648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1057: 0.712247371673584\n",
      "Seen so far: 67712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1058: 0.532414436340332\n",
      "Seen so far: 67776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1059: 0.5830225348472595\n",
      "Seen so far: 67840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1060: 0.666699230670929\n",
      "Seen so far: 67904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1061: 0.7450811862945557\n",
      "Seen so far: 67968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1062: 1.120309829711914\n",
      "Seen so far: 68032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1063: 0.42284083366394043\n",
      "Seen so far: 68096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1064: 0.8995926380157471\n",
      "Seen so far: 68160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1065: 0.7157025933265686\n",
      "Seen so far: 68224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1066: 0.8378658294677734\n",
      "Seen so far: 68288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1067: 0.6744812726974487\n",
      "Seen so far: 68352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1068: 0.7730497717857361\n",
      "Seen so far: 68416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1069: 0.757082462310791\n",
      "Seen so far: 68480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1070: 0.5563098788261414\n",
      "Seen so far: 68544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1071: 0.6472408175468445\n",
      "Seen so far: 68608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1072: 0.6958426833152771\n",
      "Seen so far: 68672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1073: 1.1691150665283203\n",
      "Seen so far: 68736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1074: 0.694101870059967\n",
      "Seen so far: 68800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1075: 0.6746834516525269\n",
      "Seen so far: 68864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1076: 0.5461845397949219\n",
      "Seen so far: 68928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1077: 1.034027099609375\n",
      "Seen so far: 68992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1078: 1.1267250776290894\n",
      "Seen so far: 69056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1079: 0.832323431968689\n",
      "Seen so far: 69120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1080: 0.7276065945625305\n",
      "Seen so far: 69184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1081: 0.7658987045288086\n",
      "Seen so far: 69248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1082: 0.7903359532356262\n",
      "Seen so far: 69312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1083: 0.7357119917869568\n",
      "Seen so far: 69376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1084: 0.9295461177825928\n",
      "Seen so far: 69440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1085: 0.863981306552887\n",
      "Seen so far: 69504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1086: 1.032443642616272\n",
      "Seen so far: 69568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1087: 1.0419731140136719\n",
      "Seen so far: 69632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1088: 1.0230070352554321\n",
      "Seen so far: 69696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1089: 0.6997783184051514\n",
      "Seen so far: 69760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1090: 0.5930601954460144\n",
      "Seen so far: 69824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1091: 0.990700364112854\n",
      "Seen so far: 69888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1092: 0.9698240756988525\n",
      "Seen so far: 69952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1093: 0.6689265966415405\n",
      "Seen so far: 70016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1094: 0.973091185092926\n",
      "Seen so far: 70080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1095: 0.784202516078949\n",
      "Seen so far: 70144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1096: 0.5203310251235962\n",
      "Seen so far: 70208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1097: 0.7248966097831726\n",
      "Seen so far: 70272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1098: 1.0953335762023926\n",
      "Seen so far: 70336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1099: 0.7012753486633301\n",
      "Seen so far: 70400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1100: 1.2421555519104004\n",
      "Seen so far: 70464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1101: 1.032880425453186\n",
      "Seen so far: 70528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1102: 0.7329472899436951\n",
      "Seen so far: 70592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1103: 0.8993993401527405\n",
      "Seen so far: 70656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1104: 0.5670453906059265\n",
      "Seen so far: 70720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1105: 0.9583626985549927\n",
      "Seen so far: 70784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1106: 0.927788257598877\n",
      "Seen so far: 70848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1107: 0.7457635402679443\n",
      "Seen so far: 70912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1108: 0.8683630228042603\n",
      "Seen so far: 70976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1109: 0.719200849533081\n",
      "Seen so far: 71040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1110: 0.6832970380783081\n",
      "Seen so far: 71104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1111: 0.7627058029174805\n",
      "Seen so far: 71168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1112: 1.1833661794662476\n",
      "Seen so far: 71232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1113: 1.316634178161621\n",
      "Seen so far: 71296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1114: 0.5940825939178467\n",
      "Seen so far: 71360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1115: 1.1836628913879395\n",
      "Seen so far: 71424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1116: 0.7089985013008118\n",
      "Seen so far: 71488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1117: 0.7626389265060425\n",
      "Seen so far: 71552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1118: 0.5259160995483398\n",
      "Seen so far: 71616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1119: 0.8506592512130737\n",
      "Seen so far: 71680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1120: 0.6828914880752563\n",
      "Seen so far: 71744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1121: 0.9790971279144287\n",
      "Seen so far: 71808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1122: 0.4824918508529663\n",
      "Seen so far: 71872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1123: 0.7895891666412354\n",
      "Seen so far: 71936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1124: 0.8925531506538391\n",
      "Seen so far: 72000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1125: 1.163577675819397\n",
      "Seen so far: 72064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1126: 0.6516825556755066\n",
      "Seen so far: 72128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1127: 0.7522683143615723\n",
      "Seen so far: 72192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1128: 1.4096062183380127\n",
      "Seen so far: 72256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1129: 0.6860052347183228\n",
      "Seen so far: 72320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1130: 0.7614639401435852\n",
      "Seen so far: 72384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1131: 0.9308856725692749\n",
      "Seen so far: 72448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1132: 0.818509578704834\n",
      "Seen so far: 72512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1133: 0.8466856479644775\n",
      "Seen so far: 72576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1134: 0.8224340677261353\n",
      "Seen so far: 72640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1135: 1.0325225591659546\n",
      "Seen so far: 72704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1136: 0.9118579626083374\n",
      "Seen so far: 72768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1137: 1.0820459127426147\n",
      "Seen so far: 72832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1138: 0.8242204189300537\n",
      "Seen so far: 72896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1139: 0.5840952396392822\n",
      "Seen so far: 72960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1140: 1.0063855648040771\n",
      "Seen so far: 73024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1141: 0.5528327226638794\n",
      "Seen so far: 73088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1142: 0.921357274055481\n",
      "Seen so far: 73152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1143: 0.6512453556060791\n",
      "Seen so far: 73216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1144: 0.9832850694656372\n",
      "Seen so far: 73280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1145: 0.8912194967269897\n",
      "Seen so far: 73344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1146: 0.7934705018997192\n",
      "Seen so far: 73408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1147: 0.977813184261322\n",
      "Seen so far: 73472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1148: 1.4281086921691895\n",
      "Seen so far: 73536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1149: 0.6721636056900024\n",
      "Seen so far: 73600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1150: 0.7993422150611877\n",
      "Seen so far: 73664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1151: 0.7057415843009949\n",
      "Seen so far: 73728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1152: 0.742865264415741\n",
      "Seen so far: 73792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1153: 0.8119759559631348\n",
      "Seen so far: 73856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1154: 0.6170699000358582\n",
      "Seen so far: 73920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1155: 1.0543917417526245\n",
      "Seen so far: 73984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1156: 0.7354193925857544\n",
      "Seen so far: 74048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1157: 0.9375168085098267\n",
      "Seen so far: 74112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1158: 1.099960207939148\n",
      "Seen so far: 74176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1159: 0.8803830742835999\n",
      "Seen so far: 74240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1160: 0.8635890483856201\n",
      "Seen so far: 74304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1161: 0.7983713150024414\n",
      "Seen so far: 74368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1162: 0.6131429672241211\n",
      "Seen so far: 74432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1163: 0.6255342960357666\n",
      "Seen so far: 74496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1164: 0.9093833565711975\n",
      "Seen so far: 74560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1165: 0.705425500869751\n",
      "Seen so far: 74624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1166: 1.0427649021148682\n",
      "Seen so far: 74688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1167: 0.7464776635169983\n",
      "Seen so far: 74752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1168: 0.41359037160873413\n",
      "Seen so far: 74816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1169: 0.6731075048446655\n",
      "Seen so far: 74880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1170: 1.0456212759017944\n",
      "Seen so far: 74944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1171: 0.6133217811584473\n",
      "Seen so far: 75008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1172: 1.2079477310180664\n",
      "Seen so far: 75072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1173: 0.7652910947799683\n",
      "Seen so far: 75136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1174: 1.061781883239746\n",
      "Seen so far: 75200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1175: 1.3589704036712646\n",
      "Seen so far: 75264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1176: 1.08004891872406\n",
      "Seen so far: 75328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1177: 1.0004525184631348\n",
      "Seen so far: 75392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1178: 1.320629358291626\n",
      "Seen so far: 75456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1179: 0.37082013487815857\n",
      "Seen so far: 75520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1180: 0.782402515411377\n",
      "Seen so far: 75584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1181: 0.9489730596542358\n",
      "Seen so far: 75648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1182: 1.3245091438293457\n",
      "Seen so far: 75712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1183: 0.9896205067634583\n",
      "Seen so far: 75776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1184: 0.8243083357810974\n",
      "Seen so far: 75840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1185: 0.6349989771842957\n",
      "Seen so far: 75904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1186: 0.7071843147277832\n",
      "Seen so far: 75968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1187: 0.8904595971107483\n",
      "Seen so far: 76032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1188: 0.8612964153289795\n",
      "Seen so far: 76096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1189: 0.5271672010421753\n",
      "Seen so far: 76160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1190: 0.6382153034210205\n",
      "Seen so far: 76224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1191: 0.5011016130447388\n",
      "Seen so far: 76288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1192: 1.368201732635498\n",
      "Seen so far: 76352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1193: 0.7362713813781738\n",
      "Seen so far: 76416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1194: 1.1491978168487549\n",
      "Seen so far: 76480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1195: 0.6206415891647339\n",
      "Seen so far: 76544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1196: 0.6463025808334351\n",
      "Seen so far: 76608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1197: 1.1193807125091553\n",
      "Seen so far: 76672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1198: 1.1786136627197266\n",
      "Seen so far: 76736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1199: 1.132086992263794\n",
      "Seen so far: 76800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1200: 0.8785805702209473\n",
      "Seen so far: 76864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1201: 0.8415379524230957\n",
      "Seen so far: 76928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1202: 0.9393132925033569\n",
      "Seen so far: 76992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1203: 0.7035809755325317\n",
      "Seen so far: 77056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1204: 0.9246562719345093\n",
      "Seen so far: 77120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1205: 0.6803127527236938\n",
      "Seen so far: 77184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1206: 0.6725815534591675\n",
      "Seen so far: 77248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1207: 0.9482619166374207\n",
      "Seen so far: 77312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1208: 1.1401616334915161\n",
      "Seen so far: 77376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1209: 0.987684428691864\n",
      "Seen so far: 77440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1210: 0.7139567136764526\n",
      "Seen so far: 77504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1211: 0.7507144212722778\n",
      "Seen so far: 77568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1212: 0.6711757183074951\n",
      "Seen so far: 77632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1213: 0.8277236223220825\n",
      "Seen so far: 77696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1214: 1.3941712379455566\n",
      "Seen so far: 77760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1215: 0.36095130443573\n",
      "Seen so far: 77824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1216: 0.7409700155258179\n",
      "Seen so far: 77888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1217: 0.9143979549407959\n",
      "Seen so far: 77952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1218: 0.9105960130691528\n",
      "Seen so far: 78016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1219: 1.079955816268921\n",
      "Seen so far: 78080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1220: 0.7469666004180908\n",
      "Seen so far: 78144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1221: 0.7260205745697021\n",
      "Seen so far: 78208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1222: 0.8384287357330322\n",
      "Seen so far: 78272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1223: 0.7813903093338013\n",
      "Seen so far: 78336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1224: 0.5960537791252136\n",
      "Seen so far: 78400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1225: 1.0285260677337646\n",
      "Seen so far: 78464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1226: 0.8621097803115845\n",
      "Seen so far: 78528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1227: 0.8766645193099976\n",
      "Seen so far: 78592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1228: 0.8138893246650696\n",
      "Seen so far: 78656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1229: 0.9641355276107788\n",
      "Seen so far: 78720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1230: 0.9455021619796753\n",
      "Seen so far: 78784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1231: 0.7051466703414917\n",
      "Seen so far: 78848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1232: 0.9384564161300659\n",
      "Seen so far: 78912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1233: 0.8150737285614014\n",
      "Seen so far: 78976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1234: 0.9813442230224609\n",
      "Seen so far: 79040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1235: 0.6580012440681458\n",
      "Seen so far: 79104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1236: 0.8047198057174683\n",
      "Seen so far: 79168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1237: 0.8554775714874268\n",
      "Seen so far: 79232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1238: 1.0265644788742065\n",
      "Seen so far: 79296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1239: 0.6972543001174927\n",
      "Seen so far: 79360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1240: 0.9861592054367065\n",
      "Seen so far: 79424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1241: 0.9872866272926331\n",
      "Seen so far: 79488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1242: 0.8210622072219849\n",
      "Seen so far: 79552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1243: 1.0500307083129883\n",
      "Seen so far: 79616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1244: 0.7202034592628479\n",
      "Seen so far: 79680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1245: 0.9475108981132507\n",
      "Seen so far: 79744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1246: 0.7396913766860962\n",
      "Seen so far: 79808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1247: 0.5559282302856445\n",
      "Seen so far: 79872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1248: 0.7256247997283936\n",
      "Seen so far: 79936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1249: 1.017052412033081\n",
      "Seen so far: 80000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1250: 0.7550117373466492\n",
      "Seen so far: 80064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1251: 0.45118072628974915\n",
      "Seen so far: 80128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1252: 0.9784820675849915\n",
      "Seen so far: 80192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1253: 0.642288088798523\n",
      "Seen so far: 80256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1254: 0.798701286315918\n",
      "Seen so far: 80320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1255: 0.6695574522018433\n",
      "Seen so far: 80384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1256: 1.169416904449463\n",
      "Seen so far: 80448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1257: 0.9675078988075256\n",
      "Seen so far: 80512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1258: 0.5856016874313354\n",
      "Seen so far: 80576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1259: 0.6119447946548462\n",
      "Seen so far: 80640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1260: 0.567803680896759\n",
      "Seen so far: 80704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1261: 0.5238566994667053\n",
      "Seen so far: 80768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1262: 0.8098349571228027\n",
      "Seen so far: 80832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1263: 0.5854803323745728\n",
      "Seen so far: 80896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1264: 0.9099414944648743\n",
      "Seen so far: 80960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1265: 0.866652250289917\n",
      "Seen so far: 81024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1266: 0.4969576597213745\n",
      "Seen so far: 81088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1267: 0.7038397789001465\n",
      "Seen so far: 81152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1268: 0.7107806205749512\n",
      "Seen so far: 81216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1269: 0.8697183132171631\n",
      "Seen so far: 81280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1270: 1.2279175519943237\n",
      "Seen so far: 81344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1271: 0.6507083773612976\n",
      "Seen so far: 81408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1272: 0.9976942539215088\n",
      "Seen so far: 81472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1273: 1.0157299041748047\n",
      "Seen so far: 81536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1274: 0.6200374960899353\n",
      "Seen so far: 81600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1275: 0.7859654426574707\n",
      "Seen so far: 81664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1276: 0.5097846984863281\n",
      "Seen so far: 81728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1277: 0.848128080368042\n",
      "Seen so far: 81792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1278: 1.0804708003997803\n",
      "Seen so far: 81856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1279: 1.013622522354126\n",
      "Seen so far: 81920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1280: 1.0255540609359741\n",
      "Seen so far: 81984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1281: 0.6286301612854004\n",
      "Seen so far: 82048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1282: 0.7672843933105469\n",
      "Seen so far: 82112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1283: 0.6848644018173218\n",
      "Seen so far: 82176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1284: 1.0731709003448486\n",
      "Seen so far: 82240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1285: 0.9748783111572266\n",
      "Seen so far: 82304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1286: 0.6503154635429382\n",
      "Seen so far: 82368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1287: 0.7674217224121094\n",
      "Seen so far: 82432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1288: 0.6551823616027832\n",
      "Seen so far: 82496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1289: 0.8965688347816467\n",
      "Seen so far: 82560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1290: 0.46969175338745117\n",
      "Seen so far: 82624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1291: 1.0826244354248047\n",
      "Seen so far: 82688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1292: 0.31262487173080444\n",
      "Seen so far: 82752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1293: 0.8653509616851807\n",
      "Seen so far: 82816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1294: 0.9110559225082397\n",
      "Seen so far: 82880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1295: 0.7359086275100708\n",
      "Seen so far: 82944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1296: 0.4564545154571533\n",
      "Seen so far: 83008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1297: 0.8964670896530151\n",
      "Seen so far: 83072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1298: 0.5933007001876831\n",
      "Seen so far: 83136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1299: 0.748383641242981\n",
      "Seen so far: 83200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1300: 1.0669779777526855\n",
      "Seen so far: 83264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1301: 0.6728203296661377\n",
      "Seen so far: 83328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1302: 0.8523893356323242\n",
      "Seen so far: 83392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1303: 0.9338570833206177\n",
      "Seen so far: 83456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1304: 0.5049392580986023\n",
      "Seen so far: 83520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1305: 0.7311339378356934\n",
      "Seen so far: 83584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1306: 0.849449634552002\n",
      "Seen so far: 83648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1307: 0.6326195597648621\n",
      "Seen so far: 83712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1308: 0.7807619571685791\n",
      "Seen so far: 83776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1309: 0.5995799899101257\n",
      "Seen so far: 83840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1310: 0.5756406784057617\n",
      "Seen so far: 83904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1311: 0.669124960899353\n",
      "Seen so far: 83968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1312: 0.6636313796043396\n",
      "Seen so far: 84032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1313: 0.7509793043136597\n",
      "Seen so far: 84096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1314: 0.6450451612472534\n",
      "Seen so far: 84160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1315: 0.9585167765617371\n",
      "Seen so far: 84224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1316: 0.8812738656997681\n",
      "Seen so far: 84288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1317: 1.2019777297973633\n",
      "Seen so far: 84352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1318: 0.7475677132606506\n",
      "Seen so far: 84416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1319: 0.896014392375946\n",
      "Seen so far: 84480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1320: 0.9737445712089539\n",
      "Seen so far: 84544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1321: 1.2126367092132568\n",
      "Seen so far: 84608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1322: 0.7275274991989136\n",
      "Seen so far: 84672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1323: 0.6999268531799316\n",
      "Seen so far: 84736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1324: 0.7000256776809692\n",
      "Seen so far: 84800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1325: 0.8768215179443359\n",
      "Seen so far: 84864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1326: 0.8580891489982605\n",
      "Seen so far: 84928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1327: 0.7177022695541382\n",
      "Seen so far: 84992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1328: 1.010679006576538\n",
      "Seen so far: 85056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1329: 0.7170090675354004\n",
      "Seen so far: 85120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1330: 0.6344716548919678\n",
      "Seen so far: 85184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1331: 0.9857757091522217\n",
      "Seen so far: 85248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1332: 0.8527249097824097\n",
      "Seen so far: 85312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1333: 1.1018893718719482\n",
      "Seen so far: 85376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1334: 0.9688714742660522\n",
      "Seen so far: 85440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1335: 0.8452144265174866\n",
      "Seen so far: 85504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1336: 0.7359659075737\n",
      "Seen so far: 85568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1337: 0.6746256947517395\n",
      "Seen so far: 85632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1338: 1.091989517211914\n",
      "Seen so far: 85696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1339: 0.807852029800415\n",
      "Seen so far: 85760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1340: 1.4375905990600586\n",
      "Seen so far: 85824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1341: 1.0417333841323853\n",
      "Seen so far: 85888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1342: 0.6375757455825806\n",
      "Seen so far: 85952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1343: 0.9051086902618408\n",
      "Seen so far: 86016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1344: 1.071310043334961\n",
      "Seen so far: 86080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1345: 0.6884920001029968\n",
      "Seen so far: 86144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1346: 1.057807207107544\n",
      "Seen so far: 86208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1347: 0.6272218227386475\n",
      "Seen so far: 86272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1348: 1.0409021377563477\n",
      "Seen so far: 86336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1349: 1.1400938034057617\n",
      "Seen so far: 86400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1350: 1.0262340307235718\n",
      "Seen so far: 86464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1351: 0.5539628267288208\n",
      "Seen so far: 86528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1352: 1.2840726375579834\n",
      "Seen so far: 86592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1353: 0.5639098286628723\n",
      "Seen so far: 86656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1354: 1.3752928972244263\n",
      "Seen so far: 86720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1355: 0.9030404090881348\n",
      "Seen so far: 86784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1356: 0.691725492477417\n",
      "Seen so far: 86848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1357: 1.072941541671753\n",
      "Seen so far: 86912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1358: 0.7801403999328613\n",
      "Seen so far: 86976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1359: 0.7834880352020264\n",
      "Seen so far: 87040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1360: 0.8951112031936646\n",
      "Seen so far: 87104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1361: 0.641384482383728\n",
      "Seen so far: 87168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1362: 0.7563226819038391\n",
      "Seen so far: 87232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1363: 0.8416234254837036\n",
      "Seen so far: 87296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1364: 0.9488242864608765\n",
      "Seen so far: 87360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1365: 0.8261448740959167\n",
      "Seen so far: 87424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1366: 1.0215753316879272\n",
      "Seen so far: 87488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1367: 1.272007703781128\n",
      "Seen so far: 87552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1368: 0.8926906585693359\n",
      "Seen so far: 87616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1369: 0.6313728094100952\n",
      "Seen so far: 87680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1370: 0.7360118627548218\n",
      "Seen so far: 87744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1371: 0.6879069805145264\n",
      "Seen so far: 87808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1372: 1.0857502222061157\n",
      "Seen so far: 87872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1373: 0.7952995300292969\n",
      "Seen so far: 87936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1374: 0.8268661499023438\n",
      "Seen so far: 88000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1375: 0.9463990926742554\n",
      "Seen so far: 88064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1376: 1.2383716106414795\n",
      "Seen so far: 88128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1377: 1.0260815620422363\n",
      "Seen so far: 88192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1378: 1.0455255508422852\n",
      "Seen so far: 88256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1379: 0.9279937744140625\n",
      "Seen so far: 88320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1380: 1.006873607635498\n",
      "Seen so far: 88384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1381: 0.6958524584770203\n",
      "Seen so far: 88448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1382: 0.8265329003334045\n",
      "Seen so far: 88512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1383: 1.0009326934814453\n",
      "Seen so far: 88576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1384: 0.5365391373634338\n",
      "Seen so far: 88640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1385: 0.6774673461914062\n",
      "Seen so far: 88704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1386: 0.8923341035842896\n",
      "Seen so far: 88768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1387: 0.9394505023956299\n",
      "Seen so far: 88832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1388: 1.07157564163208\n",
      "Seen so far: 88896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1389: 0.623746395111084\n",
      "Seen so far: 88960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1390: 0.878305196762085\n",
      "Seen so far: 89024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1391: 1.2544777393341064\n",
      "Seen so far: 89088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1392: 0.9792095422744751\n",
      "Seen so far: 89152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1393: 1.34920334815979\n",
      "Seen so far: 89216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1394: 0.6946716904640198\n",
      "Seen so far: 89280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1395: 0.8110413551330566\n",
      "Seen so far: 89344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1396: 1.0022941827774048\n",
      "Seen so far: 89408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1397: 0.8409117460250854\n",
      "Seen so far: 89472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1398: 0.8581427931785583\n",
      "Seen so far: 89536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1399: 1.129314661026001\n",
      "Seen so far: 89600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1400: 0.9235486388206482\n",
      "Seen so far: 89664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1401: 0.7091425657272339\n",
      "Seen so far: 89728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1402: 0.8466726541519165\n",
      "Seen so far: 89792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1403: 0.928504467010498\n",
      "Seen so far: 89856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1404: 0.5457572340965271\n",
      "Seen so far: 89920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1405: 0.5985158085823059\n",
      "Seen so far: 89984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1406: 1.32038152217865\n",
      "Seen so far: 90048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1407: 0.5611901879310608\n",
      "Seen so far: 90112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1408: 0.7051250338554382\n",
      "Seen so far: 90176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1409: 0.785953164100647\n",
      "Seen so far: 90240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1410: 0.9475131034851074\n",
      "Seen so far: 90304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1411: 0.9711387157440186\n",
      "Seen so far: 90368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1412: 0.987213671207428\n",
      "Seen so far: 90432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1413: 0.95366370677948\n",
      "Seen so far: 90496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1414: 0.6592744588851929\n",
      "Seen so far: 90560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1415: 0.6821490526199341\n",
      "Seen so far: 90624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1416: 0.8776296377182007\n",
      "Seen so far: 90688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1417: 0.9440292716026306\n",
      "Seen so far: 90752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1418: 0.8309564590454102\n",
      "Seen so far: 90816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1419: 0.962804913520813\n",
      "Seen so far: 90880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1420: 0.6207570433616638\n",
      "Seen so far: 90944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1421: 0.4817243218421936\n",
      "Seen so far: 91008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1422: 0.8765096664428711\n",
      "Seen so far: 91072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1423: 0.9420998096466064\n",
      "Seen so far: 91136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1424: 0.7925232648849487\n",
      "Seen so far: 91200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1425: 0.4708758592605591\n",
      "Seen so far: 91264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1426: 0.72493976354599\n",
      "Seen so far: 91328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1427: 0.8492118120193481\n",
      "Seen so far: 91392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1428: 1.001835584640503\n",
      "Seen so far: 91456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1429: 0.747162938117981\n",
      "Seen so far: 91520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1430: 0.6961467266082764\n",
      "Seen so far: 91584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1431: 1.0064990520477295\n",
      "Seen so far: 91648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1432: 0.4225999414920807\n",
      "Seen so far: 91712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1433: 0.795755922794342\n",
      "Seen so far: 91776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1434: 0.5175967216491699\n",
      "Seen so far: 91840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1435: 0.8733319044113159\n",
      "Seen so far: 91904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1436: 0.8277547359466553\n",
      "Seen so far: 91968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1437: 0.7162454724311829\n",
      "Seen so far: 92032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1438: 0.9960694909095764\n",
      "Seen so far: 92096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1439: 0.9226563572883606\n",
      "Seen so far: 92160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1440: 0.8618260622024536\n",
      "Seen so far: 92224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1441: 0.7288839817047119\n",
      "Seen so far: 92288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1442: 1.2103030681610107\n",
      "Seen so far: 92352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1443: 1.0643428564071655\n",
      "Seen so far: 92416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1444: 1.2312378883361816\n",
      "Seen so far: 92480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1445: 0.9928848743438721\n",
      "Seen so far: 92544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1446: 0.7532988786697388\n",
      "Seen so far: 92608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1447: 0.4956612288951874\n",
      "Seen so far: 92672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1448: 0.5286997556686401\n",
      "Seen so far: 92736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1449: 1.1646946668624878\n",
      "Seen so far: 92800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1450: 0.48416686058044434\n",
      "Seen so far: 92864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1451: 1.042517066001892\n",
      "Seen so far: 92928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1452: 0.5308833122253418\n",
      "Seen so far: 92992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1453: 1.13847017288208\n",
      "Seen so far: 93056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1454: 0.6724675893783569\n",
      "Seen so far: 93120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1455: 1.1173654794692993\n",
      "Seen so far: 93184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1456: 0.7204943299293518\n",
      "Seen so far: 93248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1457: 1.0316286087036133\n",
      "Seen so far: 93312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1458: 1.0257431268692017\n",
      "Seen so far: 93376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1459: 0.9429803490638733\n",
      "Seen so far: 93440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1460: 0.9427149295806885\n",
      "Seen so far: 93504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1461: 0.7407220005989075\n",
      "Seen so far: 93568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1462: 0.9473393559455872\n",
      "Seen so far: 93632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1463: 1.0286903381347656\n",
      "Seen so far: 93696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1464: 0.5319019556045532\n",
      "Seen so far: 93760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1465: 0.9013705253601074\n",
      "Seen so far: 93824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1466: 0.7707878947257996\n",
      "Seen so far: 93888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1467: 0.6770464181900024\n",
      "Seen so far: 93952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1468: 0.8301641345024109\n",
      "Seen so far: 94016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1469: 0.6532084941864014\n",
      "Seen so far: 94080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1470: 1.1445655822753906\n",
      "Seen so far: 94144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1471: 0.44333186745643616\n",
      "Seen so far: 94208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1472: 0.9132490158081055\n",
      "Seen so far: 94272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1473: 0.8496671915054321\n",
      "Seen so far: 94336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1474: 0.5932034850120544\n",
      "Seen so far: 94400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1475: 1.1910312175750732\n",
      "Seen so far: 94464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1476: 0.44865596294403076\n",
      "Seen so far: 94528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1477: 0.5720608234405518\n",
      "Seen so far: 94592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1478: 1.260521411895752\n",
      "Seen so far: 94656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1479: 0.8820044994354248\n",
      "Seen so far: 94720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1480: 0.7766426205635071\n",
      "Seen so far: 94784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1481: 1.012109637260437\n",
      "Seen so far: 94848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1482: 0.5111732482910156\n",
      "Seen so far: 94912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1483: 1.0552034378051758\n",
      "Seen so far: 94976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1484: 0.6742973327636719\n",
      "Seen so far: 95040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1485: 0.72205650806427\n",
      "Seen so far: 95104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1486: 0.5449485182762146\n",
      "Seen so far: 95168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1487: 0.5404256582260132\n",
      "Seen so far: 95232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1488: 0.8330647945404053\n",
      "Seen so far: 95296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1489: 0.7501356601715088\n",
      "Seen so far: 95360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1490: 0.6525701284408569\n",
      "Seen so far: 95424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1491: 0.6077073812484741\n",
      "Seen so far: 95488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1492: 0.8493331670761108\n",
      "Seen so far: 95552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1493: 0.793968915939331\n",
      "Seen so far: 95616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1494: 0.8650308847427368\n",
      "Seen so far: 95680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1495: 1.306249976158142\n",
      "Seen so far: 95744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1496: 0.7794581651687622\n",
      "Seen so far: 95808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1497: 1.0755362510681152\n",
      "Seen so far: 95872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1498: 0.6563030481338501\n",
      "Seen so far: 95936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1499: 0.8305273652076721\n",
      "Seen so far: 96000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1500: 0.7349255681037903\n",
      "Seen so far: 96064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1501: 1.218299150466919\n",
      "Seen so far: 96128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1502: 0.8953424096107483\n",
      "Seen so far: 96192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1503: 0.40002626180648804\n",
      "Seen so far: 96256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1504: 0.8197095394134521\n",
      "Seen so far: 96320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1505: 1.062779188156128\n",
      "Seen so far: 96384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1506: 0.5378466248512268\n",
      "Seen so far: 96448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1507: 1.6461076736450195\n",
      "Seen so far: 96512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1508: 0.5996973514556885\n",
      "Seen so far: 96576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1509: 1.1833335161209106\n",
      "Seen so far: 96640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1510: 1.635291576385498\n",
      "Seen so far: 96704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1511: 0.8309539556503296\n",
      "Seen so far: 96768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1512: 0.8263841867446899\n",
      "Seen so far: 96832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1513: 0.9157460927963257\n",
      "Seen so far: 96896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1514: 0.9592008590698242\n",
      "Seen so far: 96960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1515: 1.341073751449585\n",
      "Seen so far: 97024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1516: 0.7717384696006775\n",
      "Seen so far: 97088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1517: 1.4764479398727417\n",
      "Seen so far: 97152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1518: 0.9709540009498596\n",
      "Seen so far: 97216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1519: 0.6077836155891418\n",
      "Seen so far: 97280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1520: 0.7327879071235657\n",
      "Seen so far: 97344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1521: 0.7767589092254639\n",
      "Seen so far: 97408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1522: 0.9594317674636841\n",
      "Seen so far: 97472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1523: 1.0611090660095215\n",
      "Seen so far: 97536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1524: 0.984700620174408\n",
      "Seen so far: 97600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1525: 1.154404878616333\n",
      "Seen so far: 97664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1526: 1.1590170860290527\n",
      "Seen so far: 97728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1527: 0.7278122901916504\n",
      "Seen so far: 97792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1528: 0.47823435068130493\n",
      "Seen so far: 97856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1529: 0.7128835916519165\n",
      "Seen so far: 97920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1530: 0.7182416915893555\n",
      "Seen so far: 97984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1531: 0.4244392216205597\n",
      "Seen so far: 98048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1532: 0.8956423997879028\n",
      "Seen so far: 98112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1533: 0.6487451195716858\n",
      "Seen so far: 98176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1534: 0.9106093645095825\n",
      "Seen so far: 98240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1535: 0.6417373418807983\n",
      "Seen so far: 98304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1536: 0.7457338571548462\n",
      "Seen so far: 98368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1537: 0.8111820220947266\n",
      "Seen so far: 98432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1538: 0.924904465675354\n",
      "Seen so far: 98496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1539: 0.6187714338302612\n",
      "Seen so far: 98560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1540: 0.5945380926132202\n",
      "Seen so far: 98624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1541: 0.4816623330116272\n",
      "Seen so far: 98688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1542: 0.7744216918945312\n",
      "Seen so far: 98752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1543: 0.9665941596031189\n",
      "Seen so far: 98816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1544: 0.5395283699035645\n",
      "Seen so far: 98880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1545: 0.5496014356613159\n",
      "Seen so far: 98944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1546: 0.8512560725212097\n",
      "Seen so far: 99008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1547: 0.8870437741279602\n",
      "Seen so far: 99072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1548: 0.7767019867897034\n",
      "Seen so far: 99136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1549: 0.6978441476821899\n",
      "Seen so far: 99200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1550: 0.8812012672424316\n",
      "Seen so far: 99264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1551: 1.1795661449432373\n",
      "Seen so far: 99328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1552: 0.6300305724143982\n",
      "Seen so far: 99392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1553: 0.5113195776939392\n",
      "Seen so far: 99456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1554: 1.172878623008728\n",
      "Seen so far: 99520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1555: 0.9278966188430786\n",
      "Seen so far: 99584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1556: 1.0934054851531982\n",
      "Seen so far: 99648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1557: 1.0464167594909668\n",
      "Seen so far: 99712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1558: 0.7749358415603638\n",
      "Seen so far: 99776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1559: 0.5111973285675049\n",
      "Seen so far: 99840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1560: 1.32076895236969\n",
      "Seen so far: 99904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1561: 0.811397910118103\n",
      "Seen so far: 99968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1562: 0.8912769556045532\n",
      "Seen so far: 100032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1563: 0.7643742561340332\n",
      "Seen so far: 100096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1564: 0.989506721496582\n",
      "Seen so far: 100160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1565: 1.0039958953857422\n",
      "Seen so far: 100224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1566: 0.8773951530456543\n",
      "Seen so far: 100288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1567: 0.5724043846130371\n",
      "Seen so far: 100352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1568: 0.7275221347808838\n",
      "Seen so far: 100416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1569: 0.6688578128814697\n",
      "Seen so far: 100480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1570: 1.1326260566711426\n",
      "Seen so far: 100544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1571: 1.1051461696624756\n",
      "Seen so far: 100608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1572: 0.49389684200286865\n",
      "Seen so far: 100672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1573: 1.2017977237701416\n",
      "Seen so far: 100736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1574: 0.7541705369949341\n",
      "Seen so far: 100800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1575: 0.9403687119483948\n",
      "Seen so far: 100864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1576: 0.7755208015441895\n",
      "Seen so far: 100928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1577: 0.6917561292648315\n",
      "Seen so far: 100992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1578: 0.9638228416442871\n",
      "Seen so far: 101056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1579: 0.5942571759223938\n",
      "Seen so far: 101120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1580: 0.8289117813110352\n",
      "Seen so far: 101184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1581: 0.7906521558761597\n",
      "Seen so far: 101248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1582: 0.97867751121521\n",
      "Seen so far: 101312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1583: 0.7808467149734497\n",
      "Seen so far: 101376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1584: 0.8318139910697937\n",
      "Seen so far: 101440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1585: 1.3790569305419922\n",
      "Seen so far: 101504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1586: 0.7191423177719116\n",
      "Seen so far: 101568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1587: 0.5968896150588989\n",
      "Seen so far: 101632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1588: 0.5812419652938843\n",
      "Seen so far: 101696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1589: 0.8653231859207153\n",
      "Seen so far: 101760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1590: 0.8048960566520691\n",
      "Seen so far: 101824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1591: 0.8315079212188721\n",
      "Seen so far: 101888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1592: 0.8139896988868713\n",
      "Seen so far: 101952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1593: 0.6917116045951843\n",
      "Seen so far: 102016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1594: 0.560264527797699\n",
      "Seen so far: 102080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1595: 1.0371652841567993\n",
      "Seen so far: 102144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1596: 0.716262936592102\n",
      "Seen so far: 102208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1597: 0.8647300004959106\n",
      "Seen so far: 102272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1598: 0.7437609434127808\n",
      "Seen so far: 102336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1599: 0.7820320129394531\n",
      "Seen so far: 102400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1600: 0.34345418214797974\n",
      "Seen so far: 102464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1601: 0.7503151893615723\n",
      "Seen so far: 102528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1602: 0.47512200474739075\n",
      "Seen so far: 102592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1603: 1.260056734085083\n",
      "Seen so far: 102656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1604: 0.6527593731880188\n",
      "Seen so far: 102720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1605: 1.5438461303710938\n",
      "Seen so far: 102784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1606: 0.988300085067749\n",
      "Seen so far: 102848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1607: 0.789475679397583\n",
      "Seen so far: 102912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1608: 0.7823418378829956\n",
      "Seen so far: 102976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1609: 0.9240418672561646\n",
      "Seen so far: 103040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1610: 0.9845940470695496\n",
      "Seen so far: 103104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1611: 0.8892033696174622\n",
      "Seen so far: 103168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1612: 0.9387238621711731\n",
      "Seen so far: 103232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1613: 1.0416514873504639\n",
      "Seen so far: 103296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1614: 0.6952484250068665\n",
      "Seen so far: 103360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1615: 0.7772934436798096\n",
      "Seen so far: 103424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1616: 0.7606601715087891\n",
      "Seen so far: 103488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1617: 0.8957078456878662\n",
      "Seen so far: 103552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1618: 0.6346340179443359\n",
      "Seen so far: 103616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1619: 0.8870104551315308\n",
      "Seen so far: 103680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1620: 0.7279821038246155\n",
      "Seen so far: 103744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1621: 0.6197229027748108\n",
      "Seen so far: 103808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1622: 0.7892873883247375\n",
      "Seen so far: 103872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1623: 0.9855678677558899\n",
      "Seen so far: 103936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1624: 0.6970576047897339\n",
      "Seen so far: 104000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1625: 1.2582896947860718\n",
      "Seen so far: 104064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1626: 0.8692321181297302\n",
      "Seen so far: 104128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1627: 0.7189978361129761\n",
      "Seen so far: 104192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1628: 0.7665059566497803\n",
      "Seen so far: 104256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1629: 0.6045382022857666\n",
      "Seen so far: 104320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1630: 1.0111985206604004\n",
      "Seen so far: 104384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1631: 0.796040415763855\n",
      "Seen so far: 104448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1632: 1.090710163116455\n",
      "Seen so far: 104512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1633: 0.8530111312866211\n",
      "Seen so far: 104576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1634: 1.0618484020233154\n",
      "Seen so far: 104640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1635: 0.8387914299964905\n",
      "Seen so far: 104704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1636: 0.8131117224693298\n",
      "Seen so far: 104768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1637: 0.49671074748039246\n",
      "Seen so far: 104832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1638: 0.9734533429145813\n",
      "Seen so far: 104896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1639: 0.6662801504135132\n",
      "Seen so far: 104960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1640: 0.8560168147087097\n",
      "Seen so far: 105024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1641: 0.6862103939056396\n",
      "Seen so far: 105088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1642: 0.8857752680778503\n",
      "Seen so far: 105152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1643: 1.3394825458526611\n",
      "Seen so far: 105216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1644: 0.8226966261863708\n",
      "Seen so far: 105280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1645: 1.072636365890503\n",
      "Seen so far: 105344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1646: 0.7794677019119263\n",
      "Seen so far: 105408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1647: 0.5906804800033569\n",
      "Seen so far: 105472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1648: 0.7596935629844666\n",
      "Seen so far: 105536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1649: 0.873853862285614\n",
      "Seen so far: 105600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1650: 0.7615984678268433\n",
      "Seen so far: 105664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1651: 1.0148732662200928\n",
      "Seen so far: 105728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1652: 0.6878513097763062\n",
      "Seen so far: 105792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1653: 0.6455942988395691\n",
      "Seen so far: 105856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1654: 0.8590435981750488\n",
      "Seen so far: 105920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1655: 0.7692025899887085\n",
      "Seen so far: 105984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1656: 0.5358914732933044\n",
      "Seen so far: 106048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1657: 0.8409821391105652\n",
      "Seen so far: 106112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1658: 0.5316076278686523\n",
      "Seen so far: 106176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1659: 0.9628866910934448\n",
      "Seen so far: 106240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1660: 0.8666328191757202\n",
      "Seen so far: 106304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1661: 0.893500804901123\n",
      "Seen so far: 106368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1662: 0.4902244806289673\n",
      "Seen so far: 106432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1663: 0.7409053444862366\n",
      "Seen so far: 106496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1664: 1.0442135334014893\n",
      "Seen so far: 106560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1665: 1.1961009502410889\n",
      "Seen so far: 106624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1666: 0.8147529363632202\n",
      "Seen so far: 106688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1667: 0.716381311416626\n",
      "Seen so far: 106752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1668: 1.05023992061615\n",
      "Seen so far: 106816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1669: 0.5608529448509216\n",
      "Seen so far: 106880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1670: 0.642833411693573\n",
      "Seen so far: 106944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1671: 0.8762912750244141\n",
      "Seen so far: 107008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1672: 0.9947758913040161\n",
      "Seen so far: 107072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1673: 0.5415295958518982\n",
      "Seen so far: 107136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1674: 0.6837860345840454\n",
      "Seen so far: 107200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1675: 1.1124796867370605\n",
      "Seen so far: 107264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1676: 0.6037116646766663\n",
      "Seen so far: 107328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1677: 0.7164950370788574\n",
      "Seen so far: 107392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1678: 0.7153036594390869\n",
      "Seen so far: 107456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1679: 0.8130465745925903\n",
      "Seen so far: 107520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1680: 1.0410728454589844\n",
      "Seen so far: 107584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1681: 1.34614896774292\n",
      "Seen so far: 107648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1682: 0.7221769690513611\n",
      "Seen so far: 107712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1683: 1.104574203491211\n",
      "Seen so far: 107776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1684: 0.8822078704833984\n",
      "Seen so far: 107840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1685: 0.8145467042922974\n",
      "Seen so far: 107904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1686: 1.1033865213394165\n",
      "Seen so far: 107968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1687: 1.0327013731002808\n",
      "Seen so far: 108032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1688: 1.073951005935669\n",
      "Seen so far: 108096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1689: 0.7321143746376038\n",
      "Seen so far: 108160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1690: 0.9501668214797974\n",
      "Seen so far: 108224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1691: 0.5711010694503784\n",
      "Seen so far: 108288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1692: 0.605927050113678\n",
      "Seen so far: 108352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1693: 1.0748534202575684\n",
      "Seen so far: 108416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1694: 0.8979717493057251\n",
      "Seen so far: 108480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1695: 0.8821326494216919\n",
      "Seen so far: 108544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1696: 1.0486226081848145\n",
      "Seen so far: 108608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1697: 1.0389171838760376\n",
      "Seen so far: 108672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1698: 0.4814322590827942\n",
      "Seen so far: 108736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1699: 0.5650569200515747\n",
      "Seen so far: 108800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1700: 0.6548819541931152\n",
      "Seen so far: 108864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1701: 0.8546102046966553\n",
      "Seen so far: 108928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1702: 1.0992952585220337\n",
      "Seen so far: 108992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1703: 0.6567094326019287\n",
      "Seen so far: 109056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1704: 1.065759539604187\n",
      "Seen so far: 109120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1705: 0.9791965484619141\n",
      "Seen so far: 109184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1706: 1.0495573282241821\n",
      "Seen so far: 109248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1707: 0.6439395546913147\n",
      "Seen so far: 109312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1708: 0.9071688652038574\n",
      "Seen so far: 109376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1709: 1.301023006439209\n",
      "Seen so far: 109440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1710: 0.7424975633621216\n",
      "Seen so far: 109504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1711: 0.5250861644744873\n",
      "Seen so far: 109568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1712: 0.6224184036254883\n",
      "Seen so far: 109632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1713: 0.4739316999912262\n",
      "Seen so far: 109696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1714: 0.8698053359985352\n",
      "Seen so far: 109760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1715: 0.5786640644073486\n",
      "Seen so far: 109824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1716: 1.0731092691421509\n",
      "Seen so far: 109888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1717: 0.6142208576202393\n",
      "Seen so far: 109952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1718: 0.8083134889602661\n",
      "Seen so far: 110016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1719: 0.6480101346969604\n",
      "Seen so far: 110080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1720: 0.9925814270973206\n",
      "Seen so far: 110144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1721: 1.010430097579956\n",
      "Seen so far: 110208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1722: 0.7714064717292786\n",
      "Seen so far: 110272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1723: 0.6037520170211792\n",
      "Seen so far: 110336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1724: 0.9186793565750122\n",
      "Seen so far: 110400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1725: 0.8660554885864258\n",
      "Seen so far: 110464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1726: 1.4466736316680908\n",
      "Seen so far: 110528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1727: 0.8147292137145996\n",
      "Seen so far: 110592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1728: 0.7487102746963501\n",
      "Seen so far: 110656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1729: 0.9124433994293213\n",
      "Seen so far: 110720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1730: 0.795951783657074\n",
      "Seen so far: 110784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1731: 0.6636899709701538\n",
      "Seen so far: 110848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1732: 1.0621707439422607\n",
      "Seen so far: 110912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1733: 1.1601593494415283\n",
      "Seen so far: 110976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1734: 0.7200034260749817\n",
      "Seen so far: 111040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1735: 0.7488583326339722\n",
      "Seen so far: 111104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1736: 0.7741774916648865\n",
      "Seen so far: 111168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1737: 0.9187200665473938\n",
      "Seen so far: 111232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1738: 0.749640166759491\n",
      "Seen so far: 111296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1739: 0.6453967094421387\n",
      "Seen so far: 111360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1740: 1.0632883310317993\n",
      "Seen so far: 111424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1741: 0.9735579490661621\n",
      "Seen so far: 111488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1742: 0.9199630618095398\n",
      "Seen so far: 111552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1743: 0.6413537263870239\n",
      "Seen so far: 111616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1744: 0.8159171342849731\n",
      "Seen so far: 111680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1745: 1.0083668231964111\n",
      "Seen so far: 111744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1746: 1.1420358419418335\n",
      "Seen so far: 111808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1747: 1.217597484588623\n",
      "Seen so far: 111872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1748: 0.7555001974105835\n",
      "Seen so far: 111936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1749: 0.6505725979804993\n",
      "Seen so far: 112000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1750: 0.8306479454040527\n",
      "Seen so far: 112064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1751: 0.9453443884849548\n",
      "Seen so far: 112128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1752: 1.0627256631851196\n",
      "Seen so far: 112192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1753: 1.2295010089874268\n",
      "Seen so far: 112256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1754: 1.1611725091934204\n",
      "Seen so far: 112320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1755: 0.8260213732719421\n",
      "Seen so far: 112384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1756: 1.3228819370269775\n",
      "Seen so far: 112448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1757: 0.6924657821655273\n",
      "Seen so far: 112512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1758: 1.1577675342559814\n",
      "Seen so far: 112576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1759: 0.6673938035964966\n",
      "Seen so far: 112640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1760: 0.8447256684303284\n",
      "Seen so far: 112704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1761: 0.9195349812507629\n",
      "Seen so far: 112768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1762: 0.9711896181106567\n",
      "Seen so far: 112832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1763: 0.9905515909194946\n",
      "Seen so far: 112896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1764: 0.9231905937194824\n",
      "Seen so far: 112960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1765: 0.46314263343811035\n",
      "Seen so far: 113024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1766: 0.7959708571434021\n",
      "Seen so far: 113088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1767: 0.8980442881584167\n",
      "Seen so far: 113152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1768: 1.0433781147003174\n",
      "Seen so far: 113216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1769: 0.6187664270401001\n",
      "Seen so far: 113280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1770: 0.6985247135162354\n",
      "Seen so far: 113344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1771: 0.969404935836792\n",
      "Seen so far: 113408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1772: 0.9574455618858337\n",
      "Seen so far: 113472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1773: 0.9115849137306213\n",
      "Seen so far: 113536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1774: 0.5725283622741699\n",
      "Seen so far: 113600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1775: 0.8997088074684143\n",
      "Seen so far: 113664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1776: 1.342923641204834\n",
      "Seen so far: 113728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1777: 0.9287497997283936\n",
      "Seen so far: 113792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1778: 0.787765622138977\n",
      "Seen so far: 113856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1779: 1.178389549255371\n",
      "Seen so far: 113920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1780: 1.1884841918945312\n",
      "Seen so far: 113984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1781: 1.0975388288497925\n",
      "Seen so far: 114048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1782: 0.42121511697769165\n",
      "Seen so far: 114112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1783: 0.9147549867630005\n",
      "Seen so far: 114176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1784: 0.9002854824066162\n",
      "Seen so far: 114240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1785: 0.7767032384872437\n",
      "Seen so far: 114304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1786: 0.969386100769043\n",
      "Seen so far: 114368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1787: 0.8257360458374023\n",
      "Seen so far: 114432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1788: 0.6325491070747375\n",
      "Seen so far: 114496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1789: 0.9142916798591614\n",
      "Seen so far: 114560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1790: 0.832004189491272\n",
      "Seen so far: 114624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1791: 0.6983542442321777\n",
      "Seen so far: 114688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1792: 0.4961460828781128\n",
      "Seen so far: 114752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1793: 0.9791659116744995\n",
      "Seen so far: 114816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1794: 0.6075908541679382\n",
      "Seen so far: 114880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1795: 0.7147090435028076\n",
      "Seen so far: 114944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1796: 0.7725328207015991\n",
      "Seen so far: 115008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1797: 0.4429200291633606\n",
      "Seen so far: 115072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1798: 0.6082303524017334\n",
      "Seen so far: 115136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1799: 0.6542781591415405\n",
      "Seen so far: 115200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1800: 0.8806717395782471\n",
      "Seen so far: 115264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1801: 0.6047676205635071\n",
      "Seen so far: 115328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1802: 0.5031636953353882\n",
      "Seen so far: 115392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1803: 0.9777752161026001\n",
      "Seen so far: 115456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1804: 0.5636193752288818\n",
      "Seen so far: 115520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1805: 0.5381094217300415\n",
      "Seen so far: 115584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1806: 0.6905020475387573\n",
      "Seen so far: 115648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1807: 0.7582793235778809\n",
      "Seen so far: 115712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1808: 1.0141897201538086\n",
      "Seen so far: 115776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1809: 0.7407646179199219\n",
      "Seen so far: 115840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1810: 0.710588812828064\n",
      "Seen so far: 115904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1811: 0.8478206396102905\n",
      "Seen so far: 115968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1812: 0.719673216342926\n",
      "Seen so far: 116032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1813: 1.0638285875320435\n",
      "Seen so far: 116096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1814: 0.8797757625579834\n",
      "Seen so far: 116160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1815: 1.3428020477294922\n",
      "Seen so far: 116224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1816: 0.7609273195266724\n",
      "Seen so far: 116288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1817: 0.7953287363052368\n",
      "Seen so far: 116352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1818: 0.78121417760849\n",
      "Seen so far: 116416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1819: 0.5385858416557312\n",
      "Seen so far: 116480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1820: 0.7344903945922852\n",
      "Seen so far: 116544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1821: 1.1521358489990234\n",
      "Seen so far: 116608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1822: 1.2383302450180054\n",
      "Seen so far: 116672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1823: 1.174105167388916\n",
      "Seen so far: 116736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1824: 1.0223901271820068\n",
      "Seen so far: 116800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1825: 0.632729172706604\n",
      "Seen so far: 116864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1826: 1.1490263938903809\n",
      "Seen so far: 116928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1827: 1.0089387893676758\n",
      "Seen so far: 116992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1828: 0.9986765384674072\n",
      "Seen so far: 117056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1829: 0.8170424699783325\n",
      "Seen so far: 117120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1830: 0.7616958022117615\n",
      "Seen so far: 117184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1831: 0.778225302696228\n",
      "Seen so far: 117248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1832: 1.1530046463012695\n",
      "Seen so far: 117312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1833: 0.7408126592636108\n",
      "Seen so far: 117376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1834: 1.1748106479644775\n",
      "Seen so far: 117440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1835: 0.6541200876235962\n",
      "Seen so far: 117504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1836: 0.8002235889434814\n",
      "Seen so far: 117568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1837: 0.5821738243103027\n",
      "Seen so far: 117632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1838: 0.9965953826904297\n",
      "Seen so far: 117696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1839: 0.6746247410774231\n",
      "Seen so far: 117760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1840: 1.306915521621704\n",
      "Seen so far: 117824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1841: 0.805596649646759\n",
      "Seen so far: 117888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1842: 0.5670011043548584\n",
      "Seen so far: 117952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1843: 0.9355175495147705\n",
      "Seen so far: 118016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1844: 0.8733030557632446\n",
      "Seen so far: 118080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1845: 0.9456994533538818\n",
      "Seen so far: 118144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1846: 0.9110214114189148\n",
      "Seen so far: 118208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1847: 0.8875311017036438\n",
      "Seen so far: 118272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1848: 0.8076741099357605\n",
      "Seen so far: 118336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1849: 1.2126121520996094\n",
      "Seen so far: 118400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1850: 0.5743986368179321\n",
      "Seen so far: 118464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1851: 1.1439805030822754\n",
      "Seen so far: 118528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1852: 0.947006344795227\n",
      "Seen so far: 118592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1853: 0.5031453967094421\n",
      "Seen so far: 118656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1854: 1.0397253036499023\n",
      "Seen so far: 118720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1855: 1.1974618434906006\n",
      "Seen so far: 118784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1856: 0.7656200528144836\n",
      "Seen so far: 118848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1857: 0.5611586570739746\n",
      "Seen so far: 118912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1858: 0.9645219445228577\n",
      "Seen so far: 118976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1859: 0.560276985168457\n",
      "Seen so far: 119040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1860: 0.6348356008529663\n",
      "Seen so far: 119104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1861: 0.9263637661933899\n",
      "Seen so far: 119168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1862: 0.7302206754684448\n",
      "Seen so far: 119232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1863: 0.659837007522583\n",
      "Seen so far: 119296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1864: 0.7380445599555969\n",
      "Seen so far: 119360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1865: 0.780794620513916\n",
      "Seen so far: 119424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1866: 0.879876971244812\n",
      "Seen so far: 119488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1867: 0.7618976831436157\n",
      "Seen so far: 119552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1868: 0.5752177834510803\n",
      "Seen so far: 119616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1869: 0.5594425201416016\n",
      "Seen so far: 119680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1870: 0.5418816804885864\n",
      "Seen so far: 119744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1871: 0.7704367637634277\n",
      "Seen so far: 119808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1872: 0.7417075037956238\n",
      "Seen so far: 119872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1873: 0.9886261224746704\n",
      "Seen so far: 119936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1874: 0.8733286261558533\n",
      "Seen so far: 120000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1875: 0.7090156078338623\n",
      "Seen so far: 120064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1876: 0.6666288375854492\n",
      "Seen so far: 120128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1877: 0.5492082834243774\n",
      "Seen so far: 120192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1878: 0.8619398474693298\n",
      "Seen so far: 120256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1879: 0.7469024062156677\n",
      "Seen so far: 120320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1880: 0.8671853542327881\n",
      "Seen so far: 120384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1881: 0.4936071038246155\n",
      "Seen so far: 120448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1882: 1.0320667028427124\n",
      "Seen so far: 120512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1883: 0.4597569406032562\n",
      "Seen so far: 120576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1884: 0.861396849155426\n",
      "Seen so far: 120640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1885: 0.8166130781173706\n",
      "Seen so far: 120704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1886: 0.7253651022911072\n",
      "Seen so far: 120768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1887: 0.7415473461151123\n",
      "Seen so far: 120832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1888: 0.4982065260410309\n",
      "Seen so far: 120896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1889: 1.0294309854507446\n",
      "Seen so far: 120960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1890: 1.383707046508789\n",
      "Seen so far: 121024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1891: 0.9893269538879395\n",
      "Seen so far: 121088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1892: 0.7747229337692261\n",
      "Seen so far: 121152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1893: 0.9143449068069458\n",
      "Seen so far: 121216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1894: 0.8422736525535583\n",
      "Seen so far: 121280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1895: 0.7204890251159668\n",
      "Seen so far: 121344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1896: 0.3710081875324249\n",
      "Seen so far: 121408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1897: 0.8867336511611938\n",
      "Seen so far: 121472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1898: 0.5888292193412781\n",
      "Seen so far: 121536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1899: 0.9512262344360352\n",
      "Seen so far: 121600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1900: 0.812483012676239\n",
      "Seen so far: 121664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1901: 0.6997648477554321\n",
      "Seen so far: 121728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1902: 1.2177759408950806\n",
      "Seen so far: 121792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1903: 0.8343250751495361\n",
      "Seen so far: 121856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1904: 0.9676064848899841\n",
      "Seen so far: 121920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1905: 0.7783123254776001\n",
      "Seen so far: 121984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1906: 0.6849733591079712\n",
      "Seen so far: 122048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1907: 1.003474235534668\n",
      "Seen so far: 122112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1908: 0.9475061893463135\n",
      "Seen so far: 122176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1909: 0.9775488972663879\n",
      "Seen so far: 122240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1910: 0.588691771030426\n",
      "Seen so far: 122304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1911: 0.7373937964439392\n",
      "Seen so far: 122368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1912: 1.0394818782806396\n",
      "Seen so far: 122432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1913: 0.7400014400482178\n",
      "Seen so far: 122496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1914: 0.7085769176483154\n",
      "Seen so far: 122560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1915: 0.7157111167907715\n",
      "Seen so far: 122624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1916: 0.7034261226654053\n",
      "Seen so far: 122688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1917: 0.9495781660079956\n",
      "Seen so far: 122752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1918: 0.9988073110580444\n",
      "Seen so far: 122816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1919: 0.8495901226997375\n",
      "Seen so far: 122880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1920: 1.005730390548706\n",
      "Seen so far: 122944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1921: 0.9866541624069214\n",
      "Seen so far: 123008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1922: 0.9306544065475464\n",
      "Seen so far: 123072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1923: 0.8035924434661865\n",
      "Seen so far: 123136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1924: 1.0188438892364502\n",
      "Seen so far: 123200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1925: 0.7502872347831726\n",
      "Seen so far: 123264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1926: 0.8598375916481018\n",
      "Seen so far: 123328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1927: 0.8252593278884888\n",
      "Seen so far: 123392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1928: 0.5289353132247925\n",
      "Seen so far: 123456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1929: 0.6368432641029358\n",
      "Seen so far: 123520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1930: 1.1484166383743286\n",
      "Seen so far: 123584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1931: 0.8874645233154297\n",
      "Seen so far: 123648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1932: 1.2719722986221313\n",
      "Seen so far: 123712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1933: 0.7978070974349976\n",
      "Seen so far: 123776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1934: 0.8891419768333435\n",
      "Seen so far: 123840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1935: 1.102187991142273\n",
      "Seen so far: 123904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1936: 1.0961835384368896\n",
      "Seen so far: 123968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1937: 0.8737225532531738\n",
      "Seen so far: 124032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1938: 0.627562403678894\n",
      "Seen so far: 124096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1939: 1.1482363939285278\n",
      "Seen so far: 124160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1940: 0.7865455150604248\n",
      "Seen so far: 124224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1941: 0.786720871925354\n",
      "Seen so far: 124288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1942: 0.7825945615768433\n",
      "Seen so far: 124352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1943: 0.5979258418083191\n",
      "Seen so far: 124416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1944: 1.0553218126296997\n",
      "Seen so far: 124480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1945: 0.8983566761016846\n",
      "Seen so far: 124544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1946: 0.8131744861602783\n",
      "Seen so far: 124608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1947: 0.5628263354301453\n",
      "Seen so far: 124672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1948: 1.036031723022461\n",
      "Seen so far: 124736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1949: 0.8343492746353149\n",
      "Seen so far: 124800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1950: 1.072153091430664\n",
      "Seen so far: 124864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1951: 0.6070103645324707\n",
      "Seen so far: 124928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1952: 0.343109130859375\n",
      "Seen so far: 124992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1953: 0.5459437370300293\n",
      "Seen so far: 125056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1954: 0.7361752390861511\n",
      "Seen so far: 125120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1955: 0.8474407196044922\n",
      "Seen so far: 125184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1956: 0.7657511234283447\n",
      "Seen so far: 125248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1957: 0.8446506261825562\n",
      "Seen so far: 125312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1958: 0.5326018333435059\n",
      "Seen so far: 125376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1959: 0.6041103005409241\n",
      "Seen so far: 125440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1960: 0.931219220161438\n",
      "Seen so far: 125504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1961: 0.7609513401985168\n",
      "Seen so far: 125568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1962: 0.6904503703117371\n",
      "Seen so far: 125632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1963: 0.850151002407074\n",
      "Seen so far: 125696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1964: 0.6844170689582825\n",
      "Seen so far: 125760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1965: 1.1935997009277344\n",
      "Seen so far: 125824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1966: 0.6946426630020142\n",
      "Seen so far: 125888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1967: 0.9113278388977051\n",
      "Seen so far: 125952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1968: 0.6172133684158325\n",
      "Seen so far: 126016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1969: 0.7733137607574463\n",
      "Seen so far: 126080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1970: 0.901495099067688\n",
      "Seen so far: 126144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1971: 0.7220262885093689\n",
      "Seen so far: 126208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1972: 0.7669195532798767\n",
      "Seen so far: 126272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1973: 0.9129111170768738\n",
      "Seen so far: 126336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1974: 0.826660692691803\n",
      "Seen so far: 126400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1975: 1.2095807790756226\n",
      "Seen so far: 126464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1976: 0.5016649961471558\n",
      "Seen so far: 126528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1977: 0.8130292296409607\n",
      "Seen so far: 126592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1978: 0.8795711994171143\n",
      "Seen so far: 126656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1979: 0.446353018283844\n",
      "Seen so far: 126720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1980: 0.965887188911438\n",
      "Seen so far: 126784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1981: 0.7266000509262085\n",
      "Seen so far: 126848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1982: 0.5116564631462097\n",
      "Seen so far: 126912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1983: 1.0285587310791016\n",
      "Seen so far: 126976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1984: 0.9925331473350525\n",
      "Seen so far: 127040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1985: 1.162581443786621\n",
      "Seen so far: 127104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1986: 0.4152277112007141\n",
      "Seen so far: 127168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1987: 1.0838594436645508\n",
      "Seen so far: 127232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1988: 1.1412501335144043\n",
      "Seen so far: 127296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1989: 0.7092475295066833\n",
      "Seen so far: 127360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1990: 0.9131896495819092\n",
      "Seen so far: 127424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1991: 1.200026273727417\n",
      "Seen so far: 127488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1992: 1.027694582939148\n",
      "Seen so far: 127552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1993: 0.7919767498970032\n",
      "Seen so far: 127616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1994: 1.0741442441940308\n",
      "Seen so far: 127680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1995: 0.5986598134040833\n",
      "Seen so far: 127744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1996: 0.9531543254852295\n",
      "Seen so far: 127808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1997: 0.9348882436752319\n",
      "Seen so far: 127872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1998: 0.8668255805969238\n",
      "Seen so far: 127936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1999: 0.6876572370529175\n",
      "Seen so far: 128000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2000: 0.6798643469810486\n",
      "Seen so far: 128064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2001: 0.7615799903869629\n",
      "Seen so far: 128128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2002: 1.0629727840423584\n",
      "Seen so far: 128192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2003: 0.48649537563323975\n",
      "Seen so far: 128256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2004: 0.9111151695251465\n",
      "Seen so far: 128320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2005: 0.7441911697387695\n",
      "Seen so far: 128384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2006: 1.1210273504257202\n",
      "Seen so far: 128448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2007: 0.5820732116699219\n",
      "Seen so far: 128512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2008: 0.7733678817749023\n",
      "Seen so far: 128576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2009: 0.9183689951896667\n",
      "Seen so far: 128640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2010: 1.1932775974273682\n",
      "Seen so far: 128704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2011: 0.9060967564582825\n",
      "Seen so far: 128768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2012: 0.7414321899414062\n",
      "Seen so far: 128832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2013: 0.7673131823539734\n",
      "Seen so far: 128896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2014: 0.7279424667358398\n",
      "Seen so far: 128960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2015: 0.7475310564041138\n",
      "Seen so far: 129024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2016: 0.529330849647522\n",
      "Seen so far: 129088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2017: 0.9474287629127502\n",
      "Seen so far: 129152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2018: 0.5534729957580566\n",
      "Seen so far: 129216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2019: 1.0437551736831665\n",
      "Seen so far: 129280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2020: 0.4515179395675659\n",
      "Seen so far: 129344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2021: 0.9712876677513123\n",
      "Seen so far: 129408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2022: 1.1053942441940308\n",
      "Seen so far: 129472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2023: 0.6890215277671814\n",
      "Seen so far: 129536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2024: 0.6072577834129333\n",
      "Seen so far: 129600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2025: 0.7706047296524048\n",
      "Seen so far: 129664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2026: 0.7612078189849854\n",
      "Seen so far: 129728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2027: 1.1885312795639038\n",
      "Seen so far: 129792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2028: 0.7172474265098572\n",
      "Seen so far: 129856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2029: 0.772197425365448\n",
      "Seen so far: 129920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2030: 1.0855374336242676\n",
      "Seen so far: 129984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2031: 1.100649118423462\n",
      "Seen so far: 130048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2032: 0.9818271398544312\n",
      "Seen so far: 130112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2033: 1.3101998567581177\n",
      "Seen so far: 130176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2034: 1.219975233078003\n",
      "Seen so far: 130240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2035: 0.6713989973068237\n",
      "Seen so far: 130304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2036: 0.6456680297851562\n",
      "Seen so far: 130368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2037: 0.6201348304748535\n",
      "Seen so far: 130432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2038: 0.9315809011459351\n",
      "Seen so far: 130496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2039: 0.8693596124649048\n",
      "Seen so far: 130560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2040: 0.6096712350845337\n",
      "Seen so far: 130624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2041: 0.6893134117126465\n",
      "Seen so far: 130688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2042: 0.7832462191581726\n",
      "Seen so far: 130752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2043: 0.8044365644454956\n",
      "Seen so far: 130816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2044: 0.7495986819267273\n",
      "Seen so far: 130880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2045: 0.7240362763404846\n",
      "Seen so far: 130944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2046: 0.7991570234298706\n",
      "Seen so far: 131008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2047: 0.57252037525177\n",
      "Seen so far: 131072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2048: 0.6136451959609985\n",
      "Seen so far: 131136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2049: 0.9816247224807739\n",
      "Seen so far: 131200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2050: 0.8048079609870911\n",
      "Seen so far: 131264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2051: 1.0076847076416016\n",
      "Seen so far: 131328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2052: 0.6851401329040527\n",
      "Seen so far: 131392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2053: 0.9361437559127808\n",
      "Seen so far: 131456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2054: 0.8556617498397827\n",
      "Seen so far: 131520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2055: 0.31594860553741455\n",
      "Seen so far: 131584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2056: 0.555370569229126\n",
      "Seen so far: 131648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2057: 0.7602171301841736\n",
      "Seen so far: 131712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2058: 0.7908709645271301\n",
      "Seen so far: 131776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2059: 1.0697202682495117\n",
      "Seen so far: 131840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2060: 0.8217808604240417\n",
      "Seen so far: 131904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2061: 1.0284068584442139\n",
      "Seen so far: 131968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2062: 0.9085925221443176\n",
      "Seen so far: 132032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2063: 0.7635397911071777\n",
      "Seen so far: 132096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2064: 0.839504063129425\n",
      "Seen so far: 132160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2065: 0.7314327955245972\n",
      "Seen so far: 132224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2066: 1.0024526119232178\n",
      "Seen so far: 132288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2067: 0.7405034303665161\n",
      "Seen so far: 132352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2068: 1.0735812187194824\n",
      "Seen so far: 132416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2069: 1.0316145420074463\n",
      "Seen so far: 132480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2070: 0.556777834892273\n",
      "Seen so far: 132544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2071: 0.5264959335327148\n",
      "Seen so far: 132608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2072: 1.1093199253082275\n",
      "Seen so far: 132672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2073: 0.7397056818008423\n",
      "Seen so far: 132736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2074: 0.75286865234375\n",
      "Seen so far: 132800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2075: 0.9113597869873047\n",
      "Seen so far: 132864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2076: 0.5468409061431885\n",
      "Seen so far: 132928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2077: 0.8817727565765381\n",
      "Seen so far: 132992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2078: 1.0101730823516846\n",
      "Seen so far: 133056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2079: 1.0867441892623901\n",
      "Seen so far: 133120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2080: 0.4165359139442444\n",
      "Seen so far: 133184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2081: 1.0203777551651\n",
      "Seen so far: 133248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2082: 0.6769292950630188\n",
      "Seen so far: 133312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2083: 0.6886464357376099\n",
      "Seen so far: 133376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2084: 0.6810418367385864\n",
      "Seen so far: 133440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2085: 0.401588499546051\n",
      "Seen so far: 133504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2086: 0.384499728679657\n",
      "Seen so far: 133568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2087: 0.912411093711853\n",
      "Seen so far: 133632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2088: 0.6893434524536133\n",
      "Seen so far: 133696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2089: 1.0487711429595947\n",
      "Seen so far: 133760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2090: 0.6118569374084473\n",
      "Seen so far: 133824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2091: 0.666320264339447\n",
      "Seen so far: 133888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2092: 0.6522489190101624\n",
      "Seen so far: 133952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2093: 0.5776294469833374\n",
      "Seen so far: 134016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2094: 0.8437886238098145\n",
      "Seen so far: 134080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2095: 1.046635389328003\n",
      "Seen so far: 134144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2096: 0.7293378114700317\n",
      "Seen so far: 134208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2097: 0.5309587717056274\n",
      "Seen so far: 134272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2098: 0.728769063949585\n",
      "Seen so far: 134336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2099: 0.6730490326881409\n",
      "Seen so far: 134400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2100: 0.8224949240684509\n",
      "Seen so far: 134464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2101: 0.43311595916748047\n",
      "Seen so far: 134528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2102: 0.9523698091506958\n",
      "Seen so far: 134592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2103: 0.6616616249084473\n",
      "Seen so far: 134656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2104: 0.6580684185028076\n",
      "Seen so far: 134720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2105: 0.5813714861869812\n",
      "Seen so far: 134784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2106: 0.745695948600769\n",
      "Seen so far: 134848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2107: 0.7498522996902466\n",
      "Seen so far: 134912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2108: 0.4552227556705475\n",
      "Seen so far: 134976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2109: 0.6093704104423523\n",
      "Seen so far: 135040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2110: 0.8892043828964233\n",
      "Seen so far: 135104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2111: 0.6833492517471313\n",
      "Seen so far: 135168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2112: 0.5788209438323975\n",
      "Seen so far: 135232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2113: 0.8982776403427124\n",
      "Seen so far: 135296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2114: 0.8046802282333374\n",
      "Seen so far: 135360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2115: 0.7764688730239868\n",
      "Seen so far: 135424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2116: 0.5192757844924927\n",
      "Seen so far: 135488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2117: 0.5179022550582886\n",
      "Seen so far: 135552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2118: 1.2625482082366943\n",
      "Seen so far: 135616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2119: 0.8234091997146606\n",
      "Seen so far: 135680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2120: 1.0345187187194824\n",
      "Seen so far: 135744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2121: 0.6485469341278076\n",
      "Seen so far: 135808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2122: 0.9025930166244507\n",
      "Seen so far: 135872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2123: 0.8259975910186768\n",
      "Seen so far: 135936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2124: 0.7303175330162048\n",
      "Seen so far: 136000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2125: 1.1543011665344238\n",
      "Seen so far: 136064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2126: 0.8480002880096436\n",
      "Seen so far: 136128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2127: 1.1410865783691406\n",
      "Seen so far: 136192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2128: 0.9162565469741821\n",
      "Seen so far: 136256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2129: 0.8632665872573853\n",
      "Seen so far: 136320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2130: 0.7695847749710083\n",
      "Seen so far: 136384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2131: 1.0088763236999512\n",
      "Seen so far: 136448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2132: 0.8038430213928223\n",
      "Seen so far: 136512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2133: 0.6042945384979248\n",
      "Seen so far: 136576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2134: 0.2729286849498749\n",
      "Seen so far: 136640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2135: 0.4099753201007843\n",
      "Seen so far: 136704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2136: 0.49779391288757324\n",
      "Seen so far: 136768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2137: 0.8703229427337646\n",
      "Seen so far: 136832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2138: 1.0083014965057373\n",
      "Seen so far: 136896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2139: 0.7812237739562988\n",
      "Seen so far: 136960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2140: 1.0295727252960205\n",
      "Seen so far: 137024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2141: 1.4519615173339844\n",
      "Seen so far: 137088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2142: 0.4938988983631134\n",
      "Seen so far: 137152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2143: 0.839424729347229\n",
      "Seen so far: 137216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2144: 0.7082656621932983\n",
      "Seen so far: 137280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2145: 1.0138421058654785\n",
      "Seen so far: 137344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2146: 1.2818818092346191\n",
      "Seen so far: 137408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2147: 0.5980420112609863\n",
      "Seen so far: 137472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2148: 0.845749020576477\n",
      "Seen so far: 137536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2149: 0.8886933922767639\n",
      "Seen so far: 137600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2150: 0.6236621141433716\n",
      "Seen so far: 137664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2151: 0.6277329921722412\n",
      "Seen so far: 137728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2152: 1.1748347282409668\n",
      "Seen so far: 137792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2153: 0.5670568943023682\n",
      "Seen so far: 137856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2154: 0.7903311252593994\n",
      "Seen so far: 137920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2155: 0.909579873085022\n",
      "Seen so far: 137984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2156: 0.8261497020721436\n",
      "Seen so far: 138048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2157: 0.3482610881328583\n",
      "Seen so far: 138112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2158: 0.6749953031539917\n",
      "Seen so far: 138176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2159: 0.43659645318984985\n",
      "Seen so far: 138240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2160: 1.0157841444015503\n",
      "Seen so far: 138304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2161: 0.6614905595779419\n",
      "Seen so far: 138368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2162: 0.6719655990600586\n",
      "Seen so far: 138432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2163: 0.5942965745925903\n",
      "Seen so far: 138496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2164: 1.1414698362350464\n",
      "Seen so far: 138560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2165: 0.7482531070709229\n",
      "Seen so far: 138624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2166: 0.6549347639083862\n",
      "Seen so far: 138688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2167: 0.8335221409797668\n",
      "Seen so far: 138752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2168: 0.6143121719360352\n",
      "Seen so far: 138816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2169: 0.5232424736022949\n",
      "Seen so far: 138880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2170: 0.9044536352157593\n",
      "Seen so far: 138944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2171: 0.8274129629135132\n",
      "Seen so far: 139008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2172: 0.4986307919025421\n",
      "Seen so far: 139072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2173: 0.7516718506813049\n",
      "Seen so far: 139136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2174: 1.218515396118164\n",
      "Seen so far: 139200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2175: 0.7253448963165283\n",
      "Seen so far: 139264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2176: 0.8543866276741028\n",
      "Seen so far: 139328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2177: 0.779319167137146\n",
      "Seen so far: 139392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2178: 0.4977387487888336\n",
      "Seen so far: 139456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2179: 0.448925256729126\n",
      "Seen so far: 139520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2180: 0.689998209476471\n",
      "Seen so far: 139584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2181: 0.9120204448699951\n",
      "Seen so far: 139648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2182: 0.9320204257965088\n",
      "Seen so far: 139712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2183: 0.5220222473144531\n",
      "Seen so far: 139776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2184: 0.9916872978210449\n",
      "Seen so far: 139840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2185: 0.6463519334793091\n",
      "Seen so far: 139904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2186: 0.7420074939727783\n",
      "Seen so far: 139968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2187: 0.7922536134719849\n",
      "Seen so far: 140032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2188: 0.3320024013519287\n",
      "Seen so far: 140096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2189: 0.7189318537712097\n",
      "Seen so far: 140160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2190: 0.7353506088256836\n",
      "Seen so far: 140224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2191: 0.6585489511489868\n",
      "Seen so far: 140288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2192: 0.5608105659484863\n",
      "Seen so far: 140352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2193: 0.6819746494293213\n",
      "Seen so far: 140416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2194: 0.4292614459991455\n",
      "Seen so far: 140480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2195: 0.9799935817718506\n",
      "Seen so far: 140544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2196: 0.5428587198257446\n",
      "Seen so far: 140608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2197: 0.586600661277771\n",
      "Seen so far: 140672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2198: 1.0095065832138062\n",
      "Seen so far: 140736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2199: 0.715859055519104\n",
      "Seen so far: 140800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2200: 1.0381139516830444\n",
      "Seen so far: 140864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2201: 0.8292253017425537\n",
      "Seen so far: 140928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2202: 0.7421916723251343\n",
      "Seen so far: 140992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2203: 1.0862877368927002\n",
      "Seen so far: 141056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2204: 0.5669541954994202\n",
      "Seen so far: 141120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2205: 0.5240445137023926\n",
      "Seen so far: 141184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2206: 1.1528947353363037\n",
      "Seen so far: 141248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2207: 0.7959977388381958\n",
      "Seen so far: 141312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2208: 1.8071054220199585\n",
      "Seen so far: 141376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2209: 0.917914628982544\n",
      "Seen so far: 141440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2210: 0.7584874629974365\n",
      "Seen so far: 141504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2211: 0.8105778694152832\n",
      "Seen so far: 141568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2212: 0.5830532908439636\n",
      "Seen so far: 141632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2213: 0.7230700850486755\n",
      "Seen so far: 141696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2214: 1.0126714706420898\n",
      "Seen so far: 141760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2215: 0.8609591722488403\n",
      "Seen so far: 141824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2216: 0.6998740434646606\n",
      "Seen so far: 141888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2217: 0.806388258934021\n",
      "Seen so far: 141952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2218: 0.8940670490264893\n",
      "Seen so far: 142016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2219: 0.912460446357727\n",
      "Seen so far: 142080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2220: 0.8981013894081116\n",
      "Seen so far: 142144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2221: 1.0424749851226807\n",
      "Seen so far: 142208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2222: 1.0722577571868896\n",
      "Seen so far: 142272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2223: 0.5467348098754883\n",
      "Seen so far: 142336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2224: 0.8935763835906982\n",
      "Seen so far: 142400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2225: 0.8821684122085571\n",
      "Seen so far: 142464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2226: 1.0807524919509888\n",
      "Seen so far: 142528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2227: 0.6708056330680847\n",
      "Seen so far: 142592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2228: 0.9401401281356812\n",
      "Seen so far: 142656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2229: 1.0304005146026611\n",
      "Seen so far: 142720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2230: 0.8285366296768188\n",
      "Seen so far: 142784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2231: 0.95279860496521\n",
      "Seen so far: 142848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2232: 1.0622162818908691\n",
      "Seen so far: 142912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2233: 0.7304803133010864\n",
      "Seen so far: 142976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2234: 0.6778482794761658\n",
      "Seen so far: 143040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2235: 1.1801629066467285\n",
      "Seen so far: 143104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2236: 0.7234567403793335\n",
      "Seen so far: 143168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2237: 0.9024190306663513\n",
      "Seen so far: 143232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2238: 0.6130160093307495\n",
      "Seen so far: 143296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2239: 0.9473567605018616\n",
      "Seen so far: 143360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2240: 0.7493807673454285\n",
      "Seen so far: 143424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2241: 1.162570834159851\n",
      "Seen so far: 143488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2242: 0.7207600474357605\n",
      "Seen so far: 143552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2243: 1.195939540863037\n",
      "Seen so far: 143616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2244: 0.9205823540687561\n",
      "Seen so far: 143680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2245: 0.5231980085372925\n",
      "Seen so far: 143744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2246: 0.8405705690383911\n",
      "Seen so far: 143808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2247: 1.021582841873169\n",
      "Seen so far: 143872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2248: 0.49792906641960144\n",
      "Seen so far: 143936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2249: 1.0445488691329956\n",
      "Seen so far: 144000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2250: 0.8264102935791016\n",
      "Seen so far: 144064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2251: 0.7930298447608948\n",
      "Seen so far: 144128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2252: 0.7213764786720276\n",
      "Seen so far: 144192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2253: 1.0581836700439453\n",
      "Seen so far: 144256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2254: 0.6944553852081299\n",
      "Seen so far: 144320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2255: 0.7495231628417969\n",
      "Seen so far: 144384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2256: 0.9571985006332397\n",
      "Seen so far: 144448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2257: 1.0822714567184448\n",
      "Seen so far: 144512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2258: 1.3332188129425049\n",
      "Seen so far: 144576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2259: 0.9549459218978882\n",
      "Seen so far: 144640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2260: 0.8140734434127808\n",
      "Seen so far: 144704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2261: 1.1120171546936035\n",
      "Seen so far: 144768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2262: 0.8143001198768616\n",
      "Seen so far: 144832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2263: 1.0153192281723022\n",
      "Seen so far: 144896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2264: 0.9237332344055176\n",
      "Seen so far: 144960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2265: 0.5691290497779846\n",
      "Seen so far: 145024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2266: 0.7837525010108948\n",
      "Seen so far: 145088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2267: 0.9199068546295166\n",
      "Seen so far: 145152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2268: 0.6327263712882996\n",
      "Seen so far: 145216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2269: 0.5262381434440613\n",
      "Seen so far: 145280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2270: 0.6546560525894165\n",
      "Seen so far: 145344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2271: 0.6091956496238708\n",
      "Seen so far: 145408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2272: 1.1151502132415771\n",
      "Seen so far: 145472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2273: 0.8757020235061646\n",
      "Seen so far: 145536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2274: 0.8468883037567139\n",
      "Seen so far: 145600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2275: 1.1046323776245117\n",
      "Seen so far: 145664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2276: 0.7051457166671753\n",
      "Seen so far: 145728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2277: 0.8082197904586792\n",
      "Seen so far: 145792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2278: 0.9191182851791382\n",
      "Seen so far: 145856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2279: 0.5767661929130554\n",
      "Seen so far: 145920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2280: 1.0193252563476562\n",
      "Seen so far: 145984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2281: 0.677300214767456\n",
      "Seen so far: 146048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2282: 0.9119519591331482\n",
      "Seen so far: 146112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2283: 0.9613367915153503\n",
      "Seen so far: 146176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2284: 0.69427490234375\n",
      "Seen so far: 146240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2285: 0.842485785484314\n",
      "Seen so far: 146304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2286: 1.0241601467132568\n",
      "Seen so far: 146368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2287: 0.5391353368759155\n",
      "Seen so far: 146432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2288: 0.6104304790496826\n",
      "Seen so far: 146496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2289: 0.8676066994667053\n",
      "Seen so far: 146560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2290: 0.7960864305496216\n",
      "Seen so far: 146624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2291: 0.702202320098877\n",
      "Seen so far: 146688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2292: 0.771946132183075\n",
      "Seen so far: 146752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2293: 1.1460912227630615\n",
      "Seen so far: 146816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2294: 1.1817435026168823\n",
      "Seen so far: 146880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2295: 1.008175253868103\n",
      "Seen so far: 146944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2296: 0.71403968334198\n",
      "Seen so far: 147008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2297: 1.2974945306777954\n",
      "Seen so far: 147072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2298: 0.9129601716995239\n",
      "Seen so far: 147136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2299: 0.4632345736026764\n",
      "Seen so far: 147200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2300: 0.7845772504806519\n",
      "Seen so far: 147264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2301: 0.8255372047424316\n",
      "Seen so far: 147328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2302: 0.917805016040802\n",
      "Seen so far: 147392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2303: 0.970645546913147\n",
      "Seen so far: 147456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2304: 0.5573462247848511\n",
      "Seen so far: 147520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2305: 0.9798045754432678\n",
      "Seen so far: 147584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2306: 0.6602298021316528\n",
      "Seen so far: 147648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2307: 0.776382327079773\n",
      "Seen so far: 147712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2308: 0.8497911095619202\n",
      "Seen so far: 147776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2309: 0.8990275859832764\n",
      "Seen so far: 147840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2310: 0.6138454675674438\n",
      "Seen so far: 147904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2311: 0.6042648553848267\n",
      "Seen so far: 147968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2312: 0.4497694969177246\n",
      "Seen so far: 148032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2313: 0.7564164400100708\n",
      "Seen so far: 148096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2314: 1.18662428855896\n",
      "Seen so far: 148160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2315: 0.7776972651481628\n",
      "Seen so far: 148224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2316: 0.8923487663269043\n",
      "Seen so far: 148288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2317: 0.5312570333480835\n",
      "Seen so far: 148352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2318: 0.5130689144134521\n",
      "Seen so far: 148416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2319: 0.8166049718856812\n",
      "Seen so far: 148480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2320: 0.7530385255813599\n",
      "Seen so far: 148544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2321: 0.6287881731987\n",
      "Seen so far: 148608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2322: 0.5414771437644958\n",
      "Seen so far: 148672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2323: 0.5526951551437378\n",
      "Seen so far: 148736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2324: 1.101251244544983\n",
      "Seen so far: 148800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2325: 0.4257310628890991\n",
      "Seen so far: 148864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2326: 0.6787691116333008\n",
      "Seen so far: 148928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2327: 0.8834239840507507\n",
      "Seen so far: 148992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2328: 0.4827786684036255\n",
      "Seen so far: 149056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2329: 0.7670007944107056\n",
      "Seen so far: 149120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2330: 0.7897695302963257\n",
      "Seen so far: 149184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2331: 0.469343900680542\n",
      "Seen so far: 149248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2332: 0.929982602596283\n",
      "Seen so far: 149312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2333: 0.7173961400985718\n",
      "Seen so far: 149376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2334: 0.8840871453285217\n",
      "Seen so far: 149440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2335: 0.7724944353103638\n",
      "Seen so far: 149504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2336: 0.8301595449447632\n",
      "Seen so far: 149568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2337: 0.8570535182952881\n",
      "Seen so far: 149632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2338: 0.7269699573516846\n",
      "Seen so far: 149696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2339: 0.9683003425598145\n",
      "Seen so far: 149760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2340: 1.0776782035827637\n",
      "Seen so far: 149824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2341: 1.092505693435669\n",
      "Seen so far: 149888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2342: 0.4860568642616272\n",
      "Seen so far: 149952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2343: 0.5760911107063293\n",
      "Seen so far: 150016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2344: 0.9696929454803467\n",
      "Seen so far: 150080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2345: 0.9101115465164185\n",
      "Seen so far: 150144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2346: 0.7102705240249634\n",
      "Seen so far: 150208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2347: 0.6433748602867126\n",
      "Seen so far: 150272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2348: 0.9878697395324707\n",
      "Seen so far: 150336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2349: 0.6602143049240112\n",
      "Seen so far: 150400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2350: 1.0328445434570312\n",
      "Seen so far: 150464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2351: 0.8434911370277405\n",
      "Seen so far: 150528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2352: 1.0856398344039917\n",
      "Seen so far: 150592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2353: 0.737801194190979\n",
      "Seen so far: 150656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2354: 0.7791587710380554\n",
      "Seen so far: 150720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2355: 0.7570458650588989\n",
      "Seen so far: 150784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2356: 0.7087345123291016\n",
      "Seen so far: 150848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2357: 1.2018738985061646\n",
      "Seen so far: 150912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2358: 1.0518693923950195\n",
      "Seen so far: 150976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2359: 0.9423502683639526\n",
      "Seen so far: 151040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2360: 0.9632176160812378\n",
      "Seen so far: 151104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2361: 0.82100510597229\n",
      "Seen so far: 151168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2362: 1.058218002319336\n",
      "Seen so far: 151232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2363: 0.8684182167053223\n",
      "Seen so far: 151296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2364: 0.6550686359405518\n",
      "Seen so far: 151360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2365: 1.169762134552002\n",
      "Seen so far: 151424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2366: 0.8581016063690186\n",
      "Seen so far: 151488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2367: 0.840296745300293\n",
      "Seen so far: 151552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2368: 0.9301746487617493\n",
      "Seen so far: 151616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2369: 1.1275147199630737\n",
      "Seen so far: 151680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2370: 0.8947915434837341\n",
      "Seen so far: 151744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2371: 0.8612672090530396\n",
      "Seen so far: 151808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2372: 0.8470776081085205\n",
      "Seen so far: 151872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2373: 1.114819049835205\n",
      "Seen so far: 151936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2374: 0.7155612707138062\n",
      "Seen so far: 152000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2375: 0.914389967918396\n",
      "Seen so far: 152064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2376: 1.3924689292907715\n",
      "Seen so far: 152128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2377: 0.7745509147644043\n",
      "Seen so far: 152192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2378: 0.5237849950790405\n",
      "Seen so far: 152256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2379: 0.7872819900512695\n",
      "Seen so far: 152320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2380: 0.638972282409668\n",
      "Seen so far: 152384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2381: 0.45659491419792175\n",
      "Seen so far: 152448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2382: 0.5175927877426147\n",
      "Seen so far: 152512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2383: 0.7084418535232544\n",
      "Seen so far: 152576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2384: 0.9911117553710938\n",
      "Seen so far: 152640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2385: 1.0173536539077759\n",
      "Seen so far: 152704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2386: 0.8901687860488892\n",
      "Seen so far: 152768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2387: 0.6510891914367676\n",
      "Seen so far: 152832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2388: 0.704869270324707\n",
      "Seen so far: 152896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2389: 0.8779634237289429\n",
      "Seen so far: 152960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2390: 1.1475576162338257\n",
      "Seen so far: 153024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2391: 0.8405308723449707\n",
      "Seen so far: 153088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2392: 0.532386302947998\n",
      "Seen so far: 153152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2393: 0.8967606425285339\n",
      "Seen so far: 153216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2394: 0.7680011987686157\n",
      "Seen so far: 153280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2395: 1.040517807006836\n",
      "Seen so far: 153344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2396: 0.6646256446838379\n",
      "Seen so far: 153408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2397: 1.0616377592086792\n",
      "Seen so far: 153472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2398: 0.7611672282218933\n",
      "Seen so far: 153536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2399: 0.5756576061248779\n",
      "Seen so far: 153600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2400: 0.6607744693756104\n",
      "Seen so far: 153664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2401: 0.674873948097229\n",
      "Seen so far: 153728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2402: 0.9089102149009705\n",
      "Seen so far: 153792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2403: 1.0779669284820557\n",
      "Seen so far: 153856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2404: 0.7049544453620911\n",
      "Seen so far: 153920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2405: 1.0301328897476196\n",
      "Seen so far: 153984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2406: 0.47778183221817017\n",
      "Seen so far: 154048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2407: 1.3383957147598267\n",
      "Seen so far: 154112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2408: 0.39831554889678955\n",
      "Seen so far: 154176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2409: 0.8406700491905212\n",
      "Seen so far: 154240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2410: 0.543117344379425\n",
      "Seen so far: 154304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2411: 1.1369189023971558\n",
      "Seen so far: 154368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2412: 1.0710135698318481\n",
      "Seen so far: 154432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2413: 1.1055686473846436\n",
      "Seen so far: 154496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2414: 0.8551721572875977\n",
      "Seen so far: 154560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2415: 1.1515984535217285\n",
      "Seen so far: 154624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2416: 0.912255048751831\n",
      "Seen so far: 154688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2417: 0.9909341335296631\n",
      "Seen so far: 154752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2418: 0.9262363910675049\n",
      "Seen so far: 154816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2419: 0.6590108871459961\n",
      "Seen so far: 154880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2420: 0.8339958190917969\n",
      "Seen so far: 154944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2421: 0.7825714945793152\n",
      "Seen so far: 155008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2422: 0.663522481918335\n",
      "Seen so far: 155072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2423: 0.7145328521728516\n",
      "Seen so far: 155136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2424: 0.8395975828170776\n",
      "Seen so far: 155200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2425: 1.0424635410308838\n",
      "Seen so far: 155264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2426: 0.8357946872711182\n",
      "Seen so far: 155328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2427: 1.1561105251312256\n",
      "Seen so far: 155392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2428: 1.0338058471679688\n",
      "Seen so far: 155456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2429: 0.7134278416633606\n",
      "Seen so far: 155520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2430: 0.9024915099143982\n",
      "Seen so far: 155584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2431: 1.1783428192138672\n",
      "Seen so far: 155648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2432: 0.6867908239364624\n",
      "Seen so far: 155712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2433: 0.6501424312591553\n",
      "Seen so far: 155776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2434: 0.7530893087387085\n",
      "Seen so far: 155840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2435: 1.1980751752853394\n",
      "Seen so far: 155904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2436: 1.2383846044540405\n",
      "Seen so far: 155968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2437: 0.49047544598579407\n",
      "Seen so far: 156032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2438: 0.9741136431694031\n",
      "Seen so far: 156096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2439: 0.6947587728500366\n",
      "Seen so far: 156160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2440: 0.6410437822341919\n",
      "Seen so far: 156224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2441: 0.422707736492157\n",
      "Seen so far: 156288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2442: 1.0189425945281982\n",
      "Seen so far: 156352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2443: 0.8056125640869141\n",
      "Seen so far: 156416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2444: 0.8276083469390869\n",
      "Seen so far: 156480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2445: 0.871003270149231\n",
      "Seen so far: 156544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2446: 0.839586079120636\n",
      "Seen so far: 156608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2447: 0.48636484146118164\n",
      "Seen so far: 156672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2448: 1.1984666585922241\n",
      "Seen so far: 156736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2449: 0.8126051425933838\n",
      "Seen so far: 156800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2450: 0.7967222332954407\n",
      "Seen so far: 156864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2451: 0.925345242023468\n",
      "Seen so far: 156928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2452: 0.8749356269836426\n",
      "Seen so far: 156992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2453: 0.6476508378982544\n",
      "Seen so far: 157056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2454: 1.0535986423492432\n",
      "Seen so far: 157120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2455: 0.8271279335021973\n",
      "Seen so far: 157184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2456: 0.6327630877494812\n",
      "Seen so far: 157248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2457: 1.0658481121063232\n",
      "Seen so far: 157312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2458: 0.6382917761802673\n",
      "Seen so far: 157376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2459: 0.8323508501052856\n",
      "Seen so far: 157440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2460: 0.8687203526496887\n",
      "Seen so far: 157504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2461: 0.610880970954895\n",
      "Seen so far: 157568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2462: 0.8345069885253906\n",
      "Seen so far: 157632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2463: 0.6273281574249268\n",
      "Seen so far: 157696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2464: 0.7907527685165405\n",
      "Seen so far: 157760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2465: 0.9143899083137512\n",
      "Seen so far: 157824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2466: 1.3187074661254883\n",
      "Seen so far: 157888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2467: 1.2160923480987549\n",
      "Seen so far: 157952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2468: 0.8656244874000549\n",
      "Seen so far: 158016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2469: 0.7081090211868286\n",
      "Seen so far: 158080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2470: 0.7614966034889221\n",
      "Seen so far: 158144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2471: 1.1795403957366943\n",
      "Seen so far: 158208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2472: 0.9636040925979614\n",
      "Seen so far: 158272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2473: 0.7784446477890015\n",
      "Seen so far: 158336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2474: 1.3653311729431152\n",
      "Seen so far: 158400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2475: 0.7660428285598755\n",
      "Seen so far: 158464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2476: 0.7918044328689575\n",
      "Seen so far: 158528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2477: 0.8710522651672363\n",
      "Seen so far: 158592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2478: 1.002685785293579\n",
      "Seen so far: 158656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2479: 0.9138922691345215\n",
      "Seen so far: 158720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2480: 0.8270482420921326\n",
      "Seen so far: 158784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2481: 0.693199098110199\n",
      "Seen so far: 158848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2482: 0.7771587371826172\n",
      "Seen so far: 158912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2483: 0.9498304128646851\n",
      "Seen so far: 158976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2484: 0.7495283484458923\n",
      "Seen so far: 159040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2485: 0.542047917842865\n",
      "Seen so far: 159104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2486: 1.23379385471344\n",
      "Seen so far: 159168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2487: 0.7632080912590027\n",
      "Seen so far: 159232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2488: 0.9726153612136841\n",
      "Seen so far: 159296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2489: 0.5987811088562012\n",
      "Seen so far: 159360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2490: 0.7150115966796875\n",
      "Seen so far: 159424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2491: 0.875998854637146\n",
      "Seen so far: 159488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2492: 0.810808002948761\n",
      "Seen so far: 159552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2493: 0.45423272252082825\n",
      "Seen so far: 159616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2494: 0.6192162036895752\n",
      "Seen so far: 159680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2495: 0.5463213920593262\n",
      "Seen so far: 159744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2496: 0.5593825578689575\n",
      "Seen so far: 159808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2497: 0.7357358932495117\n",
      "Seen so far: 159872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2498: 0.5750126838684082\n",
      "Seen so far: 159936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2499: 1.1214637756347656\n",
      "Seen so far: 160000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2500: 0.8216456174850464\n",
      "Seen so far: 160064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2501: 0.7743621468544006\n",
      "Seen so far: 160128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2502: 0.639015793800354\n",
      "Seen so far: 160192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2503: 0.7607859373092651\n",
      "Seen so far: 160256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2504: 0.9087019562721252\n",
      "Seen so far: 160320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2505: 1.135797142982483\n",
      "Seen so far: 160384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2506: 0.7727343440055847\n",
      "Seen so far: 160448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2507: 0.8255382776260376\n",
      "Seen so far: 160512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2508: 0.7630623579025269\n",
      "Seen so far: 160576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2509: 0.8884825706481934\n",
      "Seen so far: 160640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2510: 1.005977988243103\n",
      "Seen so far: 160704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2511: 0.9301407933235168\n",
      "Seen so far: 160768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2512: 0.5930047631263733\n",
      "Seen so far: 160832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2513: 0.7945553064346313\n",
      "Seen so far: 160896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2514: 0.7170073986053467\n",
      "Seen so far: 160960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2515: 0.7516581416130066\n",
      "Seen so far: 161024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2516: 0.8077060580253601\n",
      "Seen so far: 161088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2517: 0.9740598797798157\n",
      "Seen so far: 161152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2518: 0.9393264055252075\n",
      "Seen so far: 161216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2519: 0.9657629728317261\n",
      "Seen so far: 161280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2520: 0.5644387006759644\n",
      "Seen so far: 161344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2521: 0.7882457971572876\n",
      "Seen so far: 161408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2522: 0.6444287300109863\n",
      "Seen so far: 161472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2523: 0.9909675121307373\n",
      "Seen so far: 161536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2524: 0.8096048831939697\n",
      "Seen so far: 161600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2525: 0.7645014524459839\n",
      "Seen so far: 161664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2526: 0.63046795129776\n",
      "Seen so far: 161728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2527: 0.7842212915420532\n",
      "Seen so far: 161792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2528: 1.0827457904815674\n",
      "Seen so far: 161856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2529: 0.9479080438613892\n",
      "Seen so far: 161920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2530: 0.578087568283081\n",
      "Seen so far: 161984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2531: 0.7688575983047485\n",
      "Seen so far: 162048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2532: 0.5198531746864319\n",
      "Seen so far: 162112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2533: 1.2241277694702148\n",
      "Seen so far: 162176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2534: 0.874377429485321\n",
      "Seen so far: 162240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2535: 0.6629319787025452\n",
      "Seen so far: 162304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2536: 0.8238876461982727\n",
      "Seen so far: 162368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2537: 0.9395130276679993\n",
      "Seen so far: 162432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2538: 0.7502627372741699\n",
      "Seen so far: 162496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2539: 0.9434607028961182\n",
      "Seen so far: 162560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2540: 1.1313995122909546\n",
      "Seen so far: 162624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2541: 1.6532235145568848\n",
      "Seen so far: 162688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2542: 0.7134544253349304\n",
      "Seen so far: 162752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2543: 0.8896820545196533\n",
      "Seen so far: 162816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2544: 0.8465515375137329\n",
      "Seen so far: 162880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2545: 1.286630630493164\n",
      "Seen so far: 162944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2546: 0.5494544506072998\n",
      "Seen so far: 163008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2547: 1.0544363260269165\n",
      "Seen so far: 163072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2548: 1.0303090810775757\n",
      "Seen so far: 163136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2549: 1.2479771375656128\n",
      "Seen so far: 163200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2550: 1.332198977470398\n",
      "Seen so far: 163264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2551: 0.766143798828125\n",
      "Seen so far: 163328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2552: 0.4073481261730194\n",
      "Seen so far: 163392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2553: 1.0046138763427734\n",
      "Seen so far: 163456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2554: 0.6986186504364014\n",
      "Seen so far: 163520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2555: 0.6190100312232971\n",
      "Seen so far: 163584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2556: 1.2387770414352417\n",
      "Seen so far: 163648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2557: 0.6377465724945068\n",
      "Seen so far: 163712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2558: 0.6032660007476807\n",
      "Seen so far: 163776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2559: 0.8711636066436768\n",
      "Seen so far: 163840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2560: 1.154709815979004\n",
      "Seen so far: 163904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2561: 0.9358687400817871\n",
      "Seen so far: 163968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2562: 0.5685809254646301\n",
      "Seen so far: 164032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2563: 0.8595626950263977\n",
      "Seen so far: 164096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2564: 0.9509039521217346\n",
      "Seen so far: 164160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2565: 0.42321252822875977\n",
      "Seen so far: 164224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2566: 1.0236798524856567\n",
      "Seen so far: 164288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2567: 1.0159475803375244\n",
      "Seen so far: 164352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2568: 1.3684675693511963\n",
      "Seen so far: 164416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2569: 0.9133660793304443\n",
      "Seen so far: 164480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2570: 0.8533975481987\n",
      "Seen so far: 164544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2571: 0.5869160890579224\n",
      "Seen so far: 164608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2572: 1.2861669063568115\n",
      "Seen so far: 164672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2573: 0.681159496307373\n",
      "Seen so far: 164736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2574: 0.8256657123565674\n",
      "Seen so far: 164800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2575: 0.5932444334030151\n",
      "Seen so far: 164864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2576: 0.6335819959640503\n",
      "Seen so far: 164928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2577: 0.7467707395553589\n",
      "Seen so far: 164992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2578: 0.5584283471107483\n",
      "Seen so far: 165056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2579: 0.7324117422103882\n",
      "Seen so far: 165120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2580: 0.8786351084709167\n",
      "Seen so far: 165184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2581: 0.7132600545883179\n",
      "Seen so far: 165248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2582: 1.1335238218307495\n",
      "Seen so far: 165312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2583: 0.7243326306343079\n",
      "Seen so far: 165376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2584: 0.4121229946613312\n",
      "Seen so far: 165440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2585: 0.596176266670227\n",
      "Seen so far: 165504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2586: 0.8118753433227539\n",
      "Seen so far: 165568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2587: 0.6701329350471497\n",
      "Seen so far: 165632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2588: 0.7209989428520203\n",
      "Seen so far: 165696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2589: 0.8554052114486694\n",
      "Seen so far: 165760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2590: 0.8148884773254395\n",
      "Seen so far: 165824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2591: 0.9147148728370667\n",
      "Seen so far: 165888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2592: 0.775732159614563\n",
      "Seen so far: 165952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2593: 0.9236314296722412\n",
      "Seen so far: 166016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2594: 0.9261913895606995\n",
      "Seen so far: 166080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2595: 0.7045964002609253\n",
      "Seen so far: 166144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2596: 0.7947074174880981\n",
      "Seen so far: 166208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2597: 0.6776610612869263\n",
      "Seen so far: 166272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2598: 0.916054904460907\n",
      "Seen so far: 166336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2599: 0.7775241136550903\n",
      "Seen so far: 166400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2600: 0.8153313398361206\n",
      "Seen so far: 166464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2601: 0.5771965980529785\n",
      "Seen so far: 166528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2602: 0.6395306587219238\n",
      "Seen so far: 166592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2603: 0.7881186008453369\n",
      "Seen so far: 166656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2604: 0.8659436702728271\n",
      "Seen so far: 166720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2605: 0.6659915447235107\n",
      "Seen so far: 166784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2606: 0.7584590315818787\n",
      "Seen so far: 166848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2607: 1.4621613025665283\n",
      "Seen so far: 166912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2608: 0.6098116636276245\n",
      "Seen so far: 166976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2609: 0.7913622260093689\n",
      "Seen so far: 167040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2610: 0.9442828893661499\n",
      "Seen so far: 167104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2611: 0.7661434412002563\n",
      "Seen so far: 167168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2612: 1.136418104171753\n",
      "Seen so far: 167232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2613: 0.5252082943916321\n",
      "Seen so far: 167296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2614: 0.8348238468170166\n",
      "Seen so far: 167360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2615: 0.6550078392028809\n",
      "Seen so far: 167424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2616: 0.6362606287002563\n",
      "Seen so far: 167488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2617: 0.6981421709060669\n",
      "Seen so far: 167552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2618: 0.730749249458313\n",
      "Seen so far: 167616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2619: 1.1926498413085938\n",
      "Seen so far: 167680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2620: 0.5775066614151001\n",
      "Seen so far: 167744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2621: 0.709086537361145\n",
      "Seen so far: 167808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2622: 0.9181195497512817\n",
      "Seen so far: 167872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2623: 0.9632270336151123\n",
      "Seen so far: 167936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2624: 0.9405153393745422\n",
      "Seen so far: 168000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2625: 0.5711464881896973\n",
      "Seen so far: 168064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2626: 0.5278011560440063\n",
      "Seen so far: 168128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2627: 0.9268866777420044\n",
      "Seen so far: 168192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2628: 0.4978419542312622\n",
      "Seen so far: 168256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2629: 0.8220421075820923\n",
      "Seen so far: 168320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2630: 1.0601551532745361\n",
      "Seen so far: 168384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2631: 0.7850775122642517\n",
      "Seen so far: 168448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2632: 0.6650343537330627\n",
      "Seen so far: 168512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2633: 0.707198977470398\n",
      "Seen so far: 168576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2634: 0.8682156801223755\n",
      "Seen so far: 168640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2635: 0.8695802092552185\n",
      "Seen so far: 168704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2636: 0.9947055578231812\n",
      "Seen so far: 168768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2637: 0.7671801447868347\n",
      "Seen so far: 168832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2638: 1.4415066242218018\n",
      "Seen so far: 168896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2639: 1.016414999961853\n",
      "Seen so far: 168960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2640: 0.6786279678344727\n",
      "Seen so far: 169024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2641: 0.5619875192642212\n",
      "Seen so far: 169088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2642: 0.6582531332969666\n",
      "Seen so far: 169152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2643: 1.0059045553207397\n",
      "Seen so far: 169216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2644: 0.6871821880340576\n",
      "Seen so far: 169280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2645: 0.8345191478729248\n",
      "Seen so far: 169344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2646: 0.7427259683609009\n",
      "Seen so far: 169408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2647: 0.6583898663520813\n",
      "Seen so far: 169472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2648: 0.9423377513885498\n",
      "Seen so far: 169536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2649: 0.9813246726989746\n",
      "Seen so far: 169600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2650: 0.8747631907463074\n",
      "Seen so far: 169664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2651: 1.1205809116363525\n",
      "Seen so far: 169728 samples\n",
      "Training acc over epoch: 0.725162923336029\n",
      "Start of epoch 7\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 0: 0.7817689776420593\n",
      "Seen so far: 64 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1: 0.7114893198013306\n",
      "Seen so far: 128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2: 0.57530677318573\n",
      "Seen so far: 192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 3: 0.7966113090515137\n",
      "Seen so far: 256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 4: 0.7540130019187927\n",
      "Seen so far: 320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 5: 1.1717145442962646\n",
      "Seen so far: 384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 6: 1.1114485263824463\n",
      "Seen so far: 448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 7: 0.8070998191833496\n",
      "Seen so far: 512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 8: 1.0926036834716797\n",
      "Seen so far: 576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 9: 0.8981199264526367\n",
      "Seen so far: 640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 10: 0.6651099920272827\n",
      "Seen so far: 704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 11: 0.5209580659866333\n",
      "Seen so far: 768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 12: 0.5412682294845581\n",
      "Seen so far: 832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 13: 0.4966089129447937\n",
      "Seen so far: 896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 14: 1.0785648822784424\n",
      "Seen so far: 960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 15: 0.6362518668174744\n",
      "Seen so far: 1024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 16: 1.0293262004852295\n",
      "Seen so far: 1088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 17: 1.1763850450515747\n",
      "Seen so far: 1152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 18: 0.881421685218811\n",
      "Seen so far: 1216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 19: 1.0174229145050049\n",
      "Seen so far: 1280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 20: 0.8214105367660522\n",
      "Seen so far: 1344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 21: 1.2362985610961914\n",
      "Seen so far: 1408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 22: 1.0128419399261475\n",
      "Seen so far: 1472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 23: 1.3122434616088867\n",
      "Seen so far: 1536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 24: 0.5043296813964844\n",
      "Seen so far: 1600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 25: 0.6306780576705933\n",
      "Seen so far: 1664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 26: 0.9617183208465576\n",
      "Seen so far: 1728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 27: 1.1480578184127808\n",
      "Seen so far: 1792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 28: 0.8544123768806458\n",
      "Seen so far: 1856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 29: 0.8194393515586853\n",
      "Seen so far: 1920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 30: 0.7548258900642395\n",
      "Seen so far: 1984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 31: 0.8963538408279419\n",
      "Seen so far: 2048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 32: 1.1034526824951172\n",
      "Seen so far: 2112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 33: 0.8012242317199707\n",
      "Seen so far: 2176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 34: 0.9120239019393921\n",
      "Seen so far: 2240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 35: 0.942188024520874\n",
      "Seen so far: 2304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 36: 0.58668452501297\n",
      "Seen so far: 2368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 37: 0.9132227897644043\n",
      "Seen so far: 2432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 38: 0.8566842079162598\n",
      "Seen so far: 2496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 39: 0.8764125108718872\n",
      "Seen so far: 2560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 40: 0.981552243232727\n",
      "Seen so far: 2624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 41: 1.0517410039901733\n",
      "Seen so far: 2688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 42: 0.9119417667388916\n",
      "Seen so far: 2752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 43: 0.702775239944458\n",
      "Seen so far: 2816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 44: 1.036128044128418\n",
      "Seen so far: 2880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 45: 1.0523040294647217\n",
      "Seen so far: 2944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 46: 0.7722417712211609\n",
      "Seen so far: 3008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 47: 0.6881915926933289\n",
      "Seen so far: 3072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 48: 0.9726927280426025\n",
      "Seen so far: 3136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 49: 0.5945006608963013\n",
      "Seen so far: 3200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 50: 1.0173776149749756\n",
      "Seen so far: 3264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 51: 0.8273413777351379\n",
      "Seen so far: 3328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 52: 0.6192414164543152\n",
      "Seen so far: 3392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 53: 0.6800600290298462\n",
      "Seen so far: 3456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 54: 0.6135197877883911\n",
      "Seen so far: 3520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 55: 0.9000239372253418\n",
      "Seen so far: 3584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 56: 1.3451091051101685\n",
      "Seen so far: 3648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 57: 1.470507264137268\n",
      "Seen so far: 3712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 58: 0.512945294380188\n",
      "Seen so far: 3776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 59: 0.8525539636611938\n",
      "Seen so far: 3840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 60: 0.19226548075675964\n",
      "Seen so far: 3904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 61: 0.5122171640396118\n",
      "Seen so far: 3968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 62: 1.0527693033218384\n",
      "Seen so far: 4032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 63: 0.8520358204841614\n",
      "Seen so far: 4096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 64: 0.7166671752929688\n",
      "Seen so far: 4160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 65: 0.7356579303741455\n",
      "Seen so far: 4224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 66: 1.371307611465454\n",
      "Seen so far: 4288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 67: 1.1748486757278442\n",
      "Seen so far: 4352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 68: 1.0242067575454712\n",
      "Seen so far: 4416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 69: 0.6657204627990723\n",
      "Seen so far: 4480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 70: 0.7252472639083862\n",
      "Seen so far: 4544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 71: 0.844794511795044\n",
      "Seen so far: 4608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 72: 1.1120942831039429\n",
      "Seen so far: 4672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 73: 0.7221150994300842\n",
      "Seen so far: 4736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 74: 0.8457357883453369\n",
      "Seen so far: 4800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 75: 0.882809042930603\n",
      "Seen so far: 4864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 76: 1.3169758319854736\n",
      "Seen so far: 4928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 77: 0.6074273586273193\n",
      "Seen so far: 4992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 78: 0.5766146779060364\n",
      "Seen so far: 5056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 79: 1.0909769535064697\n",
      "Seen so far: 5120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 80: 0.5109893083572388\n",
      "Seen so far: 5184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 81: 0.8743427991867065\n",
      "Seen so far: 5248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 82: 1.1585333347320557\n",
      "Seen so far: 5312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 83: 0.9004040360450745\n",
      "Seen so far: 5376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 84: 0.9427499175071716\n",
      "Seen so far: 5440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 85: 0.9053292274475098\n",
      "Seen so far: 5504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 86: 0.6404860019683838\n",
      "Seen so far: 5568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 87: 0.8498071432113647\n",
      "Seen so far: 5632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 88: 0.7315496206283569\n",
      "Seen so far: 5696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 89: 0.979721188545227\n",
      "Seen so far: 5760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 90: 1.0176525115966797\n",
      "Seen so far: 5824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 91: 1.1737871170043945\n",
      "Seen so far: 5888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 92: 0.743557333946228\n",
      "Seen so far: 5952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 93: 0.8644285202026367\n",
      "Seen so far: 6016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 94: 0.9837329387664795\n",
      "Seen so far: 6080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 95: 0.5990972518920898\n",
      "Seen so far: 6144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 96: 0.8562998175621033\n",
      "Seen so far: 6208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 97: 0.8699766993522644\n",
      "Seen so far: 6272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 98: 0.5989630818367004\n",
      "Seen so far: 6336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 99: 0.9180323481559753\n",
      "Seen so far: 6400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 100: 0.8433272242546082\n",
      "Seen so far: 6464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 101: 0.6015074253082275\n",
      "Seen so far: 6528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 102: 0.856561541557312\n",
      "Seen so far: 6592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 103: 0.7364658117294312\n",
      "Seen so far: 6656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 104: 0.9005192518234253\n",
      "Seen so far: 6720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 105: 0.9740692377090454\n",
      "Seen so far: 6784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 106: 0.5894051790237427\n",
      "Seen so far: 6848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 107: 0.7734787464141846\n",
      "Seen so far: 6912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 108: 0.9024143218994141\n",
      "Seen so far: 6976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 109: 0.8948274850845337\n",
      "Seen so far: 7040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 110: 0.7745433449745178\n",
      "Seen so far: 7104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 111: 0.7209250330924988\n",
      "Seen so far: 7168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 112: 0.6227932572364807\n",
      "Seen so far: 7232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 113: 0.9574360847473145\n",
      "Seen so far: 7296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 114: 1.0295659303665161\n",
      "Seen so far: 7360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 115: 0.5410485863685608\n",
      "Seen so far: 7424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 116: 1.0727242231369019\n",
      "Seen so far: 7488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 117: 1.0010697841644287\n",
      "Seen so far: 7552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 118: 1.0007866621017456\n",
      "Seen so far: 7616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 119: 0.5677586793899536\n",
      "Seen so far: 7680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 120: 0.9099801778793335\n",
      "Seen so far: 7744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 121: 1.0634880065917969\n",
      "Seen so far: 7808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 122: 0.8779470324516296\n",
      "Seen so far: 7872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 123: 0.5778781175613403\n",
      "Seen so far: 7936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 124: 0.9591163396835327\n",
      "Seen so far: 8000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 125: 0.7722620964050293\n",
      "Seen so far: 8064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 126: 0.6628485918045044\n",
      "Seen so far: 8128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 127: 1.1996244192123413\n",
      "Seen so far: 8192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 128: 0.5244288444519043\n",
      "Seen so far: 8256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 129: 0.9513447284698486\n",
      "Seen so far: 8320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 130: 1.040794014930725\n",
      "Seen so far: 8384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 131: 1.1993069648742676\n",
      "Seen so far: 8448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 132: 0.7458878755569458\n",
      "Seen so far: 8512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 133: 0.7763781547546387\n",
      "Seen so far: 8576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 134: 0.9017301797866821\n",
      "Seen so far: 8640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 135: 1.0599333047866821\n",
      "Seen so far: 8704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 136: 0.8909064531326294\n",
      "Seen so far: 8768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 137: 1.0955424308776855\n",
      "Seen so far: 8832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 138: 0.6021136045455933\n",
      "Seen so far: 8896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 139: 0.9300776720046997\n",
      "Seen so far: 8960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 140: 0.8865999579429626\n",
      "Seen so far: 9024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 141: 0.8864810466766357\n",
      "Seen so far: 9088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 142: 0.576129674911499\n",
      "Seen so far: 9152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 143: 0.8754734992980957\n",
      "Seen so far: 9216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 144: 1.0029172897338867\n",
      "Seen so far: 9280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 145: 0.7601444721221924\n",
      "Seen so far: 9344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 146: 0.5259900093078613\n",
      "Seen so far: 9408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 147: 0.9852020144462585\n",
      "Seen so far: 9472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 148: 1.3155654668807983\n",
      "Seen so far: 9536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 149: 0.8283179998397827\n",
      "Seen so far: 9600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 150: 0.5827751159667969\n",
      "Seen so far: 9664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 151: 0.5670459866523743\n",
      "Seen so far: 9728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 152: 1.2315785884857178\n",
      "Seen so far: 9792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 153: 1.0268840789794922\n",
      "Seen so far: 9856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 154: 1.4580316543579102\n",
      "Seen so far: 9920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 155: 0.9155178070068359\n",
      "Seen so far: 9984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 156: 1.0430498123168945\n",
      "Seen so far: 10048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 157: 0.7304505109786987\n",
      "Seen so far: 10112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 158: 1.3228284120559692\n",
      "Seen so far: 10176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 159: 1.043891429901123\n",
      "Seen so far: 10240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 160: 0.7888088822364807\n",
      "Seen so far: 10304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 161: 0.7858639359474182\n",
      "Seen so far: 10368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 162: 1.0029757022857666\n",
      "Seen so far: 10432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 163: 0.9106905460357666\n",
      "Seen so far: 10496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 164: 0.9129989147186279\n",
      "Seen so far: 10560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 165: 0.9974554777145386\n",
      "Seen so far: 10624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 166: 0.7801551222801208\n",
      "Seen so far: 10688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 167: 0.6078351736068726\n",
      "Seen so far: 10752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 168: 0.8746236562728882\n",
      "Seen so far: 10816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 169: 0.5473612546920776\n",
      "Seen so far: 10880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 170: 0.882706344127655\n",
      "Seen so far: 10944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 171: 0.7705585360527039\n",
      "Seen so far: 11008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 172: 1.11304771900177\n",
      "Seen so far: 11072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 173: 0.8355119228363037\n",
      "Seen so far: 11136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 174: 0.8714261054992676\n",
      "Seen so far: 11200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 175: 0.8365593552589417\n",
      "Seen so far: 11264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 176: 1.056952714920044\n",
      "Seen so far: 11328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 177: 0.6639391183853149\n",
      "Seen so far: 11392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 178: 0.7371134757995605\n",
      "Seen so far: 11456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 179: 0.9353349208831787\n",
      "Seen so far: 11520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 180: 0.9615728259086609\n",
      "Seen so far: 11584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 181: 0.5862321853637695\n",
      "Seen so far: 11648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 182: 0.846583902835846\n",
      "Seen so far: 11712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 183: 1.1169073581695557\n",
      "Seen so far: 11776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 184: 0.9453200697898865\n",
      "Seen so far: 11840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 185: 1.052610158920288\n",
      "Seen so far: 11904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 186: 0.7990014553070068\n",
      "Seen so far: 11968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 187: 0.9685484170913696\n",
      "Seen so far: 12032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 188: 1.2011291980743408\n",
      "Seen so far: 12096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 189: 0.9601908922195435\n",
      "Seen so far: 12160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 190: 0.9280507564544678\n",
      "Seen so far: 12224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 191: 0.4027615785598755\n",
      "Seen so far: 12288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 192: 0.7599060535430908\n",
      "Seen so far: 12352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 193: 0.9711810350418091\n",
      "Seen so far: 12416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 194: 1.0335395336151123\n",
      "Seen so far: 12480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 195: 0.7272197008132935\n",
      "Seen so far: 12544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 196: 0.4647985100746155\n",
      "Seen so far: 12608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 197: 0.7914411425590515\n",
      "Seen so far: 12672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 198: 1.332078218460083\n",
      "Seen so far: 12736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 199: 0.7439425587654114\n",
      "Seen so far: 12800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 200: 0.8964112997055054\n",
      "Seen so far: 12864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 201: 0.6418013572692871\n",
      "Seen so far: 12928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 202: 0.9489119052886963\n",
      "Seen so far: 12992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 203: 0.8031549453735352\n",
      "Seen so far: 13056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 204: 0.8612248301506042\n",
      "Seen so far: 13120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 205: 0.5494765043258667\n",
      "Seen so far: 13184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 206: 1.1024622917175293\n",
      "Seen so far: 13248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 207: 0.8325867056846619\n",
      "Seen so far: 13312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 208: 1.1576207876205444\n",
      "Seen so far: 13376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 209: 0.7665362358093262\n",
      "Seen so far: 13440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 210: 0.6857785582542419\n",
      "Seen so far: 13504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 211: 0.6742738485336304\n",
      "Seen so far: 13568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 212: 1.2436894178390503\n",
      "Seen so far: 13632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 213: 0.9467664957046509\n",
      "Seen so far: 13696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 214: 0.9414136409759521\n",
      "Seen so far: 13760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 215: 0.9088609218597412\n",
      "Seen so far: 13824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 216: 0.6526479721069336\n",
      "Seen so far: 13888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 217: 0.7001728415489197\n",
      "Seen so far: 13952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 218: 0.7147456407546997\n",
      "Seen so far: 14016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 219: 0.4960949122905731\n",
      "Seen so far: 14080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 220: 0.6786524057388306\n",
      "Seen so far: 14144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 221: 0.6623380184173584\n",
      "Seen so far: 14208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 222: 0.7184147834777832\n",
      "Seen so far: 14272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 223: 0.7865241169929504\n",
      "Seen so far: 14336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 224: 0.5813615322113037\n",
      "Seen so far: 14400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 225: 0.6986277103424072\n",
      "Seen so far: 14464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 226: 0.6241884231567383\n",
      "Seen so far: 14528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 227: 0.6752147674560547\n",
      "Seen so far: 14592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 228: 0.7228697538375854\n",
      "Seen so far: 14656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 229: 1.0704909563064575\n",
      "Seen so far: 14720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 230: 0.5567082166671753\n",
      "Seen so far: 14784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 231: 0.8329544067382812\n",
      "Seen so far: 14848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 232: 0.7534958124160767\n",
      "Seen so far: 14912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 233: 1.1254075765609741\n",
      "Seen so far: 14976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 234: 0.7085822224617004\n",
      "Seen so far: 15040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 235: 0.4361332058906555\n",
      "Seen so far: 15104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 236: 0.6248719692230225\n",
      "Seen so far: 15168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 237: 0.8215711116790771\n",
      "Seen so far: 15232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 238: 1.1077587604522705\n",
      "Seen so far: 15296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 239: 0.8639046549797058\n",
      "Seen so far: 15360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 240: 1.1644070148468018\n",
      "Seen so far: 15424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 241: 0.9199552536010742\n",
      "Seen so far: 15488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 242: 1.266593098640442\n",
      "Seen so far: 15552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 243: 0.8617336750030518\n",
      "Seen so far: 15616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 244: 0.7319276928901672\n",
      "Seen so far: 15680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 245: 0.9507112503051758\n",
      "Seen so far: 15744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 246: 1.0464991331100464\n",
      "Seen so far: 15808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 247: 1.1026709079742432\n",
      "Seen so far: 15872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 248: 0.5993640422821045\n",
      "Seen so far: 15936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 249: 0.5006314516067505\n",
      "Seen so far: 16000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 250: 0.9985567331314087\n",
      "Seen so far: 16064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 251: 1.1501500606536865\n",
      "Seen so far: 16128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 252: 0.9694887399673462\n",
      "Seen so far: 16192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 253: 0.7773356437683105\n",
      "Seen so far: 16256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 254: 0.7278493642807007\n",
      "Seen so far: 16320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 255: 0.9756611585617065\n",
      "Seen so far: 16384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 256: 1.060034990310669\n",
      "Seen so far: 16448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 257: 1.2547638416290283\n",
      "Seen so far: 16512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 258: 0.6578962802886963\n",
      "Seen so far: 16576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 259: 0.8424433469772339\n",
      "Seen so far: 16640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 260: 0.3958868682384491\n",
      "Seen so far: 16704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 261: 0.8902056217193604\n",
      "Seen so far: 16768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 262: 1.1038850545883179\n",
      "Seen so far: 16832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 263: 0.9759207963943481\n",
      "Seen so far: 16896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 264: 0.533758282661438\n",
      "Seen so far: 16960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 265: 0.9096288681030273\n",
      "Seen so far: 17024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 266: 0.7782319784164429\n",
      "Seen so far: 17088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 267: 0.9539304971694946\n",
      "Seen so far: 17152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 268: 0.9256695508956909\n",
      "Seen so far: 17216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 269: 0.8938812017440796\n",
      "Seen so far: 17280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 270: 0.4054071605205536\n",
      "Seen so far: 17344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 271: 1.1134326457977295\n",
      "Seen so far: 17408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 272: 0.5183117389678955\n",
      "Seen so far: 17472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 273: 1.1482667922973633\n",
      "Seen so far: 17536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 274: 1.100581407546997\n",
      "Seen so far: 17600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 275: 0.668014645576477\n",
      "Seen so far: 17664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 276: 1.0307310819625854\n",
      "Seen so far: 17728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 277: 1.2142412662506104\n",
      "Seen so far: 17792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 278: 0.7484447956085205\n",
      "Seen so far: 17856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 279: 1.257577896118164\n",
      "Seen so far: 17920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 280: 0.5253210067749023\n",
      "Seen so far: 17984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 281: 0.8171688914299011\n",
      "Seen so far: 18048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 282: 0.7257695198059082\n",
      "Seen so far: 18112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 283: 0.46333974599838257\n",
      "Seen so far: 18176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 284: 0.40032869577407837\n",
      "Seen so far: 18240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 285: 0.491272509098053\n",
      "Seen so far: 18304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 286: 0.7177136540412903\n",
      "Seen so far: 18368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 287: 0.5331755876541138\n",
      "Seen so far: 18432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 288: 0.6953928470611572\n",
      "Seen so far: 18496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 289: 0.7423611879348755\n",
      "Seen so far: 18560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 290: 0.9946094155311584\n",
      "Seen so far: 18624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 291: 0.39062246680259705\n",
      "Seen so far: 18688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 292: 1.1382941007614136\n",
      "Seen so far: 18752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 293: 1.3297553062438965\n",
      "Seen so far: 18816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 294: 0.5162097215652466\n",
      "Seen so far: 18880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 295: 0.9983000159263611\n",
      "Seen so far: 18944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 296: 0.9886077642440796\n",
      "Seen so far: 19008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 297: 0.5388492345809937\n",
      "Seen so far: 19072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 298: 0.6838176846504211\n",
      "Seen so far: 19136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 299: 1.3723686933517456\n",
      "Seen so far: 19200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 300: 0.7325440049171448\n",
      "Seen so far: 19264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 301: 0.7602545022964478\n",
      "Seen so far: 19328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 302: 0.7178664207458496\n",
      "Seen so far: 19392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 303: 0.5808489322662354\n",
      "Seen so far: 19456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 304: 0.8849733471870422\n",
      "Seen so far: 19520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 305: 0.7535938024520874\n",
      "Seen so far: 19584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 306: 0.9618606567382812\n",
      "Seen so far: 19648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 307: 0.9258163571357727\n",
      "Seen so far: 19712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 308: 0.9046379327774048\n",
      "Seen so far: 19776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 309: 0.6251809597015381\n",
      "Seen so far: 19840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 310: 0.7879551649093628\n",
      "Seen so far: 19904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 311: 0.7991759777069092\n",
      "Seen so far: 19968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 312: 0.9982880353927612\n",
      "Seen so far: 20032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 313: 0.8871516585350037\n",
      "Seen so far: 20096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 314: 0.956377387046814\n",
      "Seen so far: 20160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 315: 0.6269307136535645\n",
      "Seen so far: 20224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 316: 0.8710920214653015\n",
      "Seen so far: 20288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 317: 0.9342710971832275\n",
      "Seen so far: 20352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 318: 0.9036716222763062\n",
      "Seen so far: 20416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 319: 0.8101859092712402\n",
      "Seen so far: 20480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 320: 0.8935090899467468\n",
      "Seen so far: 20544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 321: 0.7474789619445801\n",
      "Seen so far: 20608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 322: 1.0392394065856934\n",
      "Seen so far: 20672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 323: 0.8988208770751953\n",
      "Seen so far: 20736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 324: 1.083763837814331\n",
      "Seen so far: 20800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 325: 0.6063834428787231\n",
      "Seen so far: 20864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 326: 0.8019216656684875\n",
      "Seen so far: 20928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 327: 0.9133307933807373\n",
      "Seen so far: 20992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 328: 0.9427785873413086\n",
      "Seen so far: 21056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 329: 0.9593831896781921\n",
      "Seen so far: 21120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 330: 0.7225284576416016\n",
      "Seen so far: 21184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 331: 0.7325211763381958\n",
      "Seen so far: 21248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 332: 0.9674861431121826\n",
      "Seen so far: 21312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 333: 1.0465673208236694\n",
      "Seen so far: 21376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 334: 0.9303976893424988\n",
      "Seen so far: 21440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 335: 1.1068053245544434\n",
      "Seen so far: 21504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 336: 0.8723288774490356\n",
      "Seen so far: 21568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 337: 0.5718406438827515\n",
      "Seen so far: 21632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 338: 0.7901060581207275\n",
      "Seen so far: 21696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 339: 0.5225118398666382\n",
      "Seen so far: 21760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 340: 0.6214655637741089\n",
      "Seen so far: 21824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 341: 0.9642007350921631\n",
      "Seen so far: 21888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 342: 0.9210811853408813\n",
      "Seen so far: 21952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 343: 1.2731534242630005\n",
      "Seen so far: 22016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 344: 0.8874623775482178\n",
      "Seen so far: 22080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 345: 0.6473891735076904\n",
      "Seen so far: 22144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 346: 0.6179862022399902\n",
      "Seen so far: 22208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 347: 1.2594629526138306\n",
      "Seen so far: 22272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 348: 0.3501804769039154\n",
      "Seen so far: 22336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 349: 0.8516841530799866\n",
      "Seen so far: 22400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 350: 0.956083357334137\n",
      "Seen so far: 22464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 351: 0.6523621678352356\n",
      "Seen so far: 22528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 352: 0.8935692310333252\n",
      "Seen so far: 22592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 353: 1.0575530529022217\n",
      "Seen so far: 22656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 354: 0.7932562828063965\n",
      "Seen so far: 22720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 355: 0.907443642616272\n",
      "Seen so far: 22784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 356: 0.5228211879730225\n",
      "Seen so far: 22848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 357: 0.7856882810592651\n",
      "Seen so far: 22912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 358: 0.7903050780296326\n",
      "Seen so far: 22976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 359: 0.9525304436683655\n",
      "Seen so far: 23040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 360: 0.8977205157279968\n",
      "Seen so far: 23104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 361: 0.5745267271995544\n",
      "Seen so far: 23168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 362: 0.92403244972229\n",
      "Seen so far: 23232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 363: 0.8717288970947266\n",
      "Seen so far: 23296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 364: 0.9288893938064575\n",
      "Seen so far: 23360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 365: 0.9501447081565857\n",
      "Seen so far: 23424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 366: 1.087060570716858\n",
      "Seen so far: 23488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 367: 0.7391944527626038\n",
      "Seen so far: 23552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 368: 0.8153423070907593\n",
      "Seen so far: 23616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 369: 0.9586302042007446\n",
      "Seen so far: 23680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 370: 0.5497618913650513\n",
      "Seen so far: 23744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 371: 1.1639232635498047\n",
      "Seen so far: 23808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 372: 0.5354976058006287\n",
      "Seen so far: 23872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 373: 0.6859778165817261\n",
      "Seen so far: 23936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 374: 0.9092775583267212\n",
      "Seen so far: 24000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 375: 0.7891643047332764\n",
      "Seen so far: 24064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 376: 0.6790469884872437\n",
      "Seen so far: 24128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 377: 1.2172870635986328\n",
      "Seen so far: 24192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 378: 0.6757549047470093\n",
      "Seen so far: 24256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 379: 0.8438674211502075\n",
      "Seen so far: 24320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 380: 0.9893687963485718\n",
      "Seen so far: 24384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 381: 0.6998705863952637\n",
      "Seen so far: 24448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 382: 0.7026443481445312\n",
      "Seen so far: 24512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 383: 0.9979120492935181\n",
      "Seen so far: 24576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 384: 0.9985079169273376\n",
      "Seen so far: 24640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 385: 0.6984512805938721\n",
      "Seen so far: 24704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 386: 1.1429071426391602\n",
      "Seen so far: 24768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 387: 0.7205332517623901\n",
      "Seen so far: 24832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 388: 1.1466671228408813\n",
      "Seen so far: 24896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 389: 0.7234011888504028\n",
      "Seen so far: 24960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 390: 1.0515307188034058\n",
      "Seen so far: 25024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 391: 0.5488961935043335\n",
      "Seen so far: 25088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 392: 1.0279772281646729\n",
      "Seen so far: 25152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 393: 1.0240389108657837\n",
      "Seen so far: 25216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 394: 0.5651599168777466\n",
      "Seen so far: 25280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 395: 1.179263710975647\n",
      "Seen so far: 25344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 396: 0.8246840238571167\n",
      "Seen so far: 25408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 397: 1.1553738117218018\n",
      "Seen so far: 25472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 398: 0.7457984685897827\n",
      "Seen so far: 25536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 399: 0.8702661991119385\n",
      "Seen so far: 25600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 400: 0.7723914980888367\n",
      "Seen so far: 25664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 401: 0.6954932808876038\n",
      "Seen so far: 25728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 402: 0.7750359773635864\n",
      "Seen so far: 25792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 403: 0.661432147026062\n",
      "Seen so far: 25856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 404: 0.5497944951057434\n",
      "Seen so far: 25920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 405: 0.944979727268219\n",
      "Seen so far: 25984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 406: 0.9516792297363281\n",
      "Seen so far: 26048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 407: 0.8015376329421997\n",
      "Seen so far: 26112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 408: 1.0032999515533447\n",
      "Seen so far: 26176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 409: 0.8861309289932251\n",
      "Seen so far: 26240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 410: 0.4997606575489044\n",
      "Seen so far: 26304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 411: 1.0990275144577026\n",
      "Seen so far: 26368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 412: 0.9856924414634705\n",
      "Seen so far: 26432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 413: 0.8094408512115479\n",
      "Seen so far: 26496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 414: 0.3933395445346832\n",
      "Seen so far: 26560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 415: 0.9417492747306824\n",
      "Seen so far: 26624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 416: 0.9999853372573853\n",
      "Seen so far: 26688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 417: 0.8726384043693542\n",
      "Seen so far: 26752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 418: 0.7935962677001953\n",
      "Seen so far: 26816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 419: 1.3165403604507446\n",
      "Seen so far: 26880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 420: 0.8488463759422302\n",
      "Seen so far: 26944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 421: 1.5801186561584473\n",
      "Seen so far: 27008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 422: 0.7116063833236694\n",
      "Seen so far: 27072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 423: 0.7411025166511536\n",
      "Seen so far: 27136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 424: 0.7360782623291016\n",
      "Seen so far: 27200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 425: 0.7964140176773071\n",
      "Seen so far: 27264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 426: 1.011857271194458\n",
      "Seen so far: 27328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 427: 1.0389163494110107\n",
      "Seen so far: 27392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 428: 0.7539507746696472\n",
      "Seen so far: 27456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 429: 0.7494996786117554\n",
      "Seen so far: 27520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 430: 0.8946363925933838\n",
      "Seen so far: 27584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 431: 0.7251397967338562\n",
      "Seen so far: 27648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 432: 1.0398962497711182\n",
      "Seen so far: 27712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 433: 0.5734245777130127\n",
      "Seen so far: 27776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 434: 0.7266215085983276\n",
      "Seen so far: 27840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 435: 0.9607930183410645\n",
      "Seen so far: 27904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 436: 0.8872638940811157\n",
      "Seen so far: 27968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 437: 0.8535801768302917\n",
      "Seen so far: 28032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 438: 0.9485657215118408\n",
      "Seen so far: 28096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 439: 0.7523117661476135\n",
      "Seen so far: 28160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 440: 0.8823494911193848\n",
      "Seen so far: 28224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 441: 1.07918119430542\n",
      "Seen so far: 28288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 442: 0.9382853507995605\n",
      "Seen so far: 28352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 443: 0.494289755821228\n",
      "Seen so far: 28416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 444: 1.0587064027786255\n",
      "Seen so far: 28480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 445: 0.9087626338005066\n",
      "Seen so far: 28544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 446: 0.7768874168395996\n",
      "Seen so far: 28608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 447: 0.6545636653900146\n",
      "Seen so far: 28672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 448: 0.803173840045929\n",
      "Seen so far: 28736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 449: 0.7672508955001831\n",
      "Seen so far: 28800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 450: 1.2840520143508911\n",
      "Seen so far: 28864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 451: 0.8551346063613892\n",
      "Seen so far: 28928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 452: 1.0040769577026367\n",
      "Seen so far: 28992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 453: 0.7934340834617615\n",
      "Seen so far: 29056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 454: 0.8327490091323853\n",
      "Seen so far: 29120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 455: 0.6778706312179565\n",
      "Seen so far: 29184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 456: 0.7449939250946045\n",
      "Seen so far: 29248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 457: 0.6712610721588135\n",
      "Seen so far: 29312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 458: 1.1649750471115112\n",
      "Seen so far: 29376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 459: 0.9202293157577515\n",
      "Seen so far: 29440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 460: 0.9347503781318665\n",
      "Seen so far: 29504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 461: 0.9217442274093628\n",
      "Seen so far: 29568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 462: 0.8107421398162842\n",
      "Seen so far: 29632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 463: 0.8897781372070312\n",
      "Seen so far: 29696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 464: 0.7845997214317322\n",
      "Seen so far: 29760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 465: 0.612444281578064\n",
      "Seen so far: 29824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 466: 0.8516168594360352\n",
      "Seen so far: 29888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 467: 0.8590450882911682\n",
      "Seen so far: 29952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 468: 0.975143313407898\n",
      "Seen so far: 30016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 469: 0.6888673305511475\n",
      "Seen so far: 30080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 470: 0.49992311000823975\n",
      "Seen so far: 30144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 471: 0.7336068749427795\n",
      "Seen so far: 30208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 472: 0.6921072602272034\n",
      "Seen so far: 30272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 473: 0.798643171787262\n",
      "Seen so far: 30336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 474: 0.5783202648162842\n",
      "Seen so far: 30400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 475: 0.8547376394271851\n",
      "Seen so far: 30464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 476: 0.8130034804344177\n",
      "Seen so far: 30528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 477: 0.6024956703186035\n",
      "Seen so far: 30592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 478: 0.818732500076294\n",
      "Seen so far: 30656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 479: 1.042920708656311\n",
      "Seen so far: 30720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 480: 0.6480275988578796\n",
      "Seen so far: 30784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 481: 0.7423383593559265\n",
      "Seen so far: 30848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 482: 0.6094375848770142\n",
      "Seen so far: 30912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 483: 0.7919843196868896\n",
      "Seen so far: 30976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 484: 0.6613719463348389\n",
      "Seen so far: 31040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 485: 0.768701434135437\n",
      "Seen so far: 31104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 486: 0.9227230548858643\n",
      "Seen so far: 31168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 487: 0.8276964426040649\n",
      "Seen so far: 31232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 488: 1.039676547050476\n",
      "Seen so far: 31296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 489: 1.2155141830444336\n",
      "Seen so far: 31360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 490: 0.6867625117301941\n",
      "Seen so far: 31424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 491: 0.7985450029373169\n",
      "Seen so far: 31488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 492: 0.7123516798019409\n",
      "Seen so far: 31552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 493: 0.8048393130302429\n",
      "Seen so far: 31616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 494: 0.8456833362579346\n",
      "Seen so far: 31680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 495: 0.6683974266052246\n",
      "Seen so far: 31744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 496: 0.8456853628158569\n",
      "Seen so far: 31808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 497: 0.8763941526412964\n",
      "Seen so far: 31872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 498: 0.6900404691696167\n",
      "Seen so far: 31936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 499: 0.9640580415725708\n",
      "Seen so far: 32000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 500: 0.6504068374633789\n",
      "Seen so far: 32064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 501: 0.9148647785186768\n",
      "Seen so far: 32128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 502: 0.5387275815010071\n",
      "Seen so far: 32192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 503: 0.7088696956634521\n",
      "Seen so far: 32256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 504: 1.2670085430145264\n",
      "Seen so far: 32320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 505: 0.9101828336715698\n",
      "Seen so far: 32384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 506: 0.9963893294334412\n",
      "Seen so far: 32448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 507: 1.1730947494506836\n",
      "Seen so far: 32512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 508: 0.8045247793197632\n",
      "Seen so far: 32576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 509: 0.689740777015686\n",
      "Seen so far: 32640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 510: 0.8796851634979248\n",
      "Seen so far: 32704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 511: 1.0440934896469116\n",
      "Seen so far: 32768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 512: 0.9968289136886597\n",
      "Seen so far: 32832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 513: 1.08932626247406\n",
      "Seen so far: 32896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 514: 0.6054837703704834\n",
      "Seen so far: 32960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 515: 0.6137059330940247\n",
      "Seen so far: 33024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 516: 0.738052248954773\n",
      "Seen so far: 33088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 517: 0.9629101753234863\n",
      "Seen so far: 33152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 518: 0.7892991304397583\n",
      "Seen so far: 33216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 519: 0.944148063659668\n",
      "Seen so far: 33280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 520: 0.7184451222419739\n",
      "Seen so far: 33344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 521: 0.6593979001045227\n",
      "Seen so far: 33408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 522: 0.5715920329093933\n",
      "Seen so far: 33472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 523: 0.8378984332084656\n",
      "Seen so far: 33536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 524: 0.6260762214660645\n",
      "Seen so far: 33600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 525: 0.7404347658157349\n",
      "Seen so far: 33664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 526: 1.0277378559112549\n",
      "Seen so far: 33728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 527: 0.8866904973983765\n",
      "Seen so far: 33792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 528: 1.0440118312835693\n",
      "Seen so far: 33856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 529: 0.7602014541625977\n",
      "Seen so far: 33920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 530: 0.8878682255744934\n",
      "Seen so far: 33984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 531: 0.4718064069747925\n",
      "Seen so far: 34048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 532: 0.9456439018249512\n",
      "Seen so far: 34112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 533: 1.2354341745376587\n",
      "Seen so far: 34176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 534: 0.8271405696868896\n",
      "Seen so far: 34240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 535: 0.9296825528144836\n",
      "Seen so far: 34304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 536: 0.6158021092414856\n",
      "Seen so far: 34368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 537: 0.7784754037857056\n",
      "Seen so far: 34432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 538: 0.655521810054779\n",
      "Seen so far: 34496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 539: 0.6221120357513428\n",
      "Seen so far: 34560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 540: 0.91100013256073\n",
      "Seen so far: 34624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 541: 0.7981042265892029\n",
      "Seen so far: 34688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 542: 0.7041974067687988\n",
      "Seen so far: 34752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 543: 0.6617680788040161\n",
      "Seen so far: 34816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 544: 0.6398510336875916\n",
      "Seen so far: 34880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 545: 0.9164038896560669\n",
      "Seen so far: 34944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 546: 0.9428873062133789\n",
      "Seen so far: 35008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 547: 0.9677633047103882\n",
      "Seen so far: 35072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 548: 0.9656301736831665\n",
      "Seen so far: 35136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 549: 0.8169386386871338\n",
      "Seen so far: 35200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 550: 0.7958246469497681\n",
      "Seen so far: 35264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 551: 0.5543756484985352\n",
      "Seen so far: 35328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 552: 0.7756300568580627\n",
      "Seen so far: 35392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 553: 0.9856131076812744\n",
      "Seen so far: 35456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 554: 0.9117158651351929\n",
      "Seen so far: 35520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 555: 0.9429459571838379\n",
      "Seen so far: 35584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 556: 0.8115031719207764\n",
      "Seen so far: 35648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 557: 1.0999219417572021\n",
      "Seen so far: 35712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 558: 0.5463812947273254\n",
      "Seen so far: 35776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 559: 0.7702163457870483\n",
      "Seen so far: 35840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 560: 0.7731459736824036\n",
      "Seen so far: 35904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 561: 0.7105295658111572\n",
      "Seen so far: 35968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 562: 1.0178167819976807\n",
      "Seen so far: 36032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 563: 0.974911093711853\n",
      "Seen so far: 36096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 564: 0.5922205448150635\n",
      "Seen so far: 36160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 565: 0.6831625699996948\n",
      "Seen so far: 36224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 566: 0.5957382917404175\n",
      "Seen so far: 36288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 567: 0.8172391057014465\n",
      "Seen so far: 36352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 568: 0.6755959391593933\n",
      "Seen so far: 36416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 569: 0.5467601418495178\n",
      "Seen so far: 36480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 570: 1.0209026336669922\n",
      "Seen so far: 36544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 571: 0.9656195640563965\n",
      "Seen so far: 36608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 572: 0.911530077457428\n",
      "Seen so far: 36672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 573: 1.0304243564605713\n",
      "Seen so far: 36736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 574: 0.8155922889709473\n",
      "Seen so far: 36800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 575: 1.0031201839447021\n",
      "Seen so far: 36864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 576: 0.5937415957450867\n",
      "Seen so far: 36928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 577: 1.06096613407135\n",
      "Seen so far: 36992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 578: 0.5330345630645752\n",
      "Seen so far: 37056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 579: 0.872040867805481\n",
      "Seen so far: 37120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 580: 0.5373131036758423\n",
      "Seen so far: 37184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 581: 0.6877338290214539\n",
      "Seen so far: 37248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 582: 1.2395408153533936\n",
      "Seen so far: 37312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 583: 0.7002199292182922\n",
      "Seen so far: 37376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 584: 1.0589845180511475\n",
      "Seen so far: 37440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 585: 0.6396145820617676\n",
      "Seen so far: 37504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 586: 0.7487257122993469\n",
      "Seen so far: 37568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 587: 0.5805361270904541\n",
      "Seen so far: 37632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 588: 0.7673371434211731\n",
      "Seen so far: 37696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 589: 0.7073121070861816\n",
      "Seen so far: 37760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 590: 0.4716106653213501\n",
      "Seen so far: 37824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 591: 0.6250827312469482\n",
      "Seen so far: 37888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 592: 0.9162814617156982\n",
      "Seen so far: 37952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 593: 0.8732242584228516\n",
      "Seen so far: 38016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 594: 0.5319854021072388\n",
      "Seen so far: 38080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 595: 0.7224470376968384\n",
      "Seen so far: 38144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 596: 0.6275029182434082\n",
      "Seen so far: 38208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 597: 0.4635528326034546\n",
      "Seen so far: 38272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 598: 0.791057825088501\n",
      "Seen so far: 38336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 599: 0.5163404941558838\n",
      "Seen so far: 38400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 600: 0.5196614861488342\n",
      "Seen so far: 38464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 601: 0.40714743733406067\n",
      "Seen so far: 38528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 602: 0.9935508370399475\n",
      "Seen so far: 38592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 603: 1.395097017288208\n",
      "Seen so far: 38656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 604: 0.9673475623130798\n",
      "Seen so far: 38720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 605: 0.7016451358795166\n",
      "Seen so far: 38784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 606: 1.3951194286346436\n",
      "Seen so far: 38848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 607: 0.8760949373245239\n",
      "Seen so far: 38912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 608: 0.8581529855728149\n",
      "Seen so far: 38976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 609: 0.644416332244873\n",
      "Seen so far: 39040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 610: 0.4963585138320923\n",
      "Seen so far: 39104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 611: 0.6404485702514648\n",
      "Seen so far: 39168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 612: 0.7137502431869507\n",
      "Seen so far: 39232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 613: 0.6977061033248901\n",
      "Seen so far: 39296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 614: 0.9520957469940186\n",
      "Seen so far: 39360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 615: 0.8172301054000854\n",
      "Seen so far: 39424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 616: 0.6070823669433594\n",
      "Seen so far: 39488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 617: 1.0319502353668213\n",
      "Seen so far: 39552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 618: 1.1862778663635254\n",
      "Seen so far: 39616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 619: 0.8847292065620422\n",
      "Seen so far: 39680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 620: 0.9983890056610107\n",
      "Seen so far: 39744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 621: 0.9340634346008301\n",
      "Seen so far: 39808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 622: 0.835141658782959\n",
      "Seen so far: 39872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 623: 0.7722950577735901\n",
      "Seen so far: 39936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 624: 0.7840248346328735\n",
      "Seen so far: 40000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 625: 0.7703661918640137\n",
      "Seen so far: 40064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 626: 0.7801980972290039\n",
      "Seen so far: 40128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 627: 0.5632152557373047\n",
      "Seen so far: 40192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 628: 0.8688180446624756\n",
      "Seen so far: 40256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 629: 0.9321970343589783\n",
      "Seen so far: 40320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 630: 0.8387724161148071\n",
      "Seen so far: 40384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 631: 0.7232736349105835\n",
      "Seen so far: 40448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 632: 0.7869572639465332\n",
      "Seen so far: 40512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 633: 1.0006024837493896\n",
      "Seen so far: 40576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 634: 0.5364269614219666\n",
      "Seen so far: 40640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 635: 0.592252254486084\n",
      "Seen so far: 40704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 636: 1.009120225906372\n",
      "Seen so far: 40768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 637: 0.4075533151626587\n",
      "Seen so far: 40832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 638: 0.6353820562362671\n",
      "Seen so far: 40896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 639: 0.8251456618309021\n",
      "Seen so far: 40960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 640: 0.7798352241516113\n",
      "Seen so far: 41024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 641: 0.3386273980140686\n",
      "Seen so far: 41088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 642: 0.708257794380188\n",
      "Seen so far: 41152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 643: 0.5369915962219238\n",
      "Seen so far: 41216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 644: 0.8123925924301147\n",
      "Seen so far: 41280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 645: 0.9464788436889648\n",
      "Seen so far: 41344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 646: 0.7215320467948914\n",
      "Seen so far: 41408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 647: 0.7492614388465881\n",
      "Seen so far: 41472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 648: 0.7171748280525208\n",
      "Seen so far: 41536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 649: 1.1488487720489502\n",
      "Seen so far: 41600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 650: 1.3306180238723755\n",
      "Seen so far: 41664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 651: 0.6995159387588501\n",
      "Seen so far: 41728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 652: 0.7780380249023438\n",
      "Seen so far: 41792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 653: 0.6917086839675903\n",
      "Seen so far: 41856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 654: 0.9645349383354187\n",
      "Seen so far: 41920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 655: 0.48346975445747375\n",
      "Seen so far: 41984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 656: 0.8584651350975037\n",
      "Seen so far: 42048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 657: 1.3471838235855103\n",
      "Seen so far: 42112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 658: 0.6403940916061401\n",
      "Seen so far: 42176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 659: 0.7486277222633362\n",
      "Seen so far: 42240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 660: 0.8581060171127319\n",
      "Seen so far: 42304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 661: 0.7146579623222351\n",
      "Seen so far: 42368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 662: 0.7657602429389954\n",
      "Seen so far: 42432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 663: 0.84403395652771\n",
      "Seen so far: 42496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 664: 0.8437578082084656\n",
      "Seen so far: 42560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 665: 0.9760150909423828\n",
      "Seen so far: 42624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 666: 0.7780792117118835\n",
      "Seen so far: 42688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 667: 0.5864667892456055\n",
      "Seen so far: 42752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 668: 0.6921688318252563\n",
      "Seen so far: 42816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 669: 0.9312989115715027\n",
      "Seen so far: 42880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 670: 0.8484820127487183\n",
      "Seen so far: 42944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 671: 1.3815670013427734\n",
      "Seen so far: 43008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 672: 0.940368115901947\n",
      "Seen so far: 43072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 673: 1.081360936164856\n",
      "Seen so far: 43136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 674: 0.7112770676612854\n",
      "Seen so far: 43200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 675: 0.8998239040374756\n",
      "Seen so far: 43264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 676: 1.0434463024139404\n",
      "Seen so far: 43328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 677: 0.8047841787338257\n",
      "Seen so far: 43392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 678: 0.7187663316726685\n",
      "Seen so far: 43456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 679: 1.016280174255371\n",
      "Seen so far: 43520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 680: 0.790770947933197\n",
      "Seen so far: 43584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 681: 1.2057048082351685\n",
      "Seen so far: 43648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 682: 0.9038795828819275\n",
      "Seen so far: 43712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 683: 0.5295805931091309\n",
      "Seen so far: 43776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 684: 0.7996782064437866\n",
      "Seen so far: 43840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 685: 0.5586373805999756\n",
      "Seen so far: 43904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 686: 1.0267767906188965\n",
      "Seen so far: 43968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 687: 0.9144656658172607\n",
      "Seen so far: 44032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 688: 0.5739842057228088\n",
      "Seen so far: 44096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 689: 0.5906423330307007\n",
      "Seen so far: 44160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 690: 0.780839204788208\n",
      "Seen so far: 44224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 691: 0.9707737565040588\n",
      "Seen so far: 44288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 692: 1.0311626195907593\n",
      "Seen so far: 44352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 693: 0.8789717555046082\n",
      "Seen so far: 44416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 694: 0.8020668029785156\n",
      "Seen so far: 44480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 695: 0.4803563952445984\n",
      "Seen so far: 44544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 696: 0.7961275577545166\n",
      "Seen so far: 44608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 697: 0.7926456332206726\n",
      "Seen so far: 44672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 698: 0.7617895007133484\n",
      "Seen so far: 44736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 699: 0.7720094919204712\n",
      "Seen so far: 44800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 700: 0.8874273896217346\n",
      "Seen so far: 44864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 701: 0.8599306344985962\n",
      "Seen so far: 44928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 702: 0.635034441947937\n",
      "Seen so far: 44992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 703: 0.5363852977752686\n",
      "Seen so far: 45056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 704: 0.703289806842804\n",
      "Seen so far: 45120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 705: 0.6159276962280273\n",
      "Seen so far: 45184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 706: 0.842755913734436\n",
      "Seen so far: 45248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 707: 0.44481462240219116\n",
      "Seen so far: 45312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 708: 0.6631489396095276\n",
      "Seen so far: 45376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 709: 1.2889426946640015\n",
      "Seen so far: 45440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 710: 0.7881910800933838\n",
      "Seen so far: 45504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 711: 0.6287081241607666\n",
      "Seen so far: 45568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 712: 0.8796168565750122\n",
      "Seen so far: 45632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 713: 0.9477182030677795\n",
      "Seen so far: 45696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 714: 0.9123638868331909\n",
      "Seen so far: 45760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 715: 1.099546194076538\n",
      "Seen so far: 45824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 716: 0.34283363819122314\n",
      "Seen so far: 45888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 717: 1.1341582536697388\n",
      "Seen so far: 45952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 718: 1.2225441932678223\n",
      "Seen so far: 46016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 719: 0.9956134557723999\n",
      "Seen so far: 46080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 720: 0.8740171194076538\n",
      "Seen so far: 46144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 721: 0.8810879588127136\n",
      "Seen so far: 46208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 722: 0.49854084849357605\n",
      "Seen so far: 46272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 723: 0.6518698930740356\n",
      "Seen so far: 46336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 724: 0.7400009036064148\n",
      "Seen so far: 46400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 725: 1.1149005889892578\n",
      "Seen so far: 46464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 726: 0.8129415512084961\n",
      "Seen so far: 46528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 727: 0.7650254964828491\n",
      "Seen so far: 46592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 728: 0.9361527562141418\n",
      "Seen so far: 46656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 729: 0.6841928362846375\n",
      "Seen so far: 46720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 730: 0.7356224060058594\n",
      "Seen so far: 46784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 731: 0.8651747107505798\n",
      "Seen so far: 46848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 732: 1.656879186630249\n",
      "Seen so far: 46912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 733: 0.9714792370796204\n",
      "Seen so far: 46976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 734: 0.7049698233604431\n",
      "Seen so far: 47040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 735: 0.7188705205917358\n",
      "Seen so far: 47104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 736: 0.6721205115318298\n",
      "Seen so far: 47168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 737: 0.5762205123901367\n",
      "Seen so far: 47232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 738: 0.5394271612167358\n",
      "Seen so far: 47296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 739: 0.9157190322875977\n",
      "Seen so far: 47360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 740: 0.6597853899002075\n",
      "Seen so far: 47424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 741: 0.7446471452713013\n",
      "Seen so far: 47488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 742: 0.5723663568496704\n",
      "Seen so far: 47552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 743: 1.163582682609558\n",
      "Seen so far: 47616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 744: 0.6563763618469238\n",
      "Seen so far: 47680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 745: 0.874096155166626\n",
      "Seen so far: 47744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 746: 0.9773662686347961\n",
      "Seen so far: 47808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 747: 0.9135023355484009\n",
      "Seen so far: 47872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 748: 0.5322603583335876\n",
      "Seen so far: 47936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 749: 1.2405226230621338\n",
      "Seen so far: 48000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 750: 0.6886531114578247\n",
      "Seen so far: 48064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 751: 0.7371230721473694\n",
      "Seen so far: 48128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 752: 0.9627015590667725\n",
      "Seen so far: 48192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 753: 1.2106107473373413\n",
      "Seen so far: 48256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 754: 1.0545657873153687\n",
      "Seen so far: 48320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 755: 0.6392242908477783\n",
      "Seen so far: 48384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 756: 1.2699952125549316\n",
      "Seen so far: 48448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 757: 0.9646910429000854\n",
      "Seen so far: 48512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 758: 0.6184452176094055\n",
      "Seen so far: 48576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 759: 0.8742947578430176\n",
      "Seen so far: 48640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 760: 1.00640869140625\n",
      "Seen so far: 48704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 761: 1.0177805423736572\n",
      "Seen so far: 48768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 762: 0.6700994968414307\n",
      "Seen so far: 48832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 763: 1.1041343212127686\n",
      "Seen so far: 48896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 764: 0.787216305732727\n",
      "Seen so far: 48960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 765: 0.7972482442855835\n",
      "Seen so far: 49024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 766: 0.8463767170906067\n",
      "Seen so far: 49088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 767: 0.660497784614563\n",
      "Seen so far: 49152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 768: 0.45761311054229736\n",
      "Seen so far: 49216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 769: 0.6475576162338257\n",
      "Seen so far: 49280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 770: 0.6802153587341309\n",
      "Seen so far: 49344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 771: 0.677175760269165\n",
      "Seen so far: 49408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 772: 1.1372896432876587\n",
      "Seen so far: 49472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 773: 0.8760497570037842\n",
      "Seen so far: 49536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 774: 0.6717126965522766\n",
      "Seen so far: 49600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 775: 0.8237449526786804\n",
      "Seen so far: 49664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 776: 0.7607442140579224\n",
      "Seen so far: 49728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 777: 0.9753661155700684\n",
      "Seen so far: 49792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 778: 0.7509856224060059\n",
      "Seen so far: 49856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 779: 0.5072025656700134\n",
      "Seen so far: 49920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 780: 1.228798270225525\n",
      "Seen so far: 49984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 781: 1.0669019222259521\n",
      "Seen so far: 50048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 782: 0.8169966340065002\n",
      "Seen so far: 50112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 783: 0.8558109998703003\n",
      "Seen so far: 50176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 784: 1.0452481508255005\n",
      "Seen so far: 50240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 785: 0.7944040298461914\n",
      "Seen so far: 50304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 786: 1.1572566032409668\n",
      "Seen so far: 50368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 787: 0.9260219931602478\n",
      "Seen so far: 50432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 788: 0.3951084017753601\n",
      "Seen so far: 50496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 789: 1.0456277132034302\n",
      "Seen so far: 50560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 790: 1.10606050491333\n",
      "Seen so far: 50624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 791: 0.5708566308021545\n",
      "Seen so far: 50688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 792: 0.6318932771682739\n",
      "Seen so far: 50752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 793: 0.7013513445854187\n",
      "Seen so far: 50816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 794: 1.0081642866134644\n",
      "Seen so far: 50880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 795: 0.5716273784637451\n",
      "Seen so far: 50944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 796: 0.6998358964920044\n",
      "Seen so far: 51008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 797: 0.7701708674430847\n",
      "Seen so far: 51072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 798: 1.1738628149032593\n",
      "Seen so far: 51136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 799: 0.9455742239952087\n",
      "Seen so far: 51200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 800: 0.6321783065795898\n",
      "Seen so far: 51264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 801: 0.7540843486785889\n",
      "Seen so far: 51328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 802: 0.8832758665084839\n",
      "Seen so far: 51392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 803: 0.8219938278198242\n",
      "Seen so far: 51456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 804: 0.46150073409080505\n",
      "Seen so far: 51520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 805: 0.8538705706596375\n",
      "Seen so far: 51584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 806: 0.843105137348175\n",
      "Seen so far: 51648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 807: 0.5295122861862183\n",
      "Seen so far: 51712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 808: 0.7274616956710815\n",
      "Seen so far: 51776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 809: 0.7146728038787842\n",
      "Seen so far: 51840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 810: 0.8242584466934204\n",
      "Seen so far: 51904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 811: 0.6955152750015259\n",
      "Seen so far: 51968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 812: 0.8533202409744263\n",
      "Seen so far: 52032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 813: 0.6915338039398193\n",
      "Seen so far: 52096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 814: 0.5841109752655029\n",
      "Seen so far: 52160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 815: 1.0922248363494873\n",
      "Seen so far: 52224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 816: 0.950545072555542\n",
      "Seen so far: 52288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 817: 0.5895375609397888\n",
      "Seen so far: 52352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 818: 1.330533742904663\n",
      "Seen so far: 52416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 819: 0.3114111125469208\n",
      "Seen so far: 52480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 820: 0.9674047231674194\n",
      "Seen so far: 52544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 821: 0.7302778959274292\n",
      "Seen so far: 52608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 822: 0.5840047001838684\n",
      "Seen so far: 52672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 823: 0.9212727546691895\n",
      "Seen so far: 52736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 824: 0.9976540803909302\n",
      "Seen so far: 52800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 825: 0.9040167331695557\n",
      "Seen so far: 52864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 826: 0.7441901564598083\n",
      "Seen so far: 52928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 827: 1.2474101781845093\n",
      "Seen so far: 52992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 828: 0.7659064531326294\n",
      "Seen so far: 53056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 829: 0.9471322298049927\n",
      "Seen so far: 53120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 830: 0.9059543013572693\n",
      "Seen so far: 53184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 831: 1.0326056480407715\n",
      "Seen so far: 53248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 832: 0.9413230419158936\n",
      "Seen so far: 53312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 833: 0.8346307277679443\n",
      "Seen so far: 53376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 834: 0.6253839135169983\n",
      "Seen so far: 53440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 835: 0.6656203269958496\n",
      "Seen so far: 53504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 836: 0.8442553877830505\n",
      "Seen so far: 53568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 837: 0.6982116103172302\n",
      "Seen so far: 53632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 838: 0.37745535373687744\n",
      "Seen so far: 53696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 839: 0.6349381804466248\n",
      "Seen so far: 53760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 840: 0.5440405607223511\n",
      "Seen so far: 53824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 841: 1.1230278015136719\n",
      "Seen so far: 53888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 842: 0.7531099319458008\n",
      "Seen so far: 53952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 843: 0.6764612793922424\n",
      "Seen so far: 54016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 844: 0.9628438353538513\n",
      "Seen so far: 54080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 845: 0.8839617967605591\n",
      "Seen so far: 54144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 846: 0.6406317949295044\n",
      "Seen so far: 54208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 847: 0.8600349426269531\n",
      "Seen so far: 54272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 848: 0.655093789100647\n",
      "Seen so far: 54336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 849: 0.6036449670791626\n",
      "Seen so far: 54400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 850: 0.49470973014831543\n",
      "Seen so far: 54464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 851: 0.4741901755332947\n",
      "Seen so far: 54528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 852: 0.404930055141449\n",
      "Seen so far: 54592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 853: 0.7112566232681274\n",
      "Seen so far: 54656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 854: 0.6392617225646973\n",
      "Seen so far: 54720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 855: 0.6717772483825684\n",
      "Seen so far: 54784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 856: 0.5725353956222534\n",
      "Seen so far: 54848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 857: 0.5187556743621826\n",
      "Seen so far: 54912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 858: 0.8542486429214478\n",
      "Seen so far: 54976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 859: 1.1254143714904785\n",
      "Seen so far: 55040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 860: 0.6580228805541992\n",
      "Seen so far: 55104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 861: 0.6905869245529175\n",
      "Seen so far: 55168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 862: 0.6919655799865723\n",
      "Seen so far: 55232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 863: 0.8909580111503601\n",
      "Seen so far: 55296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 864: 1.0376312732696533\n",
      "Seen so far: 55360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 865: 0.5510644316673279\n",
      "Seen so far: 55424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 866: 0.6524837613105774\n",
      "Seen so far: 55488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 867: 0.7669421434402466\n",
      "Seen so far: 55552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 868: 0.9191420078277588\n",
      "Seen so far: 55616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 869: 0.7956869006156921\n",
      "Seen so far: 55680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 870: 1.1941649913787842\n",
      "Seen so far: 55744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 871: 1.0985774993896484\n",
      "Seen so far: 55808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 872: 0.5028650760650635\n",
      "Seen so far: 55872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 873: 1.0142173767089844\n",
      "Seen so far: 55936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 874: 0.9266917705535889\n",
      "Seen so far: 56000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 875: 1.0114163160324097\n",
      "Seen so far: 56064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 876: 0.8557466268539429\n",
      "Seen so far: 56128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 877: 0.8490720987319946\n",
      "Seen so far: 56192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 878: 0.8597978949546814\n",
      "Seen so far: 56256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 879: 0.36559224128723145\n",
      "Seen so far: 56320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 880: 0.9384623765945435\n",
      "Seen so far: 56384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 881: 1.2406671047210693\n",
      "Seen so far: 56448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 882: 0.8351819515228271\n",
      "Seen so far: 56512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 883: 0.8122736215591431\n",
      "Seen so far: 56576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 884: 0.40234628319740295\n",
      "Seen so far: 56640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 885: 0.8357745409011841\n",
      "Seen so far: 56704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 886: 0.8955450057983398\n",
      "Seen so far: 56768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 887: 0.8251726627349854\n",
      "Seen so far: 56832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 888: 0.8126415014266968\n",
      "Seen so far: 56896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 889: 1.1815675497055054\n",
      "Seen so far: 56960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 890: 0.7152590155601501\n",
      "Seen so far: 57024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 891: 1.129622220993042\n",
      "Seen so far: 57088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 892: 0.505975067615509\n",
      "Seen so far: 57152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 893: 1.3033819198608398\n",
      "Seen so far: 57216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 894: 0.8770093321800232\n",
      "Seen so far: 57280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 895: 0.8700157999992371\n",
      "Seen so far: 57344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 896: 1.2130913734436035\n",
      "Seen so far: 57408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 897: 0.7964850068092346\n",
      "Seen so far: 57472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 898: 0.5453871488571167\n",
      "Seen so far: 57536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 899: 0.5105649828910828\n",
      "Seen so far: 57600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 900: 0.7327226400375366\n",
      "Seen so far: 57664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 901: 1.0906472206115723\n",
      "Seen so far: 57728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 902: 1.045225739479065\n",
      "Seen so far: 57792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 903: 0.7893033623695374\n",
      "Seen so far: 57856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 904: 0.8377429246902466\n",
      "Seen so far: 57920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 905: 0.805595874786377\n",
      "Seen so far: 57984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 906: 1.0319310426712036\n",
      "Seen so far: 58048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 907: 0.7925599813461304\n",
      "Seen so far: 58112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 908: 0.556286096572876\n",
      "Seen so far: 58176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 909: 0.8788567781448364\n",
      "Seen so far: 58240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 910: 0.65803062915802\n",
      "Seen so far: 58304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 911: 0.692354679107666\n",
      "Seen so far: 58368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 912: 0.6921976804733276\n",
      "Seen so far: 58432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 913: 1.479984998703003\n",
      "Seen so far: 58496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 914: 0.6825819611549377\n",
      "Seen so far: 58560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 915: 0.5712493658065796\n",
      "Seen so far: 58624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 916: 1.0888018608093262\n",
      "Seen so far: 58688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 917: 0.6490331292152405\n",
      "Seen so far: 58752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 918: 0.90925532579422\n",
      "Seen so far: 58816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 919: 0.6437630653381348\n",
      "Seen so far: 58880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 920: 0.7903034687042236\n",
      "Seen so far: 58944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 921: 0.6121000051498413\n",
      "Seen so far: 59008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 922: 0.9720072746276855\n",
      "Seen so far: 59072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 923: 0.8895533680915833\n",
      "Seen so far: 59136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 924: 0.8518815636634827\n",
      "Seen so far: 59200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 925: 0.7893009185791016\n",
      "Seen so far: 59264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 926: 0.9662957787513733\n",
      "Seen so far: 59328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 927: 0.8006066083908081\n",
      "Seen so far: 59392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 928: 0.6092685461044312\n",
      "Seen so far: 59456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 929: 0.7078977823257446\n",
      "Seen so far: 59520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 930: 0.8362526893615723\n",
      "Seen so far: 59584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 931: 1.118891716003418\n",
      "Seen so far: 59648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 932: 1.244297742843628\n",
      "Seen so far: 59712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 933: 0.885936975479126\n",
      "Seen so far: 59776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 934: 1.1697518825531006\n",
      "Seen so far: 59840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 935: 0.628943145275116\n",
      "Seen so far: 59904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 936: 0.9702757596969604\n",
      "Seen so far: 59968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 937: 0.9923578500747681\n",
      "Seen so far: 60032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 938: 0.9594566226005554\n",
      "Seen so far: 60096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 939: 0.7177537679672241\n",
      "Seen so far: 60160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 940: 0.6555523872375488\n",
      "Seen so far: 60224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 941: 0.7331711649894714\n",
      "Seen so far: 60288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 942: 0.8806971311569214\n",
      "Seen so far: 60352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 943: 0.8998578786849976\n",
      "Seen so far: 60416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 944: 0.7312107682228088\n",
      "Seen so far: 60480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 945: 0.9833357334136963\n",
      "Seen so far: 60544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 946: 0.8234944939613342\n",
      "Seen so far: 60608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 947: 0.9361885786056519\n",
      "Seen so far: 60672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 948: 0.5398994088172913\n",
      "Seen so far: 60736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 949: 0.7561569213867188\n",
      "Seen so far: 60800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 950: 0.8510702848434448\n",
      "Seen so far: 60864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 951: 0.7907260060310364\n",
      "Seen so far: 60928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 952: 0.9981671571731567\n",
      "Seen so far: 60992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 953: 1.0851116180419922\n",
      "Seen so far: 61056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 954: 0.9285498261451721\n",
      "Seen so far: 61120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 955: 0.8451775908470154\n",
      "Seen so far: 61184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 956: 1.2597817182540894\n",
      "Seen so far: 61248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 957: 0.8664422035217285\n",
      "Seen so far: 61312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 958: 1.0034250020980835\n",
      "Seen so far: 61376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 959: 0.6488217711448669\n",
      "Seen so far: 61440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 960: 0.7380836606025696\n",
      "Seen so far: 61504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 961: 0.725630521774292\n",
      "Seen so far: 61568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 962: 0.7391548156738281\n",
      "Seen so far: 61632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 963: 0.8949099779129028\n",
      "Seen so far: 61696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 964: 0.829422652721405\n",
      "Seen so far: 61760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 965: 0.9104718565940857\n",
      "Seen so far: 61824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 966: 0.49935293197631836\n",
      "Seen so far: 61888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 967: 0.6362588405609131\n",
      "Seen so far: 61952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 968: 0.8111389875411987\n",
      "Seen so far: 62016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 969: 0.9159866571426392\n",
      "Seen so far: 62080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 970: 1.071903944015503\n",
      "Seen so far: 62144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 971: 0.6687877178192139\n",
      "Seen so far: 62208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 972: 1.1233004331588745\n",
      "Seen so far: 62272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 973: 0.7255873680114746\n",
      "Seen so far: 62336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 974: 0.6709591150283813\n",
      "Seen so far: 62400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 975: 0.8455352783203125\n",
      "Seen so far: 62464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 976: 0.8564352989196777\n",
      "Seen so far: 62528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 977: 0.9388614296913147\n",
      "Seen so far: 62592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 978: 1.1296234130859375\n",
      "Seen so far: 62656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 979: 0.8741194009780884\n",
      "Seen so far: 62720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 980: 0.866590142250061\n",
      "Seen so far: 62784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 981: 0.8525224328041077\n",
      "Seen so far: 62848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 982: 0.6967663764953613\n",
      "Seen so far: 62912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 983: 0.5618290901184082\n",
      "Seen so far: 62976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 984: 0.7474772930145264\n",
      "Seen so far: 63040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 985: 0.9383146166801453\n",
      "Seen so far: 63104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 986: 0.8132806420326233\n",
      "Seen so far: 63168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 987: 1.0706177949905396\n",
      "Seen so far: 63232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 988: 0.7823929786682129\n",
      "Seen so far: 63296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 989: 0.8920915722846985\n",
      "Seen so far: 63360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 990: 0.7076489925384521\n",
      "Seen so far: 63424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 991: 0.7059575915336609\n",
      "Seen so far: 63488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 992: 0.3204134702682495\n",
      "Seen so far: 63552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 993: 0.8249393701553345\n",
      "Seen so far: 63616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 994: 1.0696995258331299\n",
      "Seen so far: 63680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 995: 0.756871223449707\n",
      "Seen so far: 63744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 996: 0.8354055881500244\n",
      "Seen so far: 63808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 997: 0.39249762892723083\n",
      "Seen so far: 63872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 998: 0.7866239547729492\n",
      "Seen so far: 63936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 999: 0.7405524849891663\n",
      "Seen so far: 64000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1000: 0.6756678819656372\n",
      "Seen so far: 64064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1001: 0.7032740116119385\n",
      "Seen so far: 64128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1002: 0.7275843620300293\n",
      "Seen so far: 64192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1003: 0.712219774723053\n",
      "Seen so far: 64256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1004: 0.7730820178985596\n",
      "Seen so far: 64320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1005: 0.838088870048523\n",
      "Seen so far: 64384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1006: 0.8336338996887207\n",
      "Seen so far: 64448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1007: 0.8908635973930359\n",
      "Seen so far: 64512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1008: 1.1109418869018555\n",
      "Seen so far: 64576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1009: 0.929166853427887\n",
      "Seen so far: 64640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1010: 0.5016995668411255\n",
      "Seen so far: 64704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1011: 0.7140907049179077\n",
      "Seen so far: 64768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1012: 0.7710520625114441\n",
      "Seen so far: 64832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1013: 0.8688507080078125\n",
      "Seen so far: 64896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1014: 0.7692217826843262\n",
      "Seen so far: 64960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1015: 0.35348254442214966\n",
      "Seen so far: 65024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1016: 0.9550542831420898\n",
      "Seen so far: 65088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1017: 1.058883547782898\n",
      "Seen so far: 65152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1018: 0.6556642055511475\n",
      "Seen so far: 65216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1019: 1.135721206665039\n",
      "Seen so far: 65280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1020: 0.3995153307914734\n",
      "Seen so far: 65344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1021: 0.52670818567276\n",
      "Seen so far: 65408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1022: 0.5088948011398315\n",
      "Seen so far: 65472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1023: 1.29088294506073\n",
      "Seen so far: 65536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1024: 0.605821430683136\n",
      "Seen so far: 65600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1025: 0.8126632571220398\n",
      "Seen so far: 65664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1026: 0.7297089099884033\n",
      "Seen so far: 65728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1027: 1.1459782123565674\n",
      "Seen so far: 65792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1028: 0.5636283159255981\n",
      "Seen so far: 65856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1029: 1.0142441987991333\n",
      "Seen so far: 65920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1030: 0.8792505264282227\n",
      "Seen so far: 65984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1031: 0.6576914191246033\n",
      "Seen so far: 66048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1032: 0.6663146615028381\n",
      "Seen so far: 66112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1033: 1.1349763870239258\n",
      "Seen so far: 66176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1034: 1.1608951091766357\n",
      "Seen so far: 66240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1035: 1.139442801475525\n",
      "Seen so far: 66304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1036: 0.517253041267395\n",
      "Seen so far: 66368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1037: 0.9012762308120728\n",
      "Seen so far: 66432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1038: 0.7824023962020874\n",
      "Seen so far: 66496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1039: 0.6413121223449707\n",
      "Seen so far: 66560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1040: 1.0019965171813965\n",
      "Seen so far: 66624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1041: 0.956648588180542\n",
      "Seen so far: 66688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1042: 0.6296384930610657\n",
      "Seen so far: 66752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1043: 0.9048037528991699\n",
      "Seen so far: 66816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1044: 0.4217640161514282\n",
      "Seen so far: 66880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1045: 0.9637278318405151\n",
      "Seen so far: 66944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1046: 0.8323578834533691\n",
      "Seen so far: 67008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1047: 0.7031068801879883\n",
      "Seen so far: 67072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1048: 0.8740265965461731\n",
      "Seen so far: 67136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1049: 0.6176534295082092\n",
      "Seen so far: 67200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1050: 1.2841626405715942\n",
      "Seen so far: 67264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1051: 1.0617868900299072\n",
      "Seen so far: 67328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1052: 0.5984912514686584\n",
      "Seen so far: 67392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1053: 0.82926344871521\n",
      "Seen so far: 67456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1054: 1.0077117681503296\n",
      "Seen so far: 67520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1055: 0.8051394820213318\n",
      "Seen so far: 67584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1056: 0.5873448848724365\n",
      "Seen so far: 67648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1057: 0.5636798143386841\n",
      "Seen so far: 67712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1058: 0.5377615094184875\n",
      "Seen so far: 67776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1059: 0.5520894527435303\n",
      "Seen so far: 67840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1060: 0.586428165435791\n",
      "Seen so far: 67904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1061: 0.7086176872253418\n",
      "Seen so far: 67968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1062: 0.9550751447677612\n",
      "Seen so far: 68032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1063: 0.4680270850658417\n",
      "Seen so far: 68096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1064: 0.9073731303215027\n",
      "Seen so far: 68160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1065: 0.7534816861152649\n",
      "Seen so far: 68224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1066: 0.8027881383895874\n",
      "Seen so far: 68288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1067: 0.5377662181854248\n",
      "Seen so far: 68352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1068: 0.7182527780532837\n",
      "Seen so far: 68416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1069: 0.6817772388458252\n",
      "Seen so far: 68480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1070: 0.6105345487594604\n",
      "Seen so far: 68544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1071: 0.5649973154067993\n",
      "Seen so far: 68608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1072: 0.6350007057189941\n",
      "Seen so far: 68672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1073: 1.1854496002197266\n",
      "Seen so far: 68736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1074: 0.7167501449584961\n",
      "Seen so far: 68800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1075: 0.6280472278594971\n",
      "Seen so far: 68864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1076: 0.5108782649040222\n",
      "Seen so far: 68928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1077: 0.9242390394210815\n",
      "Seen so far: 68992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1078: 1.058797836303711\n",
      "Seen so far: 69056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1079: 0.7858395576477051\n",
      "Seen so far: 69120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1080: 0.6970542073249817\n",
      "Seen so far: 69184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1081: 0.7221752405166626\n",
      "Seen so far: 69248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1082: 0.7639771699905396\n",
      "Seen so far: 69312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1083: 0.773198664188385\n",
      "Seen so far: 69376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1084: 0.8623418807983398\n",
      "Seen so far: 69440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1085: 0.8429024815559387\n",
      "Seen so far: 69504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1086: 0.9687783718109131\n",
      "Seen so far: 69568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1087: 0.9653056263923645\n",
      "Seen so far: 69632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1088: 1.0179827213287354\n",
      "Seen so far: 69696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1089: 0.6928688287734985\n",
      "Seen so far: 69760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1090: 0.5882433652877808\n",
      "Seen so far: 69824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1091: 0.8553255796432495\n",
      "Seen so far: 69888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1092: 1.0136915445327759\n",
      "Seen so far: 69952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1093: 0.6246792078018188\n",
      "Seen so far: 70016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1094: 0.9981216192245483\n",
      "Seen so far: 70080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1095: 0.720470666885376\n",
      "Seen so far: 70144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1096: 0.505166232585907\n",
      "Seen so far: 70208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1097: 0.6439721584320068\n",
      "Seen so far: 70272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1098: 1.0130430459976196\n",
      "Seen so far: 70336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1099: 0.6284502744674683\n",
      "Seen so far: 70400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1100: 1.2192696332931519\n",
      "Seen so far: 70464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1101: 1.0944886207580566\n",
      "Seen so far: 70528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1102: 0.7588760852813721\n",
      "Seen so far: 70592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1103: 0.9125312566757202\n",
      "Seen so far: 70656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1104: 0.6199193000793457\n",
      "Seen so far: 70720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1105: 0.9474702477455139\n",
      "Seen so far: 70784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1106: 0.8578084111213684\n",
      "Seen so far: 70848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1107: 0.7108136415481567\n",
      "Seen so far: 70912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1108: 0.8470499515533447\n",
      "Seen so far: 70976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1109: 0.6602272391319275\n",
      "Seen so far: 71040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1110: 0.7460702657699585\n",
      "Seen so far: 71104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1111: 0.7309257984161377\n",
      "Seen so far: 71168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1112: 1.1756319999694824\n",
      "Seen so far: 71232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1113: 1.2867233753204346\n",
      "Seen so far: 71296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1114: 0.6337665915489197\n",
      "Seen so far: 71360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1115: 1.180544376373291\n",
      "Seen so far: 71424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1116: 0.7954296469688416\n",
      "Seen so far: 71488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1117: 0.7596282958984375\n",
      "Seen so far: 71552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1118: 0.5403815507888794\n",
      "Seen so far: 71616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1119: 0.7813431024551392\n",
      "Seen so far: 71680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1120: 0.637711763381958\n",
      "Seen so far: 71744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1121: 0.9100510478019714\n",
      "Seen so far: 71808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1122: 0.4197397530078888\n",
      "Seen so far: 71872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1123: 0.9065637588500977\n",
      "Seen so far: 71936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1124: 0.8529277443885803\n",
      "Seen so far: 72000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1125: 1.1533654928207397\n",
      "Seen so far: 72064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1126: 0.5828994512557983\n",
      "Seen so far: 72128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1127: 0.7211711406707764\n",
      "Seen so far: 72192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1128: 1.4093459844589233\n",
      "Seen so far: 72256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1129: 0.6055095195770264\n",
      "Seen so far: 72320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1130: 0.7505183219909668\n",
      "Seen so far: 72384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1131: 0.9780919551849365\n",
      "Seen so far: 72448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1132: 0.8592376112937927\n",
      "Seen so far: 72512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1133: 0.8442392349243164\n",
      "Seen so far: 72576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1134: 0.7658258676528931\n",
      "Seen so far: 72640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1135: 0.9627278447151184\n",
      "Seen so far: 72704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1136: 0.936690092086792\n",
      "Seen so far: 72768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1137: 1.0484671592712402\n",
      "Seen so far: 72832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1138: 0.8477827310562134\n",
      "Seen so far: 72896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1139: 0.5505267381668091\n",
      "Seen so far: 72960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1140: 0.9718878865242004\n",
      "Seen so far: 73024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1141: 0.564173698425293\n",
      "Seen so far: 73088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1142: 0.8549806475639343\n",
      "Seen so far: 73152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1143: 0.6104168891906738\n",
      "Seen so far: 73216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1144: 0.903800368309021\n",
      "Seen so far: 73280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1145: 0.8930538892745972\n",
      "Seen so far: 73344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1146: 0.7921572327613831\n",
      "Seen so far: 73408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1147: 0.9525275230407715\n",
      "Seen so far: 73472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1148: 1.2698265314102173\n",
      "Seen so far: 73536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1149: 0.6159101128578186\n",
      "Seen so far: 73600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1150: 0.7370858192443848\n",
      "Seen so far: 73664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1151: 0.672182023525238\n",
      "Seen so far: 73728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1152: 0.6706050634384155\n",
      "Seen so far: 73792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1153: 0.8586225509643555\n",
      "Seen so far: 73856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1154: 0.5451487302780151\n",
      "Seen so far: 73920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1155: 1.0455255508422852\n",
      "Seen so far: 73984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1156: 0.7157885432243347\n",
      "Seen so far: 74048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1157: 0.8215818405151367\n",
      "Seen so far: 74112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1158: 0.9981471300125122\n",
      "Seen so far: 74176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1159: 0.815147876739502\n",
      "Seen so far: 74240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1160: 0.8328328132629395\n",
      "Seen so far: 74304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1161: 0.709936261177063\n",
      "Seen so far: 74368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1162: 0.568537175655365\n",
      "Seen so far: 74432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1163: 0.5867910981178284\n",
      "Seen so far: 74496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1164: 0.7907900214195251\n",
      "Seen so far: 74560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1165: 0.7733691930770874\n",
      "Seen so far: 74624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1166: 0.9856680631637573\n",
      "Seen so far: 74688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1167: 0.8164753913879395\n",
      "Seen so far: 74752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1168: 0.45414450764656067\n",
      "Seen so far: 74816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1169: 0.6676427125930786\n",
      "Seen so far: 74880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1170: 0.9206750392913818\n",
      "Seen so far: 74944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1171: 0.7100040316581726\n",
      "Seen so far: 75008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1172: 1.0972799062728882\n",
      "Seen so far: 75072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1173: 0.8204079866409302\n",
      "Seen so far: 75136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1174: 0.9387941360473633\n",
      "Seen so far: 75200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1175: 1.30715012550354\n",
      "Seen so far: 75264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1176: 0.9923279285430908\n",
      "Seen so far: 75328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1177: 0.9781486988067627\n",
      "Seen so far: 75392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1178: 1.2737221717834473\n",
      "Seen so far: 75456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1179: 0.378795325756073\n",
      "Seen so far: 75520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1180: 0.6526777148246765\n",
      "Seen so far: 75584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1181: 0.9018063545227051\n",
      "Seen so far: 75648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1182: 1.2838667631149292\n",
      "Seen so far: 75712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1183: 0.9884305596351624\n",
      "Seen so far: 75776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1184: 0.8652552366256714\n",
      "Seen so far: 75840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1185: 0.6168490052223206\n",
      "Seen so far: 75904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1186: 0.6610620021820068\n",
      "Seen so far: 75968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1187: 0.986036479473114\n",
      "Seen so far: 76032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1188: 0.8815692663192749\n",
      "Seen so far: 76096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1189: 0.5503088235855103\n",
      "Seen so far: 76160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1190: 0.606859028339386\n",
      "Seen so far: 76224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1191: 0.48579949140548706\n",
      "Seen so far: 76288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1192: 1.2794016599655151\n",
      "Seen so far: 76352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1193: 0.6866835355758667\n",
      "Seen so far: 76416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1194: 1.1868014335632324\n",
      "Seen so far: 76480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1195: 0.6237300038337708\n",
      "Seen so far: 76544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1196: 0.6307567358016968\n",
      "Seen so far: 76608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1197: 0.8920998573303223\n",
      "Seen so far: 76672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1198: 0.9821150898933411\n",
      "Seen so far: 76736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1199: 1.0583449602127075\n",
      "Seen so far: 76800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1200: 0.7415599822998047\n",
      "Seen so far: 76864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1201: 0.8698095679283142\n",
      "Seen so far: 76928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1202: 0.8199268579483032\n",
      "Seen so far: 76992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1203: 0.6780703067779541\n",
      "Seen so far: 77056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1204: 0.9225472211837769\n",
      "Seen so far: 77120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1205: 0.7270790934562683\n",
      "Seen so far: 77184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1206: 0.5883074998855591\n",
      "Seen so far: 77248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1207: 0.8235379457473755\n",
      "Seen so far: 77312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1208: 1.0923678874969482\n",
      "Seen so far: 77376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1209: 0.9649060964584351\n",
      "Seen so far: 77440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1210: 0.7230440378189087\n",
      "Seen so far: 77504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1211: 0.7764021158218384\n",
      "Seen so far: 77568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1212: 0.7212363481521606\n",
      "Seen so far: 77632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1213: 0.7661543488502502\n",
      "Seen so far: 77696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1214: 1.2932989597320557\n",
      "Seen so far: 77760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1215: 0.38107648491859436\n",
      "Seen so far: 77824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1216: 0.6995882391929626\n",
      "Seen so far: 77888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1217: 0.7252057790756226\n",
      "Seen so far: 77952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1218: 0.890669584274292\n",
      "Seen so far: 78016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1219: 1.1050992012023926\n",
      "Seen so far: 78080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1220: 0.6781294941902161\n",
      "Seen so far: 78144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1221: 0.6145243048667908\n",
      "Seen so far: 78208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1222: 0.7673720121383667\n",
      "Seen so far: 78272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1223: 0.7465037107467651\n",
      "Seen so far: 78336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1224: 0.5620602965354919\n",
      "Seen so far: 78400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1225: 1.1227275133132935\n",
      "Seen so far: 78464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1226: 0.8354291319847107\n",
      "Seen so far: 78528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1227: 0.7381624579429626\n",
      "Seen so far: 78592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1228: 0.7416909337043762\n",
      "Seen so far: 78656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1229: 0.9122382402420044\n",
      "Seen so far: 78720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1230: 0.8774168491363525\n",
      "Seen so far: 78784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1231: 0.8082982301712036\n",
      "Seen so far: 78848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1232: 0.9309344291687012\n",
      "Seen so far: 78912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1233: 0.6477989554405212\n",
      "Seen so far: 78976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1234: 1.0581822395324707\n",
      "Seen so far: 79040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1235: 0.6297854781150818\n",
      "Seen so far: 79104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1236: 0.853703498840332\n",
      "Seen so far: 79168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1237: 0.7530352473258972\n",
      "Seen so far: 79232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1238: 0.9947342276573181\n",
      "Seen so far: 79296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1239: 0.750340461730957\n",
      "Seen so far: 79360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1240: 0.9727851152420044\n",
      "Seen so far: 79424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1241: 0.9484341740608215\n",
      "Seen so far: 79488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1242: 0.7685273289680481\n",
      "Seen so far: 79552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1243: 1.014286756515503\n",
      "Seen so far: 79616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1244: 0.6996586322784424\n",
      "Seen so far: 79680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1245: 0.9093601703643799\n",
      "Seen so far: 79744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1246: 0.7997265458106995\n",
      "Seen so far: 79808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1247: 0.5580763220787048\n",
      "Seen so far: 79872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1248: 0.6234807372093201\n",
      "Seen so far: 79936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1249: 1.0582917928695679\n",
      "Seen so far: 80000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1250: 0.7653918266296387\n",
      "Seen so far: 80064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1251: 0.41842132806777954\n",
      "Seen so far: 80128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1252: 0.8827019929885864\n",
      "Seen so far: 80192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1253: 0.5812824964523315\n",
      "Seen so far: 80256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1254: 0.7155059576034546\n",
      "Seen so far: 80320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1255: 0.6944634914398193\n",
      "Seen so far: 80384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1256: 1.154707908630371\n",
      "Seen so far: 80448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1257: 0.9342204332351685\n",
      "Seen so far: 80512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1258: 0.6469206213951111\n",
      "Seen so far: 80576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1259: 0.6585007905960083\n",
      "Seen so far: 80640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1260: 0.5521068572998047\n",
      "Seen so far: 80704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1261: 0.521639883518219\n",
      "Seen so far: 80768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1262: 0.8125088810920715\n",
      "Seen so far: 80832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1263: 0.5210592746734619\n",
      "Seen so far: 80896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1264: 0.8784947395324707\n",
      "Seen so far: 80960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1265: 0.8695603609085083\n",
      "Seen so far: 81024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1266: 0.5776846408843994\n",
      "Seen so far: 81088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1267: 0.6330100297927856\n",
      "Seen so far: 81152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1268: 0.6497297286987305\n",
      "Seen so far: 81216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1269: 0.8992077112197876\n",
      "Seen so far: 81280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1270: 1.1805813312530518\n",
      "Seen so far: 81344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1271: 0.6239708065986633\n",
      "Seen so far: 81408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1272: 1.0196990966796875\n",
      "Seen so far: 81472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1273: 0.9771386384963989\n",
      "Seen so far: 81536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1274: 0.4211295545101166\n",
      "Seen so far: 81600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1275: 0.760623574256897\n",
      "Seen so far: 81664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1276: 0.499664843082428\n",
      "Seen so far: 81728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1277: 0.739819347858429\n",
      "Seen so far: 81792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1278: 1.1005167961120605\n",
      "Seen so far: 81856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1279: 0.913654088973999\n",
      "Seen so far: 81920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1280: 0.9500253796577454\n",
      "Seen so far: 81984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1281: 0.6286830902099609\n",
      "Seen so far: 82048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1282: 0.8001519441604614\n",
      "Seen so far: 82112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1283: 0.6984344124794006\n",
      "Seen so far: 82176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1284: 1.093015193939209\n",
      "Seen so far: 82240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1285: 1.079399824142456\n",
      "Seen so far: 82304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1286: 0.6823931932449341\n",
      "Seen so far: 82368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1287: 0.8071886301040649\n",
      "Seen so far: 82432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1288: 0.6774508953094482\n",
      "Seen so far: 82496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1289: 0.9773872494697571\n",
      "Seen so far: 82560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1290: 0.47676852345466614\n",
      "Seen so far: 82624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1291: 0.9463292360305786\n",
      "Seen so far: 82688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1292: 0.32083845138549805\n",
      "Seen so far: 82752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1293: 0.7887505292892456\n",
      "Seen so far: 82816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1294: 0.9134668111801147\n",
      "Seen so far: 82880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1295: 0.7799299359321594\n",
      "Seen so far: 82944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1296: 0.4769335687160492\n",
      "Seen so far: 83008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1297: 0.9186570644378662\n",
      "Seen so far: 83072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1298: 0.5601055026054382\n",
      "Seen so far: 83136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1299: 0.6767325401306152\n",
      "Seen so far: 83200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1300: 0.9665030241012573\n",
      "Seen so far: 83264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1301: 0.719246506690979\n",
      "Seen so far: 83328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1302: 0.9866244792938232\n",
      "Seen so far: 83392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1303: 0.9212732315063477\n",
      "Seen so far: 83456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1304: 0.4745008945465088\n",
      "Seen so far: 83520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1305: 0.6812494993209839\n",
      "Seen so far: 83584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1306: 0.8668102622032166\n",
      "Seen so far: 83648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1307: 0.5475539565086365\n",
      "Seen so far: 83712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1308: 0.7803347110748291\n",
      "Seen so far: 83776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1309: 0.5228750109672546\n",
      "Seen so far: 83840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1310: 0.4658331871032715\n",
      "Seen so far: 83904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1311: 0.602529764175415\n",
      "Seen so far: 83968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1312: 0.6150670051574707\n",
      "Seen so far: 84032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1313: 0.6966413259506226\n",
      "Seen so far: 84096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1314: 0.5250734090805054\n",
      "Seen so far: 84160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1315: 0.8991693258285522\n",
      "Seen so far: 84224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1316: 0.8771859407424927\n",
      "Seen so far: 84288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1317: 1.196081519126892\n",
      "Seen so far: 84352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1318: 0.7456382513046265\n",
      "Seen so far: 84416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1319: 0.8833743333816528\n",
      "Seen so far: 84480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1320: 0.9633713960647583\n",
      "Seen so far: 84544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1321: 1.2647104263305664\n",
      "Seen so far: 84608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1322: 0.8270589709281921\n",
      "Seen so far: 84672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1323: 0.7356487512588501\n",
      "Seen so far: 84736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1324: 0.6187721490859985\n",
      "Seen so far: 84800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1325: 0.8005744218826294\n",
      "Seen so far: 84864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1326: 0.8572952747344971\n",
      "Seen so far: 84928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1327: 0.6967228651046753\n",
      "Seen so far: 84992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1328: 0.8852150440216064\n",
      "Seen so far: 85056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1329: 0.8424814939498901\n",
      "Seen so far: 85120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1330: 0.7074123620986938\n",
      "Seen so far: 85184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1331: 0.887847900390625\n",
      "Seen so far: 85248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1332: 0.887946367263794\n",
      "Seen so far: 85312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1333: 0.9581462740898132\n",
      "Seen so far: 85376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1334: 0.9372749924659729\n",
      "Seen so far: 85440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1335: 0.8079274892807007\n",
      "Seen so far: 85504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1336: 0.7721831798553467\n",
      "Seen so far: 85568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1337: 0.6035326719284058\n",
      "Seen so far: 85632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1338: 1.0274474620819092\n",
      "Seen so far: 85696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1339: 0.8072373270988464\n",
      "Seen so far: 85760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1340: 1.4868409633636475\n",
      "Seen so far: 85824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1341: 0.9715672731399536\n",
      "Seen so far: 85888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1342: 0.5717712640762329\n",
      "Seen so far: 85952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1343: 0.7773892879486084\n",
      "Seen so far: 86016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1344: 1.1182160377502441\n",
      "Seen so far: 86080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1345: 0.6241859197616577\n",
      "Seen so far: 86144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1346: 1.0051867961883545\n",
      "Seen so far: 86208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1347: 0.6477549076080322\n",
      "Seen so far: 86272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1348: 0.9567925930023193\n",
      "Seen so far: 86336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1349: 1.1199887990951538\n",
      "Seen so far: 86400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1350: 1.0016274452209473\n",
      "Seen so far: 86464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1351: 0.5590002536773682\n",
      "Seen so far: 86528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1352: 1.1545393466949463\n",
      "Seen so far: 86592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1353: 0.5313270092010498\n",
      "Seen so far: 86656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1354: 1.1066639423370361\n",
      "Seen so far: 86720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1355: 0.9185868501663208\n",
      "Seen so far: 86784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1356: 0.5983688235282898\n",
      "Seen so far: 86848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1357: 1.0811935663223267\n",
      "Seen so far: 86912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1358: 0.6915409564971924\n",
      "Seen so far: 86976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1359: 0.7549809217453003\n",
      "Seen so far: 87040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1360: 0.9157366752624512\n",
      "Seen so far: 87104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1361: 0.6526444554328918\n",
      "Seen so far: 87168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1362: 0.8098885416984558\n",
      "Seen so far: 87232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1363: 0.8369607329368591\n",
      "Seen so far: 87296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1364: 0.9282187223434448\n",
      "Seen so far: 87360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1365: 0.8300192356109619\n",
      "Seen so far: 87424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1366: 0.8712091445922852\n",
      "Seen so far: 87488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1367: 1.370255708694458\n",
      "Seen so far: 87552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1368: 0.8820226192474365\n",
      "Seen so far: 87616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1369: 0.5744845271110535\n",
      "Seen so far: 87680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1370: 0.7424672842025757\n",
      "Seen so far: 87744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1371: 0.6647208333015442\n",
      "Seen so far: 87808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1372: 1.0039055347442627\n",
      "Seen so far: 87872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1373: 0.7394789457321167\n",
      "Seen so far: 87936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1374: 0.8257532715797424\n",
      "Seen so far: 88000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1375: 0.9030625820159912\n",
      "Seen so far: 88064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1376: 1.0060625076293945\n",
      "Seen so far: 88128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1377: 0.9874125719070435\n",
      "Seen so far: 88192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1378: 0.8995463848114014\n",
      "Seen so far: 88256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1379: 0.8626308441162109\n",
      "Seen so far: 88320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1380: 0.9428696036338806\n",
      "Seen so far: 88384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1381: 0.7216492891311646\n",
      "Seen so far: 88448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1382: 0.6956299543380737\n",
      "Seen so far: 88512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1383: 0.9094552993774414\n",
      "Seen so far: 88576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1384: 0.5004414319992065\n",
      "Seen so far: 88640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1385: 0.6094455718994141\n",
      "Seen so far: 88704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1386: 0.8541103601455688\n",
      "Seen so far: 88768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1387: 0.8905795812606812\n",
      "Seen so far: 88832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1388: 1.0071196556091309\n",
      "Seen so far: 88896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1389: 0.5512557029724121\n",
      "Seen so far: 88960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1390: 0.9081156253814697\n",
      "Seen so far: 89024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1391: 1.0830659866333008\n",
      "Seen so far: 89088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1392: 0.9571195840835571\n",
      "Seen so far: 89152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1393: 1.2673008441925049\n",
      "Seen so far: 89216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1394: 0.6311273574829102\n",
      "Seen so far: 89280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1395: 0.7166248559951782\n",
      "Seen so far: 89344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1396: 0.9313949942588806\n",
      "Seen so far: 89408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1397: 0.8590810298919678\n",
      "Seen so far: 89472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1398: 0.9081881642341614\n",
      "Seen so far: 89536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1399: 1.0689573287963867\n",
      "Seen so far: 89600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1400: 0.8749300241470337\n",
      "Seen so far: 89664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1401: 0.6413152813911438\n",
      "Seen so far: 89728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1402: 0.8298474550247192\n",
      "Seen so far: 89792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1403: 0.8979851007461548\n",
      "Seen so far: 89856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1404: 0.5839977264404297\n",
      "Seen so far: 89920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1405: 0.5490764379501343\n",
      "Seen so far: 89984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1406: 1.3920714855194092\n",
      "Seen so far: 90048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1407: 0.6334011554718018\n",
      "Seen so far: 90112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1408: 0.6729655265808105\n",
      "Seen so far: 90176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1409: 0.7130515575408936\n",
      "Seen so far: 90240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1410: 0.8917620182037354\n",
      "Seen so far: 90304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1411: 1.04547119140625\n",
      "Seen so far: 90368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1412: 1.050995945930481\n",
      "Seen so far: 90432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1413: 0.8956006169319153\n",
      "Seen so far: 90496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1414: 0.605656623840332\n",
      "Seen so far: 90560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1415: 0.6805629730224609\n",
      "Seen so far: 90624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1416: 0.8093031644821167\n",
      "Seen so far: 90688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1417: 0.8318008184432983\n",
      "Seen so far: 90752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1418: 0.7763065099716187\n",
      "Seen so far: 90816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1419: 0.9223748445510864\n",
      "Seen so far: 90880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1420: 0.6665737628936768\n",
      "Seen so far: 90944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1421: 0.525015115737915\n",
      "Seen so far: 91008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1422: 0.8247091770172119\n",
      "Seen so far: 91072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1423: 0.9254127740859985\n",
      "Seen so far: 91136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1424: 0.88601154088974\n",
      "Seen so far: 91200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1425: 0.4475420117378235\n",
      "Seen so far: 91264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1426: 0.7205953598022461\n",
      "Seen so far: 91328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1427: 0.7821740508079529\n",
      "Seen so far: 91392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1428: 0.9359763264656067\n",
      "Seen so far: 91456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1429: 0.6912312507629395\n",
      "Seen so far: 91520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1430: 0.7187914252281189\n",
      "Seen so far: 91584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1431: 1.012647271156311\n",
      "Seen so far: 91648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1432: 0.3756609261035919\n",
      "Seen so far: 91712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1433: 0.8097100257873535\n",
      "Seen so far: 91776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1434: 0.48854655027389526\n",
      "Seen so far: 91840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1435: 0.814116358757019\n",
      "Seen so far: 91904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1436: 0.7290747761726379\n",
      "Seen so far: 91968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1437: 0.72249436378479\n",
      "Seen so far: 92032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1438: 0.8902280926704407\n",
      "Seen so far: 92096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1439: 0.9242467284202576\n",
      "Seen so far: 92160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1440: 0.8548822402954102\n",
      "Seen so far: 92224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1441: 0.656104326248169\n",
      "Seen so far: 92288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1442: 1.0227009057998657\n",
      "Seen so far: 92352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1443: 0.9468840956687927\n",
      "Seen so far: 92416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1444: 1.1252930164337158\n",
      "Seen so far: 92480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1445: 0.9636303186416626\n",
      "Seen so far: 92544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1446: 0.7120224237442017\n",
      "Seen so far: 92608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1447: 0.4696723222732544\n",
      "Seen so far: 92672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1448: 0.4922849237918854\n",
      "Seen so far: 92736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1449: 1.1744590997695923\n",
      "Seen so far: 92800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1450: 0.44916021823883057\n",
      "Seen so far: 92864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1451: 0.9746110439300537\n",
      "Seen so far: 92928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1452: 0.48793280124664307\n",
      "Seen so far: 92992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1453: 0.9532182812690735\n",
      "Seen so far: 93056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1454: 0.675420343875885\n",
      "Seen so far: 93120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1455: 1.1148130893707275\n",
      "Seen so far: 93184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1456: 0.6034722328186035\n",
      "Seen so far: 93248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1457: 0.9886254072189331\n",
      "Seen so far: 93312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1458: 0.9281615018844604\n",
      "Seen so far: 93376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1459: 0.8638827800750732\n",
      "Seen so far: 93440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1460: 0.9656404852867126\n",
      "Seen so far: 93504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1461: 0.75099778175354\n",
      "Seen so far: 93568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1462: 0.7769620418548584\n",
      "Seen so far: 93632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1463: 1.0202922821044922\n",
      "Seen so far: 93696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1464: 0.49966132640838623\n",
      "Seen so far: 93760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1465: 0.9075223803520203\n",
      "Seen so far: 93824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1466: 0.7860761880874634\n",
      "Seen so far: 93888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1467: 0.6390061974525452\n",
      "Seen so far: 93952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1468: 0.7623977661132812\n",
      "Seen so far: 94016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1469: 0.6355468034744263\n",
      "Seen so far: 94080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1470: 1.095886468887329\n",
      "Seen so far: 94144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1471: 0.30447253584861755\n",
      "Seen so far: 94208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1472: 0.7444795370101929\n",
      "Seen so far: 94272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1473: 0.7611315250396729\n",
      "Seen so far: 94336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1474: 0.5913681387901306\n",
      "Seen so far: 94400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1475: 1.1285446882247925\n",
      "Seen so far: 94464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1476: 0.44973650574684143\n",
      "Seen so far: 94528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1477: 0.5244474411010742\n",
      "Seen so far: 94592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1478: 1.1993263959884644\n",
      "Seen so far: 94656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1479: 0.7815393209457397\n",
      "Seen so far: 94720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1480: 0.7501342296600342\n",
      "Seen so far: 94784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1481: 0.8733167052268982\n",
      "Seen so far: 94848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1482: 0.449678897857666\n",
      "Seen so far: 94912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1483: 0.941382884979248\n",
      "Seen so far: 94976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1484: 0.601330041885376\n",
      "Seen so far: 95040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1485: 0.722980260848999\n",
      "Seen so far: 95104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1486: 0.5645890831947327\n",
      "Seen so far: 95168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1487: 0.4367574155330658\n",
      "Seen so far: 95232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1488: 0.8645764589309692\n",
      "Seen so far: 95296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1489: 0.6836211681365967\n",
      "Seen so far: 95360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1490: 0.6986016035079956\n",
      "Seen so far: 95424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1491: 0.5201765298843384\n",
      "Seen so far: 95488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1492: 0.8548842072486877\n",
      "Seen so far: 95552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1493: 0.7935996055603027\n",
      "Seen so far: 95616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1494: 0.8059861660003662\n",
      "Seen so far: 95680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1495: 1.2773144245147705\n",
      "Seen so far: 95744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1496: 0.7829298973083496\n",
      "Seen so far: 95808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1497: 1.0636333227157593\n",
      "Seen so far: 95872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1498: 0.6911423206329346\n",
      "Seen so far: 95936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1499: 0.8505842685699463\n",
      "Seen so far: 96000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1500: 0.7127365469932556\n",
      "Seen so far: 96064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1501: 1.1218154430389404\n",
      "Seen so far: 96128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1502: 0.7656069397926331\n",
      "Seen so far: 96192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1503: 0.4055803418159485\n",
      "Seen so far: 96256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1504: 0.8086435794830322\n",
      "Seen so far: 96320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1505: 1.054932951927185\n",
      "Seen so far: 96384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1506: 0.5295457243919373\n",
      "Seen so far: 96448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1507: 1.5010130405426025\n",
      "Seen so far: 96512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1508: 0.5931938886642456\n",
      "Seen so far: 96576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1509: 1.0945141315460205\n",
      "Seen so far: 96640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1510: 1.4700260162353516\n",
      "Seen so far: 96704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1511: 0.7192248106002808\n",
      "Seen so far: 96768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1512: 0.7767876982688904\n",
      "Seen so far: 96832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1513: 0.8034539818763733\n",
      "Seen so far: 96896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1514: 0.9785698652267456\n",
      "Seen so far: 96960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1515: 1.3840579986572266\n",
      "Seen so far: 97024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1516: 0.7588879466056824\n",
      "Seen so far: 97088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1517: 1.3850038051605225\n",
      "Seen so far: 97152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1518: 1.0085734128952026\n",
      "Seen so far: 97216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1519: 0.5970527529716492\n",
      "Seen so far: 97280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1520: 0.6710212826728821\n",
      "Seen so far: 97344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1521: 0.7755684852600098\n",
      "Seen so far: 97408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1522: 0.9690706729888916\n",
      "Seen so far: 97472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1523: 1.060737133026123\n",
      "Seen so far: 97536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1524: 0.9235379695892334\n",
      "Seen so far: 97600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1525: 1.2448914051055908\n",
      "Seen so far: 97664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1526: 1.086200475692749\n",
      "Seen so far: 97728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1527: 0.6242081522941589\n",
      "Seen so far: 97792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1528: 0.4900422692298889\n",
      "Seen so far: 97856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1529: 0.7800524830818176\n",
      "Seen so far: 97920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1530: 0.7289941310882568\n",
      "Seen so far: 97984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1531: 0.36967435479164124\n",
      "Seen so far: 98048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1532: 0.9407083988189697\n",
      "Seen so far: 98112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1533: 0.6531455516815186\n",
      "Seen so far: 98176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1534: 0.936814546585083\n",
      "Seen so far: 98240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1535: 0.5185683965682983\n",
      "Seen so far: 98304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1536: 0.7479026913642883\n",
      "Seen so far: 98368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1537: 0.7300125360488892\n",
      "Seen so far: 98432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1538: 0.8160427808761597\n",
      "Seen so far: 98496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1539: 0.6268928050994873\n",
      "Seen so far: 98560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1540: 0.6096347570419312\n",
      "Seen so far: 98624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1541: 0.5153253078460693\n",
      "Seen so far: 98688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1542: 0.6374197602272034\n",
      "Seen so far: 98752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1543: 0.9375919103622437\n",
      "Seen so far: 98816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1544: 0.5469069480895996\n",
      "Seen so far: 98880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1545: 0.4975928068161011\n",
      "Seen so far: 98944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1546: 0.8420737385749817\n",
      "Seen so far: 99008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1547: 0.909240186214447\n",
      "Seen so far: 99072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1548: 0.8661196231842041\n",
      "Seen so far: 99136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1549: 0.6216803193092346\n",
      "Seen so far: 99200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1550: 0.8069593906402588\n",
      "Seen so far: 99264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1551: 1.2660714387893677\n",
      "Seen so far: 99328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1552: 0.6252132654190063\n",
      "Seen so far: 99392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1553: 0.5347344875335693\n",
      "Seen so far: 99456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1554: 1.1048274040222168\n",
      "Seen so far: 99520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1555: 0.8968701362609863\n",
      "Seen so far: 99584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1556: 0.9741844534873962\n",
      "Seen so far: 99648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1557: 0.97503662109375\n",
      "Seen so far: 99712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1558: 0.7534695863723755\n",
      "Seen so far: 99776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1559: 0.4441354274749756\n",
      "Seen so far: 99840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1560: 1.3447335958480835\n",
      "Seen so far: 99904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1561: 0.7415343523025513\n",
      "Seen so far: 99968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1562: 0.8189327716827393\n",
      "Seen so far: 100032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1563: 0.7040648460388184\n",
      "Seen so far: 100096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1564: 0.9892138838768005\n",
      "Seen so far: 100160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1565: 0.970011830329895\n",
      "Seen so far: 100224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1566: 0.8669365644454956\n",
      "Seen so far: 100288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1567: 0.5505330562591553\n",
      "Seen so far: 100352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1568: 0.6619937419891357\n",
      "Seen so far: 100416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1569: 0.6682285070419312\n",
      "Seen so far: 100480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1570: 1.1612038612365723\n",
      "Seen so far: 100544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1571: 1.0768288373947144\n",
      "Seen so far: 100608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1572: 0.4964490830898285\n",
      "Seen so far: 100672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1573: 1.0897419452667236\n",
      "Seen so far: 100736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1574: 0.7265084981918335\n",
      "Seen so far: 100800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1575: 0.9314300417900085\n",
      "Seen so far: 100864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1576: 0.8271827697753906\n",
      "Seen so far: 100928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1577: 0.7071046829223633\n",
      "Seen so far: 100992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1578: 0.9658913016319275\n",
      "Seen so far: 101056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1579: 0.6541690826416016\n",
      "Seen so far: 101120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1580: 0.8639346361160278\n",
      "Seen so far: 101184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1581: 0.7824549674987793\n",
      "Seen so far: 101248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1582: 0.9013441801071167\n",
      "Seen so far: 101312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1583: 0.7277576923370361\n",
      "Seen so far: 101376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1584: 0.8807805180549622\n",
      "Seen so far: 101440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1585: 1.342132568359375\n",
      "Seen so far: 101504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1586: 0.7472460269927979\n",
      "Seen so far: 101568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1587: 0.5857622027397156\n",
      "Seen so far: 101632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1588: 0.5201154351234436\n",
      "Seen so far: 101696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1589: 0.8478110432624817\n",
      "Seen so far: 101760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1590: 0.851479172706604\n",
      "Seen so far: 101824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1591: 0.8679513931274414\n",
      "Seen so far: 101888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1592: 0.7134064435958862\n",
      "Seen so far: 101952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1593: 0.6603102684020996\n",
      "Seen so far: 102016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1594: 0.5658538341522217\n",
      "Seen so far: 102080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1595: 1.0555263757705688\n",
      "Seen so far: 102144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1596: 0.7005503177642822\n",
      "Seen so far: 102208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1597: 0.9120312929153442\n",
      "Seen so far: 102272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1598: 0.6386611461639404\n",
      "Seen so far: 102336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1599: 0.8771501779556274\n",
      "Seen so far: 102400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1600: 0.35301077365875244\n",
      "Seen so far: 102464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1601: 0.7402041554450989\n",
      "Seen so far: 102528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1602: 0.4595918655395508\n",
      "Seen so far: 102592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1603: 1.2052417993545532\n",
      "Seen so far: 102656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1604: 0.7067544460296631\n",
      "Seen so far: 102720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1605: 1.3557313680648804\n",
      "Seen so far: 102784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1606: 0.9147505164146423\n",
      "Seen so far: 102848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1607: 0.7028974890708923\n",
      "Seen so far: 102912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1608: 0.8069795370101929\n",
      "Seen so far: 102976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1609: 0.8393480777740479\n",
      "Seen so far: 103040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1610: 0.935143768787384\n",
      "Seen so far: 103104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1611: 0.7639739513397217\n",
      "Seen so far: 103168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1612: 0.8981813192367554\n",
      "Seen so far: 103232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1613: 1.0398961305618286\n",
      "Seen so far: 103296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1614: 0.7129501104354858\n",
      "Seen so far: 103360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1615: 0.7757059335708618\n",
      "Seen so far: 103424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1616: 0.793720006942749\n",
      "Seen so far: 103488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1617: 0.760584831237793\n",
      "Seen so far: 103552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1618: 0.6345025300979614\n",
      "Seen so far: 103616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1619: 0.8499279022216797\n",
      "Seen so far: 103680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1620: 0.7386084794998169\n",
      "Seen so far: 103744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1621: 0.6268776655197144\n",
      "Seen so far: 103808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1622: 0.7894827127456665\n",
      "Seen so far: 103872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1623: 0.9705543518066406\n",
      "Seen so far: 103936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1624: 0.6477773189544678\n",
      "Seen so far: 104000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1625: 1.1303900480270386\n",
      "Seen so far: 104064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1626: 0.8676770925521851\n",
      "Seen so far: 104128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1627: 0.7482520937919617\n",
      "Seen so far: 104192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1628: 0.7572214603424072\n",
      "Seen so far: 104256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1629: 0.6479815244674683\n",
      "Seen so far: 104320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1630: 0.9487615823745728\n",
      "Seen so far: 104384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1631: 0.7392170429229736\n",
      "Seen so far: 104448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1632: 0.9939905405044556\n",
      "Seen so far: 104512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1633: 0.8325260281562805\n",
      "Seen so far: 104576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1634: 0.9255363941192627\n",
      "Seen so far: 104640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1635: 0.7442736625671387\n",
      "Seen so far: 104704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1636: 0.7510845065116882\n",
      "Seen so far: 104768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1637: 0.4502616822719574\n",
      "Seen so far: 104832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1638: 0.8720672130584717\n",
      "Seen so far: 104896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1639: 0.5791791677474976\n",
      "Seen so far: 104960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1640: 0.7614941596984863\n",
      "Seen so far: 105024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1641: 0.7050814628601074\n",
      "Seen so far: 105088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1642: 0.8965048789978027\n",
      "Seen so far: 105152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1643: 1.2251636981964111\n",
      "Seen so far: 105216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1644: 0.7902481555938721\n",
      "Seen so far: 105280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1645: 0.9953137636184692\n",
      "Seen so far: 105344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1646: 0.7672476768493652\n",
      "Seen so far: 105408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1647: 0.5992709398269653\n",
      "Seen so far: 105472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1648: 0.7696537375450134\n",
      "Seen so far: 105536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1649: 0.8944392800331116\n",
      "Seen so far: 105600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1650: 0.7590175867080688\n",
      "Seen so far: 105664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1651: 0.970814049243927\n",
      "Seen so far: 105728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1652: 0.703417181968689\n",
      "Seen so far: 105792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1653: 0.6444040536880493\n",
      "Seen so far: 105856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1654: 0.7334276437759399\n",
      "Seen so far: 105920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1655: 0.7912603616714478\n",
      "Seen so far: 105984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1656: 0.4528539180755615\n",
      "Seen so far: 106048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1657: 0.7388575077056885\n",
      "Seen so far: 106112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1658: 0.5320913791656494\n",
      "Seen so far: 106176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1659: 0.8621417284011841\n",
      "Seen so far: 106240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1660: 0.9404191970825195\n",
      "Seen so far: 106304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1661: 0.7436145544052124\n",
      "Seen so far: 106368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1662: 0.4903365969657898\n",
      "Seen so far: 106432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1663: 0.8065201640129089\n",
      "Seen so far: 106496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1664: 0.9960423707962036\n",
      "Seen so far: 106560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1665: 1.2417514324188232\n",
      "Seen so far: 106624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1666: 0.7709242105484009\n",
      "Seen so far: 106688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1667: 0.5826067924499512\n",
      "Seen so far: 106752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1668: 1.0265976190567017\n",
      "Seen so far: 106816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1669: 0.496751606464386\n",
      "Seen so far: 106880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1670: 0.6565893888473511\n",
      "Seen so far: 106944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1671: 0.8418642282485962\n",
      "Seen so far: 107008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1672: 0.9809378385543823\n",
      "Seen so far: 107072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1673: 0.5080158710479736\n",
      "Seen so far: 107136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1674: 0.6955407857894897\n",
      "Seen so far: 107200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1675: 1.1054134368896484\n",
      "Seen so far: 107264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1676: 0.6328085660934448\n",
      "Seen so far: 107328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1677: 0.644663393497467\n",
      "Seen so far: 107392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1678: 0.7648801803588867\n",
      "Seen so far: 107456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1679: 0.8512611985206604\n",
      "Seen so far: 107520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1680: 0.9705935716629028\n",
      "Seen so far: 107584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1681: 1.2364366054534912\n",
      "Seen so far: 107648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1682: 0.7336461544036865\n",
      "Seen so far: 107712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1683: 1.1676303148269653\n",
      "Seen so far: 107776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1684: 0.9262543320655823\n",
      "Seen so far: 107840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1685: 0.9357861280441284\n",
      "Seen so far: 107904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1686: 1.1654515266418457\n",
      "Seen so far: 107968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1687: 1.105920672416687\n",
      "Seen so far: 108032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1688: 1.0015935897827148\n",
      "Seen so far: 108096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1689: 0.7310709357261658\n",
      "Seen so far: 108160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1690: 0.9918296337127686\n",
      "Seen so far: 108224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1691: 0.6061625480651855\n",
      "Seen so far: 108288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1692: 0.6406257152557373\n",
      "Seen so far: 108352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1693: 1.0697598457336426\n",
      "Seen so far: 108416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1694: 1.01369309425354\n",
      "Seen so far: 108480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1695: 0.8910092115402222\n",
      "Seen so far: 108544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1696: 1.005418300628662\n",
      "Seen so far: 108608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1697: 1.014114260673523\n",
      "Seen so far: 108672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1698: 0.4484763443470001\n",
      "Seen so far: 108736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1699: 0.5152910947799683\n",
      "Seen so far: 108800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1700: 0.580690860748291\n",
      "Seen so far: 108864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1701: 0.8487809896469116\n",
      "Seen so far: 108928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1702: 1.0164756774902344\n",
      "Seen so far: 108992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1703: 0.5913400650024414\n",
      "Seen so far: 109056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1704: 1.0215835571289062\n",
      "Seen so far: 109120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1705: 1.0724313259124756\n",
      "Seen so far: 109184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1706: 0.9768401384353638\n",
      "Seen so far: 109248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1707: 0.6261221170425415\n",
      "Seen so far: 109312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1708: 0.9656500816345215\n",
      "Seen so far: 109376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1709: 1.2403638362884521\n",
      "Seen so far: 109440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1710: 0.7200818657875061\n",
      "Seen so far: 109504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1711: 0.45792996883392334\n",
      "Seen so far: 109568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1712: 0.6042308807373047\n",
      "Seen so far: 109632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1713: 0.42882704734802246\n",
      "Seen so far: 109696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1714: 0.852489709854126\n",
      "Seen so far: 109760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1715: 0.5462839603424072\n",
      "Seen so far: 109824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1716: 0.9897496700286865\n",
      "Seen so far: 109888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1717: 0.5739297270774841\n",
      "Seen so far: 109952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1718: 0.7947466969490051\n",
      "Seen so far: 110016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1719: 0.6156154870986938\n",
      "Seen so far: 110080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1720: 0.9431886076927185\n",
      "Seen so far: 110144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1721: 1.0398690700531006\n",
      "Seen so far: 110208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1722: 0.6960943937301636\n",
      "Seen so far: 110272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1723: 0.6150104999542236\n",
      "Seen so far: 110336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1724: 0.8776759505271912\n",
      "Seen so far: 110400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1725: 0.7766544818878174\n",
      "Seen so far: 110464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1726: 1.3098247051239014\n",
      "Seen so far: 110528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1727: 0.7565434575080872\n",
      "Seen so far: 110592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1728: 0.7179992198944092\n",
      "Seen so far: 110656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1729: 0.9505817890167236\n",
      "Seen so far: 110720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1730: 0.7685501575469971\n",
      "Seen so far: 110784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1731: 0.6332931518554688\n",
      "Seen so far: 110848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1732: 1.010000228881836\n",
      "Seen so far: 110912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1733: 1.0454760789871216\n",
      "Seen so far: 110976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1734: 0.6990293860435486\n",
      "Seen so far: 111040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1735: 0.7430627346038818\n",
      "Seen so far: 111104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1736: 0.6884950399398804\n",
      "Seen so far: 111168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1737: 1.0142074823379517\n",
      "Seen so far: 111232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1738: 0.80806565284729\n",
      "Seen so far: 111296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1739: 0.7358037233352661\n",
      "Seen so far: 111360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1740: 1.101803183555603\n",
      "Seen so far: 111424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1741: 0.9502133131027222\n",
      "Seen so far: 111488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1742: 0.7603604793548584\n",
      "Seen so far: 111552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1743: 0.6676583290100098\n",
      "Seen so far: 111616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1744: 0.8925505876541138\n",
      "Seen so far: 111680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1745: 0.9745308756828308\n",
      "Seen so far: 111744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1746: 1.0964415073394775\n",
      "Seen so far: 111808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1747: 1.1921489238739014\n",
      "Seen so far: 111872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1748: 0.7241036891937256\n",
      "Seen so far: 111936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1749: 0.565144419670105\n",
      "Seen so far: 112000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1750: 0.90638667345047\n",
      "Seen so far: 112064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1751: 0.8546885251998901\n",
      "Seen so far: 112128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1752: 1.0826821327209473\n",
      "Seen so far: 112192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1753: 1.1277598142623901\n",
      "Seen so far: 112256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1754: 1.1229146718978882\n",
      "Seen so far: 112320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1755: 0.8963260650634766\n",
      "Seen so far: 112384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1756: 1.3427398204803467\n",
      "Seen so far: 112448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1757: 0.6350786685943604\n",
      "Seen so far: 112512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1758: 1.2270147800445557\n",
      "Seen so far: 112576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1759: 0.7130466103553772\n",
      "Seen so far: 112640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1760: 0.8737916946411133\n",
      "Seen so far: 112704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1761: 0.7941053509712219\n",
      "Seen so far: 112768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1762: 0.9305484294891357\n",
      "Seen so far: 112832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1763: 0.8849385976791382\n",
      "Seen so far: 112896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1764: 0.9596485495567322\n",
      "Seen so far: 112960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1765: 0.4872303903102875\n",
      "Seen so far: 113024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1766: 0.7184809446334839\n",
      "Seen so far: 113088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1767: 0.8920124173164368\n",
      "Seen so far: 113152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1768: 1.0164949893951416\n",
      "Seen so far: 113216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1769: 0.5704033374786377\n",
      "Seen so far: 113280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1770: 0.6672310829162598\n",
      "Seen so far: 113344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1771: 0.9611035585403442\n",
      "Seen so far: 113408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1772: 0.9257974624633789\n",
      "Seen so far: 113472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1773: 0.8791599273681641\n",
      "Seen so far: 113536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1774: 0.5908961296081543\n",
      "Seen so far: 113600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1775: 0.8275049924850464\n",
      "Seen so far: 113664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1776: 0.9941511750221252\n",
      "Seen so far: 113728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1777: 0.8564736843109131\n",
      "Seen so far: 113792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1778: 0.7602558135986328\n",
      "Seen so far: 113856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1779: 1.2143893241882324\n",
      "Seen so far: 113920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1780: 1.1615068912506104\n",
      "Seen so far: 113984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1781: 1.0577770471572876\n",
      "Seen so far: 114048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1782: 0.39842790365219116\n",
      "Seen so far: 114112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1783: 1.0892720222473145\n",
      "Seen so far: 114176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1784: 0.8814783096313477\n",
      "Seen so far: 114240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1785: 0.7650477886199951\n",
      "Seen so far: 114304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1786: 0.8687520027160645\n",
      "Seen so far: 114368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1787: 0.7458702921867371\n",
      "Seen so far: 114432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1788: 0.5970600843429565\n",
      "Seen so far: 114496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1789: 0.7797054052352905\n",
      "Seen so far: 114560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1790: 0.8206696510314941\n",
      "Seen so far: 114624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1791: 0.6578181982040405\n",
      "Seen so far: 114688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1792: 0.4480958878993988\n",
      "Seen so far: 114752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1793: 0.9489022493362427\n",
      "Seen so far: 114816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1794: 0.5359904766082764\n",
      "Seen so far: 114880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1795: 0.7059105634689331\n",
      "Seen so far: 114944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1796: 0.7493517994880676\n",
      "Seen so far: 115008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1797: 0.3979003429412842\n",
      "Seen so far: 115072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1798: 0.4784502685070038\n",
      "Seen so far: 115136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1799: 0.6729069352149963\n",
      "Seen so far: 115200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1800: 0.8752859234809875\n",
      "Seen so far: 115264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1801: 0.6680096387863159\n",
      "Seen so far: 115328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1802: 0.45014336705207825\n",
      "Seen so far: 115392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1803: 0.9890091419219971\n",
      "Seen so far: 115456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1804: 0.49118179082870483\n",
      "Seen so far: 115520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1805: 0.555206298828125\n",
      "Seen so far: 115584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1806: 0.7327976226806641\n",
      "Seen so far: 115648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1807: 0.732840895652771\n",
      "Seen so far: 115712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1808: 1.0797909498214722\n",
      "Seen so far: 115776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1809: 0.6908738613128662\n",
      "Seen so far: 115840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1810: 0.6902323961257935\n",
      "Seen so far: 115904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1811: 0.854181170463562\n",
      "Seen so far: 115968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1812: 0.6138361692428589\n",
      "Seen so far: 116032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1813: 0.8924658298492432\n",
      "Seen so far: 116096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1814: 0.9123579263687134\n",
      "Seen so far: 116160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1815: 1.3149396181106567\n",
      "Seen so far: 116224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1816: 0.7819903492927551\n",
      "Seen so far: 116288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1817: 0.8068947196006775\n",
      "Seen so far: 116352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1818: 0.8197821974754333\n",
      "Seen so far: 116416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1819: 0.5402500629425049\n",
      "Seen so far: 116480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1820: 0.6698802709579468\n",
      "Seen so far: 116544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1821: 1.0386232137680054\n",
      "Seen so far: 116608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1822: 1.135817050933838\n",
      "Seen so far: 116672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1823: 1.1234900951385498\n",
      "Seen so far: 116736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1824: 1.0306460857391357\n",
      "Seen so far: 116800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1825: 0.6184811592102051\n",
      "Seen so far: 116864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1826: 1.0561832189559937\n",
      "Seen so far: 116928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1827: 0.906586766242981\n",
      "Seen so far: 116992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1828: 0.9829819798469543\n",
      "Seen so far: 117056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1829: 0.8194733262062073\n",
      "Seen so far: 117120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1830: 0.6804035902023315\n",
      "Seen so far: 117184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1831: 0.7608374357223511\n",
      "Seen so far: 117248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1832: 1.163122296333313\n",
      "Seen so far: 117312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1833: 0.7598775625228882\n",
      "Seen so far: 117376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1834: 1.1235278844833374\n",
      "Seen so far: 117440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1835: 0.6174891591072083\n",
      "Seen so far: 117504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1836: 0.8150296211242676\n",
      "Seen so far: 117568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1837: 0.551129162311554\n",
      "Seen so far: 117632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1838: 0.8566822409629822\n",
      "Seen so far: 117696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1839: 0.6277207136154175\n",
      "Seen so far: 117760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1840: 1.2138299942016602\n",
      "Seen so far: 117824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1841: 0.7183051705360413\n",
      "Seen so far: 117888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1842: 0.5191785097122192\n",
      "Seen so far: 117952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1843: 0.8584802150726318\n",
      "Seen so far: 118016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1844: 0.7642725110054016\n",
      "Seen so far: 118080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1845: 0.931991457939148\n",
      "Seen so far: 118144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1846: 0.9830754399299622\n",
      "Seen so far: 118208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1847: 0.8371326923370361\n",
      "Seen so far: 118272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1848: 0.7514938116073608\n",
      "Seen so far: 118336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1849: 1.068331241607666\n",
      "Seen so far: 118400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1850: 0.5556261539459229\n",
      "Seen so far: 118464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1851: 1.1124372482299805\n",
      "Seen so far: 118528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1852: 0.813765287399292\n",
      "Seen so far: 118592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1853: 0.528721809387207\n",
      "Seen so far: 118656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1854: 1.0186431407928467\n",
      "Seen so far: 118720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1855: 1.1540107727050781\n",
      "Seen so far: 118784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1856: 0.7548211812973022\n",
      "Seen so far: 118848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1857: 0.6021298170089722\n",
      "Seen so far: 118912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1858: 0.9366925358772278\n",
      "Seen so far: 118976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1859: 0.5403236150741577\n",
      "Seen so far: 119040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1860: 0.6644673347473145\n",
      "Seen so far: 119104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1861: 0.8731647729873657\n",
      "Seen so far: 119168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1862: 0.6541868448257446\n",
      "Seen so far: 119232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1863: 0.6463921070098877\n",
      "Seen so far: 119296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1864: 0.7293734550476074\n",
      "Seen so far: 119360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1865: 0.7703298330307007\n",
      "Seen so far: 119424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1866: 0.8999716639518738\n",
      "Seen so far: 119488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1867: 0.7769501805305481\n",
      "Seen so far: 119552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1868: 0.5625530481338501\n",
      "Seen so far: 119616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1869: 0.5915310382843018\n",
      "Seen so far: 119680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1870: 0.4937888979911804\n",
      "Seen so far: 119744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1871: 0.7422807216644287\n",
      "Seen so far: 119808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1872: 0.7066930532455444\n",
      "Seen so far: 119872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1873: 0.9600156545639038\n",
      "Seen so far: 119936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1874: 0.7262507677078247\n",
      "Seen so far: 120000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1875: 0.6526857614517212\n",
      "Seen so far: 120064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1876: 0.6579517126083374\n",
      "Seen so far: 120128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1877: 0.5692228078842163\n",
      "Seen so far: 120192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1878: 0.9039876461029053\n",
      "Seen so far: 120256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1879: 0.6261549592018127\n",
      "Seen so far: 120320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1880: 0.7791182398796082\n",
      "Seen so far: 120384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1881: 0.4940054416656494\n",
      "Seen so far: 120448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1882: 0.9055248498916626\n",
      "Seen so far: 120512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1883: 0.4157302975654602\n",
      "Seen so far: 120576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1884: 0.7362726926803589\n",
      "Seen so far: 120640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1885: 0.8375244736671448\n",
      "Seen so far: 120704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1886: 0.6006959080696106\n",
      "Seen so far: 120768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1887: 0.6684789657592773\n",
      "Seen so far: 120832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1888: 0.4440435767173767\n",
      "Seen so far: 120896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1889: 0.9774935841560364\n",
      "Seen so far: 120960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1890: 1.3176538944244385\n",
      "Seen so far: 121024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1891: 0.9720119833946228\n",
      "Seen so far: 121088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1892: 0.8066326975822449\n",
      "Seen so far: 121152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1893: 0.9371500015258789\n",
      "Seen so far: 121216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1894: 0.8041154146194458\n",
      "Seen so far: 121280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1895: 0.6483120918273926\n",
      "Seen so far: 121344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1896: 0.32070812582969666\n",
      "Seen so far: 121408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1897: 0.9343917965888977\n",
      "Seen so far: 121472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1898: 0.5323494672775269\n",
      "Seen so far: 121536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1899: 0.8256392478942871\n",
      "Seen so far: 121600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1900: 0.8758431077003479\n",
      "Seen so far: 121664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1901: 0.6407310962677002\n",
      "Seen so far: 121728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1902: 1.1070301532745361\n",
      "Seen so far: 121792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1903: 0.8042899370193481\n",
      "Seen so far: 121856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1904: 0.8301321864128113\n",
      "Seen so far: 121920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1905: 0.8300613760948181\n",
      "Seen so far: 121984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1906: 0.6603842973709106\n",
      "Seen so far: 122048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1907: 0.9561517834663391\n",
      "Seen so far: 122112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1908: 0.7955359220504761\n",
      "Seen so far: 122176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1909: 0.8516991138458252\n",
      "Seen so far: 122240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1910: 0.6428992748260498\n",
      "Seen so far: 122304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1911: 0.6913548707962036\n",
      "Seen so far: 122368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1912: 0.9650889039039612\n",
      "Seen so far: 122432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1913: 0.7105019092559814\n",
      "Seen so far: 122496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1914: 0.5539547801017761\n",
      "Seen so far: 122560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1915: 0.6609012484550476\n",
      "Seen so far: 122624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1916: 0.7010467648506165\n",
      "Seen so far: 122688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1917: 0.8795127272605896\n",
      "Seen so far: 122752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1918: 0.9922778606414795\n",
      "Seen so far: 122816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1919: 0.9105687737464905\n",
      "Seen so far: 122880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1920: 0.9806182384490967\n",
      "Seen so far: 122944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1921: 0.8333754539489746\n",
      "Seen so far: 123008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1922: 0.9989991784095764\n",
      "Seen so far: 123072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1923: 0.8777653574943542\n",
      "Seen so far: 123136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1924: 0.9135990142822266\n",
      "Seen so far: 123200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1925: 0.7786232233047485\n",
      "Seen so far: 123264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1926: 0.8332375288009644\n",
      "Seen so far: 123328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1927: 0.7579065561294556\n",
      "Seen so far: 123392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1928: 0.5167765617370605\n",
      "Seen so far: 123456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1929: 0.6630427837371826\n",
      "Seen so far: 123520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1930: 1.1107511520385742\n",
      "Seen so far: 123584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1931: 0.9650058746337891\n",
      "Seen so far: 123648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1932: 1.256113052368164\n",
      "Seen so far: 123712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1933: 0.8029488325119019\n",
      "Seen so far: 123776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1934: 0.7391549944877625\n",
      "Seen so far: 123840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1935: 1.0001327991485596\n",
      "Seen so far: 123904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1936: 1.0720610618591309\n",
      "Seen so far: 123968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1937: 0.9094089269638062\n",
      "Seen so far: 124032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1938: 0.58198082447052\n",
      "Seen so far: 124096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1939: 1.1692392826080322\n",
      "Seen so far: 124160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1940: 0.8064733743667603\n",
      "Seen so far: 124224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1941: 0.8280227184295654\n",
      "Seen so far: 124288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1942: 0.7192407846450806\n",
      "Seen so far: 124352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1943: 0.5991668701171875\n",
      "Seen so far: 124416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1944: 0.9591313004493713\n",
      "Seen so far: 124480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1945: 0.8590989112854004\n",
      "Seen so far: 124544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1946: 0.7745521068572998\n",
      "Seen so far: 124608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1947: 0.47739377617836\n",
      "Seen so far: 124672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1948: 1.04263436794281\n",
      "Seen so far: 124736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1949: 0.9514862298965454\n",
      "Seen so far: 124800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1950: 1.089013934135437\n",
      "Seen so far: 124864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1951: 0.5731816291809082\n",
      "Seen so far: 124928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1952: 0.2527513802051544\n",
      "Seen so far: 124992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1953: 0.5631662011146545\n",
      "Seen so far: 125056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1954: 0.7184914946556091\n",
      "Seen so far: 125120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1955: 0.8149359822273254\n",
      "Seen so far: 125184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1956: 0.7362921237945557\n",
      "Seen so far: 125248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1957: 0.7286496162414551\n",
      "Seen so far: 125312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1958: 0.5034587383270264\n",
      "Seen so far: 125376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1959: 0.6141734719276428\n",
      "Seen so far: 125440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1960: 1.0072472095489502\n",
      "Seen so far: 125504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1961: 0.7312714457511902\n",
      "Seen so far: 125568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1962: 0.70160973072052\n",
      "Seen so far: 125632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1963: 0.8400378823280334\n",
      "Seen so far: 125696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1964: 0.6857049465179443\n",
      "Seen so far: 125760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1965: 1.1000170707702637\n",
      "Seen so far: 125824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1966: 0.7098873257637024\n",
      "Seen so far: 125888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1967: 0.7965166568756104\n",
      "Seen so far: 125952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1968: 0.6630653142929077\n",
      "Seen so far: 126016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1969: 0.774333655834198\n",
      "Seen so far: 126080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1970: 0.8656166791915894\n",
      "Seen so far: 126144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1971: 0.6154072284698486\n",
      "Seen so far: 126208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1972: 0.8075063228607178\n",
      "Seen so far: 126272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1973: 0.8008356690406799\n",
      "Seen so far: 126336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1974: 0.8711845278739929\n",
      "Seen so far: 126400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1975: 1.1255030632019043\n",
      "Seen so far: 126464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1976: 0.46315401792526245\n",
      "Seen so far: 126528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1977: 0.7481138706207275\n",
      "Seen so far: 126592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1978: 0.8670234680175781\n",
      "Seen so far: 126656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1979: 0.4003949761390686\n",
      "Seen so far: 126720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1980: 0.8515018224716187\n",
      "Seen so far: 126784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1981: 0.7143653631210327\n",
      "Seen so far: 126848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1982: 0.5031771063804626\n",
      "Seen so far: 126912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1983: 1.05869460105896\n",
      "Seen so far: 126976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1984: 0.9818342328071594\n",
      "Seen so far: 127040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1985: 1.0814207792282104\n",
      "Seen so far: 127104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1986: 0.39791029691696167\n",
      "Seen so far: 127168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1987: 1.0375583171844482\n",
      "Seen so far: 127232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1988: 1.0172374248504639\n",
      "Seen so far: 127296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1989: 0.7461308240890503\n",
      "Seen so far: 127360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1990: 0.9936966896057129\n",
      "Seen so far: 127424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1991: 1.1513960361480713\n",
      "Seen so far: 127488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1992: 0.9769092798233032\n",
      "Seen so far: 127552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1993: 0.8785359263420105\n",
      "Seen so far: 127616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1994: 0.9346869587898254\n",
      "Seen so far: 127680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1995: 0.4374163746833801\n",
      "Seen so far: 127744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1996: 0.8830698728561401\n",
      "Seen so far: 127808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1997: 0.9114056825637817\n",
      "Seen so far: 127872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1998: 0.7842006683349609\n",
      "Seen so far: 127936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1999: 0.6016896963119507\n",
      "Seen so far: 128000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2000: 0.6101502180099487\n",
      "Seen so far: 128064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2001: 0.6849361062049866\n",
      "Seen so far: 128128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2002: 0.9521389007568359\n",
      "Seen so far: 128192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2003: 0.6307093501091003\n",
      "Seen so far: 128256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2004: 0.8193761706352234\n",
      "Seen so far: 128320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2005: 0.7657971382141113\n",
      "Seen so far: 128384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2006: 1.0770313739776611\n",
      "Seen so far: 128448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2007: 0.6650828719139099\n",
      "Seen so far: 128512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2008: 0.6528812646865845\n",
      "Seen so far: 128576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2009: 1.0267956256866455\n",
      "Seen so far: 128640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2010: 1.1946172714233398\n",
      "Seen so far: 128704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2011: 0.8636375665664673\n",
      "Seen so far: 128768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2012: 0.7231686115264893\n",
      "Seen so far: 128832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2013: 0.7019723653793335\n",
      "Seen so far: 128896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2014: 0.7393698692321777\n",
      "Seen so far: 128960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2015: 0.6349164247512817\n",
      "Seen so far: 129024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2016: 0.554512619972229\n",
      "Seen so far: 129088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2017: 0.9425345063209534\n",
      "Seen so far: 129152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2018: 0.5512046813964844\n",
      "Seen so far: 129216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2019: 0.9393262267112732\n",
      "Seen so far: 129280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2020: 0.48131024837493896\n",
      "Seen so far: 129344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2021: 0.9341363906860352\n",
      "Seen so far: 129408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2022: 1.056807279586792\n",
      "Seen so far: 129472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2023: 0.6542394757270813\n",
      "Seen so far: 129536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2024: 0.687974214553833\n",
      "Seen so far: 129600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2025: 0.6651435494422913\n",
      "Seen so far: 129664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2026: 0.7306596040725708\n",
      "Seen so far: 129728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2027: 1.0925862789154053\n",
      "Seen so far: 129792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2028: 0.7191283106803894\n",
      "Seen so far: 129856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2029: 0.7252597808837891\n",
      "Seen so far: 129920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2030: 1.1451966762542725\n",
      "Seen so far: 129984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2031: 1.107142686843872\n",
      "Seen so far: 130048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2032: 0.9094804525375366\n",
      "Seen so far: 130112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2033: 1.2390203475952148\n",
      "Seen so far: 130176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2034: 1.1558195352554321\n",
      "Seen so far: 130240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2035: 0.6095706224441528\n",
      "Seen so far: 130304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2036: 0.5755114555358887\n",
      "Seen so far: 130368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2037: 0.5793893337249756\n",
      "Seen so far: 130432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2038: 0.9962567687034607\n",
      "Seen so far: 130496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2039: 0.7573276162147522\n",
      "Seen so far: 130560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2040: 0.5559937357902527\n",
      "Seen so far: 130624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2041: 0.6577348709106445\n",
      "Seen so far: 130688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2042: 0.71278315782547\n",
      "Seen so far: 130752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2043: 0.8184713125228882\n",
      "Seen so far: 130816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2044: 0.7632718086242676\n",
      "Seen so far: 130880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2045: 0.6349560618400574\n",
      "Seen so far: 130944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2046: 0.873306155204773\n",
      "Seen so far: 131008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2047: 0.5516519546508789\n",
      "Seen so far: 131072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2048: 0.6257821917533875\n",
      "Seen so far: 131136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2049: 1.0353202819824219\n",
      "Seen so far: 131200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2050: 0.8160067200660706\n",
      "Seen so far: 131264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2051: 0.9147917628288269\n",
      "Seen so far: 131328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2052: 0.7486720681190491\n",
      "Seen so far: 131392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2053: 0.9655553102493286\n",
      "Seen so far: 131456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2054: 0.6963538527488708\n",
      "Seen so far: 131520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2055: 0.2859192192554474\n",
      "Seen so far: 131584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2056: 0.48513203859329224\n",
      "Seen so far: 131648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2057: 0.8054221868515015\n",
      "Seen so far: 131712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2058: 0.8400285840034485\n",
      "Seen so far: 131776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2059: 0.9826833009719849\n",
      "Seen so far: 131840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2060: 0.907892107963562\n",
      "Seen so far: 131904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2061: 0.949828028678894\n",
      "Seen so far: 131968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2062: 0.8567699790000916\n",
      "Seen so far: 132032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2063: 0.7381823658943176\n",
      "Seen so far: 132096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2064: 0.8632151484489441\n",
      "Seen so far: 132160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2065: 0.7477458119392395\n",
      "Seen so far: 132224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2066: 0.9255963563919067\n",
      "Seen so far: 132288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2067: 0.5981372594833374\n",
      "Seen so far: 132352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2068: 1.1840293407440186\n",
      "Seen so far: 132416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2069: 1.0403999090194702\n",
      "Seen so far: 132480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2070: 0.5211700797080994\n",
      "Seen so far: 132544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2071: 0.490215003490448\n",
      "Seen so far: 132608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2072: 1.2158067226409912\n",
      "Seen so far: 132672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2073: 0.7112439274787903\n",
      "Seen so far: 132736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2074: 0.7522350549697876\n",
      "Seen so far: 132800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2075: 0.9876670837402344\n",
      "Seen so far: 132864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2076: 0.6638996601104736\n",
      "Seen so far: 132928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2077: 0.83228600025177\n",
      "Seen so far: 132992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2078: 0.9162806868553162\n",
      "Seen so far: 133056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2079: 1.0585052967071533\n",
      "Seen so far: 133120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2080: 0.41822126507759094\n",
      "Seen so far: 133184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2081: 1.1199302673339844\n",
      "Seen so far: 133248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2082: 0.6858490109443665\n",
      "Seen so far: 133312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2083: 0.681448221206665\n",
      "Seen so far: 133376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2084: 0.7396095991134644\n",
      "Seen so far: 133440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2085: 0.32640644907951355\n",
      "Seen so far: 133504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2086: 0.36308610439300537\n",
      "Seen so far: 133568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2087: 0.8784722685813904\n",
      "Seen so far: 133632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2088: 0.6349658966064453\n",
      "Seen so far: 133696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2089: 0.9745944738388062\n",
      "Seen so far: 133760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2090: 0.5967745780944824\n",
      "Seen so far: 133824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2091: 0.5847890377044678\n",
      "Seen so far: 133888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2092: 0.6999125480651855\n",
      "Seen so far: 133952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2093: 0.629644513130188\n",
      "Seen so far: 134016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2094: 0.7298075556755066\n",
      "Seen so far: 134080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2095: 1.01121985912323\n",
      "Seen so far: 134144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2096: 0.6869761943817139\n",
      "Seen so far: 134208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2097: 0.5532196760177612\n",
      "Seen so far: 134272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2098: 0.7149333357810974\n",
      "Seen so far: 134336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2099: 0.6762384176254272\n",
      "Seen so far: 134400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2100: 0.7355096340179443\n",
      "Seen so far: 134464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2101: 0.44191431999206543\n",
      "Seen so far: 134528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2102: 0.926082968711853\n",
      "Seen so far: 134592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2103: 0.5686845779418945\n",
      "Seen so far: 134656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2104: 0.5824819207191467\n",
      "Seen so far: 134720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2105: 0.5328388810157776\n",
      "Seen so far: 134784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2106: 0.8015839457511902\n",
      "Seen so far: 134848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2107: 0.7920560836791992\n",
      "Seen so far: 134912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2108: 0.372803270816803\n",
      "Seen so far: 134976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2109: 0.6153426170349121\n",
      "Seen so far: 135040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2110: 0.7764525413513184\n",
      "Seen so far: 135104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2111: 0.6154866814613342\n",
      "Seen so far: 135168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2112: 0.48651477694511414\n",
      "Seen so far: 135232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2113: 0.8330773115158081\n",
      "Seen so far: 135296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2114: 0.7431081533432007\n",
      "Seen so far: 135360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2115: 0.8105427026748657\n",
      "Seen so far: 135424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2116: 0.5023455619812012\n",
      "Seen so far: 135488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2117: 0.490376740694046\n",
      "Seen so far: 135552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2118: 1.1585195064544678\n",
      "Seen so far: 135616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2119: 0.8270251750946045\n",
      "Seen so far: 135680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2120: 0.928168535232544\n",
      "Seen so far: 135744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2121: 0.5706825852394104\n",
      "Seen so far: 135808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2122: 0.9546337127685547\n",
      "Seen so far: 135872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2123: 0.8536667823791504\n",
      "Seen so far: 135936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2124: 0.6150405406951904\n",
      "Seen so far: 136000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2125: 1.1959235668182373\n",
      "Seen so far: 136064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2126: 0.8382264375686646\n",
      "Seen so far: 136128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2127: 1.1261074542999268\n",
      "Seen so far: 136192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2128: 0.8787827491760254\n",
      "Seen so far: 136256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2129: 0.8273972868919373\n",
      "Seen so far: 136320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2130: 0.6228154897689819\n",
      "Seen so far: 136384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2131: 1.0135548114776611\n",
      "Seen so far: 136448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2132: 0.8055664896965027\n",
      "Seen so far: 136512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2133: 0.5484529733657837\n",
      "Seen so far: 136576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2134: 0.26805564761161804\n",
      "Seen so far: 136640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2135: 0.43952348828315735\n",
      "Seen so far: 136704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2136: 0.5053080320358276\n",
      "Seen so far: 136768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2137: 0.8043925166130066\n",
      "Seen so far: 136832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2138: 0.9267058372497559\n",
      "Seen so far: 136896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2139: 0.7577300667762756\n",
      "Seen so far: 136960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2140: 0.9475610256195068\n",
      "Seen so far: 137024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2141: 1.3094618320465088\n",
      "Seen so far: 137088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2142: 0.4380314350128174\n",
      "Seen so far: 137152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2143: 0.7233701944351196\n",
      "Seen so far: 137216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2144: 0.712100625038147\n",
      "Seen so far: 137280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2145: 0.9317321181297302\n",
      "Seen so far: 137344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2146: 1.3062944412231445\n",
      "Seen so far: 137408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2147: 0.5889638662338257\n",
      "Seen so far: 137472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2148: 0.880962073802948\n",
      "Seen so far: 137536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2149: 0.8705052137374878\n",
      "Seen so far: 137600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2150: 0.6102396249771118\n",
      "Seen so far: 137664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2151: 0.5948699116706848\n",
      "Seen so far: 137728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2152: 1.086766242980957\n",
      "Seen so far: 137792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2153: 0.5903064012527466\n",
      "Seen so far: 137856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2154: 0.7885154485702515\n",
      "Seen so far: 137920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2155: 0.8474898934364319\n",
      "Seen so far: 137984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2156: 0.8252855539321899\n",
      "Seen so far: 138048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2157: 0.3824477791786194\n",
      "Seen so far: 138112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2158: 0.6626326441764832\n",
      "Seen so far: 138176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2159: 0.41096484661102295\n",
      "Seen so far: 138240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2160: 0.9655695557594299\n",
      "Seen so far: 138304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2161: 0.6417495608329773\n",
      "Seen so far: 138368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2162: 0.655898928642273\n",
      "Seen so far: 138432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2163: 0.6399946212768555\n",
      "Seen so far: 138496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2164: 1.1113946437835693\n",
      "Seen so far: 138560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2165: 0.7682938575744629\n",
      "Seen so far: 138624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2166: 0.6453248262405396\n",
      "Seen so far: 138688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2167: 0.7986338138580322\n",
      "Seen so far: 138752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2168: 0.5816377401351929\n",
      "Seen so far: 138816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2169: 0.5332808494567871\n",
      "Seen so far: 138880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2170: 0.7913195490837097\n",
      "Seen so far: 138944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2171: 0.7834472060203552\n",
      "Seen so far: 139008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2172: 0.44766366481781006\n",
      "Seen so far: 139072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2173: 0.7305119037628174\n",
      "Seen so far: 139136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2174: 1.1779839992523193\n",
      "Seen so far: 139200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2175: 0.6122664213180542\n",
      "Seen so far: 139264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2176: 0.7570333480834961\n",
      "Seen so far: 139328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2177: 0.7618474960327148\n",
      "Seen so far: 139392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2178: 0.4875781834125519\n",
      "Seen so far: 139456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2179: 0.4487660527229309\n",
      "Seen so far: 139520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2180: 0.7859436273574829\n",
      "Seen so far: 139584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2181: 0.8923970460891724\n",
      "Seen so far: 139648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2182: 1.0054007768630981\n",
      "Seen so far: 139712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2183: 0.5363779664039612\n",
      "Seen so far: 139776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2184: 0.9163694381713867\n",
      "Seen so far: 139840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2185: 0.7112517356872559\n",
      "Seen so far: 139904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2186: 0.661332905292511\n",
      "Seen so far: 139968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2187: 0.6333070993423462\n",
      "Seen so far: 140032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2188: 0.45517995953559875\n",
      "Seen so far: 140096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2189: 1.079683542251587\n",
      "Seen so far: 140160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2190: 0.8966671228408813\n",
      "Seen so far: 140224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2191: 0.46897655725479126\n",
      "Seen so far: 140288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2192: 0.4948692321777344\n",
      "Seen so far: 140352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2193: 0.6862722635269165\n",
      "Seen so far: 140416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2194: 0.4053783416748047\n",
      "Seen so far: 140480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2195: 0.8833205103874207\n",
      "Seen so far: 140544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2196: 0.6147499084472656\n",
      "Seen so far: 140608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2197: 0.6464935541152954\n",
      "Seen so far: 140672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2198: 0.9640304446220398\n",
      "Seen so far: 140736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2199: 0.7384203672409058\n",
      "Seen so far: 140800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2200: 1.0345598459243774\n",
      "Seen so far: 140864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2201: 0.8980083465576172\n",
      "Seen so far: 140928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2202: 0.8590183258056641\n",
      "Seen so far: 140992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2203: 1.2760618925094604\n",
      "Seen so far: 141056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2204: 0.6408843994140625\n",
      "Seen so far: 141120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2205: 0.564037024974823\n",
      "Seen so far: 141184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2206: 1.2279832363128662\n",
      "Seen so far: 141248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2207: 0.772636890411377\n",
      "Seen so far: 141312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2208: 1.647352933883667\n",
      "Seen so far: 141376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2209: 0.6955654621124268\n",
      "Seen so far: 141440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2210: 0.8917684555053711\n",
      "Seen so far: 141504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2211: 0.7518959641456604\n",
      "Seen so far: 141568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2212: 0.5885475873947144\n",
      "Seen so far: 141632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2213: 0.7816019058227539\n",
      "Seen so far: 141696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2214: 0.983877420425415\n",
      "Seen so far: 141760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2215: 0.8731244802474976\n",
      "Seen so far: 141824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2216: 0.6244935989379883\n",
      "Seen so far: 141888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2217: 0.790087103843689\n",
      "Seen so far: 141952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2218: 0.908647894859314\n",
      "Seen so far: 142016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2219: 0.924773633480072\n",
      "Seen so far: 142080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2220: 0.8019825220108032\n",
      "Seen so far: 142144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2221: 0.9586477279663086\n",
      "Seen so far: 142208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2222: 1.0352996587753296\n",
      "Seen so far: 142272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2223: 0.5497241020202637\n",
      "Seen so far: 142336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2224: 0.9373476505279541\n",
      "Seen so far: 142400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2225: 0.883545994758606\n",
      "Seen so far: 142464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2226: 0.9560515284538269\n",
      "Seen so far: 142528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2227: 0.6843224167823792\n",
      "Seen so far: 142592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2228: 0.9392887949943542\n",
      "Seen so far: 142656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2229: 1.057790994644165\n",
      "Seen so far: 142720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2230: 0.8677518367767334\n",
      "Seen so far: 142784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2231: 1.0043413639068604\n",
      "Seen so far: 142848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2232: 0.9789727926254272\n",
      "Seen so far: 142912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2233: 0.6494531631469727\n",
      "Seen so far: 142976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2234: 0.6512583494186401\n",
      "Seen so far: 143040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2235: 1.181958556175232\n",
      "Seen so far: 143104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2236: 0.6742769479751587\n",
      "Seen so far: 143168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2237: 0.791899561882019\n",
      "Seen so far: 143232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2238: 0.6410091519355774\n",
      "Seen so far: 143296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2239: 0.9911101460456848\n",
      "Seen so far: 143360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2240: 0.7385256290435791\n",
      "Seen so far: 143424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2241: 1.1210057735443115\n",
      "Seen so far: 143488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2242: 0.719658374786377\n",
      "Seen so far: 143552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2243: 1.1693296432495117\n",
      "Seen so far: 143616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2244: 0.9139649868011475\n",
      "Seen so far: 143680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2245: 0.5559988021850586\n",
      "Seen so far: 143744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2246: 0.7533907294273376\n",
      "Seen so far: 143808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2247: 0.9307392835617065\n",
      "Seen so far: 143872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2248: 0.40728139877319336\n",
      "Seen so far: 143936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2249: 0.9843870997428894\n",
      "Seen so far: 144000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2250: 0.8474851846694946\n",
      "Seen so far: 144064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2251: 0.8049352169036865\n",
      "Seen so far: 144128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2252: 0.8074710369110107\n",
      "Seen so far: 144192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2253: 1.0270509719848633\n",
      "Seen so far: 144256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2254: 0.7329570055007935\n",
      "Seen so far: 144320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2255: 0.7820430397987366\n",
      "Seen so far: 144384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2256: 0.8419064283370972\n",
      "Seen so far: 144448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2257: 0.9767904877662659\n",
      "Seen so far: 144512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2258: 1.2504680156707764\n",
      "Seen so far: 144576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2259: 0.902628481388092\n",
      "Seen so far: 144640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2260: 0.7363775968551636\n",
      "Seen so far: 144704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2261: 1.0105199813842773\n",
      "Seen so far: 144768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2262: 0.7391320466995239\n",
      "Seen so far: 144832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2263: 0.9544980525970459\n",
      "Seen so far: 144896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2264: 0.9174611568450928\n",
      "Seen so far: 144960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2265: 0.5273908972740173\n",
      "Seen so far: 145024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2266: 0.6696833372116089\n",
      "Seen so far: 145088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2267: 0.755668580532074\n",
      "Seen so far: 145152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2268: 0.6313409805297852\n",
      "Seen so far: 145216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2269: 0.4672520160675049\n",
      "Seen so far: 145280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2270: 0.67300945520401\n",
      "Seen so far: 145344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2271: 0.5852802991867065\n",
      "Seen so far: 145408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2272: 1.0290560722351074\n",
      "Seen so far: 145472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2273: 0.8667658567428589\n",
      "Seen so far: 145536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2274: 0.9336659908294678\n",
      "Seen so far: 145600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2275: 1.057146430015564\n",
      "Seen so far: 145664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2276: 0.6919770836830139\n",
      "Seen so far: 145728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2277: 0.8087824583053589\n",
      "Seen so far: 145792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2278: 0.8762965202331543\n",
      "Seen so far: 145856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2279: 0.5388487577438354\n",
      "Seen so far: 145920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2280: 1.007738709449768\n",
      "Seen so far: 145984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2281: 0.806686282157898\n",
      "Seen so far: 146048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2282: 0.9627566933631897\n",
      "Seen so far: 146112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2283: 0.8907145261764526\n",
      "Seen so far: 146176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2284: 0.6779547333717346\n",
      "Seen so far: 146240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2285: 0.7805073261260986\n",
      "Seen so far: 146304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2286: 0.9674781560897827\n",
      "Seen so far: 146368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2287: 0.5238269567489624\n",
      "Seen so far: 146432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2288: 0.6215184926986694\n",
      "Seen so far: 146496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2289: 0.8050372004508972\n",
      "Seen so far: 146560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2290: 0.7233585715293884\n",
      "Seen so far: 146624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2291: 0.6516442894935608\n",
      "Seen so far: 146688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2292: 0.8600590229034424\n",
      "Seen so far: 146752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2293: 1.1174721717834473\n",
      "Seen so far: 146816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2294: 1.000112533569336\n",
      "Seen so far: 146880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2295: 0.946246325969696\n",
      "Seen so far: 146944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2296: 0.7626667022705078\n",
      "Seen so far: 147008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2297: 1.2839442491531372\n",
      "Seen so far: 147072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2298: 0.895966112613678\n",
      "Seen so far: 147136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2299: 0.48284912109375\n",
      "Seen so far: 147200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2300: 0.8017868995666504\n",
      "Seen so far: 147264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2301: 0.8699014782905579\n",
      "Seen so far: 147328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2302: 0.7727969884872437\n",
      "Seen so far: 147392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2303: 0.9633259177207947\n",
      "Seen so far: 147456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2304: 0.4997105598449707\n",
      "Seen so far: 147520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2305: 0.8867620229721069\n",
      "Seen so far: 147584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2306: 0.6572813987731934\n",
      "Seen so far: 147648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2307: 0.7629483938217163\n",
      "Seen so far: 147712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2308: 0.755569577217102\n",
      "Seen so far: 147776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2309: 0.8715083599090576\n",
      "Seen so far: 147840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2310: 0.6233421564102173\n",
      "Seen so far: 147904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2311: 0.6779825091362\n",
      "Seen so far: 147968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2312: 0.43328720331192017\n",
      "Seen so far: 148032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2313: 0.720005214214325\n",
      "Seen so far: 148096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2314: 1.107755422592163\n",
      "Seen so far: 148160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2315: 0.7883048057556152\n",
      "Seen so far: 148224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2316: 0.8672788143157959\n",
      "Seen so far: 148288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2317: 0.4481198787689209\n",
      "Seen so far: 148352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2318: 0.4911603331565857\n",
      "Seen so far: 148416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2319: 0.8146463632583618\n",
      "Seen so far: 148480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2320: 0.7859461307525635\n",
      "Seen so far: 148544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2321: 0.6158237457275391\n",
      "Seen so far: 148608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2322: 0.5176765322685242\n",
      "Seen so far: 148672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2323: 0.5750332474708557\n",
      "Seen so far: 148736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2324: 1.1063504219055176\n",
      "Seen so far: 148800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2325: 0.43581172823905945\n",
      "Seen so far: 148864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2326: 0.6671682596206665\n",
      "Seen so far: 148928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2327: 0.9837814569473267\n",
      "Seen so far: 148992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2328: 0.5867220759391785\n",
      "Seen so far: 149056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2329: 0.8074994683265686\n",
      "Seen so far: 149120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2330: 0.756730318069458\n",
      "Seen so far: 149184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2331: 0.47797703742980957\n",
      "Seen so far: 149248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2332: 0.9420625567436218\n",
      "Seen so far: 149312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2333: 0.7504361867904663\n",
      "Seen so far: 149376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2334: 0.8147979378700256\n",
      "Seen so far: 149440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2335: 0.7159394025802612\n",
      "Seen so far: 149504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2336: 0.766666054725647\n",
      "Seen so far: 149568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2337: 0.7594628930091858\n",
      "Seen so far: 149632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2338: 0.6789736747741699\n",
      "Seen so far: 149696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2339: 0.9734066724777222\n",
      "Seen so far: 149760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2340: 0.9621680974960327\n",
      "Seen so far: 149824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2341: 1.0522112846374512\n",
      "Seen so far: 149888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2342: 0.4841529130935669\n",
      "Seen so far: 149952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2343: 0.551958441734314\n",
      "Seen so far: 150016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2344: 0.8827426433563232\n",
      "Seen so far: 150080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2345: 0.8652740716934204\n",
      "Seen so far: 150144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2346: 0.745032548904419\n",
      "Seen so far: 150208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2347: 0.5769888162612915\n",
      "Seen so far: 150272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2348: 0.9047876596450806\n",
      "Seen so far: 150336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2349: 0.6644872426986694\n",
      "Seen so far: 150400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2350: 0.9761350750923157\n",
      "Seen so far: 150464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2351: 0.7300967574119568\n",
      "Seen so far: 150528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2352: 1.0847835540771484\n",
      "Seen so far: 150592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2353: 0.6742476224899292\n",
      "Seen so far: 150656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2354: 0.7487157583236694\n",
      "Seen so far: 150720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2355: 0.8655765056610107\n",
      "Seen so far: 150784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2356: 0.6901407241821289\n",
      "Seen so far: 150848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2357: 1.0795488357543945\n",
      "Seen so far: 150912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2358: 0.9897862076759338\n",
      "Seen so far: 150976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2359: 0.9208579063415527\n",
      "Seen so far: 151040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2360: 0.8861174583435059\n",
      "Seen so far: 151104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2361: 0.667017936706543\n",
      "Seen so far: 151168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2362: 0.8901591300964355\n",
      "Seen so far: 151232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2363: 0.819486141204834\n",
      "Seen so far: 151296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2364: 0.6080251932144165\n",
      "Seen so far: 151360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2365: 1.0608117580413818\n",
      "Seen so far: 151424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2366: 0.7644495964050293\n",
      "Seen so far: 151488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2367: 0.849778413772583\n",
      "Seen so far: 151552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2368: 0.8777350783348083\n",
      "Seen so far: 151616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2369: 1.019743800163269\n",
      "Seen so far: 151680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2370: 0.8523211479187012\n",
      "Seen so far: 151744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2371: 0.7149766683578491\n",
      "Seen so far: 151808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2372: 0.8187193870544434\n",
      "Seen so far: 151872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2373: 0.9367651343345642\n",
      "Seen so far: 151936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2374: 0.6712381839752197\n",
      "Seen so far: 152000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2375: 0.746508002281189\n",
      "Seen so far: 152064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2376: 1.267059326171875\n",
      "Seen so far: 152128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2377: 0.7805541157722473\n",
      "Seen so far: 152192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2378: 0.5270885229110718\n",
      "Seen so far: 152256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2379: 0.7553093433380127\n",
      "Seen so far: 152320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2380: 0.5732203722000122\n",
      "Seen so far: 152384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2381: 0.48718318343162537\n",
      "Seen so far: 152448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2382: 0.5338988304138184\n",
      "Seen so far: 152512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2383: 0.6481446623802185\n",
      "Seen so far: 152576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2384: 0.9257699251174927\n",
      "Seen so far: 152640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2385: 0.9314379692077637\n",
      "Seen so far: 152704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2386: 0.7844226360321045\n",
      "Seen so far: 152768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2387: 0.632042407989502\n",
      "Seen so far: 152832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2388: 0.6441669464111328\n",
      "Seen so far: 152896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2389: 0.8743442296981812\n",
      "Seen so far: 152960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2390: 1.1806135177612305\n",
      "Seen so far: 153024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2391: 0.8011193871498108\n",
      "Seen so far: 153088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2392: 0.5264464616775513\n",
      "Seen so far: 153152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2393: 0.8966434001922607\n",
      "Seen so far: 153216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2394: 0.6118350625038147\n",
      "Seen so far: 153280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2395: 0.9618059396743774\n",
      "Seen so far: 153344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2396: 0.5316140651702881\n",
      "Seen so far: 153408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2397: 0.9067100882530212\n",
      "Seen so far: 153472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2398: 0.7106974720954895\n",
      "Seen so far: 153536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2399: 0.500798225402832\n",
      "Seen so far: 153600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2400: 0.6231801509857178\n",
      "Seen so far: 153664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2401: 0.6365872621536255\n",
      "Seen so far: 153728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2402: 0.9319748878479004\n",
      "Seen so far: 153792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2403: 0.9981143474578857\n",
      "Seen so far: 153856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2404: 0.6829589605331421\n",
      "Seen so far: 153920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2405: 1.0502634048461914\n",
      "Seen so far: 153984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2406: 0.4503512382507324\n",
      "Seen so far: 154048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2407: 1.3566794395446777\n",
      "Seen so far: 154112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2408: 0.38125231862068176\n",
      "Seen so far: 154176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2409: 0.831683874130249\n",
      "Seen so far: 154240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2410: 0.4898243546485901\n",
      "Seen so far: 154304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2411: 1.1880671977996826\n",
      "Seen so far: 154368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2412: 1.0145068168640137\n",
      "Seen so far: 154432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2413: 0.9820445775985718\n",
      "Seen so far: 154496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2414: 0.9413741827011108\n",
      "Seen so far: 154560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2415: 1.0200566053390503\n",
      "Seen so far: 154624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2416: 0.856487512588501\n",
      "Seen so far: 154688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2417: 0.970000147819519\n",
      "Seen so far: 154752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2418: 0.9548176527023315\n",
      "Seen so far: 154816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2419: 0.6792452335357666\n",
      "Seen so far: 154880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2420: 0.9470318555831909\n",
      "Seen so far: 154944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2421: 0.7117339968681335\n",
      "Seen so far: 155008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2422: 0.6473795771598816\n",
      "Seen so far: 155072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2423: 0.7176737785339355\n",
      "Seen so far: 155136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2424: 0.8368507027626038\n",
      "Seen so far: 155200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2425: 0.9465091228485107\n",
      "Seen so far: 155264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2426: 0.8060563802719116\n",
      "Seen so far: 155328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2427: 1.0403436422348022\n",
      "Seen so far: 155392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2428: 0.8981817960739136\n",
      "Seen so far: 155456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2429: 0.6998169422149658\n",
      "Seen so far: 155520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2430: 0.8671615123748779\n",
      "Seen so far: 155584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2431: 1.1374545097351074\n",
      "Seen so far: 155648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2432: 0.6824774146080017\n",
      "Seen so far: 155712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2433: 0.7489110827445984\n",
      "Seen so far: 155776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2434: 0.7015388607978821\n",
      "Seen so far: 155840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2435: 1.1861484050750732\n",
      "Seen so far: 155904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2436: 1.123714566230774\n",
      "Seen so far: 155968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2437: 0.5049483180046082\n",
      "Seen so far: 156032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2438: 0.8563011288642883\n",
      "Seen so far: 156096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2439: 0.7413758039474487\n",
      "Seen so far: 156160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2440: 0.6506505012512207\n",
      "Seen so far: 156224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2441: 0.39262092113494873\n",
      "Seen so far: 156288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2442: 0.9737675189971924\n",
      "Seen so far: 156352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2443: 0.6827710866928101\n",
      "Seen so far: 156416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2444: 0.7397335767745972\n",
      "Seen so far: 156480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2445: 0.7265135645866394\n",
      "Seen so far: 156544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2446: 0.8195368051528931\n",
      "Seen so far: 156608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2447: 0.5011581182479858\n",
      "Seen so far: 156672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2448: 1.2510756254196167\n",
      "Seen so far: 156736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2449: 0.7126991748809814\n",
      "Seen so far: 156800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2450: 0.8480913043022156\n",
      "Seen so far: 156864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2451: 0.8548738956451416\n",
      "Seen so far: 156928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2452: 0.8878663778305054\n",
      "Seen so far: 156992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2453: 0.5691946148872375\n",
      "Seen so far: 157056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2454: 1.007975697517395\n",
      "Seen so far: 157120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2455: 0.842167317867279\n",
      "Seen so far: 157184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2456: 0.5974860191345215\n",
      "Seen so far: 157248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2457: 0.9248512983322144\n",
      "Seen so far: 157312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2458: 0.597659170627594\n",
      "Seen so far: 157376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2459: 0.7890570163726807\n",
      "Seen so far: 157440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2460: 0.8087548613548279\n",
      "Seen so far: 157504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2461: 0.6555287837982178\n",
      "Seen so far: 157568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2462: 0.8369866013526917\n",
      "Seen so far: 157632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2463: 0.4833510220050812\n",
      "Seen so far: 157696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2464: 0.7674686312675476\n",
      "Seen so far: 157760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2465: 0.932226300239563\n",
      "Seen so far: 157824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2466: 1.2645554542541504\n",
      "Seen so far: 157888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2467: 1.15926992893219\n",
      "Seen so far: 157952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2468: 0.7019740343093872\n",
      "Seen so far: 158016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2469: 0.7014269828796387\n",
      "Seen so far: 158080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2470: 0.7608964443206787\n",
      "Seen so far: 158144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2471: 1.2782044410705566\n",
      "Seen so far: 158208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2472: 0.8802663087844849\n",
      "Seen so far: 158272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2473: 0.788139283657074\n",
      "Seen so far: 158336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2474: 1.2432527542114258\n",
      "Seen so far: 158400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2475: 0.7009905576705933\n",
      "Seen so far: 158464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2476: 0.8115740418434143\n",
      "Seen so far: 158528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2477: 0.8180177807807922\n",
      "Seen so far: 158592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2478: 0.9986675977706909\n",
      "Seen so far: 158656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2479: 0.8790459632873535\n",
      "Seen so far: 158720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2480: 0.7770189642906189\n",
      "Seen so far: 158784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2481: 0.7601442933082581\n",
      "Seen so far: 158848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2482: 0.7882083654403687\n",
      "Seen so far: 158912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2483: 0.890989363193512\n",
      "Seen so far: 158976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2484: 0.7562406063079834\n",
      "Seen so far: 159040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2485: 0.5934303998947144\n",
      "Seen so far: 159104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2486: 1.183645486831665\n",
      "Seen so far: 159168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2487: 0.828769862651825\n",
      "Seen so far: 159232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2488: 0.913482666015625\n",
      "Seen so far: 159296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2489: 0.5974111557006836\n",
      "Seen so far: 159360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2490: 0.6831498146057129\n",
      "Seen so far: 159424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2491: 0.8489390015602112\n",
      "Seen so far: 159488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2492: 0.7827514410018921\n",
      "Seen so far: 159552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2493: 0.4631323218345642\n",
      "Seen so far: 159616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2494: 0.6041158437728882\n",
      "Seen so far: 159680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2495: 0.5620908737182617\n",
      "Seen so far: 159744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2496: 0.5274452567100525\n",
      "Seen so far: 159808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2497: 0.6686854958534241\n",
      "Seen so far: 159872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2498: 0.4845768213272095\n",
      "Seen so far: 159936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2499: 1.0411720275878906\n",
      "Seen so far: 160000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2500: 0.816408634185791\n",
      "Seen so far: 160064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2501: 0.7918143272399902\n",
      "Seen so far: 160128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2502: 0.6293749213218689\n",
      "Seen so far: 160192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2503: 0.7722045183181763\n",
      "Seen so far: 160256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2504: 0.8766317367553711\n",
      "Seen so far: 160320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2505: 1.1227011680603027\n",
      "Seen so far: 160384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2506: 0.7219595909118652\n",
      "Seen so far: 160448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2507: 0.8594621419906616\n",
      "Seen so far: 160512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2508: 0.7552791833877563\n",
      "Seen so far: 160576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2509: 0.7561057806015015\n",
      "Seen so far: 160640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2510: 1.0040407180786133\n",
      "Seen so far: 160704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2511: 0.9574856758117676\n",
      "Seen so far: 160768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2512: 0.5560976266860962\n",
      "Seen so far: 160832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2513: 0.7911217212677002\n",
      "Seen so far: 160896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2514: 0.7728185653686523\n",
      "Seen so far: 160960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2515: 0.7444307804107666\n",
      "Seen so far: 161024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2516: 0.7315331697463989\n",
      "Seen so far: 161088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2517: 0.9391175508499146\n",
      "Seen so far: 161152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2518: 0.9258067607879639\n",
      "Seen so far: 161216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2519: 0.9509000778198242\n",
      "Seen so far: 161280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2520: 0.5110271573066711\n",
      "Seen so far: 161344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2521: 0.754554033279419\n",
      "Seen so far: 161408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2522: 0.6286048889160156\n",
      "Seen so far: 161472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2523: 0.9911088943481445\n",
      "Seen so far: 161536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2524: 0.7624894380569458\n",
      "Seen so far: 161600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2525: 0.7211954593658447\n",
      "Seen so far: 161664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2526: 0.6311526298522949\n",
      "Seen so far: 161728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2527: 0.7562575340270996\n",
      "Seen so far: 161792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2528: 1.1434584856033325\n",
      "Seen so far: 161856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2529: 0.9058126211166382\n",
      "Seen so far: 161920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2530: 0.5388627052307129\n",
      "Seen so far: 161984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2531: 0.7994505167007446\n",
      "Seen so far: 162048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2532: 0.4817523956298828\n",
      "Seen so far: 162112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2533: 1.1187915802001953\n",
      "Seen so far: 162176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2534: 0.9277677536010742\n",
      "Seen so far: 162240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2535: 0.6909832954406738\n",
      "Seen so far: 162304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2536: 0.7172305583953857\n",
      "Seen so far: 162368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2537: 0.8593930006027222\n",
      "Seen so far: 162432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2538: 0.6491250991821289\n",
      "Seen so far: 162496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2539: 0.9481979608535767\n",
      "Seen so far: 162560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2540: 1.1950992345809937\n",
      "Seen so far: 162624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2541: 1.6841351985931396\n",
      "Seen so far: 162688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2542: 0.6458595991134644\n",
      "Seen so far: 162752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2543: 0.8234115839004517\n",
      "Seen so far: 162816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2544: 0.7875210046768188\n",
      "Seen so far: 162880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2545: 1.26602303981781\n",
      "Seen so far: 162944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2546: 0.5854482650756836\n",
      "Seen so far: 163008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2547: 1.0154350996017456\n",
      "Seen so far: 163072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2548: 0.9523016214370728\n",
      "Seen so far: 163136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2549: 1.2479544878005981\n",
      "Seen so far: 163200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2550: 1.3333344459533691\n",
      "Seen so far: 163264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2551: 0.7568260431289673\n",
      "Seen so far: 163328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2552: 0.40954071283340454\n",
      "Seen so far: 163392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2553: 0.9136425852775574\n",
      "Seen so far: 163456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2554: 0.6650131344795227\n",
      "Seen so far: 163520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2555: 0.5574307441711426\n",
      "Seen so far: 163584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2556: 1.0868349075317383\n",
      "Seen so far: 163648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2557: 0.6154549717903137\n",
      "Seen so far: 163712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2558: 0.5921064019203186\n",
      "Seen so far: 163776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2559: 0.9509401321411133\n",
      "Seen so far: 163840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2560: 1.046883225440979\n",
      "Seen so far: 163904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2561: 0.9160012006759644\n",
      "Seen so far: 163968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2562: 0.5938328504562378\n",
      "Seen so far: 164032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2563: 0.8894512057304382\n",
      "Seen so far: 164096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2564: 0.8600441813468933\n",
      "Seen so far: 164160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2565: 0.450548380613327\n",
      "Seen so far: 164224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2566: 0.9597076177597046\n",
      "Seen so far: 164288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2567: 0.9518278241157532\n",
      "Seen so far: 164352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2568: 1.2328009605407715\n",
      "Seen so far: 164416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2569: 0.8753594756126404\n",
      "Seen so far: 164480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2570: 0.8474656343460083\n",
      "Seen so far: 164544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2571: 0.47346222400665283\n",
      "Seen so far: 164608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2572: 1.2435299158096313\n",
      "Seen so far: 164672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2573: 0.6389873623847961\n",
      "Seen so far: 164736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2574: 0.8045839071273804\n",
      "Seen so far: 164800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2575: 0.4911140203475952\n",
      "Seen so far: 164864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2576: 0.754896879196167\n",
      "Seen so far: 164928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2577: 0.6631122827529907\n",
      "Seen so far: 164992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2578: 0.5533498525619507\n",
      "Seen so far: 165056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2579: 0.751122236251831\n",
      "Seen so far: 165120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2580: 1.1402404308319092\n",
      "Seen so far: 165184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2581: 0.739888072013855\n",
      "Seen so far: 165248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2582: 1.108469843864441\n",
      "Seen so far: 165312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2583: 0.6035199165344238\n",
      "Seen so far: 165376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2584: 0.3775601387023926\n",
      "Seen so far: 165440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2585: 0.5784865617752075\n",
      "Seen so far: 165504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2586: 0.6713083386421204\n",
      "Seen so far: 165568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2587: 0.6421210765838623\n",
      "Seen so far: 165632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2588: 0.6844521760940552\n",
      "Seen so far: 165696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2589: 0.8715564608573914\n",
      "Seen so far: 165760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2590: 0.9306899309158325\n",
      "Seen so far: 165824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2591: 0.8650037050247192\n",
      "Seen so far: 165888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2592: 0.8542564511299133\n",
      "Seen so far: 165952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2593: 0.77812260389328\n",
      "Seen so far: 166016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2594: 0.8949202299118042\n",
      "Seen so far: 166080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2595: 0.5813498497009277\n",
      "Seen so far: 166144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2596: 0.645980954170227\n",
      "Seen so far: 166208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2597: 0.7277953624725342\n",
      "Seen so far: 166272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2598: 0.9229215383529663\n",
      "Seen so far: 166336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2599: 0.7167643308639526\n",
      "Seen so far: 166400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2600: 0.820140540599823\n",
      "Seen so far: 166464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2601: 0.5764028429985046\n",
      "Seen so far: 166528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2602: 0.6138158440589905\n",
      "Seen so far: 166592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2603: 0.6424587368965149\n",
      "Seen so far: 166656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2604: 0.9230524301528931\n",
      "Seen so far: 166720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2605: 0.5985984802246094\n",
      "Seen so far: 166784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2606: 0.7673993110656738\n",
      "Seen so far: 166848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2607: 1.4129002094268799\n",
      "Seen so far: 166912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2608: 0.5239323973655701\n",
      "Seen so far: 166976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2609: 0.6878407597541809\n",
      "Seen so far: 167040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2610: 0.9880613088607788\n",
      "Seen so far: 167104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2611: 0.682721734046936\n",
      "Seen so far: 167168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2612: 1.0032737255096436\n",
      "Seen so far: 167232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2613: 0.6520122289657593\n",
      "Seen so far: 167296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2614: 0.8388670682907104\n",
      "Seen so far: 167360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2615: 0.6266473531723022\n",
      "Seen so far: 167424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2616: 0.6039235591888428\n",
      "Seen so far: 167488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2617: 0.7781286239624023\n",
      "Seen so far: 167552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2618: 0.6909804940223694\n",
      "Seen so far: 167616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2619: 1.2809479236602783\n",
      "Seen so far: 167680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2620: 0.6007553339004517\n",
      "Seen so far: 167744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2621: 0.6814373731613159\n",
      "Seen so far: 167808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2622: 0.9917147159576416\n",
      "Seen so far: 167872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2623: 0.849899411201477\n",
      "Seen so far: 167936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2624: 0.9175034761428833\n",
      "Seen so far: 168000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2625: 0.5660072565078735\n",
      "Seen so far: 168064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2626: 0.5809756517410278\n",
      "Seen so far: 168128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2627: 0.8994735479354858\n",
      "Seen so far: 168192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2628: 0.49623268842697144\n",
      "Seen so far: 168256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2629: 0.8319568634033203\n",
      "Seen so far: 168320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2630: 1.0615112781524658\n",
      "Seen so far: 168384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2631: 0.7557493448257446\n",
      "Seen so far: 168448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2632: 0.6364272832870483\n",
      "Seen so far: 168512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2633: 0.7258297204971313\n",
      "Seen so far: 168576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2634: 0.8817378282546997\n",
      "Seen so far: 168640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2635: 0.7743916511535645\n",
      "Seen so far: 168704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2636: 0.8590354919433594\n",
      "Seen so far: 168768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2637: 0.715315043926239\n",
      "Seen so far: 168832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2638: 1.5049457550048828\n",
      "Seen so far: 168896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2639: 1.0246940851211548\n",
      "Seen so far: 168960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2640: 0.674161434173584\n",
      "Seen so far: 169024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2641: 0.5337271690368652\n",
      "Seen so far: 169088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2642: 0.6741617321968079\n",
      "Seen so far: 169152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2643: 0.975517988204956\n",
      "Seen so far: 169216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2644: 0.6368902921676636\n",
      "Seen so far: 169280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2645: 0.7207273244857788\n",
      "Seen so far: 169344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2646: 0.703579843044281\n",
      "Seen so far: 169408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2647: 0.6156923174858093\n",
      "Seen so far: 169472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2648: 0.8255886435508728\n",
      "Seen so far: 169536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2649: 0.9488037824630737\n",
      "Seen so far: 169600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2650: 0.8831855058670044\n",
      "Seen so far: 169664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2651: 1.10071861743927\n",
      "Seen so far: 169728 samples\n",
      "Training acc over epoch: 0.7354996800422668\n",
      "Start of epoch 8\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 0: 0.7460281848907471\n",
      "Seen so far: 64 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1: 0.6628857254981995\n",
      "Seen so far: 128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2: 0.6382948160171509\n",
      "Seen so far: 192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 3: 0.7913227081298828\n",
      "Seen so far: 256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 4: 0.6948329210281372\n",
      "Seen so far: 320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 5: 1.3372504711151123\n",
      "Seen so far: 384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 6: 1.0718114376068115\n",
      "Seen so far: 448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 7: 0.81219482421875\n",
      "Seen so far: 512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 8: 1.0406287908554077\n",
      "Seen so far: 576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 9: 0.7722985148429871\n",
      "Seen so far: 640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 10: 0.5787253379821777\n",
      "Seen so far: 704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 11: 0.5624254941940308\n",
      "Seen so far: 768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 12: 0.5080204010009766\n",
      "Seen so far: 832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 13: 0.5035481452941895\n",
      "Seen so far: 896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 14: 1.2384378910064697\n",
      "Seen so far: 960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 15: 0.6343276500701904\n",
      "Seen so far: 1024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 16: 1.0115957260131836\n",
      "Seen so far: 1088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 17: 1.0584853887557983\n",
      "Seen so far: 1152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 18: 0.7639124393463135\n",
      "Seen so far: 1216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 19: 0.9897446036338806\n",
      "Seen so far: 1280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 20: 1.0853114128112793\n",
      "Seen so far: 1344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 21: 1.3146162033081055\n",
      "Seen so far: 1408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 22: 0.9543901085853577\n",
      "Seen so far: 1472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 23: 1.218910813331604\n",
      "Seen so far: 1536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 24: 0.5699626803398132\n",
      "Seen so far: 1600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 25: 0.692166268825531\n",
      "Seen so far: 1664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 26: 0.9383960962295532\n",
      "Seen so far: 1728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 27: 1.218428134918213\n",
      "Seen so far: 1792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 28: 0.9589196443557739\n",
      "Seen so far: 1856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 29: 0.8032104969024658\n",
      "Seen so far: 1920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 30: 0.8096963763237\n",
      "Seen so far: 1984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 31: 0.9182498455047607\n",
      "Seen so far: 2048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 32: 1.1507878303527832\n",
      "Seen so far: 2112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 33: 0.7686120867729187\n",
      "Seen so far: 2176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 34: 0.9147398471832275\n",
      "Seen so far: 2240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 35: 0.9679601788520813\n",
      "Seen so far: 2304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 36: 0.5840482711791992\n",
      "Seen so far: 2368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 37: 0.9767813682556152\n",
      "Seen so far: 2432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 38: 0.8180221915245056\n",
      "Seen so far: 2496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 39: 0.8796721696853638\n",
      "Seen so far: 2560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 40: 0.9795469045639038\n",
      "Seen so far: 2624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 41: 0.9594518542289734\n",
      "Seen so far: 2688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 42: 0.9033638834953308\n",
      "Seen so far: 2752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 43: 0.6235077381134033\n",
      "Seen so far: 2816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 44: 1.007270097732544\n",
      "Seen so far: 2880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 45: 1.0667589902877808\n",
      "Seen so far: 2944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 46: 0.6291583776473999\n",
      "Seen so far: 3008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 47: 0.6026551127433777\n",
      "Seen so far: 3072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 48: 0.9077036380767822\n",
      "Seen so far: 3136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 49: 0.6152896881103516\n",
      "Seen so far: 3200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 50: 0.9205849766731262\n",
      "Seen so far: 3264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 51: 0.9119470119476318\n",
      "Seen so far: 3328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 52: 0.5855193734169006\n",
      "Seen so far: 3392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 53: 0.6098570823669434\n",
      "Seen so far: 3456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 54: 0.518409013748169\n",
      "Seen so far: 3520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 55: 0.8296251893043518\n",
      "Seen so far: 3584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 56: 1.1916189193725586\n",
      "Seen so far: 3648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 57: 1.4332427978515625\n",
      "Seen so far: 3712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 58: 0.4951329827308655\n",
      "Seen so far: 3776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 59: 0.8120973110198975\n",
      "Seen so far: 3840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 60: 0.23749896883964539\n",
      "Seen so far: 3904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 61: 0.5346156358718872\n",
      "Seen so far: 3968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 62: 0.9416844248771667\n",
      "Seen so far: 4032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 63: 0.839262843132019\n",
      "Seen so far: 4096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 64: 0.7278735637664795\n",
      "Seen so far: 4160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 65: 0.6733188033103943\n",
      "Seen so far: 4224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 66: 1.2619895935058594\n",
      "Seen so far: 4288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 67: 1.1658955812454224\n",
      "Seen so far: 4352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 68: 1.1540453433990479\n",
      "Seen so far: 4416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 69: 0.5716215968132019\n",
      "Seen so far: 4480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 70: 0.6061758995056152\n",
      "Seen so far: 4544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 71: 0.8243392109870911\n",
      "Seen so far: 4608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 72: 0.9906012415885925\n",
      "Seen so far: 4672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 73: 0.6965747475624084\n",
      "Seen so far: 4736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 74: 0.8316807746887207\n",
      "Seen so far: 4800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 75: 0.9218339920043945\n",
      "Seen so far: 4864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 76: 1.2653077840805054\n",
      "Seen so far: 4928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 77: 0.5898803472518921\n",
      "Seen so far: 4992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 78: 0.5888749957084656\n",
      "Seen so far: 5056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 79: 1.041754961013794\n",
      "Seen so far: 5120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 80: 0.5102246999740601\n",
      "Seen so far: 5184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 81: 0.858211100101471\n",
      "Seen so far: 5248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 82: 1.144155740737915\n",
      "Seen so far: 5312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 83: 0.9219340085983276\n",
      "Seen so far: 5376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 84: 0.8165751695632935\n",
      "Seen so far: 5440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 85: 0.9301543831825256\n",
      "Seen so far: 5504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 86: 0.7692113518714905\n",
      "Seen so far: 5568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 87: 0.7773622870445251\n",
      "Seen so far: 5632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 88: 0.7656546235084534\n",
      "Seen so far: 5696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 89: 0.9362228512763977\n",
      "Seen so far: 5760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 90: 0.8976506590843201\n",
      "Seen so far: 5824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 91: 1.1003416776657104\n",
      "Seen so far: 5888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 92: 0.7446461915969849\n",
      "Seen so far: 5952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 93: 0.7679711580276489\n",
      "Seen so far: 6016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 94: 0.8402230739593506\n",
      "Seen so far: 6080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 95: 0.6043493151664734\n",
      "Seen so far: 6144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 96: 0.7872852683067322\n",
      "Seen so far: 6208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 97: 0.8303842544555664\n",
      "Seen so far: 6272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 98: 0.5464558005332947\n",
      "Seen so far: 6336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 99: 0.9955987930297852\n",
      "Seen so far: 6400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 100: 0.7730796933174133\n",
      "Seen so far: 6464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 101: 0.6223111748695374\n",
      "Seen so far: 6528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 102: 0.8271541595458984\n",
      "Seen so far: 6592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 103: 0.7586871385574341\n",
      "Seen so far: 6656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 104: 0.7986326217651367\n",
      "Seen so far: 6720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 105: 1.0263689756393433\n",
      "Seen so far: 6784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 106: 0.5434525012969971\n",
      "Seen so far: 6848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 107: 0.7782593965530396\n",
      "Seen so far: 6912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 108: 0.9145601391792297\n",
      "Seen so far: 6976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 109: 0.853188157081604\n",
      "Seen so far: 7040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 110: 0.6470856666564941\n",
      "Seen so far: 7104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 111: 0.7021026611328125\n",
      "Seen so far: 7168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 112: 0.5867102146148682\n",
      "Seen so far: 7232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 113: 1.0283130407333374\n",
      "Seen so far: 7296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 114: 1.1783384084701538\n",
      "Seen so far: 7360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 115: 0.5606672763824463\n",
      "Seen so far: 7424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 116: 0.9597941637039185\n",
      "Seen so far: 7488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 117: 0.9163628220558167\n",
      "Seen so far: 7552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 118: 0.9622093439102173\n",
      "Seen so far: 7616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 119: 0.5026587247848511\n",
      "Seen so far: 7680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 120: 0.8946065306663513\n",
      "Seen so far: 7744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 121: 1.0617430210113525\n",
      "Seen so far: 7808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 122: 0.8954407572746277\n",
      "Seen so far: 7872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 123: 0.4887215197086334\n",
      "Seen so far: 7936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 124: 0.9461902379989624\n",
      "Seen so far: 8000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 125: 0.7277799844741821\n",
      "Seen so far: 8064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 126: 0.625698983669281\n",
      "Seen so far: 8128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 127: 1.0690962076187134\n",
      "Seen so far: 8192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 128: 0.5138801336288452\n",
      "Seen so far: 8256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 129: 0.9448875784873962\n",
      "Seen so far: 8320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 130: 1.0259226560592651\n",
      "Seen so far: 8384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 131: 1.0592178106307983\n",
      "Seen so far: 8448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 132: 0.7749687433242798\n",
      "Seen so far: 8512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 133: 0.7193577885627747\n",
      "Seen so far: 8576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 134: 0.7538091540336609\n",
      "Seen so far: 8640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 135: 0.9811488389968872\n",
      "Seen so far: 8704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 136: 0.9038236737251282\n",
      "Seen so far: 8768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 137: 1.0492112636566162\n",
      "Seen so far: 8832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 138: 0.5981103181838989\n",
      "Seen so far: 8896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 139: 0.9091023206710815\n",
      "Seen so far: 8960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 140: 0.8431208729743958\n",
      "Seen so far: 9024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 141: 0.8934013843536377\n",
      "Seen so far: 9088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 142: 0.5294439792633057\n",
      "Seen so far: 9152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 143: 0.8973294496536255\n",
      "Seen so far: 9216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 144: 1.0408307313919067\n",
      "Seen so far: 9280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 145: 0.8112040758132935\n",
      "Seen so far: 9344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 146: 0.5475902557373047\n",
      "Seen so far: 9408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 147: 1.010072946548462\n",
      "Seen so far: 9472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 148: 1.2588109970092773\n",
      "Seen so far: 9536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 149: 0.8204152584075928\n",
      "Seen so far: 9600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 150: 0.5308071374893188\n",
      "Seen so far: 9664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 151: 0.6244542598724365\n",
      "Seen so far: 9728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 152: 1.1276520490646362\n",
      "Seen so far: 9792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 153: 1.0912569761276245\n",
      "Seen so far: 9856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 154: 1.4413378238677979\n",
      "Seen so far: 9920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 155: 0.8425205945968628\n",
      "Seen so far: 9984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 156: 0.9947861433029175\n",
      "Seen so far: 10048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 157: 0.6649459600448608\n",
      "Seen so far: 10112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 158: 1.2722487449645996\n",
      "Seen so far: 10176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 159: 1.026153564453125\n",
      "Seen so far: 10240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 160: 0.8539025783538818\n",
      "Seen so far: 10304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 161: 0.7417294979095459\n",
      "Seen so far: 10368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 162: 0.9367104768753052\n",
      "Seen so far: 10432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 163: 0.8347929120063782\n",
      "Seen so far: 10496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 164: 0.9792765378952026\n",
      "Seen so far: 10560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 165: 0.927880585193634\n",
      "Seen so far: 10624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 166: 0.8083165287971497\n",
      "Seen so far: 10688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 167: 0.5593286752700806\n",
      "Seen so far: 10752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 168: 0.9310776591300964\n",
      "Seen so far: 10816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 169: 0.5399894118309021\n",
      "Seen so far: 10880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 170: 0.7727894186973572\n",
      "Seen so far: 10944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 171: 0.8558149933815002\n",
      "Seen so far: 11008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 172: 1.0623811483383179\n",
      "Seen so far: 11072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 173: 0.8323673009872437\n",
      "Seen so far: 11136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 174: 0.8436222672462463\n",
      "Seen so far: 11200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 175: 0.8764011859893799\n",
      "Seen so far: 11264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 176: 1.057267427444458\n",
      "Seen so far: 11328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 177: 0.7581377625465393\n",
      "Seen so far: 11392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 178: 0.7211152911186218\n",
      "Seen so far: 11456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 179: 0.7793620824813843\n",
      "Seen so far: 11520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 180: 0.914624810218811\n",
      "Seen so far: 11584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 181: 0.5965157747268677\n",
      "Seen so far: 11648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 182: 0.7509437799453735\n",
      "Seen so far: 11712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 183: 1.050610899925232\n",
      "Seen so far: 11776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 184: 0.9334903955459595\n",
      "Seen so far: 11840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 185: 0.9997372627258301\n",
      "Seen so far: 11904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 186: 0.8244291543960571\n",
      "Seen so far: 11968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 187: 0.847314715385437\n",
      "Seen so far: 12032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 188: 1.0698788166046143\n",
      "Seen so far: 12096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 189: 0.8813965320587158\n",
      "Seen so far: 12160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 190: 0.8935853242874146\n",
      "Seen so far: 12224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 191: 0.4267381727695465\n",
      "Seen so far: 12288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 192: 0.6572546362876892\n",
      "Seen so far: 12352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 193: 0.9530168771743774\n",
      "Seen so far: 12416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 194: 1.0720925331115723\n",
      "Seen so far: 12480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 195: 0.7439028024673462\n",
      "Seen so far: 12544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 196: 0.4476708471775055\n",
      "Seen so far: 12608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 197: 0.7192506790161133\n",
      "Seen so far: 12672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 198: 1.3977653980255127\n",
      "Seen so far: 12736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 199: 0.6967623829841614\n",
      "Seen so far: 12800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 200: 0.670917272567749\n",
      "Seen so far: 12864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 201: 0.6232484579086304\n",
      "Seen so far: 12928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 202: 0.8998790979385376\n",
      "Seen so far: 12992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 203: 0.8854328989982605\n",
      "Seen so far: 13056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 204: 0.818955659866333\n",
      "Seen so far: 13120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 205: 0.5112893581390381\n",
      "Seen so far: 13184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 206: 1.0340220928192139\n",
      "Seen so far: 13248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 207: 0.7810987234115601\n",
      "Seen so far: 13312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 208: 1.152316927909851\n",
      "Seen so far: 13376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 209: 0.7756310701370239\n",
      "Seen so far: 13440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 210: 0.6753683090209961\n",
      "Seen so far: 13504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 211: 0.6385744214057922\n",
      "Seen so far: 13568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 212: 1.1816498041152954\n",
      "Seen so far: 13632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 213: 1.0471513271331787\n",
      "Seen so far: 13696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 214: 0.9693719148635864\n",
      "Seen so far: 13760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 215: 0.968649685382843\n",
      "Seen so far: 13824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 216: 0.6269993185997009\n",
      "Seen so far: 13888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 217: 0.6986913681030273\n",
      "Seen so far: 13952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 218: 0.7844258546829224\n",
      "Seen so far: 14016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 219: 0.5098729729652405\n",
      "Seen so far: 14080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 220: 0.6478208303451538\n",
      "Seen so far: 14144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 221: 0.6579399704933167\n",
      "Seen so far: 14208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 222: 0.7280341386795044\n",
      "Seen so far: 14272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 223: 0.7980844974517822\n",
      "Seen so far: 14336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 224: 0.5464694499969482\n",
      "Seen so far: 14400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 225: 0.6826692223548889\n",
      "Seen so far: 14464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 226: 0.6256601810455322\n",
      "Seen so far: 14528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 227: 0.656467616558075\n",
      "Seen so far: 14592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 228: 0.707042396068573\n",
      "Seen so far: 14656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 229: 0.9322869181632996\n",
      "Seen so far: 14720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 230: 0.5894114971160889\n",
      "Seen so far: 14784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 231: 0.8251138925552368\n",
      "Seen so far: 14848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 232: 0.6895017623901367\n",
      "Seen so far: 14912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 233: 1.16768217086792\n",
      "Seen so far: 14976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 234: 0.7750189900398254\n",
      "Seen so far: 15040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 235: 0.4980318546295166\n",
      "Seen so far: 15104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 236: 0.6121028661727905\n",
      "Seen so far: 15168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 237: 0.7518188953399658\n",
      "Seen so far: 15232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 238: 1.1633918285369873\n",
      "Seen so far: 15296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 239: 0.9156299829483032\n",
      "Seen so far: 15360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 240: 1.086726427078247\n",
      "Seen so far: 15424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 241: 0.9289507865905762\n",
      "Seen so far: 15488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 242: 1.0920069217681885\n",
      "Seen so far: 15552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 243: 0.8397826552391052\n",
      "Seen so far: 15616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 244: 0.6119760274887085\n",
      "Seen so far: 15680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 245: 0.9486904144287109\n",
      "Seen so far: 15744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 246: 1.045701026916504\n",
      "Seen so far: 15808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 247: 1.0716683864593506\n",
      "Seen so far: 15872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 248: 0.5240726470947266\n",
      "Seen so far: 15936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 249: 0.5222200155258179\n",
      "Seen so far: 16000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 250: 0.8598805665969849\n",
      "Seen so far: 16064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 251: 1.1789973974227905\n",
      "Seen so far: 16128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 252: 1.0516607761383057\n",
      "Seen so far: 16192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 253: 0.7692165374755859\n",
      "Seen so far: 16256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 254: 0.8474661707878113\n",
      "Seen so far: 16320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 255: 1.0737946033477783\n",
      "Seen so far: 16384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 256: 0.9552898406982422\n",
      "Seen so far: 16448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 257: 1.2068476676940918\n",
      "Seen so far: 16512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 258: 0.544549822807312\n",
      "Seen so far: 16576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 259: 0.8448691964149475\n",
      "Seen so far: 16640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 260: 0.3592054545879364\n",
      "Seen so far: 16704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 261: 0.9133136868476868\n",
      "Seen so far: 16768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 262: 1.059529185295105\n",
      "Seen so far: 16832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 263: 0.8836061954498291\n",
      "Seen so far: 16896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 264: 0.517375111579895\n",
      "Seen so far: 16960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 265: 0.7780337333679199\n",
      "Seen so far: 17024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 266: 0.6933767795562744\n",
      "Seen so far: 17088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 267: 0.9201002717018127\n",
      "Seen so far: 17152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 268: 0.8615056276321411\n",
      "Seen so far: 17216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 269: 0.8407735228538513\n",
      "Seen so far: 17280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 270: 0.4680214524269104\n",
      "Seen so far: 17344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 271: 1.0620851516723633\n",
      "Seen so far: 17408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 272: 0.4483858346939087\n",
      "Seen so far: 17472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 273: 1.0181106328964233\n",
      "Seen so far: 17536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 274: 0.9998958706855774\n",
      "Seen so far: 17600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 275: 0.615453839302063\n",
      "Seen so far: 17664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 276: 1.0780291557312012\n",
      "Seen so far: 17728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 277: 1.100567102432251\n",
      "Seen so far: 17792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 278: 0.8088622689247131\n",
      "Seen so far: 17856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 279: 1.188345193862915\n",
      "Seen so far: 17920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 280: 0.5166523456573486\n",
      "Seen so far: 17984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 281: 0.671517014503479\n",
      "Seen so far: 18048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 282: 0.6519380807876587\n",
      "Seen so far: 18112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 283: 0.5036181211471558\n",
      "Seen so far: 18176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 284: 0.3893561363220215\n",
      "Seen so far: 18240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 285: 0.511800229549408\n",
      "Seen so far: 18304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 286: 0.6231998205184937\n",
      "Seen so far: 18368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 287: 0.5376416444778442\n",
      "Seen so far: 18432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 288: 0.7775870561599731\n",
      "Seen so far: 18496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 289: 0.8140493631362915\n",
      "Seen so far: 18560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 290: 1.0127801895141602\n",
      "Seen so far: 18624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 291: 0.39541101455688477\n",
      "Seen so far: 18688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 292: 1.0230135917663574\n",
      "Seen so far: 18752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 293: 1.208549976348877\n",
      "Seen so far: 18816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 294: 0.4806712865829468\n",
      "Seen so far: 18880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 295: 0.9542460441589355\n",
      "Seen so far: 18944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 296: 0.9282180070877075\n",
      "Seen so far: 19008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 297: 0.5033764839172363\n",
      "Seen so far: 19072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 298: 0.6147212982177734\n",
      "Seen so far: 19136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 299: 1.2684965133666992\n",
      "Seen so far: 19200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 300: 0.6762814521789551\n",
      "Seen so far: 19264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 301: 0.7953002452850342\n",
      "Seen so far: 19328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 302: 0.6984479427337646\n",
      "Seen so far: 19392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 303: 0.5551318526268005\n",
      "Seen so far: 19456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 304: 0.8349406719207764\n",
      "Seen so far: 19520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 305: 0.8351797461509705\n",
      "Seen so far: 19584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 306: 1.0579906702041626\n",
      "Seen so far: 19648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 307: 0.8682028651237488\n",
      "Seen so far: 19712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 308: 0.8639455437660217\n",
      "Seen so far: 19776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 309: 0.5831121206283569\n",
      "Seen so far: 19840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 310: 0.7790979743003845\n",
      "Seen so far: 19904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 311: 0.7522650957107544\n",
      "Seen so far: 19968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 312: 0.9857155680656433\n",
      "Seen so far: 20032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 313: 0.8663579225540161\n",
      "Seen so far: 20096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 314: 0.7674466371536255\n",
      "Seen so far: 20160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 315: 0.5971757769584656\n",
      "Seen so far: 20224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 316: 0.8752476572990417\n",
      "Seen so far: 20288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 317: 0.8621797561645508\n",
      "Seen so far: 20352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 318: 0.8197213411331177\n",
      "Seen so far: 20416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 319: 0.7547960877418518\n",
      "Seen so far: 20480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 320: 0.8832564353942871\n",
      "Seen so far: 20544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 321: 0.8128491640090942\n",
      "Seen so far: 20608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 322: 0.951362133026123\n",
      "Seen so far: 20672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 323: 0.8158788681030273\n",
      "Seen so far: 20736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 324: 1.075429916381836\n",
      "Seen so far: 20800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 325: 0.5492710471153259\n",
      "Seen so far: 20864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 326: 0.812319815158844\n",
      "Seen so far: 20928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 327: 0.8841967582702637\n",
      "Seen so far: 20992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 328: 0.8227297067642212\n",
      "Seen so far: 21056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 329: 0.8276146650314331\n",
      "Seen so far: 21120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 330: 0.732346773147583\n",
      "Seen so far: 21184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 331: 0.7081607580184937\n",
      "Seen so far: 21248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 332: 0.9023979902267456\n",
      "Seen so far: 21312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 333: 1.037818193435669\n",
      "Seen so far: 21376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 334: 0.8603239059448242\n",
      "Seen so far: 21440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 335: 0.9948419332504272\n",
      "Seen so far: 21504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 336: 0.650105357170105\n",
      "Seen so far: 21568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 337: 0.5381110310554504\n",
      "Seen so far: 21632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 338: 0.692644476890564\n",
      "Seen so far: 21696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 339: 0.5498378276824951\n",
      "Seen so far: 21760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 340: 0.5867404937744141\n",
      "Seen so far: 21824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 341: 0.835525393486023\n",
      "Seen so far: 21888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 342: 0.7849088907241821\n",
      "Seen so far: 21952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 343: 1.23783278465271\n",
      "Seen so far: 22016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 344: 0.8425971269607544\n",
      "Seen so far: 22080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 345: 0.7034595012664795\n",
      "Seen so far: 22144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 346: 0.6048972606658936\n",
      "Seen so far: 22208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 347: 1.2753279209136963\n",
      "Seen so far: 22272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 348: 0.41864556074142456\n",
      "Seen so far: 22336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 349: 0.7527593374252319\n",
      "Seen so far: 22400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 350: 0.8689041137695312\n",
      "Seen so far: 22464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 351: 0.5778968930244446\n",
      "Seen so far: 22528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 352: 0.7836427688598633\n",
      "Seen so far: 22592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 353: 1.0620660781860352\n",
      "Seen so far: 22656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 354: 0.7904468178749084\n",
      "Seen so far: 22720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 355: 0.9644553661346436\n",
      "Seen so far: 22784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 356: 0.46546822786331177\n",
      "Seen so far: 22848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 357: 0.8329071402549744\n",
      "Seen so far: 22912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 358: 0.7625600695610046\n",
      "Seen so far: 22976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 359: 0.9132651090621948\n",
      "Seen so far: 23040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 360: 0.8497129082679749\n",
      "Seen so far: 23104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 361: 0.44732773303985596\n",
      "Seen so far: 23168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 362: 0.865293025970459\n",
      "Seen so far: 23232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 363: 0.841658353805542\n",
      "Seen so far: 23296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 364: 0.8483503460884094\n",
      "Seen so far: 23360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 365: 0.9291789531707764\n",
      "Seen so far: 23424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 366: 0.9592263698577881\n",
      "Seen so far: 23488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 367: 0.7080565690994263\n",
      "Seen so far: 23552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 368: 0.823989987373352\n",
      "Seen so far: 23616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 369: 0.9759086966514587\n",
      "Seen so far: 23680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 370: 0.4931914210319519\n",
      "Seen so far: 23744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 371: 1.0660675764083862\n",
      "Seen so far: 23808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 372: 0.4900248646736145\n",
      "Seen so far: 23872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 373: 0.6540693044662476\n",
      "Seen so far: 23936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 374: 0.8951750993728638\n",
      "Seen so far: 24000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 375: 0.837250828742981\n",
      "Seen so far: 24064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 376: 0.5790318846702576\n",
      "Seen so far: 24128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 377: 1.2212738990783691\n",
      "Seen so far: 24192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 378: 0.6139118671417236\n",
      "Seen so far: 24256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 379: 0.9519414901733398\n",
      "Seen so far: 24320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 380: 0.8699580430984497\n",
      "Seen so far: 24384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 381: 0.69849693775177\n",
      "Seen so far: 24448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 382: 0.723395586013794\n",
      "Seen so far: 24512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 383: 0.9539841413497925\n",
      "Seen so far: 24576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 384: 0.968578040599823\n",
      "Seen so far: 24640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 385: 0.6428088545799255\n",
      "Seen so far: 24704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 386: 1.1024380922317505\n",
      "Seen so far: 24768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 387: 0.6744354963302612\n",
      "Seen so far: 24832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 388: 1.0726099014282227\n",
      "Seen so far: 24896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 389: 0.6851674318313599\n",
      "Seen so far: 24960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 390: 0.9572106003761292\n",
      "Seen so far: 25024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 391: 0.4419831335544586\n",
      "Seen so far: 25088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 392: 0.978095531463623\n",
      "Seen so far: 25152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 393: 0.9843090772628784\n",
      "Seen so far: 25216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 394: 0.5853350162506104\n",
      "Seen so far: 25280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 395: 1.1311613321304321\n",
      "Seen so far: 25344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 396: 0.747934103012085\n",
      "Seen so far: 25408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 397: 1.0869756937026978\n",
      "Seen so far: 25472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 398: 0.6074078679084778\n",
      "Seen so far: 25536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 399: 0.7618075013160706\n",
      "Seen so far: 25600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 400: 0.729677677154541\n",
      "Seen so far: 25664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 401: 0.6375871896743774\n",
      "Seen so far: 25728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 402: 0.7417773008346558\n",
      "Seen so far: 25792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 403: 0.5979399681091309\n",
      "Seen so far: 25856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 404: 0.5535740852355957\n",
      "Seen so far: 25920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 405: 0.8852843046188354\n",
      "Seen so far: 25984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 406: 0.9588790535926819\n",
      "Seen so far: 26048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 407: 0.7761470675468445\n",
      "Seen so far: 26112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 408: 0.9195946455001831\n",
      "Seen so far: 26176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 409: 0.9257010221481323\n",
      "Seen so far: 26240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 410: 0.48439475893974304\n",
      "Seen so far: 26304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 411: 1.2518608570098877\n",
      "Seen so far: 26368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 412: 0.926146388053894\n",
      "Seen so far: 26432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 413: 0.8349546194076538\n",
      "Seen so far: 26496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 414: 0.43544986844062805\n",
      "Seen so far: 26560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 415: 0.9067386388778687\n",
      "Seen so far: 26624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 416: 0.9016311764717102\n",
      "Seen so far: 26688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 417: 0.789800763130188\n",
      "Seen so far: 26752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 418: 0.870491623878479\n",
      "Seen so far: 26816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 419: 1.3316031694412231\n",
      "Seen so far: 26880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 420: 0.7921913266181946\n",
      "Seen so far: 26944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 421: 1.4835702180862427\n",
      "Seen so far: 27008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 422: 0.6496984362602234\n",
      "Seen so far: 27072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 423: 0.7162255048751831\n",
      "Seen so far: 27136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 424: 0.749349057674408\n",
      "Seen so far: 27200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 425: 0.808540940284729\n",
      "Seen so far: 27264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 426: 0.9802019000053406\n",
      "Seen so far: 27328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 427: 1.071730613708496\n",
      "Seen so far: 27392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 428: 0.7262090444564819\n",
      "Seen so far: 27456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 429: 0.7484811544418335\n",
      "Seen so far: 27520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 430: 0.926601231098175\n",
      "Seen so far: 27584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 431: 0.6426088809967041\n",
      "Seen so far: 27648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 432: 0.9983241558074951\n",
      "Seen so far: 27712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 433: 0.5558698177337646\n",
      "Seen so far: 27776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 434: 0.7071642279624939\n",
      "Seen so far: 27840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 435: 0.9845651984214783\n",
      "Seen so far: 27904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 436: 0.8869637250900269\n",
      "Seen so far: 27968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 437: 0.8512090444564819\n",
      "Seen so far: 28032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 438: 0.8678373098373413\n",
      "Seen so far: 28096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 439: 0.7503737807273865\n",
      "Seen so far: 28160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 440: 0.8942897319793701\n",
      "Seen so far: 28224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 441: 1.0396718978881836\n",
      "Seen so far: 28288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 442: 0.8662601709365845\n",
      "Seen so far: 28352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 443: 0.5113807320594788\n",
      "Seen so far: 28416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 444: 0.9824047088623047\n",
      "Seen so far: 28480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 445: 0.9149181842803955\n",
      "Seen so far: 28544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 446: 0.7388132810592651\n",
      "Seen so far: 28608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 447: 0.6481783390045166\n",
      "Seen so far: 28672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 448: 0.8003722429275513\n",
      "Seen so far: 28736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 449: 0.809245228767395\n",
      "Seen so far: 28800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 450: 1.2286651134490967\n",
      "Seen so far: 28864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 451: 0.7980367541313171\n",
      "Seen so far: 28928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 452: 0.9362115263938904\n",
      "Seen so far: 28992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 453: 0.7298991680145264\n",
      "Seen so far: 29056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 454: 0.6993257999420166\n",
      "Seen so far: 29120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 455: 0.689131498336792\n",
      "Seen so far: 29184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 456: 0.7144430875778198\n",
      "Seen so far: 29248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 457: 0.7308545708656311\n",
      "Seen so far: 29312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 458: 1.1409233808517456\n",
      "Seen so far: 29376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 459: 0.7977537512779236\n",
      "Seen so far: 29440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 460: 0.8823678493499756\n",
      "Seen so far: 29504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 461: 0.9273536205291748\n",
      "Seen so far: 29568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 462: 0.85407555103302\n",
      "Seen so far: 29632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 463: 0.9140021800994873\n",
      "Seen so far: 29696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 464: 0.7166276574134827\n",
      "Seen so far: 29760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 465: 0.6792505979537964\n",
      "Seen so far: 29824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 466: 0.786676287651062\n",
      "Seen so far: 29888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 467: 0.808296799659729\n",
      "Seen so far: 29952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 468: 0.8799075484275818\n",
      "Seen so far: 30016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 469: 0.7197868824005127\n",
      "Seen so far: 30080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 470: 0.5067576169967651\n",
      "Seen so far: 30144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 471: 0.6700369715690613\n",
      "Seen so far: 30208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 472: 0.7908135652542114\n",
      "Seen so far: 30272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 473: 0.8283557891845703\n",
      "Seen so far: 30336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 474: 0.562089204788208\n",
      "Seen so far: 30400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 475: 0.763969361782074\n",
      "Seen so far: 30464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 476: 0.8206889629364014\n",
      "Seen so far: 30528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 477: 0.5559271574020386\n",
      "Seen so far: 30592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 478: 0.7269456386566162\n",
      "Seen so far: 30656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 479: 0.9902359247207642\n",
      "Seen so far: 30720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 480: 0.6224127411842346\n",
      "Seen so far: 30784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 481: 0.8187134861946106\n",
      "Seen so far: 30848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 482: 0.5947068929672241\n",
      "Seen so far: 30912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 483: 0.847956120967865\n",
      "Seen so far: 30976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 484: 0.6519264578819275\n",
      "Seen so far: 31040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 485: 0.7182475924491882\n",
      "Seen so far: 31104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 486: 0.9608442783355713\n",
      "Seen so far: 31168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 487: 0.7778114080429077\n",
      "Seen so far: 31232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 488: 0.9670430421829224\n",
      "Seen so far: 31296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 489: 1.144656777381897\n",
      "Seen so far: 31360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 490: 0.7060227990150452\n",
      "Seen so far: 31424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 491: 0.6808569431304932\n",
      "Seen so far: 31488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 492: 0.6443891525268555\n",
      "Seen so far: 31552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 493: 0.7315474152565002\n",
      "Seen so far: 31616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 494: 0.781305193901062\n",
      "Seen so far: 31680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 495: 0.6673718094825745\n",
      "Seen so far: 31744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 496: 0.872076153755188\n",
      "Seen so far: 31808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 497: 0.8904067873954773\n",
      "Seen so far: 31872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 498: 0.6958849430084229\n",
      "Seen so far: 31936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 499: 0.8756306171417236\n",
      "Seen so far: 32000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 500: 0.6479982137680054\n",
      "Seen so far: 32064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 501: 0.9089491367340088\n",
      "Seen so far: 32128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 502: 0.5605592727661133\n",
      "Seen so far: 32192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 503: 0.6516934037208557\n",
      "Seen so far: 32256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 504: 1.2528188228607178\n",
      "Seen so far: 32320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 505: 0.9954419732093811\n",
      "Seen so far: 32384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 506: 0.95152747631073\n",
      "Seen so far: 32448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 507: 1.2278972864151\n",
      "Seen so far: 32512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 508: 0.6732784509658813\n",
      "Seen so far: 32576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 509: 0.6863716840744019\n",
      "Seen so far: 32640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 510: 0.8448174595832825\n",
      "Seen so far: 32704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 511: 0.9220023155212402\n",
      "Seen so far: 32768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 512: 0.9411351084709167\n",
      "Seen so far: 32832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 513: 1.0565917491912842\n",
      "Seen so far: 32896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 514: 0.547362208366394\n",
      "Seen so far: 32960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 515: 0.6493421196937561\n",
      "Seen so far: 33024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 516: 0.6523916721343994\n",
      "Seen so far: 33088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 517: 0.8694356679916382\n",
      "Seen so far: 33152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 518: 0.7440651059150696\n",
      "Seen so far: 33216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 519: 0.8950803279876709\n",
      "Seen so far: 33280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 520: 0.7357317805290222\n",
      "Seen so far: 33344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 521: 0.6864225268363953\n",
      "Seen so far: 33408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 522: 0.7331621646881104\n",
      "Seen so far: 33472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 523: 0.9012977480888367\n",
      "Seen so far: 33536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 524: 0.7259857654571533\n",
      "Seen so far: 33600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 525: 0.6534943580627441\n",
      "Seen so far: 33664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 526: 0.7031795978546143\n",
      "Seen so far: 33728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 527: 0.9124394059181213\n",
      "Seen so far: 33792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 528: 0.7422431111335754\n",
      "Seen so far: 33856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 529: 0.5438293218612671\n",
      "Seen so far: 33920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 530: 0.8439649939537048\n",
      "Seen so far: 33984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 531: 0.4245699942111969\n",
      "Seen so far: 34048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 532: 0.9146757125854492\n",
      "Seen so far: 34112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 533: 1.1006202697753906\n",
      "Seen so far: 34176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 534: 0.9347431063652039\n",
      "Seen so far: 34240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 535: 0.8924310803413391\n",
      "Seen so far: 34304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 536: 0.637800931930542\n",
      "Seen so far: 34368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 537: 0.643373966217041\n",
      "Seen so far: 34432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 538: 0.6555509567260742\n",
      "Seen so far: 34496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 539: 0.6231447458267212\n",
      "Seen so far: 34560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 540: 1.0092523097991943\n",
      "Seen so far: 34624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 541: 0.7036654353141785\n",
      "Seen so far: 34688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 542: 0.7208880186080933\n",
      "Seen so far: 34752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 543: 0.6066305637359619\n",
      "Seen so far: 34816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 544: 0.6554746627807617\n",
      "Seen so far: 34880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 545: 0.9435141682624817\n",
      "Seen so far: 34944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 546: 0.9278721809387207\n",
      "Seen so far: 35008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 547: 0.9721360206604004\n",
      "Seen so far: 35072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 548: 0.9545940160751343\n",
      "Seen so far: 35136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 549: 0.8099843263626099\n",
      "Seen so far: 35200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 550: 0.8071951270103455\n",
      "Seen so far: 35264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 551: 0.5013419389724731\n",
      "Seen so far: 35328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 552: 0.7374683618545532\n",
      "Seen so far: 35392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 553: 0.8524653315544128\n",
      "Seen so far: 35456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 554: 0.9413408637046814\n",
      "Seen so far: 35520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 555: 0.8992007374763489\n",
      "Seen so far: 35584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 556: 0.6627645492553711\n",
      "Seen so far: 35648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 557: 1.0268537998199463\n",
      "Seen so far: 35712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 558: 0.533513605594635\n",
      "Seen so far: 35776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 559: 0.7258100509643555\n",
      "Seen so far: 35840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 560: 0.7368788123130798\n",
      "Seen so far: 35904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 561: 0.6995177865028381\n",
      "Seen so far: 35968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 562: 0.8869094848632812\n",
      "Seen so far: 36032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 563: 0.8205713033676147\n",
      "Seen so far: 36096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 564: 0.6153900623321533\n",
      "Seen so far: 36160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 565: 0.65594083070755\n",
      "Seen so far: 36224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 566: 0.6480951309204102\n",
      "Seen so far: 36288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 567: 0.8468677997589111\n",
      "Seen so far: 36352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 568: 0.6272925138473511\n",
      "Seen so far: 36416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 569: 0.5330748558044434\n",
      "Seen so far: 36480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 570: 0.9576912522315979\n",
      "Seen so far: 36544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 571: 0.9848817586898804\n",
      "Seen so far: 36608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 572: 0.8686915040016174\n",
      "Seen so far: 36672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 573: 0.9792836904525757\n",
      "Seen so far: 36736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 574: 0.8157111406326294\n",
      "Seen so far: 36800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 575: 0.9430317282676697\n",
      "Seen so far: 36864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 576: 0.6385973691940308\n",
      "Seen so far: 36928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 577: 1.0518085956573486\n",
      "Seen so far: 36992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 578: 0.4528900384902954\n",
      "Seen so far: 37056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 579: 0.8092858791351318\n",
      "Seen so far: 37120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 580: 0.5324887037277222\n",
      "Seen so far: 37184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 581: 0.7231900691986084\n",
      "Seen so far: 37248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 582: 1.201035737991333\n",
      "Seen so far: 37312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 583: 0.6536644697189331\n",
      "Seen so far: 37376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 584: 1.0036568641662598\n",
      "Seen so far: 37440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 585: 0.736610472202301\n",
      "Seen so far: 37504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 586: 0.8664127588272095\n",
      "Seen so far: 37568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 587: 0.5177421569824219\n",
      "Seen so far: 37632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 588: 0.7626758813858032\n",
      "Seen so far: 37696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 589: 0.7682357430458069\n",
      "Seen so far: 37760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 590: 0.4972093403339386\n",
      "Seen so far: 37824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 591: 0.583818793296814\n",
      "Seen so far: 37888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 592: 0.9502974152565002\n",
      "Seen so far: 37952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 593: 0.9738785028457642\n",
      "Seen so far: 38016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 594: 0.5461555123329163\n",
      "Seen so far: 38080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 595: 0.6942804455757141\n",
      "Seen so far: 38144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 596: 0.5536114573478699\n",
      "Seen so far: 38208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 597: 0.4743037819862366\n",
      "Seen so far: 38272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 598: 0.7046682238578796\n",
      "Seen so far: 38336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 599: 0.4743027687072754\n",
      "Seen so far: 38400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 600: 0.5470148324966431\n",
      "Seen so far: 38464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 601: 0.5194244384765625\n",
      "Seen so far: 38528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 602: 1.0497775077819824\n",
      "Seen so far: 38592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 603: 1.5325374603271484\n",
      "Seen so far: 38656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 604: 0.9925559759140015\n",
      "Seen so far: 38720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 605: 0.7101446390151978\n",
      "Seen so far: 38784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 606: 1.3440775871276855\n",
      "Seen so far: 38848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 607: 0.8213475346565247\n",
      "Seen so far: 38912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 608: 0.8335803151130676\n",
      "Seen so far: 38976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 609: 0.6385944485664368\n",
      "Seen so far: 39040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 610: 0.4127030670642853\n",
      "Seen so far: 39104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 611: 0.7253584861755371\n",
      "Seen so far: 39168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 612: 0.7542953491210938\n",
      "Seen so far: 39232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 613: 0.7153947353363037\n",
      "Seen so far: 39296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 614: 0.8905925154685974\n",
      "Seen so far: 39360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 615: 0.7396712899208069\n",
      "Seen so far: 39424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 616: 0.5833811163902283\n",
      "Seen so far: 39488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 617: 0.9846299886703491\n",
      "Seen so far: 39552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 618: 1.1765251159667969\n",
      "Seen so far: 39616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 619: 0.8767303824424744\n",
      "Seen so far: 39680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 620: 1.042572021484375\n",
      "Seen so far: 39744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 621: 0.8586969375610352\n",
      "Seen so far: 39808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 622: 0.7954487800598145\n",
      "Seen so far: 39872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 623: 0.7571990489959717\n",
      "Seen so far: 39936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 624: 0.7647836208343506\n",
      "Seen so far: 40000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 625: 0.7217366099357605\n",
      "Seen so far: 40064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 626: 0.6683394908905029\n",
      "Seen so far: 40128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 627: 0.5687538981437683\n",
      "Seen so far: 40192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 628: 0.827706515789032\n",
      "Seen so far: 40256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 629: 0.8810812830924988\n",
      "Seen so far: 40320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 630: 0.7239068746566772\n",
      "Seen so far: 40384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 631: 0.7283576726913452\n",
      "Seen so far: 40448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 632: 0.7072241902351379\n",
      "Seen so far: 40512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 633: 0.9181602001190186\n",
      "Seen so far: 40576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 634: 0.5119189023971558\n",
      "Seen so far: 40640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 635: 0.5830313563346863\n",
      "Seen so far: 40704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 636: 0.9725808501243591\n",
      "Seen so far: 40768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 637: 0.3909740149974823\n",
      "Seen so far: 40832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 638: 0.6412440538406372\n",
      "Seen so far: 40896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 639: 0.7646220326423645\n",
      "Seen so far: 40960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 640: 0.8149071335792542\n",
      "Seen so far: 41024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 641: 0.3313294053077698\n",
      "Seen so far: 41088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 642: 0.7393480539321899\n",
      "Seen so far: 41152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 643: 0.5057958364486694\n",
      "Seen so far: 41216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 644: 0.8300954103469849\n",
      "Seen so far: 41280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 645: 0.9611930251121521\n",
      "Seen so far: 41344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 646: 0.6689653396606445\n",
      "Seen so far: 41408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 647: 0.774278998374939\n",
      "Seen so far: 41472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 648: 0.6559213399887085\n",
      "Seen so far: 41536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 649: 1.215944766998291\n",
      "Seen so far: 41600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 650: 1.321346402168274\n",
      "Seen so far: 41664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 651: 0.7186285257339478\n",
      "Seen so far: 41728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 652: 0.6821960210800171\n",
      "Seen so far: 41792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 653: 0.5876078605651855\n",
      "Seen so far: 41856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 654: 0.9222795963287354\n",
      "Seen so far: 41920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 655: 0.4682057499885559\n",
      "Seen so far: 41984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 656: 0.8697239756584167\n",
      "Seen so far: 42048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 657: 1.2550668716430664\n",
      "Seen so far: 42112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 658: 0.6916581392288208\n",
      "Seen so far: 42176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 659: 0.6944427490234375\n",
      "Seen so far: 42240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 660: 0.8170043230056763\n",
      "Seen so far: 42304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 661: 0.6802263259887695\n",
      "Seen so far: 42368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 662: 0.8302732706069946\n",
      "Seen so far: 42432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 663: 0.7955220341682434\n",
      "Seen so far: 42496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 664: 0.851210355758667\n",
      "Seen so far: 42560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 665: 0.9538859128952026\n",
      "Seen so far: 42624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 666: 0.7244905233383179\n",
      "Seen so far: 42688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 667: 0.6197782754898071\n",
      "Seen so far: 42752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 668: 0.5863112211227417\n",
      "Seen so far: 42816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 669: 0.9325456619262695\n",
      "Seen so far: 42880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 670: 0.7815777063369751\n",
      "Seen so far: 42944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 671: 1.4028103351593018\n",
      "Seen so far: 43008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 672: 0.7868291735649109\n",
      "Seen so far: 43072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 673: 1.0309441089630127\n",
      "Seen so far: 43136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 674: 0.6920269727706909\n",
      "Seen so far: 43200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 675: 0.8612927198410034\n",
      "Seen so far: 43264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 676: 0.9314532279968262\n",
      "Seen so far: 43328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 677: 0.7996628284454346\n",
      "Seen so far: 43392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 678: 0.5774766802787781\n",
      "Seen so far: 43456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 679: 0.930992841720581\n",
      "Seen so far: 43520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 680: 0.694444477558136\n",
      "Seen so far: 43584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 681: 1.2587177753448486\n",
      "Seen so far: 43648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 682: 0.9771441221237183\n",
      "Seen so far: 43712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 683: 0.5435600876808167\n",
      "Seen so far: 43776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 684: 0.7662839889526367\n",
      "Seen so far: 43840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 685: 0.5250295400619507\n",
      "Seen so far: 43904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 686: 1.0759124755859375\n",
      "Seen so far: 43968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 687: 0.9817288517951965\n",
      "Seen so far: 44032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 688: 0.5137917995452881\n",
      "Seen so far: 44096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 689: 0.5529358983039856\n",
      "Seen so far: 44160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 690: 0.8207483291625977\n",
      "Seen so far: 44224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 691: 0.9529900550842285\n",
      "Seen so far: 44288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 692: 1.093242883682251\n",
      "Seen so far: 44352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 693: 0.8137587904930115\n",
      "Seen so far: 44416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 694: 0.7384999394416809\n",
      "Seen so far: 44480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 695: 0.43769770860671997\n",
      "Seen so far: 44544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 696: 0.8826844692230225\n",
      "Seen so far: 44608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 697: 0.7514446973800659\n",
      "Seen so far: 44672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 698: 0.780988872051239\n",
      "Seen so far: 44736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 699: 0.7086013555526733\n",
      "Seen so far: 44800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 700: 0.9713373184204102\n",
      "Seen so far: 44864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 701: 0.7548896074295044\n",
      "Seen so far: 44928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 702: 0.5848267078399658\n",
      "Seen so far: 44992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 703: 0.5399918556213379\n",
      "Seen so far: 45056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 704: 0.6311763525009155\n",
      "Seen so far: 45120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 705: 0.5893658399581909\n",
      "Seen so far: 45184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 706: 0.78399658203125\n",
      "Seen so far: 45248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 707: 0.4298672080039978\n",
      "Seen so far: 45312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 708: 0.7434546947479248\n",
      "Seen so far: 45376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 709: 1.2626771926879883\n",
      "Seen so far: 45440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 710: 0.7420299053192139\n",
      "Seen so far: 45504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 711: 0.648240327835083\n",
      "Seen so far: 45568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 712: 0.763490617275238\n",
      "Seen so far: 45632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 713: 0.8786748647689819\n",
      "Seen so far: 45696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 714: 0.8453345894813538\n",
      "Seen so far: 45760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 715: 1.0331828594207764\n",
      "Seen so far: 45824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 716: 0.3541284203529358\n",
      "Seen so far: 45888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 717: 1.0881507396697998\n",
      "Seen so far: 45952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 718: 1.2088185548782349\n",
      "Seen so far: 46016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 719: 0.9278348684310913\n",
      "Seen so far: 46080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 720: 0.8335792422294617\n",
      "Seen so far: 46144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 721: 0.8800883293151855\n",
      "Seen so far: 46208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 722: 0.44127511978149414\n",
      "Seen so far: 46272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 723: 0.6069705486297607\n",
      "Seen so far: 46336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 724: 0.6832214593887329\n",
      "Seen so far: 46400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 725: 1.0594360828399658\n",
      "Seen so far: 46464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 726: 0.6670292615890503\n",
      "Seen so far: 46528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 727: 0.750842809677124\n",
      "Seen so far: 46592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 728: 0.9135674238204956\n",
      "Seen so far: 46656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 729: 0.659110426902771\n",
      "Seen so far: 46720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 730: 0.7982178926467896\n",
      "Seen so far: 46784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 731: 0.858495831489563\n",
      "Seen so far: 46848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 732: 1.6200100183486938\n",
      "Seen so far: 46912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 733: 0.971681535243988\n",
      "Seen so far: 46976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 734: 0.6913009881973267\n",
      "Seen so far: 47040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 735: 0.7436221837997437\n",
      "Seen so far: 47104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 736: 0.6653680205345154\n",
      "Seen so far: 47168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 737: 0.5250110626220703\n",
      "Seen so far: 47232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 738: 0.5575850009918213\n",
      "Seen so far: 47296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 739: 0.8340149521827698\n",
      "Seen so far: 47360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 740: 0.6703788042068481\n",
      "Seen so far: 47424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 741: 0.768525242805481\n",
      "Seen so far: 47488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 742: 0.5987603664398193\n",
      "Seen so far: 47552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 743: 1.2347913980484009\n",
      "Seen so far: 47616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 744: 0.6764964461326599\n",
      "Seen so far: 47680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 745: 0.825314998626709\n",
      "Seen so far: 47744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 746: 1.0016791820526123\n",
      "Seen so far: 47808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 747: 0.8730207681655884\n",
      "Seen so far: 47872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 748: 0.5848156213760376\n",
      "Seen so far: 47936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 749: 1.1652950048446655\n",
      "Seen so far: 48000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 750: 0.6692844033241272\n",
      "Seen so far: 48064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 751: 0.6340371370315552\n",
      "Seen so far: 48128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 752: 0.8827555179595947\n",
      "Seen so far: 48192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 753: 1.2013888359069824\n",
      "Seen so far: 48256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 754: 0.9653503894805908\n",
      "Seen so far: 48320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 755: 0.5224829316139221\n",
      "Seen so far: 48384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 756: 1.1002182960510254\n",
      "Seen so far: 48448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 757: 0.9715604782104492\n",
      "Seen so far: 48512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 758: 0.5774476528167725\n",
      "Seen so far: 48576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 759: 0.7228643298149109\n",
      "Seen so far: 48640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 760: 0.9938744902610779\n",
      "Seen so far: 48704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 761: 1.0508054494857788\n",
      "Seen so far: 48768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 762: 0.6537858843803406\n",
      "Seen so far: 48832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 763: 0.9226245880126953\n",
      "Seen so far: 48896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 764: 0.8146602511405945\n",
      "Seen so far: 48960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 765: 0.7086969614028931\n",
      "Seen so far: 49024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 766: 0.8801809549331665\n",
      "Seen so far: 49088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 767: 0.633091926574707\n",
      "Seen so far: 49152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 768: 0.4760406017303467\n",
      "Seen so far: 49216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 769: 0.6105380058288574\n",
      "Seen so far: 49280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 770: 0.7130475044250488\n",
      "Seen so far: 49344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 771: 0.7258361577987671\n",
      "Seen so far: 49408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 772: 1.1309762001037598\n",
      "Seen so far: 49472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 773: 0.9014525413513184\n",
      "Seen so far: 49536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 774: 0.6593064069747925\n",
      "Seen so far: 49600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 775: 0.8274595737457275\n",
      "Seen so far: 49664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 776: 0.683870792388916\n",
      "Seen so far: 49728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 777: 0.947067379951477\n",
      "Seen so far: 49792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 778: 0.7862061262130737\n",
      "Seen so far: 49856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 779: 0.4877435266971588\n",
      "Seen so far: 49920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 780: 1.140106201171875\n",
      "Seen so far: 49984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 781: 1.0628101825714111\n",
      "Seen so far: 50048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 782: 0.731161892414093\n",
      "Seen so far: 50112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 783: 0.7296968102455139\n",
      "Seen so far: 50176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 784: 1.0556449890136719\n",
      "Seen so far: 50240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 785: 0.7321011424064636\n",
      "Seen so far: 50304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 786: 1.114338994026184\n",
      "Seen so far: 50368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 787: 0.88312828540802\n",
      "Seen so far: 50432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 788: 0.3800199627876282\n",
      "Seen so far: 50496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 789: 0.9162291884422302\n",
      "Seen so far: 50560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 790: 1.0775446891784668\n",
      "Seen so far: 50624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 791: 0.5232093930244446\n",
      "Seen so far: 50688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 792: 0.6794922351837158\n",
      "Seen so far: 50752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 793: 0.7129598259925842\n",
      "Seen so far: 50816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 794: 1.0286914110183716\n",
      "Seen so far: 50880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 795: 0.6397144794464111\n",
      "Seen so far: 50944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 796: 0.6434712409973145\n",
      "Seen so far: 51008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 797: 0.7407594919204712\n",
      "Seen so far: 51072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 798: 1.116004228591919\n",
      "Seen so far: 51136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 799: 0.9468302130699158\n",
      "Seen so far: 51200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 800: 0.6767758131027222\n",
      "Seen so far: 51264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 801: 0.6533060669898987\n",
      "Seen so far: 51328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 802: 0.858292818069458\n",
      "Seen so far: 51392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 803: 0.9538858532905579\n",
      "Seen so far: 51456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 804: 0.4111135005950928\n",
      "Seen so far: 51520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 805: 0.8549687266349792\n",
      "Seen so far: 51584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 806: 0.8709578514099121\n",
      "Seen so far: 51648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 807: 0.5608661770820618\n",
      "Seen so far: 51712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 808: 0.7593629956245422\n",
      "Seen so far: 51776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 809: 0.6952047348022461\n",
      "Seen so far: 51840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 810: 0.8343977928161621\n",
      "Seen so far: 51904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 811: 0.8166005611419678\n",
      "Seen so far: 51968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 812: 0.8511844873428345\n",
      "Seen so far: 52032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 813: 0.7760108709335327\n",
      "Seen so far: 52096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 814: 0.5102869868278503\n",
      "Seen so far: 52160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 815: 1.0077919960021973\n",
      "Seen so far: 52224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 816: 0.9058268070220947\n",
      "Seen so far: 52288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 817: 0.43334779143333435\n",
      "Seen so far: 52352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 818: 1.2746200561523438\n",
      "Seen so far: 52416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 819: 0.27049127221107483\n",
      "Seen so far: 52480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 820: 0.9054524898529053\n",
      "Seen so far: 52544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 821: 0.6427332758903503\n",
      "Seen so far: 52608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 822: 0.5854763388633728\n",
      "Seen so far: 52672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 823: 1.0231341123580933\n",
      "Seen so far: 52736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 824: 0.9013158082962036\n",
      "Seen so far: 52800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 825: 0.7975924015045166\n",
      "Seen so far: 52864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 826: 0.7472959160804749\n",
      "Seen so far: 52928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 827: 1.1284708976745605\n",
      "Seen so far: 52992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 828: 0.7323569655418396\n",
      "Seen so far: 53056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 829: 0.9704416990280151\n",
      "Seen so far: 53120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 830: 0.7470608353614807\n",
      "Seen so far: 53184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 831: 1.0211434364318848\n",
      "Seen so far: 53248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 832: 0.8518446683883667\n",
      "Seen so far: 53312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 833: 0.830549955368042\n",
      "Seen so far: 53376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 834: 0.5762907266616821\n",
      "Seen so far: 53440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 835: 0.6860096454620361\n",
      "Seen so far: 53504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 836: 0.7827405333518982\n",
      "Seen so far: 53568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 837: 0.6947166919708252\n",
      "Seen so far: 53632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 838: 0.4265454113483429\n",
      "Seen so far: 53696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 839: 0.6400054693222046\n",
      "Seen so far: 53760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 840: 0.5984613299369812\n",
      "Seen so far: 53824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 841: 1.1015145778656006\n",
      "Seen so far: 53888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 842: 0.6309540271759033\n",
      "Seen so far: 53952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 843: 0.6489218473434448\n",
      "Seen so far: 54016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 844: 0.8957252502441406\n",
      "Seen so far: 54080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 845: 0.834460973739624\n",
      "Seen so far: 54144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 846: 0.6308351159095764\n",
      "Seen so far: 54208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 847: 0.7788093090057373\n",
      "Seen so far: 54272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 848: 0.7246541380882263\n",
      "Seen so far: 54336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 849: 0.5737907886505127\n",
      "Seen so far: 54400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 850: 0.4545883238315582\n",
      "Seen so far: 54464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 851: 0.3623136878013611\n",
      "Seen so far: 54528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 852: 0.43463629484176636\n",
      "Seen so far: 54592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 853: 0.5673612356185913\n",
      "Seen so far: 54656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 854: 0.6162872314453125\n",
      "Seen so far: 54720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 855: 0.6634520292282104\n",
      "Seen so far: 54784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 856: 0.593082070350647\n",
      "Seen so far: 54848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 857: 0.5074319839477539\n",
      "Seen so far: 54912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 858: 0.7949080467224121\n",
      "Seen so far: 54976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 859: 0.9562438130378723\n",
      "Seen so far: 55040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 860: 0.6108830571174622\n",
      "Seen so far: 55104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 861: 0.6771775484085083\n",
      "Seen so far: 55168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 862: 0.6099181175231934\n",
      "Seen so far: 55232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 863: 0.866141140460968\n",
      "Seen so far: 55296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 864: 1.088643193244934\n",
      "Seen so far: 55360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 865: 0.5430616140365601\n",
      "Seen so far: 55424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 866: 0.6100351214408875\n",
      "Seen so far: 55488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 867: 0.6865558624267578\n",
      "Seen so far: 55552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 868: 0.9464312791824341\n",
      "Seen so far: 55616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 869: 0.8523796200752258\n",
      "Seen so far: 55680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 870: 1.102162480354309\n",
      "Seen so far: 55744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 871: 1.0018705129623413\n",
      "Seen so far: 55808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 872: 0.48790091276168823\n",
      "Seen so far: 55872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 873: 0.9507448673248291\n",
      "Seen so far: 55936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 874: 0.9657342433929443\n",
      "Seen so far: 56000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 875: 0.9320476651191711\n",
      "Seen so far: 56064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 876: 0.8264831304550171\n",
      "Seen so far: 56128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 877: 0.8023393154144287\n",
      "Seen so far: 56192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 878: 0.9046928882598877\n",
      "Seen so far: 56256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 879: 0.32044366002082825\n",
      "Seen so far: 56320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 880: 0.8532598614692688\n",
      "Seen so far: 56384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 881: 1.2705832719802856\n",
      "Seen so far: 56448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 882: 0.7707202434539795\n",
      "Seen so far: 56512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 883: 0.7844492793083191\n",
      "Seen so far: 56576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 884: 0.3611586391925812\n",
      "Seen so far: 56640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 885: 0.685202956199646\n",
      "Seen so far: 56704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 886: 0.8610353469848633\n",
      "Seen so far: 56768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 887: 0.8770735263824463\n",
      "Seen so far: 56832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 888: 0.8111734390258789\n",
      "Seen so far: 56896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 889: 1.1480211019515991\n",
      "Seen so far: 56960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 890: 0.6755611300468445\n",
      "Seen so far: 57024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 891: 1.1044009923934937\n",
      "Seen so far: 57088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 892: 0.45831453800201416\n",
      "Seen so far: 57152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 893: 1.2532172203063965\n",
      "Seen so far: 57216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 894: 0.683060884475708\n",
      "Seen so far: 57280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 895: 0.8823884725570679\n",
      "Seen so far: 57344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 896: 1.180833101272583\n",
      "Seen so far: 57408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 897: 0.7523174285888672\n",
      "Seen so far: 57472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 898: 0.5459219813346863\n",
      "Seen so far: 57536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 899: 0.49200403690338135\n",
      "Seen so far: 57600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 900: 0.6528769135475159\n",
      "Seen so far: 57664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 901: 1.0770137310028076\n",
      "Seen so far: 57728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 902: 0.9204185009002686\n",
      "Seen so far: 57792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 903: 0.7720784544944763\n",
      "Seen so far: 57856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 904: 0.7875728011131287\n",
      "Seen so far: 57920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 905: 0.7072641253471375\n",
      "Seen so far: 57984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 906: 0.7903332710266113\n",
      "Seen so far: 58048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 907: 1.0411560535430908\n",
      "Seen so far: 58112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 908: 0.4590134024620056\n",
      "Seen so far: 58176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 909: 0.9180397987365723\n",
      "Seen so far: 58240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 910: 0.6323286294937134\n",
      "Seen so far: 58304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 911: 0.6000563502311707\n",
      "Seen so far: 58368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 912: 0.7657796144485474\n",
      "Seen so far: 58432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 913: 1.3602581024169922\n",
      "Seen so far: 58496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 914: 0.7353163957595825\n",
      "Seen so far: 58560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 915: 0.640655517578125\n",
      "Seen so far: 58624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 916: 1.0909035205841064\n",
      "Seen so far: 58688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 917: 0.6528472304344177\n",
      "Seen so far: 58752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 918: 0.8196806311607361\n",
      "Seen so far: 58816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 919: 0.5287183523178101\n",
      "Seen so far: 58880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 920: 0.6875805854797363\n",
      "Seen so far: 58944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 921: 0.528745174407959\n",
      "Seen so far: 59008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 922: 1.1574935913085938\n",
      "Seen so far: 59072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 923: 0.9001184701919556\n",
      "Seen so far: 59136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 924: 0.9395455718040466\n",
      "Seen so far: 59200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 925: 0.7507961988449097\n",
      "Seen so far: 59264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 926: 0.984883189201355\n",
      "Seen so far: 59328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 927: 0.6439862251281738\n",
      "Seen so far: 59392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 928: 0.6031748652458191\n",
      "Seen so far: 59456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 929: 0.6571950912475586\n",
      "Seen so far: 59520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 930: 0.7586203813552856\n",
      "Seen so far: 59584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 931: 0.9959216117858887\n",
      "Seen so far: 59648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 932: 1.2597815990447998\n",
      "Seen so far: 59712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 933: 0.8922948241233826\n",
      "Seen so far: 59776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 934: 1.1809180974960327\n",
      "Seen so far: 59840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 935: 0.6629651784896851\n",
      "Seen so far: 59904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 936: 0.8875591158866882\n",
      "Seen so far: 59968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 937: 0.9693921804428101\n",
      "Seen so far: 60032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 938: 0.9494636654853821\n",
      "Seen so far: 60096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 939: 0.6295120120048523\n",
      "Seen so far: 60160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 940: 0.5358047485351562\n",
      "Seen so far: 60224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 941: 0.6462509036064148\n",
      "Seen so far: 60288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 942: 0.8159440159797668\n",
      "Seen so far: 60352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 943: 0.8946447372436523\n",
      "Seen so far: 60416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 944: 0.7038745284080505\n",
      "Seen so far: 60480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 945: 1.0675630569458008\n",
      "Seen so far: 60544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 946: 0.8108457922935486\n",
      "Seen so far: 60608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 947: 0.9493894577026367\n",
      "Seen so far: 60672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 948: 0.45851409435272217\n",
      "Seen so far: 60736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 949: 0.6383587718009949\n",
      "Seen so far: 60800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 950: 0.881978452205658\n",
      "Seen so far: 60864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 951: 0.8055049777030945\n",
      "Seen so far: 60928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 952: 0.9497007131576538\n",
      "Seen so far: 60992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 953: 1.0453271865844727\n",
      "Seen so far: 61056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 954: 1.0341401100158691\n",
      "Seen so far: 61120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 955: 0.8415472507476807\n",
      "Seen so far: 61184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 956: 1.3232290744781494\n",
      "Seen so far: 61248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 957: 0.7438206672668457\n",
      "Seen so far: 61312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 958: 0.9450420141220093\n",
      "Seen so far: 61376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 959: 0.5997041463851929\n",
      "Seen so far: 61440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 960: 0.6638245582580566\n",
      "Seen so far: 61504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 961: 0.7023927569389343\n",
      "Seen so far: 61568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 962: 0.6608366966247559\n",
      "Seen so far: 61632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 963: 0.6898425817489624\n",
      "Seen so far: 61696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 964: 0.771745502948761\n",
      "Seen so far: 61760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 965: 0.9071693420410156\n",
      "Seen so far: 61824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 966: 0.4261246919631958\n",
      "Seen so far: 61888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 967: 0.6265777349472046\n",
      "Seen so far: 61952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 968: 0.8115568161010742\n",
      "Seen so far: 62016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 969: 1.0133602619171143\n",
      "Seen so far: 62080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 970: 1.1021955013275146\n",
      "Seen so far: 62144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 971: 0.667511522769928\n",
      "Seen so far: 62208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 972: 1.0740966796875\n",
      "Seen so far: 62272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 973: 0.750079870223999\n",
      "Seen so far: 62336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 974: 0.6875594854354858\n",
      "Seen so far: 62400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 975: 0.8371471166610718\n",
      "Seen so far: 62464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 976: 0.8989314436912537\n",
      "Seen so far: 62528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 977: 0.886192798614502\n",
      "Seen so far: 62592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 978: 1.2182106971740723\n",
      "Seen so far: 62656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 979: 0.899733304977417\n",
      "Seen so far: 62720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 980: 0.9361259937286377\n",
      "Seen so far: 62784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 981: 0.7493188381195068\n",
      "Seen so far: 62848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 982: 0.7245912551879883\n",
      "Seen so far: 62912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 983: 0.5813192129135132\n",
      "Seen so far: 62976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 984: 0.7804507613182068\n",
      "Seen so far: 63040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 985: 0.9237881898880005\n",
      "Seen so far: 63104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 986: 0.8153022527694702\n",
      "Seen so far: 63168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 987: 0.9460439085960388\n",
      "Seen so far: 63232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 988: 0.7448574304580688\n",
      "Seen so far: 63296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 989: 0.8799523115158081\n",
      "Seen so far: 63360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 990: 0.7228409051895142\n",
      "Seen so far: 63424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 991: 0.673965573310852\n",
      "Seen so far: 63488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 992: 0.37950074672698975\n",
      "Seen so far: 63552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 993: 0.7287176847457886\n",
      "Seen so far: 63616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 994: 0.9981793165206909\n",
      "Seen so far: 63680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 995: 0.8083899617195129\n",
      "Seen so far: 63744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 996: 0.8549526333808899\n",
      "Seen so far: 63808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 997: 0.3648413121700287\n",
      "Seen so far: 63872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 998: 0.6912922859191895\n",
      "Seen so far: 63936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 999: 0.6749895811080933\n",
      "Seen so far: 64000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1000: 0.6318643093109131\n",
      "Seen so far: 64064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1001: 0.7754260301589966\n",
      "Seen so far: 64128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1002: 0.7450565099716187\n",
      "Seen so far: 64192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1003: 0.6506076455116272\n",
      "Seen so far: 64256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1004: 0.7479246854782104\n",
      "Seen so far: 64320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1005: 0.7488520741462708\n",
      "Seen so far: 64384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1006: 0.7910546660423279\n",
      "Seen so far: 64448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1007: 0.876761794090271\n",
      "Seen so far: 64512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1008: 1.0729498863220215\n",
      "Seen so far: 64576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1009: 0.893123209476471\n",
      "Seen so far: 64640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1010: 0.4888823926448822\n",
      "Seen so far: 64704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1011: 0.6548668146133423\n",
      "Seen so far: 64768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1012: 0.7008909583091736\n",
      "Seen so far: 64832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1013: 0.858989417552948\n",
      "Seen so far: 64896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1014: 0.7754656076431274\n",
      "Seen so far: 64960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1015: 0.36396968364715576\n",
      "Seen so far: 65024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1016: 0.9763960242271423\n",
      "Seen so far: 65088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1017: 0.995442271232605\n",
      "Seen so far: 65152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1018: 0.6614065170288086\n",
      "Seen so far: 65216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1019: 1.081020712852478\n",
      "Seen so far: 65280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1020: 0.44162124395370483\n",
      "Seen so far: 65344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1021: 0.5423883199691772\n",
      "Seen so far: 65408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1022: 0.4249362647533417\n",
      "Seen so far: 65472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1023: 1.1688141822814941\n",
      "Seen so far: 65536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1024: 0.6158120036125183\n",
      "Seen so far: 65600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1025: 0.7365485429763794\n",
      "Seen so far: 65664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1026: 0.7721660137176514\n",
      "Seen so far: 65728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1027: 1.0903949737548828\n",
      "Seen so far: 65792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1028: 0.49793076515197754\n",
      "Seen so far: 65856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1029: 1.002403736114502\n",
      "Seen so far: 65920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1030: 0.8393590450286865\n",
      "Seen so far: 65984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1031: 0.6785415410995483\n",
      "Seen so far: 66048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1032: 0.7771869897842407\n",
      "Seen so far: 66112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1033: 1.0586678981781006\n",
      "Seen so far: 66176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1034: 1.247172236442566\n",
      "Seen so far: 66240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1035: 1.0629669427871704\n",
      "Seen so far: 66304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1036: 0.6158417463302612\n",
      "Seen so far: 66368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1037: 0.837335467338562\n",
      "Seen so far: 66432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1038: 0.8167643547058105\n",
      "Seen so far: 66496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1039: 0.629447340965271\n",
      "Seen so far: 66560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1040: 0.9438710808753967\n",
      "Seen so far: 66624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1041: 0.9583888649940491\n",
      "Seen so far: 66688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1042: 0.6721862554550171\n",
      "Seen so far: 66752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1043: 0.8145771026611328\n",
      "Seen so far: 66816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1044: 0.38324037194252014\n",
      "Seen so far: 66880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1045: 0.8567216992378235\n",
      "Seen so far: 66944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1046: 0.7134300470352173\n",
      "Seen so far: 67008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1047: 0.6741766929626465\n",
      "Seen so far: 67072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1048: 0.7846205234527588\n",
      "Seen so far: 67136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1049: 0.5388512015342712\n",
      "Seen so far: 67200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1050: 1.1739760637283325\n",
      "Seen so far: 67264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1051: 1.1205863952636719\n",
      "Seen so far: 67328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1052: 0.6437883377075195\n",
      "Seen so far: 67392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1053: 0.7772769927978516\n",
      "Seen so far: 67456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1054: 0.9772086143493652\n",
      "Seen so far: 67520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1055: 0.848268449306488\n",
      "Seen so far: 67584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1056: 0.45043128728866577\n",
      "Seen so far: 67648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1057: 0.5966780185699463\n",
      "Seen so far: 67712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1058: 0.49652600288391113\n",
      "Seen so far: 67776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1059: 0.560333788394928\n",
      "Seen so far: 67840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1060: 0.5210158228874207\n",
      "Seen so far: 67904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1061: 0.6803344488143921\n",
      "Seen so far: 67968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1062: 1.1103110313415527\n",
      "Seen so far: 68032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1063: 0.4591422975063324\n",
      "Seen so far: 68096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1064: 0.8305133581161499\n",
      "Seen so far: 68160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1065: 0.6422009468078613\n",
      "Seen so far: 68224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1066: 0.8111625909805298\n",
      "Seen so far: 68288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1067: 0.5022817850112915\n",
      "Seen so far: 68352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1068: 0.7764757871627808\n",
      "Seen so far: 68416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1069: 0.6645692586898804\n",
      "Seen so far: 68480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1070: 0.6863240003585815\n",
      "Seen so far: 68544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1071: 0.6660568714141846\n",
      "Seen so far: 68608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1072: 0.554034948348999\n",
      "Seen so far: 68672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1073: 1.259567141532898\n",
      "Seen so far: 68736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1074: 0.6754704713821411\n",
      "Seen so far: 68800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1075: 0.6334664225578308\n",
      "Seen so far: 68864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1076: 0.44746094942092896\n",
      "Seen so far: 68928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1077: 0.7932263016700745\n",
      "Seen so far: 68992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1078: 0.886983335018158\n",
      "Seen so far: 69056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1079: 0.7767760753631592\n",
      "Seen so far: 69120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1080: 0.6074779629707336\n",
      "Seen so far: 69184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1081: 0.8272527456283569\n",
      "Seen so far: 69248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1082: 0.7279645204544067\n",
      "Seen so far: 69312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1083: 0.9157857298851013\n",
      "Seen so far: 69376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1084: 0.85743248462677\n",
      "Seen so far: 69440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1085: 0.8022513389587402\n",
      "Seen so far: 69504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1086: 0.9380749464035034\n",
      "Seen so far: 69568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1087: 0.9515015482902527\n",
      "Seen so far: 69632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1088: 0.9609267115592957\n",
      "Seen so far: 69696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1089: 0.6611327528953552\n",
      "Seen so far: 69760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1090: 0.6044936776161194\n",
      "Seen so far: 69824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1091: 0.8700209856033325\n",
      "Seen so far: 69888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1092: 0.9312551021575928\n",
      "Seen so far: 69952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1093: 0.5600579380989075\n",
      "Seen so far: 70016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1094: 0.9745320081710815\n",
      "Seen so far: 70080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1095: 0.6838087439537048\n",
      "Seen so far: 70144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1096: 0.4992687702178955\n",
      "Seen so far: 70208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1097: 0.5849287509918213\n",
      "Seen so far: 70272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1098: 0.9981083273887634\n",
      "Seen so far: 70336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1099: 0.5065877437591553\n",
      "Seen so far: 70400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1100: 1.033085823059082\n",
      "Seen so far: 70464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1101: 0.992783784866333\n",
      "Seen so far: 70528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1102: 0.6990451812744141\n",
      "Seen so far: 70592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1103: 0.8535219430923462\n",
      "Seen so far: 70656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1104: 0.6036311388015747\n",
      "Seen so far: 70720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1105: 0.8872073888778687\n",
      "Seen so far: 70784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1106: 0.8417947292327881\n",
      "Seen so far: 70848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1107: 0.6957179307937622\n",
      "Seen so far: 70912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1108: 0.8037919998168945\n",
      "Seen so far: 70976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1109: 0.5596053600311279\n",
      "Seen so far: 71040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1110: 0.6706283688545227\n",
      "Seen so far: 71104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1111: 0.7135204076766968\n",
      "Seen so far: 71168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1112: 1.1126463413238525\n",
      "Seen so far: 71232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1113: 1.3848400115966797\n",
      "Seen so far: 71296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1114: 0.5929084420204163\n",
      "Seen so far: 71360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1115: 1.179966688156128\n",
      "Seen so far: 71424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1116: 0.6977244019508362\n",
      "Seen so far: 71488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1117: 0.7097088098526001\n",
      "Seen so far: 71552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1118: 0.5534471273422241\n",
      "Seen so far: 71616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1119: 0.6766179800033569\n",
      "Seen so far: 71680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1120: 0.5933029651641846\n",
      "Seen so far: 71744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1121: 0.9274216890335083\n",
      "Seen so far: 71808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1122: 0.3003274202346802\n",
      "Seen so far: 71872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1123: 0.7299407124519348\n",
      "Seen so far: 71936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1124: 0.8482457995414734\n",
      "Seen so far: 72000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1125: 1.077606439590454\n",
      "Seen so far: 72064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1126: 0.6055065393447876\n",
      "Seen so far: 72128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1127: 0.6808487176895142\n",
      "Seen so far: 72192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1128: 1.4244388341903687\n",
      "Seen so far: 72256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1129: 0.6390359401702881\n",
      "Seen so far: 72320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1130: 0.669023871421814\n",
      "Seen so far: 72384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1131: 0.9165188670158386\n",
      "Seen so far: 72448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1132: 0.7770048379898071\n",
      "Seen so far: 72512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1133: 0.77187180519104\n",
      "Seen so far: 72576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1134: 0.7842267751693726\n",
      "Seen so far: 72640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1135: 0.9262679815292358\n",
      "Seen so far: 72704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1136: 0.8337414264678955\n",
      "Seen so far: 72768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1137: 0.9456514716148376\n",
      "Seen so far: 72832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1138: 0.7272891998291016\n",
      "Seen so far: 72896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1139: 0.5701475143432617\n",
      "Seen so far: 72960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1140: 1.0447949171066284\n",
      "Seen so far: 73024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1141: 0.5379795432090759\n",
      "Seen so far: 73088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1142: 0.737704873085022\n",
      "Seen so far: 73152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1143: 0.6559317708015442\n",
      "Seen so far: 73216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1144: 0.9137187004089355\n",
      "Seen so far: 73280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1145: 0.8217204809188843\n",
      "Seen so far: 73344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1146: 0.7109354734420776\n",
      "Seen so far: 73408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1147: 0.8500834703445435\n",
      "Seen so far: 73472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1148: 1.2589361667633057\n",
      "Seen so far: 73536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1149: 0.8041518330574036\n",
      "Seen so far: 73600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1150: 0.788002073764801\n",
      "Seen so far: 73664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1151: 0.663405179977417\n",
      "Seen so far: 73728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1152: 0.7372995615005493\n",
      "Seen so far: 73792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1153: 0.7650059461593628\n",
      "Seen so far: 73856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1154: 0.5917587280273438\n",
      "Seen so far: 73920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1155: 1.0480940341949463\n",
      "Seen so far: 73984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1156: 0.6919270157814026\n",
      "Seen so far: 74048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1157: 0.83917635679245\n",
      "Seen so far: 74112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1158: 0.8878169655799866\n",
      "Seen so far: 74176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1159: 0.8176428079605103\n",
      "Seen so far: 74240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1160: 0.8072073459625244\n",
      "Seen so far: 74304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1161: 0.6105446815490723\n",
      "Seen so far: 74368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1162: 0.5315070152282715\n",
      "Seen so far: 74432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1163: 0.5524895787239075\n",
      "Seen so far: 74496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1164: 0.775536060333252\n",
      "Seen so far: 74560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1165: 0.7080285549163818\n",
      "Seen so far: 74624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1166: 0.9102420806884766\n",
      "Seen so far: 74688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1167: 0.7443828582763672\n",
      "Seen so far: 74752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1168: 0.4759306311607361\n",
      "Seen so far: 74816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1169: 0.6530495285987854\n",
      "Seen so far: 74880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1170: 0.8032335638999939\n",
      "Seen so far: 74944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1171: 0.7388814687728882\n",
      "Seen so far: 75008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1172: 1.0210963487625122\n",
      "Seen so far: 75072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1173: 0.7489296197891235\n",
      "Seen so far: 75136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1174: 0.8817440867424011\n",
      "Seen so far: 75200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1175: 1.3190903663635254\n",
      "Seen so far: 75264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1176: 1.0693156719207764\n",
      "Seen so far: 75328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1177: 0.9839580059051514\n",
      "Seen so far: 75392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1178: 1.2248643636703491\n",
      "Seen so far: 75456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1179: 0.4106762409210205\n",
      "Seen so far: 75520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1180: 0.6852779984474182\n",
      "Seen so far: 75584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1181: 0.9414514303207397\n",
      "Seen so far: 75648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1182: 1.053623080253601\n",
      "Seen so far: 75712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1183: 0.9098570942878723\n",
      "Seen so far: 75776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1184: 0.852074146270752\n",
      "Seen so far: 75840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1185: 0.5424843430519104\n",
      "Seen so far: 75904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1186: 0.7481843829154968\n",
      "Seen so far: 75968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1187: 0.8365904092788696\n",
      "Seen so far: 76032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1188: 0.8138569593429565\n",
      "Seen so far: 76096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1189: 0.4876890480518341\n",
      "Seen so far: 76160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1190: 0.49534380435943604\n",
      "Seen so far: 76224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1191: 0.4692094326019287\n",
      "Seen so far: 76288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1192: 1.215887427330017\n",
      "Seen so far: 76352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1193: 0.6255126595497131\n",
      "Seen so far: 76416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1194: 1.1826698780059814\n",
      "Seen so far: 76480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1195: 0.5882779359817505\n",
      "Seen so far: 76544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1196: 0.5910438895225525\n",
      "Seen so far: 76608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1197: 0.7595067024230957\n",
      "Seen so far: 76672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1198: 0.8466983437538147\n",
      "Seen so far: 76736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1199: 0.9962561130523682\n",
      "Seen so far: 76800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1200: 0.7399889230728149\n",
      "Seen so far: 76864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1201: 0.8995574712753296\n",
      "Seen so far: 76928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1202: 0.8554048538208008\n",
      "Seen so far: 76992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1203: 0.6799684762954712\n",
      "Seen so far: 77056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1204: 0.8333540558815002\n",
      "Seen so far: 77120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1205: 0.6913970112800598\n",
      "Seen so far: 77184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1206: 0.588725209236145\n",
      "Seen so far: 77248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1207: 0.944352924823761\n",
      "Seen so far: 77312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1208: 1.1045442819595337\n",
      "Seen so far: 77376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1209: 0.998253583908081\n",
      "Seen so far: 77440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1210: 0.6777637004852295\n",
      "Seen so far: 77504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1211: 0.7551804780960083\n",
      "Seen so far: 77568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1212: 0.6046242713928223\n",
      "Seen so far: 77632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1213: 0.7303262948989868\n",
      "Seen so far: 77696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1214: 1.3489038944244385\n",
      "Seen so far: 77760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1215: 0.4167409837245941\n",
      "Seen so far: 77824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1216: 0.6492556929588318\n",
      "Seen so far: 77888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1217: 0.7241878509521484\n",
      "Seen so far: 77952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1218: 0.9371999502182007\n",
      "Seen so far: 78016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1219: 1.1377904415130615\n",
      "Seen so far: 78080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1220: 0.6195990443229675\n",
      "Seen so far: 78144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1221: 0.5952490568161011\n",
      "Seen so far: 78208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1222: 0.7480868101119995\n",
      "Seen so far: 78272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1223: 0.8510100841522217\n",
      "Seen so far: 78336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1224: 0.5543797016143799\n",
      "Seen so far: 78400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1225: 1.2114081382751465\n",
      "Seen so far: 78464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1226: 0.778367280960083\n",
      "Seen so far: 78528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1227: 0.7685772776603699\n",
      "Seen so far: 78592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1228: 0.8532271385192871\n",
      "Seen so far: 78656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1229: 1.0019334554672241\n",
      "Seen so far: 78720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1230: 0.9338176846504211\n",
      "Seen so far: 78784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1231: 0.8511838316917419\n",
      "Seen so far: 78848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1232: 0.9531379342079163\n",
      "Seen so far: 78912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1233: 0.6451329588890076\n",
      "Seen so far: 78976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1234: 0.9180570244789124\n",
      "Seen so far: 79040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1235: 0.6510223150253296\n",
      "Seen so far: 79104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1236: 0.8379502892494202\n",
      "Seen so far: 79168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1237: 0.7327550053596497\n",
      "Seen so far: 79232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1238: 1.0628528594970703\n",
      "Seen so far: 79296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1239: 0.8009129166603088\n",
      "Seen so far: 79360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1240: 0.9101802110671997\n",
      "Seen so far: 79424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1241: 0.9291176795959473\n",
      "Seen so far: 79488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1242: 0.6956052780151367\n",
      "Seen so far: 79552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1243: 0.989029049873352\n",
      "Seen so far: 79616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1244: 0.6292226314544678\n",
      "Seen so far: 79680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1245: 0.8856257796287537\n",
      "Seen so far: 79744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1246: 0.7185169458389282\n",
      "Seen so far: 79808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1247: 0.5161080956459045\n",
      "Seen so far: 79872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1248: 0.7188864946365356\n",
      "Seen so far: 79936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1249: 1.0565810203552246\n",
      "Seen so far: 80000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1250: 0.7622854709625244\n",
      "Seen so far: 80064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1251: 0.36535611748695374\n",
      "Seen so far: 80128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1252: 0.8774585723876953\n",
      "Seen so far: 80192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1253: 0.5277485251426697\n",
      "Seen so far: 80256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1254: 0.6754007935523987\n",
      "Seen so far: 80320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1255: 0.6391123533248901\n",
      "Seen so far: 80384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1256: 1.1632579565048218\n",
      "Seen so far: 80448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1257: 0.880385160446167\n",
      "Seen so far: 80512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1258: 0.6237419843673706\n",
      "Seen so far: 80576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1259: 0.6329203844070435\n",
      "Seen so far: 80640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1260: 0.5354298949241638\n",
      "Seen so far: 80704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1261: 0.5483503341674805\n",
      "Seen so far: 80768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1262: 0.7770101428031921\n",
      "Seen so far: 80832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1263: 0.5568834543228149\n",
      "Seen so far: 80896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1264: 0.8589935302734375\n",
      "Seen so far: 80960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1265: 0.7914028167724609\n",
      "Seen so far: 81024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1266: 0.5310829281806946\n",
      "Seen so far: 81088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1267: 0.6955724358558655\n",
      "Seen so far: 81152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1268: 0.5675790309906006\n",
      "Seen so far: 81216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1269: 0.8856236934661865\n",
      "Seen so far: 81280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1270: 1.2351831197738647\n",
      "Seen so far: 81344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1271: 0.565406858921051\n",
      "Seen so far: 81408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1272: 0.9855983257293701\n",
      "Seen so far: 81472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1273: 0.934646487236023\n",
      "Seen so far: 81536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1274: 0.4807855486869812\n",
      "Seen so far: 81600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1275: 0.7255394458770752\n",
      "Seen so far: 81664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1276: 0.486556738615036\n",
      "Seen so far: 81728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1277: 0.7111673355102539\n",
      "Seen so far: 81792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1278: 0.9009612798690796\n",
      "Seen so far: 81856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1279: 0.877057671546936\n",
      "Seen so far: 81920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1280: 0.8851823806762695\n",
      "Seen so far: 81984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1281: 0.6584737300872803\n",
      "Seen so far: 82048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1282: 0.6893433928489685\n",
      "Seen so far: 82112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1283: 0.6826412677764893\n",
      "Seen so far: 82176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1284: 1.093711018562317\n",
      "Seen so far: 82240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1285: 1.0602340698242188\n",
      "Seen so far: 82304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1286: 0.7683688998222351\n",
      "Seen so far: 82368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1287: 0.7754838466644287\n",
      "Seen so far: 82432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1288: 0.5303900241851807\n",
      "Seen so far: 82496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1289: 0.9916461706161499\n",
      "Seen so far: 82560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1290: 0.44261252880096436\n",
      "Seen so far: 82624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1291: 0.8521938323974609\n",
      "Seen so far: 82688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1292: 0.2759482264518738\n",
      "Seen so far: 82752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1293: 0.7543861865997314\n",
      "Seen so far: 82816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1294: 0.7669280767440796\n",
      "Seen so far: 82880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1295: 0.8034019470214844\n",
      "Seen so far: 82944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1296: 0.4352113902568817\n",
      "Seen so far: 83008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1297: 0.7658398151397705\n",
      "Seen so far: 83072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1298: 0.5327678322792053\n",
      "Seen so far: 83136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1299: 0.6435441970825195\n",
      "Seen so far: 83200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1300: 0.9719836711883545\n",
      "Seen so far: 83264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1301: 0.7817914485931396\n",
      "Seen so far: 83328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1302: 0.9346134662628174\n",
      "Seen so far: 83392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1303: 0.9107174873352051\n",
      "Seen so far: 83456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1304: 0.43647608160972595\n",
      "Seen so far: 83520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1305: 0.6714102625846863\n",
      "Seen so far: 83584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1306: 0.8034351468086243\n",
      "Seen so far: 83648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1307: 0.6245507597923279\n",
      "Seen so far: 83712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1308: 0.6221299767494202\n",
      "Seen so far: 83776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1309: 0.48466771841049194\n",
      "Seen so far: 83840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1310: 0.41593655943870544\n",
      "Seen so far: 83904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1311: 0.6249347925186157\n",
      "Seen so far: 83968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1312: 0.6176896095275879\n",
      "Seen so far: 84032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1313: 0.7286796569824219\n",
      "Seen so far: 84096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1314: 0.587537944316864\n",
      "Seen so far: 84160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1315: 0.7657142877578735\n",
      "Seen so far: 84224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1316: 0.8653783798217773\n",
      "Seen so far: 84288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1317: 1.219303846359253\n",
      "Seen so far: 84352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1318: 0.7462859749794006\n",
      "Seen so far: 84416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1319: 0.7850900888442993\n",
      "Seen so far: 84480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1320: 0.9602481722831726\n",
      "Seen so far: 84544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1321: 1.2915353775024414\n",
      "Seen so far: 84608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1322: 0.8065564036369324\n",
      "Seen so far: 84672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1323: 0.6838715076446533\n",
      "Seen so far: 84736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1324: 0.6346737742424011\n",
      "Seen so far: 84800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1325: 0.8026179075241089\n",
      "Seen so far: 84864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1326: 0.8236021399497986\n",
      "Seen so far: 84928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1327: 0.6752066612243652\n",
      "Seen so far: 84992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1328: 0.8698071241378784\n",
      "Seen so far: 85056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1329: 0.8412452936172485\n",
      "Seen so far: 85120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1330: 0.7156546115875244\n",
      "Seen so far: 85184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1331: 0.8212543725967407\n",
      "Seen so far: 85248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1332: 0.788925290107727\n",
      "Seen so far: 85312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1333: 1.002792477607727\n",
      "Seen so far: 85376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1334: 0.8836299180984497\n",
      "Seen so far: 85440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1335: 0.7646892666816711\n",
      "Seen so far: 85504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1336: 0.7523946166038513\n",
      "Seen so far: 85568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1337: 0.6406235694885254\n",
      "Seen so far: 85632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1338: 1.1556622982025146\n",
      "Seen so far: 85696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1339: 0.7933496832847595\n",
      "Seen so far: 85760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1340: 1.4195642471313477\n",
      "Seen so far: 85824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1341: 0.9114395976066589\n",
      "Seen so far: 85888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1342: 0.5377667546272278\n",
      "Seen so far: 85952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1343: 0.7783247232437134\n",
      "Seen so far: 86016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1344: 1.2014169692993164\n",
      "Seen so far: 86080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1345: 0.5286511182785034\n",
      "Seen so far: 86144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1346: 0.7259422540664673\n",
      "Seen so far: 86208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1347: 0.63230299949646\n",
      "Seen so far: 86272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1348: 0.912566065788269\n",
      "Seen so far: 86336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1349: 1.0521949529647827\n",
      "Seen so far: 86400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1350: 0.9429914355278015\n",
      "Seen so far: 86464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1351: 0.5714870691299438\n",
      "Seen so far: 86528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1352: 1.1952272653579712\n",
      "Seen so far: 86592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1353: 0.502223789691925\n",
      "Seen so far: 86656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1354: 0.9909642934799194\n",
      "Seen so far: 86720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1355: 0.9340175986289978\n",
      "Seen so far: 86784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1356: 0.566987156867981\n",
      "Seen so far: 86848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1357: 0.8692227602005005\n",
      "Seen so far: 86912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1358: 0.6996956467628479\n",
      "Seen so far: 86976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1359: 0.7288367748260498\n",
      "Seen so far: 87040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1360: 0.77112877368927\n",
      "Seen so far: 87104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1361: 0.6220332384109497\n",
      "Seen so far: 87168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1362: 0.802936315536499\n",
      "Seen so far: 87232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1363: 0.7594916820526123\n",
      "Seen so far: 87296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1364: 0.8879145383834839\n",
      "Seen so far: 87360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1365: 0.7087892293930054\n",
      "Seen so far: 87424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1366: 0.9293026924133301\n",
      "Seen so far: 87488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1367: 1.2387962341308594\n",
      "Seen so far: 87552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1368: 0.9087034463882446\n",
      "Seen so far: 87616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1369: 0.45570260286331177\n",
      "Seen so far: 87680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1370: 0.6786907315254211\n",
      "Seen so far: 87744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1371: 0.6006278395652771\n",
      "Seen so far: 87808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1372: 1.0595569610595703\n",
      "Seen so far: 87872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1373: 0.7080800533294678\n",
      "Seen so far: 87936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1374: 0.7164167165756226\n",
      "Seen so far: 88000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1375: 0.8569403886795044\n",
      "Seen so far: 88064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1376: 0.9849966764450073\n",
      "Seen so far: 88128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1377: 0.9201199412345886\n",
      "Seen so far: 88192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1378: 0.9752812385559082\n",
      "Seen so far: 88256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1379: 0.8954219818115234\n",
      "Seen so far: 88320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1380: 1.000538945198059\n",
      "Seen so far: 88384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1381: 0.7190811038017273\n",
      "Seen so far: 88448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1382: 0.6129534244537354\n",
      "Seen so far: 88512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1383: 0.8429219722747803\n",
      "Seen so far: 88576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1384: 0.5010192394256592\n",
      "Seen so far: 88640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1385: 0.5560389757156372\n",
      "Seen so far: 88704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1386: 0.8192080855369568\n",
      "Seen so far: 88768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1387: 0.8195939660072327\n",
      "Seen so far: 88832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1388: 1.067165493965149\n",
      "Seen so far: 88896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1389: 0.5421916246414185\n",
      "Seen so far: 88960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1390: 0.9303488731384277\n",
      "Seen so far: 89024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1391: 1.1474928855895996\n",
      "Seen so far: 89088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1392: 0.9949504137039185\n",
      "Seen so far: 89152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1393: 1.2152574062347412\n",
      "Seen so far: 89216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1394: 0.5945339202880859\n",
      "Seen so far: 89280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1395: 0.6447474360466003\n",
      "Seen so far: 89344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1396: 0.9160876870155334\n",
      "Seen so far: 89408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1397: 0.7819320559501648\n",
      "Seen so far: 89472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1398: 0.7979837656021118\n",
      "Seen so far: 89536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1399: 1.0760756731033325\n",
      "Seen so far: 89600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1400: 0.8654667735099792\n",
      "Seen so far: 89664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1401: 0.5646840333938599\n",
      "Seen so far: 89728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1402: 0.8497950434684753\n",
      "Seen so far: 89792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1403: 0.8805402517318726\n",
      "Seen so far: 89856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1404: 0.5204942226409912\n",
      "Seen so far: 89920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1405: 0.5307232141494751\n",
      "Seen so far: 89984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1406: 1.300318956375122\n",
      "Seen so far: 90048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1407: 0.5950479507446289\n",
      "Seen so far: 90112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1408: 0.5279127359390259\n",
      "Seen so far: 90176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1409: 0.7574673891067505\n",
      "Seen so far: 90240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1410: 0.7900263071060181\n",
      "Seen so far: 90304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1411: 0.9044764637947083\n",
      "Seen so far: 90368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1412: 0.9471759796142578\n",
      "Seen so far: 90432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1413: 0.7512028217315674\n",
      "Seen so far: 90496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1414: 0.5632013082504272\n",
      "Seen so far: 90560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1415: 0.6118231415748596\n",
      "Seen so far: 90624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1416: 0.7746050953865051\n",
      "Seen so far: 90688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1417: 0.7423329949378967\n",
      "Seen so far: 90752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1418: 0.7455265522003174\n",
      "Seen so far: 90816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1419: 0.7796531915664673\n",
      "Seen so far: 90880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1420: 0.6501387357711792\n",
      "Seen so far: 90944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1421: 0.5276006460189819\n",
      "Seen so far: 91008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1422: 0.7922911643981934\n",
      "Seen so far: 91072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1423: 0.9539719820022583\n",
      "Seen so far: 91136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1424: 0.7353292107582092\n",
      "Seen so far: 91200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1425: 0.43232449889183044\n",
      "Seen so far: 91264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1426: 0.5970104932785034\n",
      "Seen so far: 91328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1427: 0.7901707887649536\n",
      "Seen so far: 91392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1428: 0.9812248945236206\n",
      "Seen so far: 91456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1429: 0.6688600182533264\n",
      "Seen so far: 91520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1430: 0.6608610153198242\n",
      "Seen so far: 91584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1431: 0.8889187574386597\n",
      "Seen so far: 91648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1432: 0.33558785915374756\n",
      "Seen so far: 91712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1433: 0.7846770286560059\n",
      "Seen so far: 91776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1434: 0.43562307953834534\n",
      "Seen so far: 91840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1435: 0.7078627943992615\n",
      "Seen so far: 91904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1436: 0.7504730224609375\n",
      "Seen so far: 91968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1437: 0.655305027961731\n",
      "Seen so far: 92032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1438: 0.8208468556404114\n",
      "Seen so far: 92096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1439: 1.023988962173462\n",
      "Seen so far: 92160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1440: 0.7894686460494995\n",
      "Seen so far: 92224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1441: 0.5390339493751526\n",
      "Seen so far: 92288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1442: 0.974005937576294\n",
      "Seen so far: 92352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1443: 0.9433553218841553\n",
      "Seen so far: 92416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1444: 1.0200799703598022\n",
      "Seen so far: 92480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1445: 0.8912428617477417\n",
      "Seen so far: 92544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1446: 0.6463630795478821\n",
      "Seen so far: 92608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1447: 0.4297388195991516\n",
      "Seen so far: 92672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1448: 0.5145450234413147\n",
      "Seen so far: 92736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1449: 1.320318579673767\n",
      "Seen so far: 92800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1450: 0.5227295160293579\n",
      "Seen so far: 92864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1451: 0.9166464805603027\n",
      "Seen so far: 92928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1452: 0.459989070892334\n",
      "Seen so far: 92992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1453: 0.9851921796798706\n",
      "Seen so far: 93056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1454: 0.6714335680007935\n",
      "Seen so far: 93120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1455: 1.0893701314926147\n",
      "Seen so far: 93184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1456: 0.6839042901992798\n",
      "Seen so far: 93248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1457: 0.9098033905029297\n",
      "Seen so far: 93312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1458: 0.9014569520950317\n",
      "Seen so far: 93376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1459: 0.8819757699966431\n",
      "Seen so far: 93440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1460: 0.9168274998664856\n",
      "Seen so far: 93504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1461: 0.710579514503479\n",
      "Seen so far: 93568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1462: 0.740278959274292\n",
      "Seen so far: 93632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1463: 1.0218327045440674\n",
      "Seen so far: 93696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1464: 0.4902140498161316\n",
      "Seen so far: 93760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1465: 0.9193745851516724\n",
      "Seen so far: 93824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1466: 0.7456997632980347\n",
      "Seen so far: 93888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1467: 0.5548387765884399\n",
      "Seen so far: 93952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1468: 0.7586867213249207\n",
      "Seen so far: 94016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1469: 0.5858847498893738\n",
      "Seen so far: 94080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1470: 1.0464532375335693\n",
      "Seen so far: 94144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1471: 0.25968030095100403\n",
      "Seen so far: 94208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1472: 0.7772126197814941\n",
      "Seen so far: 94272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1473: 0.7692644596099854\n",
      "Seen so far: 94336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1474: 0.5645086765289307\n",
      "Seen so far: 94400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1475: 0.9283607602119446\n",
      "Seen so far: 94464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1476: 0.4298211336135864\n",
      "Seen so far: 94528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1477: 0.5032354593276978\n",
      "Seen so far: 94592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1478: 1.1213736534118652\n",
      "Seen so far: 94656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1479: 0.7155348658561707\n",
      "Seen so far: 94720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1480: 0.695987343788147\n",
      "Seen so far: 94784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1481: 0.805637001991272\n",
      "Seen so far: 94848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1482: 0.46611344814300537\n",
      "Seen so far: 94912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1483: 0.9828276038169861\n",
      "Seen so far: 94976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1484: 0.5722800493240356\n",
      "Seen so far: 95040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1485: 0.5622115731239319\n",
      "Seen so far: 95104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1486: 0.5706419944763184\n",
      "Seen so far: 95168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1487: 0.40799570083618164\n",
      "Seen so far: 95232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1488: 0.7843255996704102\n",
      "Seen so far: 95296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1489: 0.6221511960029602\n",
      "Seen so far: 95360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1490: 0.6308456659317017\n",
      "Seen so far: 95424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1491: 0.4351351857185364\n",
      "Seen so far: 95488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1492: 0.8307875394821167\n",
      "Seen so far: 95552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1493: 0.7578918933868408\n",
      "Seen so far: 95616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1494: 0.7449749708175659\n",
      "Seen so far: 95680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1495: 1.3056949377059937\n",
      "Seen so far: 95744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1496: 0.7439701557159424\n",
      "Seen so far: 95808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1497: 1.0361785888671875\n",
      "Seen so far: 95872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1498: 0.6467282772064209\n",
      "Seen so far: 95936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1499: 0.7950648665428162\n",
      "Seen so far: 96000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1500: 0.6975536942481995\n",
      "Seen so far: 96064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1501: 0.9947253465652466\n",
      "Seen so far: 96128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1502: 0.822363018989563\n",
      "Seen so far: 96192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1503: 0.44594284892082214\n",
      "Seen so far: 96256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1504: 0.7243118286132812\n",
      "Seen so far: 96320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1505: 0.9999347925186157\n",
      "Seen so far: 96384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1506: 0.5043778419494629\n",
      "Seen so far: 96448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1507: 1.5554280281066895\n",
      "Seen so far: 96512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1508: 0.5736224055290222\n",
      "Seen so far: 96576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1509: 1.2115106582641602\n",
      "Seen so far: 96640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1510: 1.4632883071899414\n",
      "Seen so far: 96704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1511: 0.7299266457557678\n",
      "Seen so far: 96768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1512: 0.7916144132614136\n",
      "Seen so far: 96832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1513: 0.7021968364715576\n",
      "Seen so far: 96896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1514: 0.8959875702857971\n",
      "Seen so far: 96960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1515: 1.2756600379943848\n",
      "Seen so far: 97024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1516: 0.7707827687263489\n",
      "Seen so far: 97088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1517: 1.2563774585723877\n",
      "Seen so far: 97152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1518: 0.951526939868927\n",
      "Seen so far: 97216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1519: 0.6372579336166382\n",
      "Seen so far: 97280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1520: 0.732293426990509\n",
      "Seen so far: 97344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1521: 0.667758047580719\n",
      "Seen so far: 97408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1522: 0.9138457179069519\n",
      "Seen so far: 97472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1523: 1.0282175540924072\n",
      "Seen so far: 97536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1524: 0.9510248899459839\n",
      "Seen so far: 97600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1525: 1.2056266069412231\n",
      "Seen so far: 97664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1526: 0.9669643640518188\n",
      "Seen so far: 97728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1527: 0.5759685039520264\n",
      "Seen so far: 97792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1528: 0.5447709560394287\n",
      "Seen so far: 97856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1529: 0.7489458322525024\n",
      "Seen so far: 97920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1530: 0.7482645511627197\n",
      "Seen so far: 97984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1531: 0.36875084042549133\n",
      "Seen so far: 98048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1532: 0.8014938831329346\n",
      "Seen so far: 98112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1533: 0.6370066404342651\n",
      "Seen so far: 98176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1534: 0.8712292313575745\n",
      "Seen so far: 98240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1535: 0.47152549028396606\n",
      "Seen so far: 98304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1536: 0.6706455945968628\n",
      "Seen so far: 98368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1537: 0.7500853538513184\n",
      "Seen so far: 98432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1538: 0.9220741987228394\n",
      "Seen so far: 98496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1539: 0.5789476633071899\n",
      "Seen so far: 98560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1540: 0.5260038375854492\n",
      "Seen so far: 98624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1541: 0.5031591653823853\n",
      "Seen so far: 98688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1542: 0.7660363912582397\n",
      "Seen so far: 98752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1543: 0.9120317697525024\n",
      "Seen so far: 98816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1544: 0.5946971774101257\n",
      "Seen so far: 98880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1545: 0.5148727297782898\n",
      "Seen so far: 98944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1546: 0.7627609968185425\n",
      "Seen so far: 99008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1547: 0.9453362226486206\n",
      "Seen so far: 99072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1548: 0.8027477264404297\n",
      "Seen so far: 99136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1549: 0.6222821474075317\n",
      "Seen so far: 99200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1550: 0.7403329014778137\n",
      "Seen so far: 99264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1551: 1.2269420623779297\n",
      "Seen so far: 99328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1552: 0.6615297794342041\n",
      "Seen so far: 99392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1553: 0.5418168306350708\n",
      "Seen so far: 99456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1554: 1.1104655265808105\n",
      "Seen so far: 99520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1555: 0.8326271772384644\n",
      "Seen so far: 99584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1556: 0.9172743558883667\n",
      "Seen so far: 99648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1557: 1.0859382152557373\n",
      "Seen so far: 99712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1558: 0.7773709893226624\n",
      "Seen so far: 99776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1559: 0.38436320424079895\n",
      "Seen so far: 99840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1560: 1.3557238578796387\n",
      "Seen so far: 99904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1561: 0.6695035696029663\n",
      "Seen so far: 99968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1562: 0.815239667892456\n",
      "Seen so far: 100032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1563: 0.7481812834739685\n",
      "Seen so far: 100096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1564: 0.9405608177185059\n",
      "Seen so far: 100160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1565: 0.999906063079834\n",
      "Seen so far: 100224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1566: 0.8751734495162964\n",
      "Seen so far: 100288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1567: 0.6186113357543945\n",
      "Seen so far: 100352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1568: 0.6893858313560486\n",
      "Seen so far: 100416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1569: 0.6960864663124084\n",
      "Seen so far: 100480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1570: 1.1264128684997559\n",
      "Seen so far: 100544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1571: 0.9969305992126465\n",
      "Seen so far: 100608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1572: 0.4785071015357971\n",
      "Seen so far: 100672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1573: 0.9885756373405457\n",
      "Seen so far: 100736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1574: 0.7871773838996887\n",
      "Seen so far: 100800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1575: 0.8623955249786377\n",
      "Seen so far: 100864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1576: 0.8137855529785156\n",
      "Seen so far: 100928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1577: 0.7164273858070374\n",
      "Seen so far: 100992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1578: 0.9525102376937866\n",
      "Seen so far: 101056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1579: 0.5978569984436035\n",
      "Seen so far: 101120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1580: 0.8647569417953491\n",
      "Seen so far: 101184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1581: 0.7740188837051392\n",
      "Seen so far: 101248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1582: 0.7834585905075073\n",
      "Seen so far: 101312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1583: 0.7115966081619263\n",
      "Seen so far: 101376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1584: 0.8595792651176453\n",
      "Seen so far: 101440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1585: 1.4050688743591309\n",
      "Seen so far: 101504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1586: 0.6730315685272217\n",
      "Seen so far: 101568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1587: 0.6343417763710022\n",
      "Seen so far: 101632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1588: 0.48454973101615906\n",
      "Seen so far: 101696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1589: 0.7818557024002075\n",
      "Seen so far: 101760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1590: 0.9026669859886169\n",
      "Seen so far: 101824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1591: 0.8475863933563232\n",
      "Seen so far: 101888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1592: 0.6248542070388794\n",
      "Seen so far: 101952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1593: 0.6216291189193726\n",
      "Seen so far: 102016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1594: 0.6241233348846436\n",
      "Seen so far: 102080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1595: 1.0046401023864746\n",
      "Seen so far: 102144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1596: 0.6630740165710449\n",
      "Seen so far: 102208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1597: 0.8400248289108276\n",
      "Seen so far: 102272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1598: 0.6046849489212036\n",
      "Seen so far: 102336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1599: 0.8504597544670105\n",
      "Seen so far: 102400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1600: 0.3022155165672302\n",
      "Seen so far: 102464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1601: 0.8140442371368408\n",
      "Seen so far: 102528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1602: 0.4922578036785126\n",
      "Seen so far: 102592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1603: 1.1998558044433594\n",
      "Seen so far: 102656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1604: 0.6911224126815796\n",
      "Seen so far: 102720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1605: 1.2493176460266113\n",
      "Seen so far: 102784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1606: 0.9512099623680115\n",
      "Seen so far: 102848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1607: 0.623420000076294\n",
      "Seen so far: 102912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1608: 0.7458896636962891\n",
      "Seen so far: 102976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1609: 0.7632484436035156\n",
      "Seen so far: 103040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1610: 0.839584469795227\n",
      "Seen so far: 103104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1611: 0.6779133081436157\n",
      "Seen so far: 103168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1612: 0.6651256680488586\n",
      "Seen so far: 103232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1613: 0.9946444034576416\n",
      "Seen so far: 103296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1614: 0.7250190377235413\n",
      "Seen so far: 103360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1615: 0.6972334384918213\n",
      "Seen so far: 103424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1616: 0.821160078048706\n",
      "Seen so far: 103488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1617: 0.7189192175865173\n",
      "Seen so far: 103552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1618: 0.5840273499488831\n",
      "Seen so far: 103616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1619: 0.8509745597839355\n",
      "Seen so far: 103680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1620: 0.6885063052177429\n",
      "Seen so far: 103744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1621: 0.6106802225112915\n",
      "Seen so far: 103808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1622: 0.7170245051383972\n",
      "Seen so far: 103872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1623: 0.9417322874069214\n",
      "Seen so far: 103936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1624: 0.6599045991897583\n",
      "Seen so far: 104000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1625: 1.032059907913208\n",
      "Seen so far: 104064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1626: 0.7931901216506958\n",
      "Seen so far: 104128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1627: 0.6570167541503906\n",
      "Seen so far: 104192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1628: 0.6845552921295166\n",
      "Seen so far: 104256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1629: 0.5592999458312988\n",
      "Seen so far: 104320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1630: 0.9065626859664917\n",
      "Seen so far: 104384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1631: 0.6988559365272522\n",
      "Seen so far: 104448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1632: 0.9663143754005432\n",
      "Seen so far: 104512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1633: 0.7743388414382935\n",
      "Seen so far: 104576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1634: 0.9151967763900757\n",
      "Seen so far: 104640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1635: 0.7347216010093689\n",
      "Seen so far: 104704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1636: 0.7790461778640747\n",
      "Seen so far: 104768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1637: 0.4055064022541046\n",
      "Seen so far: 104832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1638: 0.9011529088020325\n",
      "Seen so far: 104896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1639: 0.5837461948394775\n",
      "Seen so far: 104960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1640: 0.7762598991394043\n",
      "Seen so far: 105024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1641: 0.7030854225158691\n",
      "Seen so far: 105088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1642: 0.775983452796936\n",
      "Seen so far: 105152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1643: 1.1972285509109497\n",
      "Seen so far: 105216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1644: 0.7712286114692688\n",
      "Seen so far: 105280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1645: 0.9680966138839722\n",
      "Seen so far: 105344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1646: 0.7341620922088623\n",
      "Seen so far: 105408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1647: 0.5722994804382324\n",
      "Seen so far: 105472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1648: 0.7472482323646545\n",
      "Seen so far: 105536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1649: 0.9290012121200562\n",
      "Seen so far: 105600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1650: 0.7621181011199951\n",
      "Seen so far: 105664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1651: 0.9809755086898804\n",
      "Seen so far: 105728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1652: 0.6952875256538391\n",
      "Seen so far: 105792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1653: 0.6279365420341492\n",
      "Seen so far: 105856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1654: 0.7611029744148254\n",
      "Seen so far: 105920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1655: 0.7368285655975342\n",
      "Seen so far: 105984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1656: 0.3885755240917206\n",
      "Seen so far: 106048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1657: 0.8237738609313965\n",
      "Seen so far: 106112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1658: 0.4992828965187073\n",
      "Seen so far: 106176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1659: 0.8761253356933594\n",
      "Seen so far: 106240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1660: 0.8058979511260986\n",
      "Seen so far: 106304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1661: 0.747692883014679\n",
      "Seen so far: 106368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1662: 0.45688509941101074\n",
      "Seen so far: 106432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1663: 0.76015305519104\n",
      "Seen so far: 106496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1664: 0.9587036967277527\n",
      "Seen so far: 106560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1665: 1.238924264907837\n",
      "Seen so far: 106624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1666: 0.7371753454208374\n",
      "Seen so far: 106688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1667: 0.5371359586715698\n",
      "Seen so far: 106752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1668: 1.001768946647644\n",
      "Seen so far: 106816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1669: 0.5218674540519714\n",
      "Seen so far: 106880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1670: 0.5537102818489075\n",
      "Seen so far: 106944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1671: 0.7871593236923218\n",
      "Seen so far: 107008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1672: 0.8883058428764343\n",
      "Seen so far: 107072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1673: 0.476445734500885\n",
      "Seen so far: 107136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1674: 0.6706335544586182\n",
      "Seen so far: 107200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1675: 1.0279330015182495\n",
      "Seen so far: 107264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1676: 0.5502893328666687\n",
      "Seen so far: 107328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1677: 0.6785894632339478\n",
      "Seen so far: 107392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1678: 0.7375555038452148\n",
      "Seen so far: 107456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1679: 0.7693639993667603\n",
      "Seen so far: 107520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1680: 0.9019531011581421\n",
      "Seen so far: 107584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1681: 1.2845854759216309\n",
      "Seen so far: 107648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1682: 0.710904598236084\n",
      "Seen so far: 107712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1683: 1.1155606508255005\n",
      "Seen so far: 107776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1684: 0.8445045351982117\n",
      "Seen so far: 107840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1685: 0.9407026767730713\n",
      "Seen so far: 107904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1686: 1.1123243570327759\n",
      "Seen so far: 107968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1687: 1.0456761121749878\n",
      "Seen so far: 108032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1688: 0.8817448616027832\n",
      "Seen so far: 108096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1689: 0.8111339211463928\n",
      "Seen so far: 108160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1690: 0.9416263699531555\n",
      "Seen so far: 108224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1691: 0.5714446306228638\n",
      "Seen so far: 108288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1692: 0.6412729024887085\n",
      "Seen so far: 108352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1693: 1.1023893356323242\n",
      "Seen so far: 108416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1694: 1.0228384733200073\n",
      "Seen so far: 108480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1695: 0.8976964354515076\n",
      "Seen so far: 108544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1696: 0.9592210650444031\n",
      "Seen so far: 108608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1697: 0.992684006690979\n",
      "Seen so far: 108672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1698: 0.44484952092170715\n",
      "Seen so far: 108736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1699: 0.4683114290237427\n",
      "Seen so far: 108800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1700: 0.6225162744522095\n",
      "Seen so far: 108864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1701: 0.8199180960655212\n",
      "Seen so far: 108928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1702: 1.0748720169067383\n",
      "Seen so far: 108992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1703: 0.6457376480102539\n",
      "Seen so far: 109056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1704: 1.0143696069717407\n",
      "Seen so far: 109120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1705: 1.0098583698272705\n",
      "Seen so far: 109184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1706: 0.9366288185119629\n",
      "Seen so far: 109248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1707: 0.6192635297775269\n",
      "Seen so far: 109312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1708: 0.9572862386703491\n",
      "Seen so far: 109376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1709: 1.2377848625183105\n",
      "Seen so far: 109440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1710: 0.7503729462623596\n",
      "Seen so far: 109504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1711: 0.4508048892021179\n",
      "Seen so far: 109568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1712: 0.6261149644851685\n",
      "Seen so far: 109632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1713: 0.46037042140960693\n",
      "Seen so far: 109696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1714: 0.9118390083312988\n",
      "Seen so far: 109760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1715: 0.5914229154586792\n",
      "Seen so far: 109824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1716: 0.9674936532974243\n",
      "Seen so far: 109888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1717: 0.581501841545105\n",
      "Seen so far: 109952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1718: 0.7045865058898926\n",
      "Seen so far: 110016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1719: 0.6585161685943604\n",
      "Seen so far: 110080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1720: 0.9810672402381897\n",
      "Seen so far: 110144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1721: 0.9216979742050171\n",
      "Seen so far: 110208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1722: 0.7259851098060608\n",
      "Seen so far: 110272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1723: 0.5781948566436768\n",
      "Seen so far: 110336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1724: 0.9500939249992371\n",
      "Seen so far: 110400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1725: 0.7273586392402649\n",
      "Seen so far: 110464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1726: 1.3171340227127075\n",
      "Seen so far: 110528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1727: 0.7725698351860046\n",
      "Seen so far: 110592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1728: 0.6635727882385254\n",
      "Seen so far: 110656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1729: 0.9822447299957275\n",
      "Seen so far: 110720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1730: 0.7415069341659546\n",
      "Seen so far: 110784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1731: 0.6380918025970459\n",
      "Seen so far: 110848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1732: 1.032275676727295\n",
      "Seen so far: 110912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1733: 1.0912821292877197\n",
      "Seen so far: 110976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1734: 0.7325136661529541\n",
      "Seen so far: 111040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1735: 0.7266565561294556\n",
      "Seen so far: 111104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1736: 0.6296507120132446\n",
      "Seen so far: 111168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1737: 0.8113442659378052\n",
      "Seen so far: 111232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1738: 0.8452519178390503\n",
      "Seen so far: 111296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1739: 0.6850732564926147\n",
      "Seen so far: 111360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1740: 1.113096833229065\n",
      "Seen so far: 111424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1741: 0.9238998889923096\n",
      "Seen so far: 111488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1742: 0.7374709844589233\n",
      "Seen so far: 111552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1743: 0.6828399896621704\n",
      "Seen so far: 111616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1744: 0.8825161457061768\n",
      "Seen so far: 111680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1745: 0.9295851588249207\n",
      "Seen so far: 111744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1746: 1.089568853378296\n",
      "Seen so far: 111808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1747: 1.1790529489517212\n",
      "Seen so far: 111872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1748: 0.7187780141830444\n",
      "Seen so far: 111936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1749: 0.5216302871704102\n",
      "Seen so far: 112000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1750: 0.8244482278823853\n",
      "Seen so far: 112064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1751: 0.8210826516151428\n",
      "Seen so far: 112128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1752: 1.0136736631393433\n",
      "Seen so far: 112192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1753: 1.1066288948059082\n",
      "Seen so far: 112256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1754: 1.0419597625732422\n",
      "Seen so far: 112320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1755: 0.8471274971961975\n",
      "Seen so far: 112384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1756: 1.251333475112915\n",
      "Seen so far: 112448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1757: 0.6617834568023682\n",
      "Seen so far: 112512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1758: 1.277931809425354\n",
      "Seen so far: 112576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1759: 0.7313556671142578\n",
      "Seen so far: 112640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1760: 0.8854304552078247\n",
      "Seen so far: 112704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1761: 0.8360211253166199\n",
      "Seen so far: 112768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1762: 0.825595498085022\n",
      "Seen so far: 112832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1763: 0.7486211061477661\n",
      "Seen so far: 112896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1764: 0.8875161409378052\n",
      "Seen so far: 112960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1765: 0.514083743095398\n",
      "Seen so far: 113024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1766: 0.7616928815841675\n",
      "Seen so far: 113088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1767: 0.8972156643867493\n",
      "Seen so far: 113152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1768: 1.0279403924942017\n",
      "Seen so far: 113216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1769: 0.6633268594741821\n",
      "Seen so far: 113280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1770: 0.6521658897399902\n",
      "Seen so far: 113344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1771: 0.8974749445915222\n",
      "Seen so far: 113408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1772: 0.8562654852867126\n",
      "Seen so far: 113472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1773: 0.8620352745056152\n",
      "Seen so far: 113536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1774: 0.5903085470199585\n",
      "Seen so far: 113600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1775: 0.8419915437698364\n",
      "Seen so far: 113664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1776: 0.9714632034301758\n",
      "Seen so far: 113728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1777: 0.7393269538879395\n",
      "Seen so far: 113792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1778: 0.7436810731887817\n",
      "Seen so far: 113856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1779: 1.2483630180358887\n",
      "Seen so far: 113920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1780: 1.1631085872650146\n",
      "Seen so far: 113984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1781: 0.9484569430351257\n",
      "Seen so far: 114048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1782: 0.41228121519088745\n",
      "Seen so far: 114112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1783: 1.0898878574371338\n",
      "Seen so far: 114176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1784: 0.891181230545044\n",
      "Seen so far: 114240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1785: 0.7767270803451538\n",
      "Seen so far: 114304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1786: 0.8717603087425232\n",
      "Seen so far: 114368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1787: 0.7378123998641968\n",
      "Seen so far: 114432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1788: 0.6139376163482666\n",
      "Seen so far: 114496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1789: 0.653793215751648\n",
      "Seen so far: 114560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1790: 0.7787368893623352\n",
      "Seen so far: 114624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1791: 0.6693748235702515\n",
      "Seen so far: 114688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1792: 0.4659721851348877\n",
      "Seen so far: 114752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1793: 0.936591386795044\n",
      "Seen so far: 114816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1794: 0.4879631996154785\n",
      "Seen so far: 114880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1795: 0.8126225471496582\n",
      "Seen so far: 114944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1796: 0.7777665853500366\n",
      "Seen so far: 115008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1797: 0.37900686264038086\n",
      "Seen so far: 115072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1798: 0.47179314494132996\n",
      "Seen so far: 115136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1799: 0.6466380953788757\n",
      "Seen so far: 115200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1800: 0.9270465970039368\n",
      "Seen so far: 115264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1801: 0.7161056995391846\n",
      "Seen so far: 115328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1802: 0.4063816964626312\n",
      "Seen so far: 115392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1803: 0.9628203511238098\n",
      "Seen so far: 115456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1804: 0.44275960326194763\n",
      "Seen so far: 115520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1805: 0.6128493547439575\n",
      "Seen so far: 115584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1806: 0.677589476108551\n",
      "Seen so far: 115648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1807: 0.840087354183197\n",
      "Seen so far: 115712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1808: 1.0137532949447632\n",
      "Seen so far: 115776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1809: 0.618060827255249\n",
      "Seen so far: 115840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1810: 0.6838438510894775\n",
      "Seen so far: 115904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1811: 0.8813236951828003\n",
      "Seen so far: 115968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1812: 0.5537788271903992\n",
      "Seen so far: 116032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1813: 0.9013484716415405\n",
      "Seen so far: 116096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1814: 0.8355376720428467\n",
      "Seen so far: 116160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1815: 1.362025499343872\n",
      "Seen so far: 116224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1816: 0.7586873769760132\n",
      "Seen so far: 116288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1817: 0.7805596590042114\n",
      "Seen so far: 116352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1818: 0.8619198799133301\n",
      "Seen so far: 116416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1819: 0.46214812994003296\n",
      "Seen so far: 116480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1820: 0.6396628618240356\n",
      "Seen so far: 116544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1821: 0.9802522659301758\n",
      "Seen so far: 116608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1822: 0.997103214263916\n",
      "Seen so far: 116672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1823: 1.0650405883789062\n",
      "Seen so far: 116736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1824: 0.9745038151741028\n",
      "Seen so far: 116800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1825: 0.5811718702316284\n",
      "Seen so far: 116864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1826: 1.0337923765182495\n",
      "Seen so far: 116928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1827: 0.8170185685157776\n",
      "Seen so far: 116992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1828: 0.9534710645675659\n",
      "Seen so far: 117056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1829: 0.7830036282539368\n",
      "Seen so far: 117120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1830: 0.6139848232269287\n",
      "Seen so far: 117184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1831: 0.7218409776687622\n",
      "Seen so far: 117248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1832: 1.079925298690796\n",
      "Seen so far: 117312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1833: 0.7642598748207092\n",
      "Seen so far: 117376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1834: 1.0192886590957642\n",
      "Seen so far: 117440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1835: 0.6019073724746704\n",
      "Seen so far: 117504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1836: 0.7530275583267212\n",
      "Seen so far: 117568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1837: 0.6018189787864685\n",
      "Seen so far: 117632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1838: 0.861518144607544\n",
      "Seen so far: 117696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1839: 0.6424023509025574\n",
      "Seen so far: 117760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1840: 1.1718711853027344\n",
      "Seen so far: 117824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1841: 0.7260136604309082\n",
      "Seen so far: 117888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1842: 0.43306076526641846\n",
      "Seen so far: 117952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1843: 0.8456730842590332\n",
      "Seen so far: 118016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1844: 0.7531396746635437\n",
      "Seen so far: 118080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1845: 0.8617618083953857\n",
      "Seen so far: 118144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1846: 0.9630447030067444\n",
      "Seen so far: 118208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1847: 0.8433345556259155\n",
      "Seen so far: 118272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1848: 0.7067020535469055\n",
      "Seen so far: 118336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1849: 1.0326831340789795\n",
      "Seen so far: 118400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1850: 0.5545963048934937\n",
      "Seen so far: 118464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1851: 1.093613862991333\n",
      "Seen so far: 118528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1852: 0.8643773198127747\n",
      "Seen so far: 118592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1853: 0.5853468775749207\n",
      "Seen so far: 118656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1854: 1.0777370929718018\n",
      "Seen so far: 118720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1855: 1.0513640642166138\n",
      "Seen so far: 118784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1856: 0.7455764412879944\n",
      "Seen so far: 118848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1857: 0.5775884389877319\n",
      "Seen so far: 118912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1858: 0.9968700408935547\n",
      "Seen so far: 118976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1859: 0.6203451156616211\n",
      "Seen so far: 119040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1860: 0.6121652126312256\n",
      "Seen so far: 119104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1861: 0.819568932056427\n",
      "Seen so far: 119168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1862: 0.6596381664276123\n",
      "Seen so far: 119232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1863: 0.6054903268814087\n",
      "Seen so far: 119296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1864: 0.7266159057617188\n",
      "Seen so far: 119360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1865: 0.7267528772354126\n",
      "Seen so far: 119424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1866: 0.8591541647911072\n",
      "Seen so far: 119488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1867: 0.9546916484832764\n",
      "Seen so far: 119552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1868: 0.41704124212265015\n",
      "Seen so far: 119616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1869: 0.536764919757843\n",
      "Seen so far: 119680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1870: 0.44127407670021057\n",
      "Seen so far: 119744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1871: 0.7199220061302185\n",
      "Seen so far: 119808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1872: 0.707961916923523\n",
      "Seen so far: 119872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1873: 0.9010403752326965\n",
      "Seen so far: 119936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1874: 0.7036466598510742\n",
      "Seen so far: 120000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1875: 0.6138612031936646\n",
      "Seen so far: 120064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1876: 0.6658614277839661\n",
      "Seen so far: 120128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1877: 0.564222514629364\n",
      "Seen so far: 120192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1878: 0.7199230194091797\n",
      "Seen so far: 120256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1879: 0.5841953754425049\n",
      "Seen so far: 120320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1880: 0.8268375396728516\n",
      "Seen so far: 120384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1881: 0.4462432265281677\n",
      "Seen so far: 120448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1882: 0.8622586131095886\n",
      "Seen so far: 120512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1883: 0.4800231456756592\n",
      "Seen so far: 120576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1884: 0.7340526580810547\n",
      "Seen so far: 120640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1885: 0.8038980960845947\n",
      "Seen so far: 120704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1886: 0.6046308875083923\n",
      "Seen so far: 120768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1887: 0.6454131603240967\n",
      "Seen so far: 120832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1888: 0.4045605957508087\n",
      "Seen so far: 120896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1889: 1.0074949264526367\n",
      "Seen so far: 120960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1890: 1.2319636344909668\n",
      "Seen so far: 121024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1891: 1.0659128427505493\n",
      "Seen so far: 121088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1892: 0.7933250069618225\n",
      "Seen so far: 121152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1893: 0.974008321762085\n",
      "Seen so far: 121216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1894: 0.7147946357727051\n",
      "Seen so far: 121280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1895: 0.6496492624282837\n",
      "Seen so far: 121344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1896: 0.34951096773147583\n",
      "Seen so far: 121408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1897: 0.8551724553108215\n",
      "Seen so far: 121472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1898: 0.5769459009170532\n",
      "Seen so far: 121536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1899: 0.8455461263656616\n",
      "Seen so far: 121600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1900: 0.7759764194488525\n",
      "Seen so far: 121664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1901: 0.5971264839172363\n",
      "Seen so far: 121728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1902: 1.0257539749145508\n",
      "Seen so far: 121792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1903: 0.7694947719573975\n",
      "Seen so far: 121856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1904: 0.8221030235290527\n",
      "Seen so far: 121920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1905: 0.8072239756584167\n",
      "Seen so far: 121984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1906: 0.578482985496521\n",
      "Seen so far: 122048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1907: 0.9551005363464355\n",
      "Seen so far: 122112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1908: 0.7918497920036316\n",
      "Seen so far: 122176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1909: 0.9028043746948242\n",
      "Seen so far: 122240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1910: 0.7073025703430176\n",
      "Seen so far: 122304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1911: 0.639153242111206\n",
      "Seen so far: 122368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1912: 1.0350346565246582\n",
      "Seen so far: 122432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1913: 0.6771875619888306\n",
      "Seen so far: 122496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1914: 0.5957567691802979\n",
      "Seen so far: 122560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1915: 0.6262602210044861\n",
      "Seen so far: 122624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1916: 0.710857629776001\n",
      "Seen so far: 122688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1917: 0.8760383129119873\n",
      "Seen so far: 122752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1918: 0.9659692049026489\n",
      "Seen so far: 122816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1919: 0.8187364339828491\n",
      "Seen so far: 122880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1920: 1.0834121704101562\n",
      "Seen so far: 122944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1921: 0.7309013605117798\n",
      "Seen so far: 123008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1922: 1.0592814683914185\n",
      "Seen so far: 123072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1923: 0.8234429359436035\n",
      "Seen so far: 123136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1924: 0.945114254951477\n",
      "Seen so far: 123200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1925: 0.7736631035804749\n",
      "Seen so far: 123264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1926: 0.8631294965744019\n",
      "Seen so far: 123328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1927: 0.6924163699150085\n",
      "Seen so far: 123392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1928: 0.5266523957252502\n",
      "Seen so far: 123456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1929: 0.6895474195480347\n",
      "Seen so far: 123520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1930: 1.24917471408844\n",
      "Seen so far: 123584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1931: 0.8015830516815186\n",
      "Seen so far: 123648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1932: 1.1389849185943604\n",
      "Seen so far: 123712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1933: 0.7082065939903259\n",
      "Seen so far: 123776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1934: 0.6967248916625977\n",
      "Seen so far: 123840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1935: 0.9887775182723999\n",
      "Seen so far: 123904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1936: 1.0601882934570312\n",
      "Seen so far: 123968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1937: 0.8978132009506226\n",
      "Seen so far: 124032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1938: 0.631295382976532\n",
      "Seen so far: 124096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1939: 1.235074520111084\n",
      "Seen so far: 124160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1940: 0.7013252973556519\n",
      "Seen so far: 124224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1941: 0.873753011226654\n",
      "Seen so far: 124288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1942: 0.6870585083961487\n",
      "Seen so far: 124352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1943: 0.6368000507354736\n",
      "Seen so far: 124416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1944: 0.9383655190467834\n",
      "Seen so far: 124480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1945: 0.876124918460846\n",
      "Seen so far: 124544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1946: 0.7753872871398926\n",
      "Seen so far: 124608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1947: 0.4977441132068634\n",
      "Seen so far: 124672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1948: 0.9902983903884888\n",
      "Seen so far: 124736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1949: 0.8136770129203796\n",
      "Seen so far: 124800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1950: 0.934369683265686\n",
      "Seen so far: 124864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1951: 0.5899528861045837\n",
      "Seen so far: 124928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1952: 0.2411615550518036\n",
      "Seen so far: 124992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1953: 0.6176323294639587\n",
      "Seen so far: 125056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1954: 0.5588750839233398\n",
      "Seen so far: 125120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1955: 0.8148393630981445\n",
      "Seen so far: 125184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1956: 0.6437578201293945\n",
      "Seen so far: 125248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1957: 0.7050789594650269\n",
      "Seen so far: 125312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1958: 0.48652157187461853\n",
      "Seen so far: 125376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1959: 0.521775484085083\n",
      "Seen so far: 125440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1960: 0.9799220561981201\n",
      "Seen so far: 125504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1961: 0.5913739204406738\n",
      "Seen so far: 125568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1962: 0.6730923652648926\n",
      "Seen so far: 125632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1963: 0.8625161647796631\n",
      "Seen so far: 125696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1964: 0.6136333346366882\n",
      "Seen so far: 125760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1965: 1.104429006576538\n",
      "Seen so far: 125824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1966: 0.687533974647522\n",
      "Seen so far: 125888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1967: 0.6678364276885986\n",
      "Seen so far: 125952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1968: 0.4787498116493225\n",
      "Seen so far: 126016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1969: 0.7398855686187744\n",
      "Seen so far: 126080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1970: 0.8165350556373596\n",
      "Seen so far: 126144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1971: 0.5804312229156494\n",
      "Seen so far: 126208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1972: 0.8927015066146851\n",
      "Seen so far: 126272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1973: 0.8185210227966309\n",
      "Seen so far: 126336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1974: 0.8320801258087158\n",
      "Seen so far: 126400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1975: 0.9328492879867554\n",
      "Seen so far: 126464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1976: 0.43825727701187134\n",
      "Seen so far: 126528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1977: 0.8229476809501648\n",
      "Seen so far: 126592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1978: 0.8130956888198853\n",
      "Seen so far: 126656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1979: 0.4127739667892456\n",
      "Seen so far: 126720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1980: 0.9366690516471863\n",
      "Seen so far: 126784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1981: 0.7860884070396423\n",
      "Seen so far: 126848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1982: 0.4824784994125366\n",
      "Seen so far: 126912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1983: 1.0581345558166504\n",
      "Seen so far: 126976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1984: 0.9570952653884888\n",
      "Seen so far: 127040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1985: 1.1856391429901123\n",
      "Seen so far: 127104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1986: 0.3351861834526062\n",
      "Seen so far: 127168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1987: 1.0087214708328247\n",
      "Seen so far: 127232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1988: 1.0044738054275513\n",
      "Seen so far: 127296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1989: 0.636825442314148\n",
      "Seen so far: 127360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1990: 0.9765633344650269\n",
      "Seen so far: 127424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1991: 1.1597650051116943\n",
      "Seen so far: 127488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1992: 1.031992793083191\n",
      "Seen so far: 127552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1993: 0.844250500202179\n",
      "Seen so far: 127616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1994: 0.9811884760856628\n",
      "Seen so far: 127680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1995: 0.44650161266326904\n",
      "Seen so far: 127744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1996: 0.8606838583946228\n",
      "Seen so far: 127808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1997: 0.8013311624526978\n",
      "Seen so far: 127872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1998: 0.7475624084472656\n",
      "Seen so far: 127936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1999: 0.7530460357666016\n",
      "Seen so far: 128000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2000: 0.5981205105781555\n",
      "Seen so far: 128064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2001: 0.6248835325241089\n",
      "Seen so far: 128128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2002: 0.9574712514877319\n",
      "Seen so far: 128192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2003: 0.6000865697860718\n",
      "Seen so far: 128256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2004: 0.8215645551681519\n",
      "Seen so far: 128320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2005: 0.9027197360992432\n",
      "Seen so far: 128384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2006: 1.1285866498947144\n",
      "Seen so far: 128448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2007: 0.6387981176376343\n",
      "Seen so far: 128512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2008: 0.8000668883323669\n",
      "Seen so far: 128576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2009: 0.9121890664100647\n",
      "Seen so far: 128640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2010: 1.1152527332305908\n",
      "Seen so far: 128704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2011: 0.8706219792366028\n",
      "Seen so far: 128768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2012: 0.7966884970664978\n",
      "Seen so far: 128832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2013: 0.6264997720718384\n",
      "Seen so far: 128896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2014: 0.6648234724998474\n",
      "Seen so far: 128960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2015: 0.6251083612442017\n",
      "Seen so far: 129024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2016: 0.44791877269744873\n",
      "Seen so far: 129088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2017: 0.9041694402694702\n",
      "Seen so far: 129152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2018: 0.5176572799682617\n",
      "Seen so far: 129216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2019: 0.8392837047576904\n",
      "Seen so far: 129280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2020: 0.3643139600753784\n",
      "Seen so far: 129344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2021: 0.8784751892089844\n",
      "Seen so far: 129408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2022: 0.9347900748252869\n",
      "Seen so far: 129472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2023: 0.6625949144363403\n",
      "Seen so far: 129536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2024: 0.6712708473205566\n",
      "Seen so far: 129600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2025: 0.6586377620697021\n",
      "Seen so far: 129664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2026: 0.7064822912216187\n",
      "Seen so far: 129728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2027: 1.1252741813659668\n",
      "Seen so far: 129792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2028: 0.738233208656311\n",
      "Seen so far: 129856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2029: 0.6792310476303101\n",
      "Seen so far: 129920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2030: 1.0226528644561768\n",
      "Seen so far: 129984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2031: 1.0068578720092773\n",
      "Seen so far: 130048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2032: 0.8837224245071411\n",
      "Seen so far: 130112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2033: 1.0978018045425415\n",
      "Seen so far: 130176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2034: 1.1102466583251953\n",
      "Seen so far: 130240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2035: 0.602997362613678\n",
      "Seen so far: 130304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2036: 0.522377610206604\n",
      "Seen so far: 130368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2037: 0.5251412987709045\n",
      "Seen so far: 130432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2038: 0.9996752738952637\n",
      "Seen so far: 130496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2039: 0.7555239200592041\n",
      "Seen so far: 130560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2040: 0.5153826475143433\n",
      "Seen so far: 130624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2041: 0.8185286521911621\n",
      "Seen so far: 130688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2042: 0.6621956825256348\n",
      "Seen so far: 130752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2043: 0.7175650596618652\n",
      "Seen so far: 130816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2044: 0.7268205881118774\n",
      "Seen so far: 130880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2045: 0.5820320844650269\n",
      "Seen so far: 130944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2046: 0.8940419554710388\n",
      "Seen so far: 131008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2047: 0.5994745492935181\n",
      "Seen so far: 131072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2048: 0.5278369188308716\n",
      "Seen so far: 131136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2049: 1.016870379447937\n",
      "Seen so far: 131200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2050: 0.9126992225646973\n",
      "Seen so far: 131264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2051: 0.9204859733581543\n",
      "Seen so far: 131328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2052: 0.7053707838058472\n",
      "Seen so far: 131392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2053: 0.8679931163787842\n",
      "Seen so far: 131456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2054: 0.704071581363678\n",
      "Seen so far: 131520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2055: 0.2663883566856384\n",
      "Seen so far: 131584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2056: 0.7273244261741638\n",
      "Seen so far: 131648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2057: 0.8272620439529419\n",
      "Seen so far: 131712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2058: 0.766513466835022\n",
      "Seen so far: 131776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2059: 0.9550828337669373\n",
      "Seen so far: 131840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2060: 0.7490670680999756\n",
      "Seen so far: 131904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2061: 0.8805657625198364\n",
      "Seen so far: 131968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2062: 0.739528238773346\n",
      "Seen so far: 132032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2063: 0.7818676233291626\n",
      "Seen so far: 132096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2064: 0.8099700212478638\n",
      "Seen so far: 132160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2065: 0.7332401871681213\n",
      "Seen so far: 132224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2066: 0.9125766158103943\n",
      "Seen so far: 132288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2067: 0.5403573513031006\n",
      "Seen so far: 132352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2068: 1.1115418672561646\n",
      "Seen so far: 132416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2069: 0.8811178207397461\n",
      "Seen so far: 132480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2070: 0.49095141887664795\n",
      "Seen so far: 132544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2071: 0.5024099349975586\n",
      "Seen so far: 132608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2072: 1.1213552951812744\n",
      "Seen so far: 132672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2073: 0.8558980226516724\n",
      "Seen so far: 132736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2074: 0.7043363451957703\n",
      "Seen so far: 132800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2075: 0.9757312536239624\n",
      "Seen so far: 132864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2076: 0.7084532976150513\n",
      "Seen so far: 132928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2077: 0.8868657350540161\n",
      "Seen so far: 132992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2078: 0.692120373249054\n",
      "Seen so far: 133056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2079: 1.0296037197113037\n",
      "Seen so far: 133120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2080: 0.3793300986289978\n",
      "Seen so far: 133184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2081: 1.1279017925262451\n",
      "Seen so far: 133248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2082: 0.6329630613327026\n",
      "Seen so far: 133312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2083: 0.49501436948776245\n",
      "Seen so far: 133376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2084: 0.6964126825332642\n",
      "Seen so far: 133440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2085: 0.35537639260292053\n",
      "Seen so far: 133504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2086: 0.47406306862831116\n",
      "Seen so far: 133568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2087: 0.8427631855010986\n",
      "Seen so far: 133632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2088: 0.7287429571151733\n",
      "Seen so far: 133696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2089: 0.9772930145263672\n",
      "Seen so far: 133760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2090: 0.5690709352493286\n",
      "Seen so far: 133824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2091: 0.6012532711029053\n",
      "Seen so far: 133888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2092: 0.7473033666610718\n",
      "Seen so far: 133952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2093: 0.6293163299560547\n",
      "Seen so far: 134016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2094: 0.7067885398864746\n",
      "Seen so far: 134080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2095: 1.0060138702392578\n",
      "Seen so far: 134144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2096: 0.7162565588951111\n",
      "Seen so far: 134208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2097: 0.5812296271324158\n",
      "Seen so far: 134272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2098: 0.6928898096084595\n",
      "Seen so far: 134336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2099: 0.6689162254333496\n",
      "Seen so far: 134400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2100: 0.8451172113418579\n",
      "Seen so far: 134464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2101: 0.48461997509002686\n",
      "Seen so far: 134528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2102: 0.8762198686599731\n",
      "Seen so far: 134592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2103: 0.6397401094436646\n",
      "Seen so far: 134656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2104: 0.5642827153205872\n",
      "Seen so far: 134720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2105: 0.5296605825424194\n",
      "Seen so far: 134784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2106: 0.7469350099563599\n",
      "Seen so far: 134848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2107: 0.776579737663269\n",
      "Seen so far: 134912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2108: 0.38488730788230896\n",
      "Seen so far: 134976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2109: 0.5968396663665771\n",
      "Seen so far: 135040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2110: 0.7865710258483887\n",
      "Seen so far: 135104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2111: 0.5692558288574219\n",
      "Seen so far: 135168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2112: 0.4350041151046753\n",
      "Seen so far: 135232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2113: 0.7806657552719116\n",
      "Seen so far: 135296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2114: 0.746277928352356\n",
      "Seen so far: 135360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2115: 0.8646085858345032\n",
      "Seen so far: 135424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2116: 0.480693519115448\n",
      "Seen so far: 135488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2117: 0.5501955151557922\n",
      "Seen so far: 135552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2118: 1.211038589477539\n",
      "Seen so far: 135616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2119: 0.8655077219009399\n",
      "Seen so far: 135680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2120: 0.9058873653411865\n",
      "Seen so far: 135744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2121: 0.5426850318908691\n",
      "Seen so far: 135808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2122: 0.9199210405349731\n",
      "Seen so far: 135872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2123: 0.8686830997467041\n",
      "Seen so far: 135936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2124: 0.555916428565979\n",
      "Seen so far: 136000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2125: 1.2044429779052734\n",
      "Seen so far: 136064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2126: 0.865534245967865\n",
      "Seen so far: 136128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2127: 1.0418639183044434\n",
      "Seen so far: 136192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2128: 0.8410687446594238\n",
      "Seen so far: 136256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2129: 0.9027652740478516\n",
      "Seen so far: 136320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2130: 0.650442361831665\n",
      "Seen so far: 136384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2131: 0.9327961802482605\n",
      "Seen so far: 136448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2132: 0.7594887018203735\n",
      "Seen so far: 136512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2133: 0.5297181606292725\n",
      "Seen so far: 136576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2134: 0.2925769090652466\n",
      "Seen so far: 136640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2135: 0.4292891323566437\n",
      "Seen so far: 136704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2136: 0.4795715808868408\n",
      "Seen so far: 136768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2137: 0.7486838102340698\n",
      "Seen so far: 136832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2138: 1.0302250385284424\n",
      "Seen so far: 136896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2139: 0.7971116304397583\n",
      "Seen so far: 136960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2140: 0.9825298190116882\n",
      "Seen so far: 137024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2141: 1.3993349075317383\n",
      "Seen so far: 137088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2142: 0.4071488380432129\n",
      "Seen so far: 137152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2143: 0.6990911364555359\n",
      "Seen so far: 137216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2144: 0.7116339206695557\n",
      "Seen so far: 137280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2145: 0.8994973301887512\n",
      "Seen so far: 137344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2146: 1.2537678480148315\n",
      "Seen so far: 137408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2147: 0.5419965982437134\n",
      "Seen so far: 137472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2148: 0.73329758644104\n",
      "Seen so far: 137536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2149: 0.9127131700515747\n",
      "Seen so far: 137600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2150: 0.5570801496505737\n",
      "Seen so far: 137664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2151: 0.5561805963516235\n",
      "Seen so far: 137728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2152: 1.0304620265960693\n",
      "Seen so far: 137792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2153: 0.5419949889183044\n",
      "Seen so far: 137856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2154: 0.8284120559692383\n",
      "Seen so far: 137920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2155: 0.8407261967658997\n",
      "Seen so far: 137984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2156: 0.7673791646957397\n",
      "Seen so far: 138048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2157: 0.4231403172016144\n",
      "Seen so far: 138112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2158: 0.6117137670516968\n",
      "Seen so far: 138176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2159: 0.5036057829856873\n",
      "Seen so far: 138240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2160: 0.9795178771018982\n",
      "Seen so far: 138304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2161: 0.6389868259429932\n",
      "Seen so far: 138368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2162: 0.6027414202690125\n",
      "Seen so far: 138432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2163: 0.6041924953460693\n",
      "Seen so far: 138496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2164: 1.044809341430664\n",
      "Seen so far: 138560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2165: 0.792192280292511\n",
      "Seen so far: 138624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2166: 0.6630775928497314\n",
      "Seen so far: 138688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2167: 0.7389371395111084\n",
      "Seen so far: 138752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2168: 0.568655252456665\n",
      "Seen so far: 138816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2169: 0.5474511384963989\n",
      "Seen so far: 138880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2170: 0.7666804790496826\n",
      "Seen so far: 138944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2171: 0.7809978723526001\n",
      "Seen so far: 139008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2172: 0.5041618347167969\n",
      "Seen so far: 139072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2173: 0.6170221567153931\n",
      "Seen so far: 139136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2174: 1.052876591682434\n",
      "Seen so far: 139200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2175: 0.6122219562530518\n",
      "Seen so far: 139264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2176: 0.7399485111236572\n",
      "Seen so far: 139328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2177: 0.6970685124397278\n",
      "Seen so far: 139392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2178: 0.5559229850769043\n",
      "Seen so far: 139456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2179: 0.4411667585372925\n",
      "Seen so far: 139520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2180: 0.8668123483657837\n",
      "Seen so far: 139584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2181: 0.721079409122467\n",
      "Seen so far: 139648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2182: 0.9075251817703247\n",
      "Seen so far: 139712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2183: 0.6649340391159058\n",
      "Seen so far: 139776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2184: 0.897452175617218\n",
      "Seen so far: 139840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2185: 0.7332884073257446\n",
      "Seen so far: 139904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2186: 0.7200995683670044\n",
      "Seen so far: 139968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2187: 0.7403197884559631\n",
      "Seen so far: 140032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2188: 0.4312900900840759\n",
      "Seen so far: 140096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2189: 0.8251255750656128\n",
      "Seen so far: 140160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2190: 0.6558696031570435\n",
      "Seen so far: 140224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2191: 0.5985184907913208\n",
      "Seen so far: 140288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2192: 0.675724983215332\n",
      "Seen so far: 140352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2193: 0.7617923021316528\n",
      "Seen so far: 140416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2194: 0.4491914212703705\n",
      "Seen so far: 140480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2195: 0.9053696990013123\n",
      "Seen so far: 140544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2196: 0.571213960647583\n",
      "Seen so far: 140608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2197: 0.5063169598579407\n",
      "Seen so far: 140672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2198: 1.0383632183074951\n",
      "Seen so far: 140736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2199: 0.6415570974349976\n",
      "Seen so far: 140800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2200: 0.9372716546058655\n",
      "Seen so far: 140864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2201: 0.668817400932312\n",
      "Seen so far: 140928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2202: 0.6938657760620117\n",
      "Seen so far: 140992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2203: 1.300774335861206\n",
      "Seen so far: 141056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2204: 0.5739637613296509\n",
      "Seen so far: 141120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2205: 0.4708464741706848\n",
      "Seen so far: 141184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2206: 1.2216167449951172\n",
      "Seen so far: 141248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2207: 0.748407244682312\n",
      "Seen so far: 141312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2208: 1.5790684223175049\n",
      "Seen so far: 141376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2209: 0.5690436959266663\n",
      "Seen so far: 141440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2210: 0.737483024597168\n",
      "Seen so far: 141504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2211: 0.6923388838768005\n",
      "Seen so far: 141568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2212: 0.5659677982330322\n",
      "Seen so far: 141632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2213: 0.5815978050231934\n",
      "Seen so far: 141696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2214: 0.8664758205413818\n",
      "Seen so far: 141760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2215: 0.9070547819137573\n",
      "Seen so far: 141824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2216: 0.5955114364624023\n",
      "Seen so far: 141888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2217: 0.7871731519699097\n",
      "Seen so far: 141952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2218: 0.8203538060188293\n",
      "Seen so far: 142016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2219: 0.8925420641899109\n",
      "Seen so far: 142080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2220: 0.7831019759178162\n",
      "Seen so far: 142144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2221: 0.9278716444969177\n",
      "Seen so far: 142208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2222: 1.0274507999420166\n",
      "Seen so far: 142272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2223: 0.5399600267410278\n",
      "Seen so far: 142336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2224: 0.9488746523857117\n",
      "Seen so far: 142400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2225: 0.8566731214523315\n",
      "Seen so far: 142464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2226: 0.8709187507629395\n",
      "Seen so far: 142528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2227: 0.6162641644477844\n",
      "Seen so far: 142592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2228: 0.8843333125114441\n",
      "Seen so far: 142656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2229: 0.9261680841445923\n",
      "Seen so far: 142720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2230: 0.8360633850097656\n",
      "Seen so far: 142784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2231: 1.0086028575897217\n",
      "Seen so far: 142848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2232: 0.8290464878082275\n",
      "Seen so far: 142912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2233: 0.6065499782562256\n",
      "Seen so far: 142976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2234: 0.6772903203964233\n",
      "Seen so far: 143040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2235: 0.9838465452194214\n",
      "Seen so far: 143104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2236: 0.6223598718643188\n",
      "Seen so far: 143168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2237: 0.7076141238212585\n",
      "Seen so far: 143232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2238: 0.7098469138145447\n",
      "Seen so far: 143296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2239: 0.8958322405815125\n",
      "Seen so far: 143360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2240: 0.7721574306488037\n",
      "Seen so far: 143424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2241: 1.0329898595809937\n",
      "Seen so far: 143488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2242: 0.785980224609375\n",
      "Seen so far: 143552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2243: 1.122916579246521\n",
      "Seen so far: 143616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2244: 0.8258699178695679\n",
      "Seen so far: 143680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2245: 0.49087202548980713\n",
      "Seen so far: 143744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2246: 0.7309082746505737\n",
      "Seen so far: 143808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2247: 1.0350896120071411\n",
      "Seen so far: 143872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2248: 0.3660004734992981\n",
      "Seen so far: 143936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2249: 0.9836424589157104\n",
      "Seen so far: 144000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2250: 0.6652226448059082\n",
      "Seen so far: 144064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2251: 0.7111496925354004\n",
      "Seen so far: 144128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2252: 0.6501399874687195\n",
      "Seen so far: 144192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2253: 1.0227068662643433\n",
      "Seen so far: 144256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2254: 0.6068964600563049\n",
      "Seen so far: 144320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2255: 0.7096506357192993\n",
      "Seen so far: 144384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2256: 0.7826471328735352\n",
      "Seen so far: 144448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2257: 0.8680030107498169\n",
      "Seen so far: 144512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2258: 1.2068384885787964\n",
      "Seen so far: 144576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2259: 0.8066180944442749\n",
      "Seen so far: 144640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2260: 0.7174416780471802\n",
      "Seen so far: 144704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2261: 1.066726803779602\n",
      "Seen so far: 144768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2262: 0.7583444714546204\n",
      "Seen so far: 144832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2263: 0.9684586524963379\n",
      "Seen so far: 144896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2264: 0.8829688429832458\n",
      "Seen so far: 144960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2265: 0.4458990693092346\n",
      "Seen so far: 145024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2266: 0.6663354635238647\n",
      "Seen so far: 145088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2267: 0.7424088716506958\n",
      "Seen so far: 145152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2268: 0.5804057121276855\n",
      "Seen so far: 145216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2269: 0.4243931770324707\n",
      "Seen so far: 145280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2270: 0.6497675776481628\n",
      "Seen so far: 145344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2271: 0.6019940376281738\n",
      "Seen so far: 145408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2272: 1.0195038318634033\n",
      "Seen so far: 145472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2273: 0.9007545113563538\n",
      "Seen so far: 145536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2274: 0.8378795385360718\n",
      "Seen so far: 145600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2275: 0.9993559718132019\n",
      "Seen so far: 145664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2276: 0.7194480895996094\n",
      "Seen so far: 145728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2277: 0.7196246385574341\n",
      "Seen so far: 145792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2278: 0.8847212195396423\n",
      "Seen so far: 145856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2279: 0.5056299567222595\n",
      "Seen so far: 145920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2280: 0.9767229557037354\n",
      "Seen so far: 145984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2281: 0.7063510417938232\n",
      "Seen so far: 146048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2282: 0.9483082294464111\n",
      "Seen so far: 146112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2283: 0.9432366490364075\n",
      "Seen so far: 146176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2284: 0.7801821827888489\n",
      "Seen so far: 146240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2285: 0.7328892350196838\n",
      "Seen so far: 146304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2286: 0.9972330927848816\n",
      "Seen so far: 146368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2287: 0.5821657180786133\n",
      "Seen so far: 146432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2288: 0.5662581324577332\n",
      "Seen so far: 146496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2289: 0.8483350276947021\n",
      "Seen so far: 146560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2290: 0.7300714254379272\n",
      "Seen so far: 146624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2291: 0.6265407204627991\n",
      "Seen so far: 146688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2292: 0.8045003414154053\n",
      "Seen so far: 146752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2293: 1.2460463047027588\n",
      "Seen so far: 146816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2294: 1.0096558332443237\n",
      "Seen so far: 146880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2295: 0.9643086791038513\n",
      "Seen so far: 146944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2296: 0.7243123054504395\n",
      "Seen so far: 147008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2297: 1.1998729705810547\n",
      "Seen so far: 147072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2298: 0.9524929523468018\n",
      "Seen so far: 147136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2299: 0.4515537917613983\n",
      "Seen so far: 147200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2300: 0.8187469840049744\n",
      "Seen so far: 147264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2301: 0.723476767539978\n",
      "Seen so far: 147328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2302: 0.6587058901786804\n",
      "Seen so far: 147392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2303: 0.8961595892906189\n",
      "Seen so far: 147456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2304: 0.4821004867553711\n",
      "Seen so far: 147520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2305: 0.8803452849388123\n",
      "Seen so far: 147584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2306: 0.6688663363456726\n",
      "Seen so far: 147648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2307: 0.7579802870750427\n",
      "Seen so far: 147712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2308: 0.7381120920181274\n",
      "Seen so far: 147776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2309: 0.8969841003417969\n",
      "Seen so far: 147840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2310: 0.635674774646759\n",
      "Seen so far: 147904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2311: 0.6227210164070129\n",
      "Seen so far: 147968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2312: 0.3997615873813629\n",
      "Seen so far: 148032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2313: 0.7885844707489014\n",
      "Seen so far: 148096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2314: 0.9951258301734924\n",
      "Seen so far: 148160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2315: 0.8076701164245605\n",
      "Seen so far: 148224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2316: 0.8625636100769043\n",
      "Seen so far: 148288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2317: 0.4377819299697876\n",
      "Seen so far: 148352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2318: 0.5466670989990234\n",
      "Seen so far: 148416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2319: 0.7406807541847229\n",
      "Seen so far: 148480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2320: 0.8421577215194702\n",
      "Seen so far: 148544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2321: 0.6013712882995605\n",
      "Seen so far: 148608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2322: 0.5545560121536255\n",
      "Seen so far: 148672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2323: 0.6517053842544556\n",
      "Seen so far: 148736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2324: 1.0749378204345703\n",
      "Seen so far: 148800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2325: 0.4751931428909302\n",
      "Seen so far: 148864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2326: 0.6370837688446045\n",
      "Seen so far: 148928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2327: 0.9820288419723511\n",
      "Seen so far: 148992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2328: 0.5875881314277649\n",
      "Seen so far: 149056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2329: 0.7613834142684937\n",
      "Seen so far: 149120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2330: 0.7044252157211304\n",
      "Seen so far: 149184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2331: 0.4637286961078644\n",
      "Seen so far: 149248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2332: 0.9606285691261292\n",
      "Seen so far: 149312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2333: 0.738713264465332\n",
      "Seen so far: 149376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2334: 0.8811929225921631\n",
      "Seen so far: 149440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2335: 0.7478606104850769\n",
      "Seen so far: 149504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2336: 0.7614075541496277\n",
      "Seen so far: 149568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2337: 0.7313287854194641\n",
      "Seen so far: 149632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2338: 0.6561630368232727\n",
      "Seen so far: 149696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2339: 0.9572675824165344\n",
      "Seen so far: 149760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2340: 0.9730169773101807\n",
      "Seen so far: 149824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2341: 1.0166692733764648\n",
      "Seen so far: 149888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2342: 0.4938778579235077\n",
      "Seen so far: 149952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2343: 0.4901551604270935\n",
      "Seen so far: 150016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2344: 0.8090938925743103\n",
      "Seen so far: 150080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2345: 0.821282148361206\n",
      "Seen so far: 150144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2346: 0.7702628374099731\n",
      "Seen so far: 150208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2347: 0.5132235884666443\n",
      "Seen so far: 150272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2348: 0.9526369571685791\n",
      "Seen so far: 150336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2349: 0.7052851915359497\n",
      "Seen so far: 150400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2350: 0.9676631689071655\n",
      "Seen so far: 150464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2351: 0.7065104246139526\n",
      "Seen so far: 150528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2352: 1.015792965888977\n",
      "Seen so far: 150592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2353: 0.7021322250366211\n",
      "Seen so far: 150656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2354: 0.7017326354980469\n",
      "Seen so far: 150720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2355: 0.6988425254821777\n",
      "Seen so far: 150784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2356: 0.6419854164123535\n",
      "Seen so far: 150848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2357: 0.967586100101471\n",
      "Seen so far: 150912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2358: 0.9295978546142578\n",
      "Seen so far: 150976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2359: 0.9003876447677612\n",
      "Seen so far: 151040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2360: 0.8047747611999512\n",
      "Seen so far: 151104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2361: 0.7102034687995911\n",
      "Seen so far: 151168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2362: 0.9322904348373413\n",
      "Seen so far: 151232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2363: 0.799857497215271\n",
      "Seen so far: 151296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2364: 0.5983819961547852\n",
      "Seen so far: 151360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2365: 1.0211067199707031\n",
      "Seen so far: 151424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2366: 0.6181504726409912\n",
      "Seen so far: 151488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2367: 0.7406387329101562\n",
      "Seen so far: 151552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2368: 0.9749104976654053\n",
      "Seen so far: 151616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2369: 1.0289385318756104\n",
      "Seen so far: 151680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2370: 0.8554233312606812\n",
      "Seen so far: 151744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2371: 0.7938143610954285\n",
      "Seen so far: 151808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2372: 0.7114472389221191\n",
      "Seen so far: 151872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2373: 0.8766487836837769\n",
      "Seen so far: 151936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2374: 0.653083324432373\n",
      "Seen so far: 152000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2375: 0.7778567671775818\n",
      "Seen so far: 152064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2376: 1.4454009532928467\n",
      "Seen so far: 152128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2377: 0.7357650399208069\n",
      "Seen so far: 152192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2378: 0.5250793099403381\n",
      "Seen so far: 152256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2379: 0.8022083044052124\n",
      "Seen so far: 152320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2380: 0.5328848361968994\n",
      "Seen so far: 152384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2381: 0.42199116945266724\n",
      "Seen so far: 152448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2382: 0.5361756682395935\n",
      "Seen so far: 152512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2383: 0.6327682137489319\n",
      "Seen so far: 152576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2384: 1.0423922538757324\n",
      "Seen so far: 152640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2385: 0.9104897975921631\n",
      "Seen so far: 152704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2386: 0.721859335899353\n",
      "Seen so far: 152768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2387: 0.6387899518013\n",
      "Seen so far: 152832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2388: 0.45957618951797485\n",
      "Seen so far: 152896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2389: 0.8280569911003113\n",
      "Seen so far: 152960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2390: 1.2095141410827637\n",
      "Seen so far: 153024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2391: 0.8266102075576782\n",
      "Seen so far: 153088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2392: 0.5024560689926147\n",
      "Seen so far: 153152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2393: 0.8712310194969177\n",
      "Seen so far: 153216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2394: 0.5585314631462097\n",
      "Seen so far: 153280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2395: 0.9241251349449158\n",
      "Seen so far: 153344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2396: 0.5312150716781616\n",
      "Seen so far: 153408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2397: 0.821904182434082\n",
      "Seen so far: 153472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2398: 0.6396545171737671\n",
      "Seen so far: 153536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2399: 0.5042924880981445\n",
      "Seen so far: 153600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2400: 0.5754069089889526\n",
      "Seen so far: 153664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2401: 0.6164034605026245\n",
      "Seen so far: 153728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2402: 0.8744391798973083\n",
      "Seen so far: 153792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2403: 0.9548147320747375\n",
      "Seen so far: 153856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2404: 0.6772773265838623\n",
      "Seen so far: 153920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2405: 1.0286176204681396\n",
      "Seen so far: 153984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2406: 0.4100869297981262\n",
      "Seen so far: 154048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2407: 1.2930498123168945\n",
      "Seen so far: 154112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2408: 0.44734323024749756\n",
      "Seen so far: 154176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2409: 0.826819658279419\n",
      "Seen so far: 154240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2410: 0.47391998767852783\n",
      "Seen so far: 154304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2411: 1.117634654045105\n",
      "Seen so far: 154368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2412: 1.043251872062683\n",
      "Seen so far: 154432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2413: 0.9478975534439087\n",
      "Seen so far: 154496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2414: 0.8703233003616333\n",
      "Seen so far: 154560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2415: 0.9355771541595459\n",
      "Seen so far: 154624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2416: 0.8230855464935303\n",
      "Seen so far: 154688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2417: 0.9319920539855957\n",
      "Seen so far: 154752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2418: 0.8615193367004395\n",
      "Seen so far: 154816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2419: 0.7093546390533447\n",
      "Seen so far: 154880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2420: 0.8766170740127563\n",
      "Seen so far: 154944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2421: 0.6735233664512634\n",
      "Seen so far: 155008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2422: 0.5765752792358398\n",
      "Seen so far: 155072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2423: 0.6971266865730286\n",
      "Seen so far: 155136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2424: 0.682268500328064\n",
      "Seen so far: 155200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2425: 0.9738077521324158\n",
      "Seen so far: 155264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2426: 0.7659149765968323\n",
      "Seen so far: 155328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2427: 1.044228434562683\n",
      "Seen so far: 155392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2428: 0.9987207651138306\n",
      "Seen so far: 155456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2429: 0.6535791754722595\n",
      "Seen so far: 155520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2430: 0.830212414264679\n",
      "Seen so far: 155584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2431: 1.1879589557647705\n",
      "Seen so far: 155648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2432: 0.7211641669273376\n",
      "Seen so far: 155712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2433: 0.7112104296684265\n",
      "Seen so far: 155776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2434: 0.6575171947479248\n",
      "Seen so far: 155840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2435: 1.1482090950012207\n",
      "Seen so far: 155904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2436: 1.0391576290130615\n",
      "Seen so far: 155968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2437: 0.4607756435871124\n",
      "Seen so far: 156032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2438: 0.8443383574485779\n",
      "Seen so far: 156096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2439: 0.7447780966758728\n",
      "Seen so far: 156160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2440: 0.629795491695404\n",
      "Seen so far: 156224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2441: 0.4393121302127838\n",
      "Seen so far: 156288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2442: 0.8688496351242065\n",
      "Seen so far: 156352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2443: 0.6924356818199158\n",
      "Seen so far: 156416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2444: 0.7108228206634521\n",
      "Seen so far: 156480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2445: 0.7320469617843628\n",
      "Seen so far: 156544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2446: 0.8641557097434998\n",
      "Seen so far: 156608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2447: 0.44933897256851196\n",
      "Seen so far: 156672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2448: 1.2581018209457397\n",
      "Seen so far: 156736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2449: 0.7392163872718811\n",
      "Seen so far: 156800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2450: 0.895904541015625\n",
      "Seen so far: 156864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2451: 0.7840988636016846\n",
      "Seen so far: 156928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2452: 0.7825082540512085\n",
      "Seen so far: 156992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2453: 0.5962905883789062\n",
      "Seen so far: 157056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2454: 0.897136926651001\n",
      "Seen so far: 157120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2455: 0.7589631080627441\n",
      "Seen so far: 157184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2456: 0.5823714733123779\n",
      "Seen so far: 157248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2457: 0.9508109092712402\n",
      "Seen so far: 157312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2458: 0.5715636014938354\n",
      "Seen so far: 157376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2459: 0.7051715850830078\n",
      "Seen so far: 157440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2460: 0.7990776896476746\n",
      "Seen so far: 157504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2461: 0.6680186986923218\n",
      "Seen so far: 157568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2462: 0.8297200202941895\n",
      "Seen so far: 157632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2463: 0.48132726550102234\n",
      "Seen so far: 157696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2464: 0.7336073517799377\n",
      "Seen so far: 157760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2465: 0.9442726373672485\n",
      "Seen so far: 157824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2466: 1.2378168106079102\n",
      "Seen so far: 157888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2467: 1.1601662635803223\n",
      "Seen so far: 157952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2468: 0.7081553936004639\n",
      "Seen so far: 158016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2469: 0.6473599672317505\n",
      "Seen so far: 158080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2470: 0.7585905194282532\n",
      "Seen so far: 158144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2471: 1.1317248344421387\n",
      "Seen so far: 158208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2472: 0.8453425168991089\n",
      "Seen so far: 158272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2473: 0.7969397306442261\n",
      "Seen so far: 158336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2474: 1.2598350048065186\n",
      "Seen so far: 158400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2475: 0.6864488124847412\n",
      "Seen so far: 158464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2476: 0.7526167631149292\n",
      "Seen so far: 158528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2477: 0.7313142418861389\n",
      "Seen so far: 158592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2478: 0.9289411306381226\n",
      "Seen so far: 158656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2479: 0.865870475769043\n",
      "Seen so far: 158720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2480: 0.8175128102302551\n",
      "Seen so far: 158784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2481: 0.6433769464492798\n",
      "Seen so far: 158848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2482: 0.8092836141586304\n",
      "Seen so far: 158912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2483: 0.9002729654312134\n",
      "Seen so far: 158976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2484: 0.7095749974250793\n",
      "Seen so far: 159040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2485: 0.591015100479126\n",
      "Seen so far: 159104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2486: 1.2696603536605835\n",
      "Seen so far: 159168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2487: 0.7467547655105591\n",
      "Seen so far: 159232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2488: 0.8847154378890991\n",
      "Seen so far: 159296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2489: 0.5913391709327698\n",
      "Seen so far: 159360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2490: 0.7005589604377747\n",
      "Seen so far: 159424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2491: 0.8232352137565613\n",
      "Seen so far: 159488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2492: 0.7141211628913879\n",
      "Seen so far: 159552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2493: 0.45283442735671997\n",
      "Seen so far: 159616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2494: 0.5802419185638428\n",
      "Seen so far: 159680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2495: 0.5105283260345459\n",
      "Seen so far: 159744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2496: 0.4807136654853821\n",
      "Seen so far: 159808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2497: 0.6289556622505188\n",
      "Seen so far: 159872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2498: 0.5400532484054565\n",
      "Seen so far: 159936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2499: 1.0332996845245361\n",
      "Seen so far: 160000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2500: 0.8251387476921082\n",
      "Seen so far: 160064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2501: 0.7390032410621643\n",
      "Seen so far: 160128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2502: 0.6715530753135681\n",
      "Seen so far: 160192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2503: 0.7333840131759644\n",
      "Seen so far: 160256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2504: 0.9534745812416077\n",
      "Seen so far: 160320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2505: 1.150804877281189\n",
      "Seen so far: 160384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2506: 0.7445065379142761\n",
      "Seen so far: 160448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2507: 0.8323089480400085\n",
      "Seen so far: 160512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2508: 0.7551722526550293\n",
      "Seen so far: 160576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2509: 0.7090921401977539\n",
      "Seen so far: 160640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2510: 0.9782861471176147\n",
      "Seen so far: 160704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2511: 0.9253581762313843\n",
      "Seen so far: 160768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2512: 0.5554137825965881\n",
      "Seen so far: 160832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2513: 0.7739062905311584\n",
      "Seen so far: 160896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2514: 0.735173761844635\n",
      "Seen so far: 160960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2515: 0.7157352566719055\n",
      "Seen so far: 161024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2516: 0.642774760723114\n",
      "Seen so far: 161088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2517: 0.9083467721939087\n",
      "Seen so far: 161152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2518: 0.9654206037521362\n",
      "Seen so far: 161216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2519: 0.9829473495483398\n",
      "Seen so far: 161280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2520: 0.5345906615257263\n",
      "Seen so far: 161344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2521: 0.7082349061965942\n",
      "Seen so far: 161408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2522: 0.6063966751098633\n",
      "Seen so far: 161472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2523: 0.891457200050354\n",
      "Seen so far: 161536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2524: 0.7470977306365967\n",
      "Seen so far: 161600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2525: 0.7364678382873535\n",
      "Seen so far: 161664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2526: 0.6219674944877625\n",
      "Seen so far: 161728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2527: 0.7259392142295837\n",
      "Seen so far: 161792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2528: 1.1165529489517212\n",
      "Seen so far: 161856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2529: 0.9892076253890991\n",
      "Seen so far: 161920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2530: 0.547349214553833\n",
      "Seen so far: 161984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2531: 0.7959332466125488\n",
      "Seen so far: 162048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2532: 0.4825250506401062\n",
      "Seen so far: 162112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2533: 1.146185278892517\n",
      "Seen so far: 162176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2534: 0.8210848569869995\n",
      "Seen so far: 162240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2535: 0.7013720273971558\n",
      "Seen so far: 162304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2536: 0.7221705317497253\n",
      "Seen so far: 162368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2537: 0.8671324253082275\n",
      "Seen so far: 162432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2538: 0.5787246227264404\n",
      "Seen so far: 162496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2539: 0.9704492092132568\n",
      "Seen so far: 162560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2540: 1.256500005722046\n",
      "Seen so far: 162624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2541: 1.7433409690856934\n",
      "Seen so far: 162688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2542: 0.6667901277542114\n",
      "Seen so far: 162752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2543: 0.8106287717819214\n",
      "Seen so far: 162816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2544: 0.7889267802238464\n",
      "Seen so far: 162880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2545: 1.2817637920379639\n",
      "Seen so far: 162944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2546: 0.6113330125808716\n",
      "Seen so far: 163008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2547: 0.9361267685890198\n",
      "Seen so far: 163072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2548: 0.9374582767486572\n",
      "Seen so far: 163136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2549: 1.2024211883544922\n",
      "Seen so far: 163200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2550: 1.291490912437439\n",
      "Seen so far: 163264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2551: 0.7907684445381165\n",
      "Seen so far: 163328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2552: 0.31475794315338135\n",
      "Seen so far: 163392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2553: 0.946612536907196\n",
      "Seen so far: 163456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2554: 0.6585323214530945\n",
      "Seen so far: 163520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2555: 0.5520098209381104\n",
      "Seen so far: 163584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2556: 1.0401670932769775\n",
      "Seen so far: 163648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2557: 0.6240148544311523\n",
      "Seen so far: 163712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2558: 0.6816130876541138\n",
      "Seen so far: 163776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2559: 0.9439560174942017\n",
      "Seen so far: 163840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2560: 1.0085042715072632\n",
      "Seen so far: 163904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2561: 0.8754368424415588\n",
      "Seen so far: 163968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2562: 0.6338551044464111\n",
      "Seen so far: 164032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2563: 0.8981657028198242\n",
      "Seen so far: 164096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2564: 0.7801197171211243\n",
      "Seen so far: 164160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2565: 0.4344988465309143\n",
      "Seen so far: 164224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2566: 0.9331077337265015\n",
      "Seen so far: 164288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2567: 0.8303642272949219\n",
      "Seen so far: 164352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2568: 1.1301753520965576\n",
      "Seen so far: 164416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2569: 0.9107476472854614\n",
      "Seen so far: 164480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2570: 0.8230106830596924\n",
      "Seen so far: 164544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2571: 0.4492335915565491\n",
      "Seen so far: 164608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2572: 1.2498252391815186\n",
      "Seen so far: 164672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2573: 0.6510801315307617\n",
      "Seen so far: 164736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2574: 0.8460725545883179\n",
      "Seen so far: 164800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2575: 0.5287039279937744\n",
      "Seen so far: 164864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2576: 0.6792629957199097\n",
      "Seen so far: 164928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2577: 0.6944423913955688\n",
      "Seen so far: 164992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2578: 0.5677739381790161\n",
      "Seen so far: 165056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2579: 0.766035795211792\n",
      "Seen so far: 165120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2580: 1.079134464263916\n",
      "Seen so far: 165184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2581: 0.6847028136253357\n",
      "Seen so far: 165248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2582: 1.103467583656311\n",
      "Seen so far: 165312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2583: 0.5906541347503662\n",
      "Seen so far: 165376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2584: 0.3727306127548218\n",
      "Seen so far: 165440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2585: 0.5651005506515503\n",
      "Seen so far: 165504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2586: 0.7560569643974304\n",
      "Seen so far: 165568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2587: 0.5879403948783875\n",
      "Seen so far: 165632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2588: 0.6907298564910889\n",
      "Seen so far: 165696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2589: 0.8616464138031006\n",
      "Seen so far: 165760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2590: 0.8533239364624023\n",
      "Seen so far: 165824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2591: 0.7620932459831238\n",
      "Seen so far: 165888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2592: 0.7850246429443359\n",
      "Seen so far: 165952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2593: 0.8192853927612305\n",
      "Seen so far: 166016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2594: 0.9396753311157227\n",
      "Seen so far: 166080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2595: 0.6172308921813965\n",
      "Seen so far: 166144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2596: 0.6304154992103577\n",
      "Seen so far: 166208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2597: 0.5892272591590881\n",
      "Seen so far: 166272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2598: 0.8752479553222656\n",
      "Seen so far: 166336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2599: 0.692236602306366\n",
      "Seen so far: 166400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2600: 0.7727656960487366\n",
      "Seen so far: 166464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2601: 0.5836751461029053\n",
      "Seen so far: 166528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2602: 0.614996075630188\n",
      "Seen so far: 166592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2603: 0.6289382576942444\n",
      "Seen so far: 166656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2604: 0.8917078375816345\n",
      "Seen so far: 166720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2605: 0.6277300119400024\n",
      "Seen so far: 166784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2606: 0.7806223630905151\n",
      "Seen so far: 166848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2607: 1.3388267755508423\n",
      "Seen so far: 166912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2608: 0.5498125553131104\n",
      "Seen so far: 166976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2609: 0.6379547715187073\n",
      "Seen so far: 167040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2610: 0.8926366567611694\n",
      "Seen so far: 167104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2611: 0.7414758205413818\n",
      "Seen so far: 167168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2612: 0.9558417797088623\n",
      "Seen so far: 167232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2613: 0.6145803928375244\n",
      "Seen so far: 167296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2614: 0.7859909534454346\n",
      "Seen so far: 167360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2615: 0.5708798766136169\n",
      "Seen so far: 167424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2616: 0.5982590913772583\n",
      "Seen so far: 167488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2617: 0.7275434136390686\n",
      "Seen so far: 167552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2618: 0.6702748537063599\n",
      "Seen so far: 167616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2619: 1.2083089351654053\n",
      "Seen so far: 167680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2620: 0.5788170099258423\n",
      "Seen so far: 167744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2621: 0.6828339695930481\n",
      "Seen so far: 167808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2622: 0.9060856699943542\n",
      "Seen so far: 167872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2623: 0.8572427034378052\n",
      "Seen so far: 167936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2624: 0.8813059329986572\n",
      "Seen so far: 168000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2625: 0.5783416032791138\n",
      "Seen so far: 168064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2626: 0.561843752861023\n",
      "Seen so far: 168128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2627: 0.8461481332778931\n",
      "Seen so far: 168192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2628: 0.4313861131668091\n",
      "Seen so far: 168256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2629: 0.8312250971794128\n",
      "Seen so far: 168320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2630: 1.0565482378005981\n",
      "Seen so far: 168384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2631: 0.722382664680481\n",
      "Seen so far: 168448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2632: 0.6473322510719299\n",
      "Seen so far: 168512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2633: 0.7289524078369141\n",
      "Seen so far: 168576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2634: 0.844145655632019\n",
      "Seen so far: 168640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2635: 0.7993414402008057\n",
      "Seen so far: 168704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2636: 0.7894126176834106\n",
      "Seen so far: 168768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2637: 0.7198442816734314\n",
      "Seen so far: 168832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2638: 1.491905927658081\n",
      "Seen so far: 168896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2639: 0.9825742244720459\n",
      "Seen so far: 168960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2640: 0.6383761167526245\n",
      "Seen so far: 169024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2641: 0.5221285820007324\n",
      "Seen so far: 169088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2642: 0.717119574546814\n",
      "Seen so far: 169152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2643: 0.8966742753982544\n",
      "Seen so far: 169216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2644: 0.7004666924476624\n",
      "Seen so far: 169280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2645: 0.7428422570228577\n",
      "Seen so far: 169344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2646: 0.73783278465271\n",
      "Seen so far: 169408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2647: 0.5941262245178223\n",
      "Seen so far: 169472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2648: 0.7819420695304871\n",
      "Seen so far: 169536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2649: 0.9283370971679688\n",
      "Seen so far: 169600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2650: 0.8342843651771545\n",
      "Seen so far: 169664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2651: 0.9345031976699829\n",
      "Seen so far: 169728 samples\n",
      "Training acc over epoch: 0.7441391944885254\n",
      "Start of epoch 9\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 0: 0.733260989189148\n",
      "Seen so far: 64 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1: 0.6034231781959534\n",
      "Seen so far: 128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2: 0.4402163028717041\n",
      "Seen so far: 192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 3: 0.7198954820632935\n",
      "Seen so far: 256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 4: 0.6385685801506042\n",
      "Seen so far: 320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 5: 1.28755521774292\n",
      "Seen so far: 384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 6: 0.9815724492073059\n",
      "Seen so far: 448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 7: 0.8135092258453369\n",
      "Seen so far: 512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 8: 1.0075976848602295\n",
      "Seen so far: 576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 9: 0.718757152557373\n",
      "Seen so far: 640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 10: 0.47486400604248047\n",
      "Seen so far: 704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 11: 0.5955213308334351\n",
      "Seen so far: 768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 12: 0.47248575091362\n",
      "Seen so far: 832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 13: 0.481393963098526\n",
      "Seen so far: 896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 14: 1.1163737773895264\n",
      "Seen so far: 960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 15: 0.4943026006221771\n",
      "Seen so far: 1024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 16: 1.0337198972702026\n",
      "Seen so far: 1088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 17: 1.0333484411239624\n",
      "Seen so far: 1152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 18: 0.7199939489364624\n",
      "Seen so far: 1216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 19: 0.9889519810676575\n",
      "Seen so far: 1280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 20: 0.9033814668655396\n",
      "Seen so far: 1344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 21: 1.2516460418701172\n",
      "Seen so far: 1408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 22: 0.8454110622406006\n",
      "Seen so far: 1472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 23: 1.0656650066375732\n",
      "Seen so far: 1536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 24: 0.5917404890060425\n",
      "Seen so far: 1600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 25: 0.6101346015930176\n",
      "Seen so far: 1664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 26: 0.8342527151107788\n",
      "Seen so far: 1728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 27: 1.1132452487945557\n",
      "Seen so far: 1792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 28: 0.9548256993293762\n",
      "Seen so far: 1856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 29: 0.7883063554763794\n",
      "Seen so far: 1920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 30: 0.8188337087631226\n",
      "Seen so far: 1984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 31: 0.8502358198165894\n",
      "Seen so far: 2048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 32: 1.0942914485931396\n",
      "Seen so far: 2112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 33: 0.7089705467224121\n",
      "Seen so far: 2176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 34: 0.802683413028717\n",
      "Seen so far: 2240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 35: 0.9740822911262512\n",
      "Seen so far: 2304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 36: 0.5420629978179932\n",
      "Seen so far: 2368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 37: 0.9389852285385132\n",
      "Seen so far: 2432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 38: 0.822989821434021\n",
      "Seen so far: 2496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 39: 0.8207878470420837\n",
      "Seen so far: 2560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 40: 0.9290560483932495\n",
      "Seen so far: 2624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 41: 0.8996140956878662\n",
      "Seen so far: 2688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 42: 0.953223466873169\n",
      "Seen so far: 2752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 43: 0.5946698188781738\n",
      "Seen so far: 2816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 44: 0.9098724126815796\n",
      "Seen so far: 2880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 45: 1.0466904640197754\n",
      "Seen so far: 2944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 46: 0.6152757406234741\n",
      "Seen so far: 3008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 47: 0.629760205745697\n",
      "Seen so far: 3072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 48: 0.9041364192962646\n",
      "Seen so far: 3136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 49: 0.5111917853355408\n",
      "Seen so far: 3200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 50: 0.8476352691650391\n",
      "Seen so far: 3264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 51: 0.9337704181671143\n",
      "Seen so far: 3328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 52: 0.49970653653144836\n",
      "Seen so far: 3392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 53: 0.6265454292297363\n",
      "Seen so far: 3456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 54: 0.5637657642364502\n",
      "Seen so far: 3520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 55: 0.8682969212532043\n",
      "Seen so far: 3584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 56: 1.155289649963379\n",
      "Seen so far: 3648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 57: 1.361274003982544\n",
      "Seen so far: 3712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 58: 0.466946542263031\n",
      "Seen so far: 3776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 59: 0.7592793703079224\n",
      "Seen so far: 3840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 60: 0.21299633383750916\n",
      "Seen so far: 3904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 61: 0.5721436738967896\n",
      "Seen so far: 3968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 62: 0.8583910465240479\n",
      "Seen so far: 4032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 63: 0.8734167814254761\n",
      "Seen so far: 4096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 64: 0.6857369542121887\n",
      "Seen so far: 4160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 65: 0.650208592414856\n",
      "Seen so far: 4224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 66: 1.205244541168213\n",
      "Seen so far: 4288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 67: 1.0701251029968262\n",
      "Seen so far: 4352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 68: 1.1394636631011963\n",
      "Seen so far: 4416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 69: 0.527507483959198\n",
      "Seen so far: 4480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 70: 0.6323971152305603\n",
      "Seen so far: 4544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 71: 0.720523476600647\n",
      "Seen so far: 4608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 72: 0.9811151027679443\n",
      "Seen so far: 4672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 73: 0.6815663576126099\n",
      "Seen so far: 4736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 74: 0.8464425802230835\n",
      "Seen so far: 4800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 75: 0.8646411299705505\n",
      "Seen so far: 4864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 76: 1.1819583177566528\n",
      "Seen so far: 4928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 77: 0.5792666673660278\n",
      "Seen so far: 4992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 78: 0.5554825663566589\n",
      "Seen so far: 5056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 79: 1.1128530502319336\n",
      "Seen so far: 5120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 80: 0.5088760256767273\n",
      "Seen so far: 5184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 81: 0.8245841264724731\n",
      "Seen so far: 5248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 82: 1.1146605014801025\n",
      "Seen so far: 5312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 83: 0.91222083568573\n",
      "Seen so far: 5376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 84: 0.8107575178146362\n",
      "Seen so far: 5440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 85: 0.8822822570800781\n",
      "Seen so far: 5504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 86: 0.6917874813079834\n",
      "Seen so far: 5568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 87: 0.8698347806930542\n",
      "Seen so far: 5632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 88: 0.7755199670791626\n",
      "Seen so far: 5696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 89: 0.9723107218742371\n",
      "Seen so far: 5760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 90: 0.9088954329490662\n",
      "Seen so far: 5824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 91: 1.2316844463348389\n",
      "Seen so far: 5888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 92: 0.6971654295921326\n",
      "Seen so far: 5952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 93: 0.7373307943344116\n",
      "Seen so far: 6016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 94: 0.7203099727630615\n",
      "Seen so far: 6080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 95: 0.5321232080459595\n",
      "Seen so far: 6144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 96: 0.8700571060180664\n",
      "Seen so far: 6208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 97: 0.7997243404388428\n",
      "Seen so far: 6272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 98: 0.5307179689407349\n",
      "Seen so far: 6336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 99: 0.9219260215759277\n",
      "Seen so far: 6400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 100: 0.7814515829086304\n",
      "Seen so far: 6464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 101: 0.5927609205245972\n",
      "Seen so far: 6528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 102: 0.735851526260376\n",
      "Seen so far: 6592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 103: 0.7435080409049988\n",
      "Seen so far: 6656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 104: 0.8546347618103027\n",
      "Seen so far: 6720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 105: 0.9760886430740356\n",
      "Seen so far: 6784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 106: 0.6180758476257324\n",
      "Seen so far: 6848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 107: 0.7344520092010498\n",
      "Seen so far: 6912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 108: 0.8780730962753296\n",
      "Seen so far: 6976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 109: 0.7843528985977173\n",
      "Seen so far: 7040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 110: 0.5791990756988525\n",
      "Seen so far: 7104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 111: 0.7357789874076843\n",
      "Seen so far: 7168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 112: 0.5231364369392395\n",
      "Seen so far: 7232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 113: 0.9969839453697205\n",
      "Seen so far: 7296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 114: 1.131845235824585\n",
      "Seen so far: 7360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 115: 0.5485925674438477\n",
      "Seen so far: 7424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 116: 0.9992372989654541\n",
      "Seen so far: 7488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 117: 0.9060158133506775\n",
      "Seen so far: 7552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 118: 1.00020432472229\n",
      "Seen so far: 7616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 119: 0.5697776079177856\n",
      "Seen so far: 7680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 120: 0.8146792650222778\n",
      "Seen so far: 7744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 121: 0.9140015840530396\n",
      "Seen so far: 7808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 122: 0.8562122583389282\n",
      "Seen so far: 7872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 123: 0.4860447645187378\n",
      "Seen so far: 7936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 124: 0.8648290634155273\n",
      "Seen so far: 8000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 125: 0.6972788572311401\n",
      "Seen so far: 8064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 126: 0.5555113554000854\n",
      "Seen so far: 8128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 127: 1.0387706756591797\n",
      "Seen so far: 8192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 128: 0.4953441023826599\n",
      "Seen so far: 8256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 129: 0.930880069732666\n",
      "Seen so far: 8320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 130: 0.9264333248138428\n",
      "Seen so far: 8384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 131: 0.9551530480384827\n",
      "Seen so far: 8448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 132: 0.7636462450027466\n",
      "Seen so far: 8512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 133: 0.8026965856552124\n",
      "Seen so far: 8576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 134: 0.7385756373405457\n",
      "Seen so far: 8640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 135: 0.9982465505599976\n",
      "Seen so far: 8704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 136: 0.898037314414978\n",
      "Seen so far: 8768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 137: 1.003394603729248\n",
      "Seen so far: 8832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 138: 0.5575941801071167\n",
      "Seen so far: 8896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 139: 0.8482272624969482\n",
      "Seen so far: 8960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 140: 0.7720625996589661\n",
      "Seen so far: 9024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 141: 0.8537928462028503\n",
      "Seen so far: 9088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 142: 0.5558773279190063\n",
      "Seen so far: 9152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 143: 0.9392544031143188\n",
      "Seen so far: 9216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 144: 1.0679991245269775\n",
      "Seen so far: 9280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 145: 0.7279542684555054\n",
      "Seen so far: 9344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 146: 0.5258992314338684\n",
      "Seen so far: 9408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 147: 0.9258936643600464\n",
      "Seen so far: 9472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 148: 1.09755277633667\n",
      "Seen so far: 9536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 149: 0.6489887237548828\n",
      "Seen so far: 9600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 150: 0.5295897722244263\n",
      "Seen so far: 9664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 151: 0.5749124884605408\n",
      "Seen so far: 9728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 152: 1.1697107553482056\n",
      "Seen so far: 9792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 153: 1.0395827293395996\n",
      "Seen so far: 9856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 154: 1.2769038677215576\n",
      "Seen so far: 9920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 155: 0.8975993394851685\n",
      "Seen so far: 9984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 156: 0.9210598468780518\n",
      "Seen so far: 10048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 157: 0.6728905439376831\n",
      "Seen so far: 10112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 158: 1.2975295782089233\n",
      "Seen so far: 10176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 159: 1.0129657983779907\n",
      "Seen so far: 10240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 160: 0.8216979503631592\n",
      "Seen so far: 10304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 161: 0.6460051536560059\n",
      "Seen so far: 10368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 162: 0.9698423147201538\n",
      "Seen so far: 10432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 163: 0.843741774559021\n",
      "Seen so far: 10496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 164: 0.9380823969841003\n",
      "Seen so far: 10560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 165: 0.8533264398574829\n",
      "Seen so far: 10624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 166: 0.7750216126441956\n",
      "Seen so far: 10688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 167: 0.609594464302063\n",
      "Seen so far: 10752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 168: 0.903963565826416\n",
      "Seen so far: 10816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 169: 0.5052764415740967\n",
      "Seen so far: 10880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 170: 0.8315062522888184\n",
      "Seen so far: 10944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 171: 0.8106215000152588\n",
      "Seen so far: 11008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 172: 0.8911871314048767\n",
      "Seen so far: 11072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 173: 0.8540400862693787\n",
      "Seen so far: 11136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 174: 0.7492719888687134\n",
      "Seen so far: 11200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 175: 0.834970235824585\n",
      "Seen so far: 11264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 176: 1.0948741436004639\n",
      "Seen so far: 11328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 177: 0.7424111366271973\n",
      "Seen so far: 11392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 178: 0.6482340097427368\n",
      "Seen so far: 11456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 179: 0.8653852343559265\n",
      "Seen so far: 11520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 180: 0.772826611995697\n",
      "Seen so far: 11584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 181: 0.575556755065918\n",
      "Seen so far: 11648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 182: 0.7423975467681885\n",
      "Seen so far: 11712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 183: 1.0692466497421265\n",
      "Seen so far: 11776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 184: 0.9083741903305054\n",
      "Seen so far: 11840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 185: 1.0379644632339478\n",
      "Seen so far: 11904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 186: 0.8389952182769775\n",
      "Seen so far: 11968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 187: 0.8725919127464294\n",
      "Seen so far: 12032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 188: 0.9500651359558105\n",
      "Seen so far: 12096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 189: 0.8862980604171753\n",
      "Seen so far: 12160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 190: 0.910008430480957\n",
      "Seen so far: 12224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 191: 0.32533374428749084\n",
      "Seen so far: 12288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 192: 0.6957599520683289\n",
      "Seen so far: 12352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 193: 0.935410737991333\n",
      "Seen so far: 12416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 194: 1.0509159564971924\n",
      "Seen so far: 12480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 195: 0.8015425205230713\n",
      "Seen so far: 12544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 196: 0.41393741965293884\n",
      "Seen so far: 12608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 197: 0.6439237594604492\n",
      "Seen so far: 12672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 198: 1.2776141166687012\n",
      "Seen so far: 12736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 199: 0.7720869183540344\n",
      "Seen so far: 12800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 200: 0.7224546670913696\n",
      "Seen so far: 12864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 201: 0.6315785646438599\n",
      "Seen so far: 12928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 202: 0.8533884286880493\n",
      "Seen so far: 12992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 203: 0.7867390513420105\n",
      "Seen so far: 13056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 204: 0.7806870341300964\n",
      "Seen so far: 13120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 205: 0.4626501798629761\n",
      "Seen so far: 13184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 206: 1.0529536008834839\n",
      "Seen so far: 13248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 207: 0.6853575706481934\n",
      "Seen so far: 13312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 208: 1.15546715259552\n",
      "Seen so far: 13376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 209: 0.6958998441696167\n",
      "Seen so far: 13440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 210: 0.6615933775901794\n",
      "Seen so far: 13504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 211: 0.5769954323768616\n",
      "Seen so far: 13568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 212: 1.1366585493087769\n",
      "Seen so far: 13632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 213: 0.9407743215560913\n",
      "Seen so far: 13696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 214: 1.0145511627197266\n",
      "Seen so far: 13760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 215: 0.9431698322296143\n",
      "Seen so far: 13824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 216: 0.5933347940444946\n",
      "Seen so far: 13888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 217: 0.6684009432792664\n",
      "Seen so far: 13952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 218: 0.6669297218322754\n",
      "Seen so far: 14016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 219: 0.4531126022338867\n",
      "Seen so far: 14080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 220: 0.6413921117782593\n",
      "Seen so far: 14144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 221: 0.7110605835914612\n",
      "Seen so far: 14208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 222: 0.7456788420677185\n",
      "Seen so far: 14272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 223: 0.7984514832496643\n",
      "Seen so far: 14336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 224: 0.5215293765068054\n",
      "Seen so far: 14400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 225: 0.699378252029419\n",
      "Seen so far: 14464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 226: 0.5899506211280823\n",
      "Seen so far: 14528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 227: 0.5308654308319092\n",
      "Seen so far: 14592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 228: 0.6704355478286743\n",
      "Seen so far: 14656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 229: 0.8220648765563965\n",
      "Seen so far: 14720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 230: 0.5447380542755127\n",
      "Seen so far: 14784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 231: 0.8518067598342896\n",
      "Seen so far: 14848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 232: 0.7424921989440918\n",
      "Seen so far: 14912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 233: 1.0984834432601929\n",
      "Seen so far: 14976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 234: 0.8576290607452393\n",
      "Seen so far: 15040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 235: 0.45769044756889343\n",
      "Seen so far: 15104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 236: 0.4977003335952759\n",
      "Seen so far: 15168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 237: 0.6763638854026794\n",
      "Seen so far: 15232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 238: 0.9672898054122925\n",
      "Seen so far: 15296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 239: 0.8289476037025452\n",
      "Seen so far: 15360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 240: 0.9797550439834595\n",
      "Seen so far: 15424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 241: 0.8297463059425354\n",
      "Seen so far: 15488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 242: 1.065000295639038\n",
      "Seen so far: 15552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 243: 0.8079495429992676\n",
      "Seen so far: 15616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 244: 0.6926815509796143\n",
      "Seen so far: 15680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 245: 0.8764897584915161\n",
      "Seen so far: 15744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 246: 1.0967695713043213\n",
      "Seen so far: 15808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 247: 1.0593724250793457\n",
      "Seen so far: 15872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 248: 0.479059100151062\n",
      "Seen so far: 15936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 249: 0.5479069948196411\n",
      "Seen so far: 16000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 250: 0.8647342324256897\n",
      "Seen so far: 16064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 251: 1.120368480682373\n",
      "Seen so far: 16128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 252: 1.0396747589111328\n",
      "Seen so far: 16192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 253: 0.739189624786377\n",
      "Seen so far: 16256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 254: 0.7857966423034668\n",
      "Seen so far: 16320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 255: 1.0543584823608398\n",
      "Seen so far: 16384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 256: 0.8809508681297302\n",
      "Seen so far: 16448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 257: 1.158279299736023\n",
      "Seen so far: 16512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 258: 0.6587554216384888\n",
      "Seen so far: 16576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 259: 0.8116909265518188\n",
      "Seen so far: 16640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 260: 0.32817795872688293\n",
      "Seen so far: 16704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 261: 0.8619397878646851\n",
      "Seen so far: 16768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 262: 1.0696704387664795\n",
      "Seen so far: 16832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 263: 0.8507778644561768\n",
      "Seen so far: 16896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 264: 0.5404645204544067\n",
      "Seen so far: 16960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 265: 0.7683020830154419\n",
      "Seen so far: 17024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 266: 0.6266977190971375\n",
      "Seen so far: 17088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 267: 0.9663516283035278\n",
      "Seen so far: 17152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 268: 0.8250041007995605\n",
      "Seen so far: 17216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 269: 0.7984230518341064\n",
      "Seen so far: 17280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 270: 0.4131903648376465\n",
      "Seen so far: 17344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 271: 1.1355311870574951\n",
      "Seen so far: 17408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 272: 0.37946274876594543\n",
      "Seen so far: 17472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 273: 0.9528142809867859\n",
      "Seen so far: 17536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 274: 1.0489040613174438\n",
      "Seen so far: 17600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 275: 0.5795643925666809\n",
      "Seen so far: 17664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 276: 0.983286440372467\n",
      "Seen so far: 17728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 277: 1.1004618406295776\n",
      "Seen so far: 17792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 278: 0.7745770215988159\n",
      "Seen so far: 17856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 279: 1.1302473545074463\n",
      "Seen so far: 17920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 280: 0.48052412271499634\n",
      "Seen so far: 17984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 281: 0.5452044010162354\n",
      "Seen so far: 18048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 282: 0.6958936452865601\n",
      "Seen so far: 18112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 283: 0.5118275284767151\n",
      "Seen so far: 18176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 284: 0.36926376819610596\n",
      "Seen so far: 18240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 285: 0.460195928812027\n",
      "Seen so far: 18304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 286: 0.5298500061035156\n",
      "Seen so far: 18368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 287: 0.5687317848205566\n",
      "Seen so far: 18432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 288: 0.7778997421264648\n",
      "Seen so far: 18496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 289: 0.7753195762634277\n",
      "Seen so far: 18560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 290: 0.9938929080963135\n",
      "Seen so far: 18624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 291: 0.4440944790840149\n",
      "Seen so far: 18688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 292: 0.9774941802024841\n",
      "Seen so far: 18752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 293: 1.2331199645996094\n",
      "Seen so far: 18816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 294: 0.5217547416687012\n",
      "Seen so far: 18880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 295: 0.878814697265625\n",
      "Seen so far: 18944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 296: 0.8593618869781494\n",
      "Seen so far: 19008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 297: 0.533237636089325\n",
      "Seen so far: 19072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 298: 0.6103193759918213\n",
      "Seen so far: 19136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 299: 1.3313528299331665\n",
      "Seen so far: 19200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 300: 0.6485390663146973\n",
      "Seen so far: 19264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 301: 0.7654249668121338\n",
      "Seen so far: 19328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 302: 0.7195913791656494\n",
      "Seen so far: 19392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 303: 0.5666923522949219\n",
      "Seen so far: 19456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 304: 0.8364075422286987\n",
      "Seen so far: 19520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 305: 0.8164293169975281\n",
      "Seen so far: 19584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 306: 0.9716242551803589\n",
      "Seen so far: 19648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 307: 0.8414009809494019\n",
      "Seen so far: 19712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 308: 0.7073182463645935\n",
      "Seen so far: 19776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 309: 0.6273868680000305\n",
      "Seen so far: 19840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 310: 0.7134655714035034\n",
      "Seen so far: 19904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 311: 0.775611400604248\n",
      "Seen so far: 19968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 312: 1.0393266677856445\n",
      "Seen so far: 20032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 313: 0.828279435634613\n",
      "Seen so far: 20096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 314: 0.777855396270752\n",
      "Seen so far: 20160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 315: 0.6106874942779541\n",
      "Seen so far: 20224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 316: 0.8389331698417664\n",
      "Seen so far: 20288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 317: 0.905208945274353\n",
      "Seen so far: 20352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 318: 0.8435930609703064\n",
      "Seen so far: 20416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 319: 0.8394646644592285\n",
      "Seen so far: 20480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 320: 0.8353323340415955\n",
      "Seen so far: 20544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 321: 0.8102291226387024\n",
      "Seen so far: 20608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 322: 1.00771164894104\n",
      "Seen so far: 20672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 323: 0.787041962146759\n",
      "Seen so far: 20736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 324: 1.0788955688476562\n",
      "Seen so far: 20800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 325: 0.47812581062316895\n",
      "Seen so far: 20864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 326: 0.7646161913871765\n",
      "Seen so far: 20928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 327: 0.9118905067443848\n",
      "Seen so far: 20992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 328: 0.7830706834793091\n",
      "Seen so far: 21056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 329: 0.7833502888679504\n",
      "Seen so far: 21120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 330: 0.6355236768722534\n",
      "Seen so far: 21184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 331: 0.8049858808517456\n",
      "Seen so far: 21248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 332: 0.884137749671936\n",
      "Seen so far: 21312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 333: 1.021327257156372\n",
      "Seen so far: 21376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 334: 0.7744646072387695\n",
      "Seen so far: 21440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 335: 0.9524368047714233\n",
      "Seen so far: 21504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 336: 0.6459623575210571\n",
      "Seen so far: 21568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 337: 0.5343908071517944\n",
      "Seen so far: 21632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 338: 0.6563922762870789\n",
      "Seen so far: 21696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 339: 0.5010402202606201\n",
      "Seen so far: 21760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 340: 0.5453714728355408\n",
      "Seen so far: 21824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 341: 0.8379213213920593\n",
      "Seen so far: 21888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 342: 0.7265619039535522\n",
      "Seen so far: 21952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 343: 1.1372910737991333\n",
      "Seen so far: 22016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 344: 0.7143341898918152\n",
      "Seen so far: 22080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 345: 0.6257747411727905\n",
      "Seen so far: 22144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 346: 0.5663919448852539\n",
      "Seen so far: 22208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 347: 1.2608829736709595\n",
      "Seen so far: 22272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 348: 0.4089924097061157\n",
      "Seen so far: 22336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 349: 0.712402880191803\n",
      "Seen so far: 22400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 350: 0.7506914138793945\n",
      "Seen so far: 22464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 351: 0.5738378763198853\n",
      "Seen so far: 22528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 352: 0.6897134184837341\n",
      "Seen so far: 22592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 353: 0.9117361307144165\n",
      "Seen so far: 22656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 354: 0.799656867980957\n",
      "Seen so far: 22720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 355: 0.9538314342498779\n",
      "Seen so far: 22784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 356: 0.49488022923469543\n",
      "Seen so far: 22848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 357: 0.7836660742759705\n",
      "Seen so far: 22912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 358: 0.7551860809326172\n",
      "Seen so far: 22976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 359: 0.8785268664360046\n",
      "Seen so far: 23040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 360: 0.8125914335250854\n",
      "Seen so far: 23104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 361: 0.45998620986938477\n",
      "Seen so far: 23168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 362: 0.8113266229629517\n",
      "Seen so far: 23232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 363: 0.7487390041351318\n",
      "Seen so far: 23296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 364: 0.9016377925872803\n",
      "Seen so far: 23360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 365: 0.9155390858650208\n",
      "Seen so far: 23424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 366: 0.9482277631759644\n",
      "Seen so far: 23488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 367: 0.668608546257019\n",
      "Seen so far: 23552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 368: 0.7422871589660645\n",
      "Seen so far: 23616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 369: 0.9611900448799133\n",
      "Seen so far: 23680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 370: 0.4350566565990448\n",
      "Seen so far: 23744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 371: 0.9573381543159485\n",
      "Seen so far: 23808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 372: 0.48553958535194397\n",
      "Seen so far: 23872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 373: 0.7077403664588928\n",
      "Seen so far: 23936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 374: 0.9219420552253723\n",
      "Seen so far: 24000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 375: 0.9162891507148743\n",
      "Seen so far: 24064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 376: 0.6546220779418945\n",
      "Seen so far: 24128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 377: 1.143571138381958\n",
      "Seen so far: 24192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 378: 0.5299657583236694\n",
      "Seen so far: 24256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 379: 0.8529992699623108\n",
      "Seen so far: 24320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 380: 0.8408797979354858\n",
      "Seen so far: 24384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 381: 0.6631884574890137\n",
      "Seen so far: 24448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 382: 0.7317650318145752\n",
      "Seen so far: 24512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 383: 0.917367160320282\n",
      "Seen so far: 24576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 384: 1.102239966392517\n",
      "Seen so far: 24640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 385: 0.6100648641586304\n",
      "Seen so far: 24704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 386: 1.1009886264801025\n",
      "Seen so far: 24768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 387: 0.6550451517105103\n",
      "Seen so far: 24832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 388: 1.0156041383743286\n",
      "Seen so far: 24896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 389: 0.7453564405441284\n",
      "Seen so far: 24960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 390: 0.8282129764556885\n",
      "Seen so far: 25024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 391: 0.3942558467388153\n",
      "Seen so far: 25088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 392: 0.9269575476646423\n",
      "Seen so far: 25152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 393: 1.0231404304504395\n",
      "Seen so far: 25216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 394: 0.594828188419342\n",
      "Seen so far: 25280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 395: 1.1035065650939941\n",
      "Seen so far: 25344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 396: 0.745964765548706\n",
      "Seen so far: 25408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 397: 1.0586435794830322\n",
      "Seen so far: 25472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 398: 0.6151353120803833\n",
      "Seen so far: 25536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 399: 0.755223274230957\n",
      "Seen so far: 25600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 400: 0.7238941192626953\n",
      "Seen so far: 25664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 401: 0.5626498460769653\n",
      "Seen so far: 25728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 402: 0.67642742395401\n",
      "Seen so far: 25792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 403: 0.5804437398910522\n",
      "Seen so far: 25856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 404: 0.4705689251422882\n",
      "Seen so far: 25920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 405: 0.8500992059707642\n",
      "Seen so far: 25984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 406: 0.960444450378418\n",
      "Seen so far: 26048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 407: 0.8318687677383423\n",
      "Seen so far: 26112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 408: 0.8262699842453003\n",
      "Seen so far: 26176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 409: 0.8349822759628296\n",
      "Seen so far: 26240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 410: 0.4722844362258911\n",
      "Seen so far: 26304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 411: 1.0567325353622437\n",
      "Seen so far: 26368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 412: 0.918376088142395\n",
      "Seen so far: 26432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 413: 0.767027735710144\n",
      "Seen so far: 26496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 414: 0.4685409367084503\n",
      "Seen so far: 26560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 415: 0.8344624042510986\n",
      "Seen so far: 26624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 416: 0.8603281378746033\n",
      "Seen so far: 26688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 417: 0.7492891550064087\n",
      "Seen so far: 26752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 418: 0.7497344017028809\n",
      "Seen so far: 26816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 419: 1.3314818143844604\n",
      "Seen so far: 26880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 420: 0.7275815010070801\n",
      "Seen so far: 26944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 421: 1.456287145614624\n",
      "Seen so far: 27008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 422: 0.6656476259231567\n",
      "Seen so far: 27072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 423: 0.6073130369186401\n",
      "Seen so far: 27136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 424: 0.7273585796356201\n",
      "Seen so far: 27200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 425: 0.7545653581619263\n",
      "Seen so far: 27264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 426: 0.9412575364112854\n",
      "Seen so far: 27328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 427: 0.9672222137451172\n",
      "Seen so far: 27392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 428: 0.6881283521652222\n",
      "Seen so far: 27456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 429: 0.7330848574638367\n",
      "Seen so far: 27520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 430: 0.8786510825157166\n",
      "Seen so far: 27584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 431: 0.6475744843482971\n",
      "Seen so far: 27648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 432: 0.922477662563324\n",
      "Seen so far: 27712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 433: 0.5150760412216187\n",
      "Seen so far: 27776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 434: 0.6931601166725159\n",
      "Seen so far: 27840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 435: 0.8321782350540161\n",
      "Seen so far: 27904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 436: 0.801795244216919\n",
      "Seen so far: 27968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 437: 0.8025610446929932\n",
      "Seen so far: 28032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 438: 0.8546158671379089\n",
      "Seen so far: 28096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 439: 0.6743717193603516\n",
      "Seen so far: 28160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 440: 0.8208008408546448\n",
      "Seen so far: 28224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 441: 1.0723239183425903\n",
      "Seen so far: 28288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 442: 0.8014155626296997\n",
      "Seen so far: 28352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 443: 0.5159676671028137\n",
      "Seen so far: 28416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 444: 1.0033385753631592\n",
      "Seen so far: 28480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 445: 0.9806243777275085\n",
      "Seen so far: 28544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 446: 0.7555323243141174\n",
      "Seen so far: 28608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 447: 0.652130126953125\n",
      "Seen so far: 28672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 448: 0.7537980079650879\n",
      "Seen so far: 28736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 449: 0.6982806921005249\n",
      "Seen so far: 28800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 450: 1.2389051914215088\n",
      "Seen so far: 28864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 451: 0.7704252004623413\n",
      "Seen so far: 28928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 452: 0.8998827934265137\n",
      "Seen so far: 28992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 453: 0.65654456615448\n",
      "Seen so far: 29056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 454: 0.6522599458694458\n",
      "Seen so far: 29120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 455: 0.6449227333068848\n",
      "Seen so far: 29184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 456: 0.6547390818595886\n",
      "Seen so far: 29248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 457: 0.7058756351470947\n",
      "Seen so far: 29312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 458: 1.053870677947998\n",
      "Seen so far: 29376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 459: 0.7934942841529846\n",
      "Seen so far: 29440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 460: 0.8891748189926147\n",
      "Seen so far: 29504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 461: 0.8500969409942627\n",
      "Seen so far: 29568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 462: 0.7917675971984863\n",
      "Seen so far: 29632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 463: 0.8176329731941223\n",
      "Seen so far: 29696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 464: 0.6034954786300659\n",
      "Seen so far: 29760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 465: 0.6561923623085022\n",
      "Seen so far: 29824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 466: 0.7881237268447876\n",
      "Seen so far: 29888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 467: 0.7267308235168457\n",
      "Seen so far: 29952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 468: 0.8707395792007446\n",
      "Seen so far: 30016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 469: 0.7038812637329102\n",
      "Seen so far: 30080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 470: 0.49195608496665955\n",
      "Seen so far: 30144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 471: 0.6575635075569153\n",
      "Seen so far: 30208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 472: 0.741014301776886\n",
      "Seen so far: 30272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 473: 0.7762084603309631\n",
      "Seen so far: 30336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 474: 0.5052804350852966\n",
      "Seen so far: 30400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 475: 0.7240010499954224\n",
      "Seen so far: 30464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 476: 0.786063015460968\n",
      "Seen so far: 30528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 477: 0.5718873739242554\n",
      "Seen so far: 30592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 478: 0.7650918364524841\n",
      "Seen so far: 30656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 479: 0.9273487329483032\n",
      "Seen so far: 30720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 480: 0.5717490911483765\n",
      "Seen so far: 30784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 481: 0.7822456955909729\n",
      "Seen so far: 30848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 482: 0.5070553421974182\n",
      "Seen so far: 30912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 483: 0.772175133228302\n",
      "Seen so far: 30976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 484: 0.6737625598907471\n",
      "Seen so far: 31040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 485: 0.6961503624916077\n",
      "Seen so far: 31104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 486: 1.0288665294647217\n",
      "Seen so far: 31168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 487: 0.7844480872154236\n",
      "Seen so far: 31232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 488: 0.9645196795463562\n",
      "Seen so far: 31296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 489: 1.2190731763839722\n",
      "Seen so far: 31360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 490: 0.6013354063034058\n",
      "Seen so far: 31424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 491: 0.6969729661941528\n",
      "Seen so far: 31488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 492: 0.6994650363922119\n",
      "Seen so far: 31552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 493: 0.7659224271774292\n",
      "Seen so far: 31616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 494: 0.7966670393943787\n",
      "Seen so far: 31680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 495: 0.6543881893157959\n",
      "Seen so far: 31744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 496: 0.7525407671928406\n",
      "Seen so far: 31808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 497: 0.864643931388855\n",
      "Seen so far: 31872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 498: 0.5646987557411194\n",
      "Seen so far: 31936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 499: 0.9527639746665955\n",
      "Seen so far: 32000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 500: 0.6232737898826599\n",
      "Seen so far: 32064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 501: 0.9276090860366821\n",
      "Seen so far: 32128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 502: 0.5500602722167969\n",
      "Seen so far: 32192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 503: 0.6554678678512573\n",
      "Seen so far: 32256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 504: 1.2130310535430908\n",
      "Seen so far: 32320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 505: 0.9460541009902954\n",
      "Seen so far: 32384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 506: 0.8396518230438232\n",
      "Seen so far: 32448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 507: 1.2408301830291748\n",
      "Seen so far: 32512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 508: 0.695904016494751\n",
      "Seen so far: 32576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 509: 0.5766525864601135\n",
      "Seen so far: 32640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 510: 0.8111029863357544\n",
      "Seen so far: 32704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 511: 0.9264808297157288\n",
      "Seen so far: 32768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 512: 0.8856955170631409\n",
      "Seen so far: 32832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 513: 1.1090079545974731\n",
      "Seen so far: 32896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 514: 0.6023868322372437\n",
      "Seen so far: 32960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 515: 0.6432693004608154\n",
      "Seen so far: 33024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 516: 0.5806241631507874\n",
      "Seen so far: 33088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 517: 0.8697450160980225\n",
      "Seen so far: 33152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 518: 0.6883717179298401\n",
      "Seen so far: 33216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 519: 0.9237074255943298\n",
      "Seen so far: 33280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 520: 0.7629883289337158\n",
      "Seen so far: 33344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 521: 0.5890176296234131\n",
      "Seen so far: 33408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 522: 0.6602420210838318\n",
      "Seen so far: 33472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 523: 0.9024990797042847\n",
      "Seen so far: 33536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 524: 0.6600193381309509\n",
      "Seen so far: 33600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 525: 0.6506139039993286\n",
      "Seen so far: 33664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 526: 0.6812000274658203\n",
      "Seen so far: 33728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 527: 0.8420952558517456\n",
      "Seen so far: 33792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 528: 0.7740885019302368\n",
      "Seen so far: 33856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 529: 0.5630239844322205\n",
      "Seen so far: 33920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 530: 0.8052463531494141\n",
      "Seen so far: 33984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 531: 0.39101558923721313\n",
      "Seen so far: 34048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 532: 0.9076905250549316\n",
      "Seen so far: 34112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 533: 1.0368058681488037\n",
      "Seen so far: 34176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 534: 0.6750302314758301\n",
      "Seen so far: 34240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 535: 0.8589987754821777\n",
      "Seen so far: 34304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 536: 0.5405749678611755\n",
      "Seen so far: 34368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 537: 0.6327680349349976\n",
      "Seen so far: 34432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 538: 0.664689838886261\n",
      "Seen so far: 34496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 539: 0.7008070945739746\n",
      "Seen so far: 34560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 540: 0.9275498390197754\n",
      "Seen so far: 34624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 541: 0.6651532649993896\n",
      "Seen so far: 34688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 542: 0.6139193177223206\n",
      "Seen so far: 34752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 543: 0.5913238525390625\n",
      "Seen so far: 34816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 544: 0.6276082396507263\n",
      "Seen so far: 34880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 545: 0.8907073736190796\n",
      "Seen so far: 34944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 546: 0.9559235572814941\n",
      "Seen so far: 35008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 547: 0.9271315336227417\n",
      "Seen so far: 35072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 548: 0.9213060140609741\n",
      "Seen so far: 35136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 549: 0.7782972455024719\n",
      "Seen so far: 35200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 550: 0.7843329310417175\n",
      "Seen so far: 35264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 551: 0.48025423288345337\n",
      "Seen so far: 35328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 552: 0.7600734233856201\n",
      "Seen so far: 35392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 553: 0.785982072353363\n",
      "Seen so far: 35456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 554: 0.9502333402633667\n",
      "Seen so far: 35520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 555: 0.8808379769325256\n",
      "Seen so far: 35584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 556: 0.5994994640350342\n",
      "Seen so far: 35648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 557: 0.9826808571815491\n",
      "Seen so far: 35712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 558: 0.5233526229858398\n",
      "Seen so far: 35776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 559: 0.7109861373901367\n",
      "Seen so far: 35840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 560: 0.7347370386123657\n",
      "Seen so far: 35904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 561: 0.8146535754203796\n",
      "Seen so far: 35968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 562: 0.9054094552993774\n",
      "Seen so far: 36032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 563: 0.7525407075881958\n",
      "Seen so far: 36096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 564: 0.5585383772850037\n",
      "Seen so far: 36160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 565: 0.5951723456382751\n",
      "Seen so far: 36224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 566: 0.5689737796783447\n",
      "Seen so far: 36288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 567: 0.797827959060669\n",
      "Seen so far: 36352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 568: 0.5579603314399719\n",
      "Seen so far: 36416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 569: 0.5076530575752258\n",
      "Seen so far: 36480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 570: 0.9223517775535583\n",
      "Seen so far: 36544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 571: 0.9410161375999451\n",
      "Seen so far: 36608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 572: 0.7627279162406921\n",
      "Seen so far: 36672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 573: 0.9361333847045898\n",
      "Seen so far: 36736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 574: 0.7054921388626099\n",
      "Seen so far: 36800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 575: 0.888931393623352\n",
      "Seen so far: 36864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 576: 0.5532370209693909\n",
      "Seen so far: 36928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 577: 0.9946498870849609\n",
      "Seen so far: 36992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 578: 0.4701696038246155\n",
      "Seen so far: 37056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 579: 0.8487578630447388\n",
      "Seen so far: 37120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 580: 0.5593338012695312\n",
      "Seen so far: 37184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 581: 0.664783239364624\n",
      "Seen so far: 37248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 582: 1.2434813976287842\n",
      "Seen so far: 37312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 583: 0.6200661659240723\n",
      "Seen so far: 37376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 584: 1.0287975072860718\n",
      "Seen so far: 37440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 585: 0.6174073219299316\n",
      "Seen so far: 37504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 586: 0.7779461145401001\n",
      "Seen so far: 37568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 587: 0.5544536113739014\n",
      "Seen so far: 37632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 588: 0.7263175249099731\n",
      "Seen so far: 37696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 589: 0.7320822477340698\n",
      "Seen so far: 37760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 590: 0.44146284461021423\n",
      "Seen so far: 37824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 591: 0.5033769607543945\n",
      "Seen so far: 37888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 592: 0.9899877309799194\n",
      "Seen so far: 37952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 593: 0.9169003963470459\n",
      "Seen so far: 38016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 594: 0.6088967323303223\n",
      "Seen so far: 38080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 595: 0.6943651437759399\n",
      "Seen so far: 38144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 596: 0.5252048373222351\n",
      "Seen so far: 38208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 597: 0.43092644214630127\n",
      "Seen so far: 38272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 598: 0.7571045756340027\n",
      "Seen so far: 38336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 599: 0.48050355911254883\n",
      "Seen so far: 38400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 600: 0.5672869682312012\n",
      "Seen so far: 38464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 601: 0.4048842787742615\n",
      "Seen so far: 38528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 602: 0.8995020389556885\n",
      "Seen so far: 38592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 603: 1.4045498371124268\n",
      "Seen so far: 38656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 604: 0.9216713905334473\n",
      "Seen so far: 38720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 605: 0.6202431321144104\n",
      "Seen so far: 38784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 606: 1.2750658988952637\n",
      "Seen so far: 38848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 607: 0.763034462928772\n",
      "Seen so far: 38912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 608: 0.7976081371307373\n",
      "Seen so far: 38976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 609: 0.6327778100967407\n",
      "Seen so far: 39040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 610: 0.4134412407875061\n",
      "Seen so far: 39104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 611: 0.7765673995018005\n",
      "Seen so far: 39168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 612: 0.7500697374343872\n",
      "Seen so far: 39232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 613: 0.7023643255233765\n",
      "Seen so far: 39296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 614: 0.8462713956832886\n",
      "Seen so far: 39360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 615: 0.8001288175582886\n",
      "Seen so far: 39424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 616: 0.5685816407203674\n",
      "Seen so far: 39488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 617: 0.9161351919174194\n",
      "Seen so far: 39552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 618: 1.0805323123931885\n",
      "Seen so far: 39616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 619: 0.8213475346565247\n",
      "Seen so far: 39680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 620: 1.0456643104553223\n",
      "Seen so far: 39744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 621: 0.7835384607315063\n",
      "Seen so far: 39808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 622: 0.7636461853981018\n",
      "Seen so far: 39872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 623: 0.797661304473877\n",
      "Seen so far: 39936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 624: 0.7318874001502991\n",
      "Seen so far: 40000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 625: 0.5995584726333618\n",
      "Seen so far: 40064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 626: 0.6860016584396362\n",
      "Seen so far: 40128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 627: 0.4818198084831238\n",
      "Seen so far: 40192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 628: 0.7768685817718506\n",
      "Seen so far: 40256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 629: 0.754126250743866\n",
      "Seen so far: 40320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 630: 0.6934801340103149\n",
      "Seen so far: 40384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 631: 0.7172110080718994\n",
      "Seen so far: 40448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 632: 0.7291972637176514\n",
      "Seen so far: 40512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 633: 0.8685684204101562\n",
      "Seen so far: 40576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 634: 0.5299476981163025\n",
      "Seen so far: 40640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 635: 0.47427159547805786\n",
      "Seen so far: 40704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 636: 0.9924823641777039\n",
      "Seen so far: 40768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 637: 0.37790602445602417\n",
      "Seen so far: 40832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 638: 0.6644660234451294\n",
      "Seen so far: 40896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 639: 0.6791958808898926\n",
      "Seen so far: 40960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 640: 0.7340529561042786\n",
      "Seen so far: 41024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 641: 0.2986442446708679\n",
      "Seen so far: 41088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 642: 0.8273302316665649\n",
      "Seen so far: 41152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 643: 0.53630530834198\n",
      "Seen so far: 41216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 644: 0.8225069046020508\n",
      "Seen so far: 41280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 645: 0.9653638005256653\n",
      "Seen so far: 41344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 646: 0.5613070726394653\n",
      "Seen so far: 41408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 647: 0.7351562976837158\n",
      "Seen so far: 41472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 648: 0.7569957971572876\n",
      "Seen so far: 41536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 649: 1.2247490882873535\n",
      "Seen so far: 41600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 650: 1.3800349235534668\n",
      "Seen so far: 41664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 651: 0.7129930257797241\n",
      "Seen so far: 41728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 652: 0.6434638500213623\n",
      "Seen so far: 41792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 653: 0.5361915826797485\n",
      "Seen so far: 41856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 654: 0.8435682058334351\n",
      "Seen so far: 41920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 655: 0.5077494978904724\n",
      "Seen so far: 41984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 656: 0.9122343063354492\n",
      "Seen so far: 42048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 657: 1.2879087924957275\n",
      "Seen so far: 42112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 658: 0.7106434106826782\n",
      "Seen so far: 42176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 659: 0.659386396408081\n",
      "Seen so far: 42240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 660: 0.8433675765991211\n",
      "Seen so far: 42304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 661: 0.663663387298584\n",
      "Seen so far: 42368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 662: 0.820868968963623\n",
      "Seen so far: 42432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 663: 0.6869903206825256\n",
      "Seen so far: 42496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 664: 0.8125265836715698\n",
      "Seen so far: 42560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 665: 0.9291490316390991\n",
      "Seen so far: 42624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 666: 0.783132016658783\n",
      "Seen so far: 42688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 667: 0.5449455976486206\n",
      "Seen so far: 42752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 668: 0.5128850936889648\n",
      "Seen so far: 42816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 669: 0.85141921043396\n",
      "Seen so far: 42880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 670: 0.8060239553451538\n",
      "Seen so far: 42944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 671: 1.2953306436538696\n",
      "Seen so far: 43008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 672: 0.6511799097061157\n",
      "Seen so far: 43072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 673: 0.9316830635070801\n",
      "Seen so far: 43136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 674: 0.5849103927612305\n",
      "Seen so far: 43200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 675: 0.9674626588821411\n",
      "Seen so far: 43264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 676: 0.9117542505264282\n",
      "Seen so far: 43328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 677: 0.8024204969406128\n",
      "Seen so far: 43392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 678: 0.5732625722885132\n",
      "Seen so far: 43456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 679: 0.9479464292526245\n",
      "Seen so far: 43520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 680: 0.7063720226287842\n",
      "Seen so far: 43584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 681: 1.288561463356018\n",
      "Seen so far: 43648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 682: 0.9526630640029907\n",
      "Seen so far: 43712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 683: 0.4975713789463043\n",
      "Seen so far: 43776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 684: 0.7642860412597656\n",
      "Seen so far: 43840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 685: 0.45560067892074585\n",
      "Seen so far: 43904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 686: 1.1076228618621826\n",
      "Seen so far: 43968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 687: 0.9435794353485107\n",
      "Seen so far: 44032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 688: 0.4868810176849365\n",
      "Seen so far: 44096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 689: 0.5820753574371338\n",
      "Seen so far: 44160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 690: 0.8310873508453369\n",
      "Seen so far: 44224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 691: 0.896745502948761\n",
      "Seen so far: 44288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 692: 1.1430656909942627\n",
      "Seen so far: 44352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 693: 0.9142411351203918\n",
      "Seen so far: 44416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 694: 0.7149584889411926\n",
      "Seen so far: 44480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 695: 0.4878683388233185\n",
      "Seen so far: 44544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 696: 0.8900656700134277\n",
      "Seen so far: 44608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 697: 0.7326866984367371\n",
      "Seen so far: 44672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 698: 0.7593899965286255\n",
      "Seen so far: 44736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 699: 0.7061846852302551\n",
      "Seen so far: 44800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 700: 0.9186339378356934\n",
      "Seen so far: 44864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 701: 0.6212022304534912\n",
      "Seen so far: 44928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 702: 0.48195984959602356\n",
      "Seen so far: 44992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 703: 0.5860846042633057\n",
      "Seen so far: 45056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 704: 0.6051356792449951\n",
      "Seen so far: 45120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 705: 0.6104438900947571\n",
      "Seen so far: 45184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 706: 0.7906114459037781\n",
      "Seen so far: 45248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 707: 0.4359215497970581\n",
      "Seen so far: 45312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 708: 0.682746171951294\n",
      "Seen so far: 45376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 709: 1.178773045539856\n",
      "Seen so far: 45440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 710: 0.7516576051712036\n",
      "Seen so far: 45504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 711: 0.5638758540153503\n",
      "Seen so far: 45568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 712: 0.7975893020629883\n",
      "Seen so far: 45632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 713: 0.7679916620254517\n",
      "Seen so far: 45696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 714: 0.8459874391555786\n",
      "Seen so far: 45760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 715: 0.9711705446243286\n",
      "Seen so far: 45824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 716: 0.37550610303878784\n",
      "Seen so far: 45888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 717: 1.1407976150512695\n",
      "Seen so far: 45952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 718: 1.2018929719924927\n",
      "Seen so far: 46016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 719: 0.9327296018600464\n",
      "Seen so far: 46080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 720: 0.7419799566268921\n",
      "Seen so far: 46144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 721: 0.9928445816040039\n",
      "Seen so far: 46208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 722: 0.4406856894493103\n",
      "Seen so far: 46272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 723: 0.6647472381591797\n",
      "Seen so far: 46336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 724: 0.6829598546028137\n",
      "Seen so far: 46400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 725: 1.060275912284851\n",
      "Seen so far: 46464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 726: 0.5821439027786255\n",
      "Seen so far: 46528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 727: 0.7681592106819153\n",
      "Seen so far: 46592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 728: 0.8824378848075867\n",
      "Seen so far: 46656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 729: 0.6709415912628174\n",
      "Seen so far: 46720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 730: 0.7313052415847778\n",
      "Seen so far: 46784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 731: 0.8696701526641846\n",
      "Seen so far: 46848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 732: 1.6012446880340576\n",
      "Seen so far: 46912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 733: 1.0278451442718506\n",
      "Seen so far: 46976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 734: 0.7032021284103394\n",
      "Seen so far: 47040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 735: 0.6916402578353882\n",
      "Seen so far: 47104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 736: 0.5938999056816101\n",
      "Seen so far: 47168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 737: 0.5011947154998779\n",
      "Seen so far: 47232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 738: 0.571911096572876\n",
      "Seen so far: 47296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 739: 0.8349357843399048\n",
      "Seen so far: 47360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 740: 0.5450994968414307\n",
      "Seen so far: 47424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 741: 0.690353512763977\n",
      "Seen so far: 47488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 742: 0.5052590370178223\n",
      "Seen so far: 47552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 743: 1.1909706592559814\n",
      "Seen so far: 47616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 744: 0.6154611110687256\n",
      "Seen so far: 47680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 745: 0.8257632255554199\n",
      "Seen so far: 47744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 746: 0.9734254479408264\n",
      "Seen so far: 47808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 747: 0.8291854858398438\n",
      "Seen so far: 47872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 748: 0.48889395594596863\n",
      "Seen so far: 47936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 749: 1.1540299654006958\n",
      "Seen so far: 48000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 750: 0.6574305891990662\n",
      "Seen so far: 48064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 751: 0.6520827412605286\n",
      "Seen so far: 48128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 752: 0.9347941875457764\n",
      "Seen so far: 48192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 753: 1.1430315971374512\n",
      "Seen so far: 48256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 754: 1.0971264839172363\n",
      "Seen so far: 48320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 755: 0.48550790548324585\n",
      "Seen so far: 48384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 756: 1.1334987878799438\n",
      "Seen so far: 48448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 757: 0.9610342979431152\n",
      "Seen so far: 48512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 758: 0.5097396969795227\n",
      "Seen so far: 48576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 759: 0.6157121658325195\n",
      "Seen so far: 48640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 760: 0.9863356351852417\n",
      "Seen so far: 48704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 761: 1.0065971612930298\n",
      "Seen so far: 48768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 762: 0.6541196703910828\n",
      "Seen so far: 48832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 763: 0.9164233207702637\n",
      "Seen so far: 48896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 764: 0.8511397838592529\n",
      "Seen so far: 48960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 765: 0.6201236248016357\n",
      "Seen so far: 49024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 766: 0.8602845072746277\n",
      "Seen so far: 49088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 767: 0.6160035133361816\n",
      "Seen so far: 49152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 768: 0.5029409527778625\n",
      "Seen so far: 49216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 769: 0.5398721694946289\n",
      "Seen so far: 49280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 770: 0.7310935258865356\n",
      "Seen so far: 49344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 771: 0.7419700622558594\n",
      "Seen so far: 49408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 772: 1.09638512134552\n",
      "Seen so far: 49472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 773: 0.8013681173324585\n",
      "Seen so far: 49536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 774: 0.6015860438346863\n",
      "Seen so far: 49600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 775: 0.7731102705001831\n",
      "Seen so far: 49664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 776: 0.570354700088501\n",
      "Seen so far: 49728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 777: 0.9329991936683655\n",
      "Seen so far: 49792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 778: 0.7578822374343872\n",
      "Seen so far: 49856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 779: 0.4450727105140686\n",
      "Seen so far: 49920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 780: 1.2622644901275635\n",
      "Seen so far: 49984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 781: 0.9648157954216003\n",
      "Seen so far: 50048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 782: 0.7370489835739136\n",
      "Seen so far: 50112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 783: 0.7162567377090454\n",
      "Seen so far: 50176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 784: 0.957609236240387\n",
      "Seen so far: 50240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 785: 0.612271249294281\n",
      "Seen so far: 50304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 786: 0.9900355339050293\n",
      "Seen so far: 50368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 787: 0.8403294086456299\n",
      "Seen so far: 50432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 788: 0.42254436016082764\n",
      "Seen so far: 50496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 789: 0.9736188054084778\n",
      "Seen so far: 50560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 790: 1.0643181800842285\n",
      "Seen so far: 50624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 791: 0.5938515067100525\n",
      "Seen so far: 50688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 792: 0.6770609021186829\n",
      "Seen so far: 50752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 793: 0.6696260571479797\n",
      "Seen so far: 50816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 794: 0.9808259010314941\n",
      "Seen so far: 50880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 795: 0.6156913042068481\n",
      "Seen so far: 50944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 796: 0.5944292545318604\n",
      "Seen so far: 51008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 797: 0.7819771766662598\n",
      "Seen so far: 51072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 798: 0.9784636497497559\n",
      "Seen so far: 51136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 799: 0.9185045957565308\n",
      "Seen so far: 51200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 800: 0.7011703252792358\n",
      "Seen so far: 51264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 801: 0.7094765901565552\n",
      "Seen so far: 51328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 802: 0.7532380819320679\n",
      "Seen so far: 51392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 803: 0.9991442561149597\n",
      "Seen so far: 51456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 804: 0.4014543294906616\n",
      "Seen so far: 51520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 805: 0.7959241271018982\n",
      "Seen so far: 51584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 806: 0.8626919984817505\n",
      "Seen so far: 51648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 807: 0.5986156463623047\n",
      "Seen so far: 51712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 808: 0.7559576034545898\n",
      "Seen so far: 51776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 809: 0.642176628112793\n",
      "Seen so far: 51840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 810: 0.7957479953765869\n",
      "Seen so far: 51904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 811: 0.7516350746154785\n",
      "Seen so far: 51968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 812: 0.9080089926719666\n",
      "Seen so far: 52032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 813: 0.7589691877365112\n",
      "Seen so far: 52096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 814: 0.5277280807495117\n",
      "Seen so far: 52160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 815: 0.8857287168502808\n",
      "Seen so far: 52224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 816: 0.8680737018585205\n",
      "Seen so far: 52288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 817: 0.4119081497192383\n",
      "Seen so far: 52352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 818: 1.2938597202301025\n",
      "Seen so far: 52416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 819: 0.2767595648765564\n",
      "Seen so far: 52480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 820: 0.8254501819610596\n",
      "Seen so far: 52544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 821: 0.6686681509017944\n",
      "Seen so far: 52608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 822: 0.6184765100479126\n",
      "Seen so far: 52672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 823: 0.9928333759307861\n",
      "Seen so far: 52736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 824: 0.8702199459075928\n",
      "Seen so far: 52800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 825: 0.8038434982299805\n",
      "Seen so far: 52864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 826: 0.7645103931427002\n",
      "Seen so far: 52928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 827: 1.1564359664916992\n",
      "Seen so far: 52992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 828: 0.7565853595733643\n",
      "Seen so far: 53056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 829: 0.879263162612915\n",
      "Seen so far: 53120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 830: 0.7750069499015808\n",
      "Seen so far: 53184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 831: 0.9475644826889038\n",
      "Seen so far: 53248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 832: 0.8665525913238525\n",
      "Seen so far: 53312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 833: 0.8029561042785645\n",
      "Seen so far: 53376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 834: 0.6075628995895386\n",
      "Seen so far: 53440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 835: 0.6416833400726318\n",
      "Seen so far: 53504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 836: 0.7639195322990417\n",
      "Seen so far: 53568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 837: 0.6428803205490112\n",
      "Seen so far: 53632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 838: 0.43425753712654114\n",
      "Seen so far: 53696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 839: 0.5933068990707397\n",
      "Seen so far: 53760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 840: 0.6057032346725464\n",
      "Seen so far: 53824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 841: 1.0105401277542114\n",
      "Seen so far: 53888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 842: 0.5966494083404541\n",
      "Seen so far: 53952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 843: 0.7227043509483337\n",
      "Seen so far: 54016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 844: 0.896170973777771\n",
      "Seen so far: 54080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 845: 0.8349429368972778\n",
      "Seen so far: 54144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 846: 0.545139491558075\n",
      "Seen so far: 54208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 847: 0.7476662397384644\n",
      "Seen so far: 54272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 848: 0.6938591003417969\n",
      "Seen so far: 54336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 849: 0.5244100093841553\n",
      "Seen so far: 54400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 850: 0.4491989016532898\n",
      "Seen so far: 54464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 851: 0.35887575149536133\n",
      "Seen so far: 54528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 852: 0.4112500846385956\n",
      "Seen so far: 54592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 853: 0.5508726835250854\n",
      "Seen so far: 54656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 854: 0.5222289562225342\n",
      "Seen so far: 54720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 855: 0.6117038130760193\n",
      "Seen so far: 54784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 856: 0.5999712944030762\n",
      "Seen so far: 54848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 857: 0.4694303274154663\n",
      "Seen so far: 54912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 858: 0.8048877716064453\n",
      "Seen so far: 54976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 859: 0.9161595106124878\n",
      "Seen so far: 55040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 860: 0.5679675340652466\n",
      "Seen so far: 55104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 861: 0.570541262626648\n",
      "Seen so far: 55168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 862: 0.6222769618034363\n",
      "Seen so far: 55232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 863: 0.8297839164733887\n",
      "Seen so far: 55296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 864: 0.9953402280807495\n",
      "Seen so far: 55360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 865: 0.533287763595581\n",
      "Seen so far: 55424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 866: 0.5292586088180542\n",
      "Seen so far: 55488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 867: 0.7453538179397583\n",
      "Seen so far: 55552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 868: 0.8048694133758545\n",
      "Seen so far: 55616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 869: 0.7534667253494263\n",
      "Seen so far: 55680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 870: 1.0163410902023315\n",
      "Seen so far: 55744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 871: 0.8687669634819031\n",
      "Seen so far: 55808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 872: 0.6338671445846558\n",
      "Seen so far: 55872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 873: 0.8032923936843872\n",
      "Seen so far: 55936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 874: 0.8755578994750977\n",
      "Seen so far: 56000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 875: 0.8396024107933044\n",
      "Seen so far: 56064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 876: 0.7534138560295105\n",
      "Seen so far: 56128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 877: 0.8210095763206482\n",
      "Seen so far: 56192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 878: 0.8383614420890808\n",
      "Seen so far: 56256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 879: 0.26944488286972046\n",
      "Seen so far: 56320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 880: 0.7098709344863892\n",
      "Seen so far: 56384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 881: 1.218207597732544\n",
      "Seen so far: 56448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 882: 0.6722768545150757\n",
      "Seen so far: 56512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 883: 0.7979479432106018\n",
      "Seen so far: 56576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 884: 0.3119558095932007\n",
      "Seen so far: 56640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 885: 0.7381870150566101\n",
      "Seen so far: 56704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 886: 0.9189429879188538\n",
      "Seen so far: 56768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 887: 0.804022490978241\n",
      "Seen so far: 56832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 888: 0.6229808330535889\n",
      "Seen so far: 56896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 889: 1.1222736835479736\n",
      "Seen so far: 56960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 890: 0.6953692436218262\n",
      "Seen so far: 57024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 891: 1.1383930444717407\n",
      "Seen so far: 57088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 892: 0.4726438522338867\n",
      "Seen so far: 57152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 893: 1.274035930633545\n",
      "Seen so far: 57216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 894: 0.654567539691925\n",
      "Seen so far: 57280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 895: 0.7799049615859985\n",
      "Seen so far: 57344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 896: 1.1597270965576172\n",
      "Seen so far: 57408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 897: 0.7799948453903198\n",
      "Seen so far: 57472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 898: 0.5260798931121826\n",
      "Seen so far: 57536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 899: 0.5194951891899109\n",
      "Seen so far: 57600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 900: 0.6227071285247803\n",
      "Seen so far: 57664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 901: 1.1142627000808716\n",
      "Seen so far: 57728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 902: 0.9325782060623169\n",
      "Seen so far: 57792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 903: 0.8136751651763916\n",
      "Seen so far: 57856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 904: 1.0075042247772217\n",
      "Seen so far: 57920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 905: 0.8674587607383728\n",
      "Seen so far: 57984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 906: 1.00859534740448\n",
      "Seen so far: 58048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 907: 0.6548782587051392\n",
      "Seen so far: 58112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 908: 0.5351532697677612\n",
      "Seen so far: 58176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 909: 0.8959451913833618\n",
      "Seen so far: 58240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 910: 0.5987467765808105\n",
      "Seen so far: 58304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 911: 0.5479463338851929\n",
      "Seen so far: 58368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 912: 0.7713209986686707\n",
      "Seen so far: 58432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 913: 1.430711030960083\n",
      "Seen so far: 58496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 914: 0.5759198069572449\n",
      "Seen so far: 58560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 915: 0.6491369009017944\n",
      "Seen so far: 58624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 916: 0.959659218788147\n",
      "Seen so far: 58688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 917: 0.6499620676040649\n",
      "Seen so far: 58752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 918: 0.7755810618400574\n",
      "Seen so far: 58816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 919: 0.5970511436462402\n",
      "Seen so far: 58880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 920: 0.8632065057754517\n",
      "Seen so far: 58944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 921: 0.474717915058136\n",
      "Seen so far: 59008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 922: 1.1796224117279053\n",
      "Seen so far: 59072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 923: 0.9488186836242676\n",
      "Seen so far: 59136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 924: 0.8529821634292603\n",
      "Seen so far: 59200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 925: 0.7922101020812988\n",
      "Seen so far: 59264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 926: 0.9982528686523438\n",
      "Seen so far: 59328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 927: 0.5521283149719238\n",
      "Seen so far: 59392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 928: 0.5883874893188477\n",
      "Seen so far: 59456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 929: 0.6236196160316467\n",
      "Seen so far: 59520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 930: 0.7865006923675537\n",
      "Seen so far: 59584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 931: 0.8956253528594971\n",
      "Seen so far: 59648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 932: 1.197791576385498\n",
      "Seen so far: 59712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 933: 0.7982661724090576\n",
      "Seen so far: 59776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 934: 1.0999162197113037\n",
      "Seen so far: 59840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 935: 0.5847187042236328\n",
      "Seen so far: 59904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 936: 0.8573660254478455\n",
      "Seen so far: 59968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 937: 0.9097856283187866\n",
      "Seen so far: 60032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 938: 0.9264302849769592\n",
      "Seen so far: 60096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 939: 0.6533961296081543\n",
      "Seen so far: 60160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 940: 0.577955961227417\n",
      "Seen so far: 60224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 941: 0.6058290004730225\n",
      "Seen so far: 60288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 942: 0.791865348815918\n",
      "Seen so far: 60352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 943: 0.830963134765625\n",
      "Seen so far: 60416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 944: 0.7592938542366028\n",
      "Seen so far: 60480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 945: 0.985835075378418\n",
      "Seen so far: 60544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 946: 0.8013482689857483\n",
      "Seen so far: 60608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 947: 0.8967040777206421\n",
      "Seen so far: 60672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 948: 0.3724535405635834\n",
      "Seen so far: 60736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 949: 0.5940334796905518\n",
      "Seen so far: 60800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 950: 0.9272110462188721\n",
      "Seen so far: 60864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 951: 0.7770950794219971\n",
      "Seen so far: 60928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 952: 0.9147820472717285\n",
      "Seen so far: 60992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 953: 1.0435104370117188\n",
      "Seen so far: 61056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 954: 0.972267746925354\n",
      "Seen so far: 61120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 955: 0.7760388851165771\n",
      "Seen so far: 61184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 956: 1.2519135475158691\n",
      "Seen so far: 61248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 957: 0.7632354497909546\n",
      "Seen so far: 61312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 958: 0.9110561013221741\n",
      "Seen so far: 61376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 959: 0.7122982144355774\n",
      "Seen so far: 61440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 960: 0.6293876767158508\n",
      "Seen so far: 61504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 961: 0.7368413805961609\n",
      "Seen so far: 61568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 962: 0.655219316482544\n",
      "Seen so far: 61632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 963: 0.6673173308372498\n",
      "Seen so far: 61696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 964: 0.7440488338470459\n",
      "Seen so far: 61760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 965: 0.8981338739395142\n",
      "Seen so far: 61824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 966: 0.4161888360977173\n",
      "Seen so far: 61888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 967: 0.6086202263832092\n",
      "Seen so far: 61952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 968: 0.8167142868041992\n",
      "Seen so far: 62016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 969: 0.9949066042900085\n",
      "Seen so far: 62080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 970: 1.1493184566497803\n",
      "Seen so far: 62144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 971: 0.6343468427658081\n",
      "Seen so far: 62208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 972: 1.143939733505249\n",
      "Seen so far: 62272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 973: 0.7560561895370483\n",
      "Seen so far: 62336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 974: 0.6577276587486267\n",
      "Seen so far: 62400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 975: 0.8483750224113464\n",
      "Seen so far: 62464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 976: 0.9206656217575073\n",
      "Seen so far: 62528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 977: 0.8666846752166748\n",
      "Seen so far: 62592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 978: 1.188754677772522\n",
      "Seen so far: 62656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 979: 0.9421442747116089\n",
      "Seen so far: 62720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 980: 0.9192445278167725\n",
      "Seen so far: 62784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 981: 0.8221467137336731\n",
      "Seen so far: 62848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 982: 0.6703208088874817\n",
      "Seen so far: 62912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 983: 0.5862053632736206\n",
      "Seen so far: 62976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 984: 0.7678225636482239\n",
      "Seen so far: 63040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 985: 0.9895305633544922\n",
      "Seen so far: 63104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 986: 0.8284575939178467\n",
      "Seen so far: 63168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 987: 0.9376741647720337\n",
      "Seen so far: 63232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 988: 0.6462123394012451\n",
      "Seen so far: 63296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 989: 0.7852550745010376\n",
      "Seen so far: 63360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 990: 0.7020813226699829\n",
      "Seen so far: 63424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 991: 0.6981225609779358\n",
      "Seen so far: 63488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 992: 0.36400744318962097\n",
      "Seen so far: 63552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 993: 0.6219818592071533\n",
      "Seen so far: 63616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 994: 1.0658836364746094\n",
      "Seen so far: 63680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 995: 0.808646559715271\n",
      "Seen so far: 63744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 996: 0.7982973456382751\n",
      "Seen so far: 63808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 997: 0.40340378880500793\n",
      "Seen so far: 63872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 998: 0.7368148565292358\n",
      "Seen so far: 63936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 999: 0.5667262673377991\n",
      "Seen so far: 64000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1000: 0.6333963871002197\n",
      "Seen so far: 64064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1001: 0.7169070839881897\n",
      "Seen so far: 64128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1002: 0.6414330005645752\n",
      "Seen so far: 64192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1003: 0.5737932920455933\n",
      "Seen so far: 64256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1004: 0.6480374336242676\n",
      "Seen so far: 64320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1005: 0.6403911113739014\n",
      "Seen so far: 64384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1006: 0.795608639717102\n",
      "Seen so far: 64448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1007: 0.8831003904342651\n",
      "Seen so far: 64512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1008: 1.0656836032867432\n",
      "Seen so far: 64576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1009: 0.86652010679245\n",
      "Seen so far: 64640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1010: 0.4327815771102905\n",
      "Seen so far: 64704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1011: 0.7066840529441833\n",
      "Seen so far: 64768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1012: 0.6907577514648438\n",
      "Seen so far: 64832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1013: 0.9103244543075562\n",
      "Seen so far: 64896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1014: 0.8083101511001587\n",
      "Seen so far: 64960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1015: 0.3593215346336365\n",
      "Seen so far: 65024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1016: 0.914658784866333\n",
      "Seen so far: 65088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1017: 0.9198467135429382\n",
      "Seen so far: 65152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1018: 0.7231734991073608\n",
      "Seen so far: 65216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1019: 1.010927677154541\n",
      "Seen so far: 65280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1020: 0.3634888529777527\n",
      "Seen so far: 65344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1021: 0.4736287295818329\n",
      "Seen so far: 65408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1022: 0.46801692247390747\n",
      "Seen so far: 65472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1023: 1.1108322143554688\n",
      "Seen so far: 65536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1024: 0.545691728591919\n",
      "Seen so far: 65600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1025: 0.6769704818725586\n",
      "Seen so far: 65664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1026: 0.7497388124465942\n",
      "Seen so far: 65728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1027: 1.0472493171691895\n",
      "Seen so far: 65792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1028: 0.5390141010284424\n",
      "Seen so far: 65856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1029: 0.8295074701309204\n",
      "Seen so far: 65920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1030: 0.8775874376296997\n",
      "Seen so far: 65984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1031: 0.6182210445404053\n",
      "Seen so far: 66048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1032: 0.7588695287704468\n",
      "Seen so far: 66112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1033: 0.959793210029602\n",
      "Seen so far: 66176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1034: 1.1415084600448608\n",
      "Seen so far: 66240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1035: 1.007673978805542\n",
      "Seen so far: 66304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1036: 0.47041645646095276\n",
      "Seen so far: 66368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1037: 0.7997303009033203\n",
      "Seen so far: 66432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1038: 0.8691600561141968\n",
      "Seen so far: 66496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1039: 0.6384838819503784\n",
      "Seen so far: 66560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1040: 0.9373627305030823\n",
      "Seen so far: 66624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1041: 0.8983807563781738\n",
      "Seen so far: 66688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1042: 0.559027910232544\n",
      "Seen so far: 66752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1043: 0.772064208984375\n",
      "Seen so far: 66816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1044: 0.407397985458374\n",
      "Seen so far: 66880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1045: 0.7627766728401184\n",
      "Seen so far: 66944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1046: 0.6227871179580688\n",
      "Seen so far: 67008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1047: 0.6131673455238342\n",
      "Seen so far: 67072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1048: 0.6818575263023376\n",
      "Seen so far: 67136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1049: 0.4668109714984894\n",
      "Seen so far: 67200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1050: 1.050581932067871\n",
      "Seen so far: 67264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1051: 0.9655290246009827\n",
      "Seen so far: 67328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1052: 0.6064134836196899\n",
      "Seen so far: 67392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1053: 0.8901462554931641\n",
      "Seen so far: 67456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1054: 0.9280761480331421\n",
      "Seen so far: 67520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1055: 0.8172006011009216\n",
      "Seen so far: 67584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1056: 0.44382745027542114\n",
      "Seen so far: 67648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1057: 0.5399417281150818\n",
      "Seen so far: 67712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1058: 0.459407776594162\n",
      "Seen so far: 67776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1059: 0.6260455250740051\n",
      "Seen so far: 67840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1060: 0.5999720692634583\n",
      "Seen so far: 67904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1061: 0.6935572028160095\n",
      "Seen so far: 67968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1062: 1.0691547393798828\n",
      "Seen so far: 68032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1063: 0.4093566834926605\n",
      "Seen so far: 68096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1064: 0.806358814239502\n",
      "Seen so far: 68160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1065: 0.6581324338912964\n",
      "Seen so far: 68224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1066: 0.6873881816864014\n",
      "Seen so far: 68288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1067: 0.45887720584869385\n",
      "Seen so far: 68352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1068: 0.75152987241745\n",
      "Seen so far: 68416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1069: 0.6794302463531494\n",
      "Seen so far: 68480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1070: 0.649048924446106\n",
      "Seen so far: 68544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1071: 0.7129862308502197\n",
      "Seen so far: 68608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1072: 0.6105790138244629\n",
      "Seen so far: 68672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1073: 1.3049108982086182\n",
      "Seen so far: 68736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1074: 0.6604491472244263\n",
      "Seen so far: 68800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1075: 0.5972881317138672\n",
      "Seen so far: 68864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1076: 0.5210607051849365\n",
      "Seen so far: 68928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1077: 0.774657666683197\n",
      "Seen so far: 68992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1078: 0.8158601522445679\n",
      "Seen so far: 69056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1079: 0.8227897882461548\n",
      "Seen so far: 69120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1080: 0.5636575222015381\n",
      "Seen so far: 69184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1081: 0.6913951635360718\n",
      "Seen so far: 69248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1082: 0.7828524112701416\n",
      "Seen so far: 69312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1083: 0.7575737237930298\n",
      "Seen so far: 69376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1084: 0.8161725997924805\n",
      "Seen so far: 69440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1085: 0.7836626768112183\n",
      "Seen so far: 69504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1086: 0.9404388070106506\n",
      "Seen so far: 69568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1087: 0.975985586643219\n",
      "Seen so far: 69632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1088: 0.9731379151344299\n",
      "Seen so far: 69696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1089: 0.6458737850189209\n",
      "Seen so far: 69760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1090: 0.5742039680480957\n",
      "Seen so far: 69824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1091: 0.8801017999649048\n",
      "Seen so far: 69888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1092: 0.8481872081756592\n",
      "Seen so far: 69952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1093: 0.5657073855400085\n",
      "Seen so far: 70016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1094: 0.8732408285140991\n",
      "Seen so far: 70080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1095: 0.674291729927063\n",
      "Seen so far: 70144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1096: 0.48601672053337097\n",
      "Seen so far: 70208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1097: 0.6048558354377747\n",
      "Seen so far: 70272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1098: 0.9903402328491211\n",
      "Seen so far: 70336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1099: 0.5234997272491455\n",
      "Seen so far: 70400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1100: 1.047547459602356\n",
      "Seen so far: 70464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1101: 0.9558591246604919\n",
      "Seen so far: 70528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1102: 0.6473215222358704\n",
      "Seen so far: 70592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1103: 0.8691419363021851\n",
      "Seen so far: 70656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1104: 0.61124187707901\n",
      "Seen so far: 70720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1105: 0.9349583387374878\n",
      "Seen so far: 70784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1106: 0.8443890810012817\n",
      "Seen so far: 70848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1107: 0.6738910675048828\n",
      "Seen so far: 70912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1108: 0.7367882132530212\n",
      "Seen so far: 70976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1109: 0.6276922821998596\n",
      "Seen so far: 71040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1110: 0.6126575469970703\n",
      "Seen so far: 71104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1111: 0.6835761070251465\n",
      "Seen so far: 71168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1112: 1.134200930595398\n",
      "Seen so far: 71232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1113: 1.374037504196167\n",
      "Seen so far: 71296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1114: 0.5992592573165894\n",
      "Seen so far: 71360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1115: 1.1341991424560547\n",
      "Seen so far: 71424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1116: 0.7271515130996704\n",
      "Seen so far: 71488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1117: 0.6675414443016052\n",
      "Seen so far: 71552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1118: 0.4431315064430237\n",
      "Seen so far: 71616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1119: 0.7244443893432617\n",
      "Seen so far: 71680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1120: 0.59831702709198\n",
      "Seen so far: 71744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1121: 0.8447825908660889\n",
      "Seen so far: 71808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1122: 0.2821395695209503\n",
      "Seen so far: 71872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1123: 0.6932351589202881\n",
      "Seen so far: 71936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1124: 0.8261793255805969\n",
      "Seen so far: 72000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1125: 0.9934773445129395\n",
      "Seen so far: 72064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1126: 0.5915096998214722\n",
      "Seen so far: 72128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1127: 0.7058455348014832\n",
      "Seen so far: 72192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1128: 1.3175218105316162\n",
      "Seen so far: 72256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1129: 0.641718864440918\n",
      "Seen so far: 72320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1130: 0.7058999538421631\n",
      "Seen so far: 72384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1131: 0.8873587846755981\n",
      "Seen so far: 72448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1132: 0.734544575214386\n",
      "Seen so far: 72512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1133: 0.6774234175682068\n",
      "Seen so far: 72576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1134: 0.7577113509178162\n",
      "Seen so far: 72640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1135: 1.004375696182251\n",
      "Seen so far: 72704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1136: 0.8014054298400879\n",
      "Seen so far: 72768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1137: 0.9492830038070679\n",
      "Seen so far: 72832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1138: 0.7012226581573486\n",
      "Seen so far: 72896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1139: 0.5056660175323486\n",
      "Seen so far: 72960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1140: 1.0248141288757324\n",
      "Seen so far: 73024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1141: 0.5714161396026611\n",
      "Seen so far: 73088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1142: 0.7239012718200684\n",
      "Seen so far: 73152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1143: 0.5983802080154419\n",
      "Seen so far: 73216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1144: 0.9355189204216003\n",
      "Seen so far: 73280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1145: 0.7413768172264099\n",
      "Seen so far: 73344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1146: 0.740986704826355\n",
      "Seen so far: 73408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1147: 0.7867082357406616\n",
      "Seen so far: 73472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1148: 1.2789056301116943\n",
      "Seen so far: 73536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1149: 0.7365630865097046\n",
      "Seen so far: 73600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1150: 0.7505950331687927\n",
      "Seen so far: 73664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1151: 0.6352099776268005\n",
      "Seen so far: 73728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1152: 0.6788426637649536\n",
      "Seen so far: 73792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1153: 0.7911254167556763\n",
      "Seen so far: 73856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1154: 0.6203933358192444\n",
      "Seen so far: 73920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1155: 1.1176869869232178\n",
      "Seen so far: 73984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1156: 0.6616010069847107\n",
      "Seen so far: 74048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1157: 0.8539883494377136\n",
      "Seen so far: 74112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1158: 0.8891088962554932\n",
      "Seen so far: 74176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1159: 0.8007530570030212\n",
      "Seen so far: 74240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1160: 0.8232365846633911\n",
      "Seen so far: 74304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1161: 0.5723047256469727\n",
      "Seen so far: 74368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1162: 0.4728212058544159\n",
      "Seen so far: 74432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1163: 0.5635737776756287\n",
      "Seen so far: 74496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1164: 0.6575021743774414\n",
      "Seen so far: 74560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1165: 0.7891513109207153\n",
      "Seen so far: 74624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1166: 0.8902815580368042\n",
      "Seen so far: 74688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1167: 0.6701724529266357\n",
      "Seen so far: 74752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1168: 0.4920662045478821\n",
      "Seen so far: 74816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1169: 0.6289211511611938\n",
      "Seen so far: 74880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1170: 0.756470799446106\n",
      "Seen so far: 74944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1171: 0.6574889421463013\n",
      "Seen so far: 75008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1172: 1.0204662084579468\n",
      "Seen so far: 75072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1173: 0.6383121013641357\n",
      "Seen so far: 75136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1174: 0.8788043856620789\n",
      "Seen so far: 75200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1175: 1.2374181747436523\n",
      "Seen so far: 75264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1176: 0.9781503677368164\n",
      "Seen so far: 75328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1177: 0.920832097530365\n",
      "Seen so far: 75392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1178: 1.1958060264587402\n",
      "Seen so far: 75456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1179: 0.3888400197029114\n",
      "Seen so far: 75520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1180: 0.7496772408485413\n",
      "Seen so far: 75584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1181: 0.9725395441055298\n",
      "Seen so far: 75648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1182: 1.0330997705459595\n",
      "Seen so far: 75712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1183: 0.9832373857498169\n",
      "Seen so far: 75776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1184: 0.7891366481781006\n",
      "Seen so far: 75840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1185: 0.5916377305984497\n",
      "Seen so far: 75904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1186: 0.6608928442001343\n",
      "Seen so far: 75968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1187: 0.8228495121002197\n",
      "Seen so far: 76032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1188: 0.8748579621315002\n",
      "Seen so far: 76096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1189: 0.4684408903121948\n",
      "Seen so far: 76160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1190: 0.5057008266448975\n",
      "Seen so far: 76224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1191: 0.4610554873943329\n",
      "Seen so far: 76288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1192: 1.197568416595459\n",
      "Seen so far: 76352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1193: 0.6443116664886475\n",
      "Seen so far: 76416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1194: 1.1809487342834473\n",
      "Seen so far: 76480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1195: 0.5405452251434326\n",
      "Seen so far: 76544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1196: 0.5742150545120239\n",
      "Seen so far: 76608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1197: 0.7434462904930115\n",
      "Seen so far: 76672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1198: 0.796807587146759\n",
      "Seen so far: 76736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1199: 1.1688239574432373\n",
      "Seen so far: 76800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1200: 0.7299292087554932\n",
      "Seen so far: 76864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1201: 0.8313238620758057\n",
      "Seen so far: 76928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1202: 0.7844786643981934\n",
      "Seen so far: 76992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1203: 0.6551735401153564\n",
      "Seen so far: 77056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1204: 0.8281294107437134\n",
      "Seen so far: 77120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1205: 0.5286041498184204\n",
      "Seen so far: 77184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1206: 0.5710157155990601\n",
      "Seen so far: 77248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1207: 0.8396894931793213\n",
      "Seen so far: 77312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1208: 1.1050617694854736\n",
      "Seen so far: 77376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1209: 0.9362179040908813\n",
      "Seen so far: 77440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1210: 0.5563367605209351\n",
      "Seen so far: 77504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1211: 0.6960594654083252\n",
      "Seen so far: 77568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1212: 0.6394178867340088\n",
      "Seen so far: 77632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1213: 0.7359079122543335\n",
      "Seen so far: 77696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1214: 1.259998083114624\n",
      "Seen so far: 77760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1215: 0.43330520391464233\n",
      "Seen so far: 77824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1216: 0.6451644897460938\n",
      "Seen so far: 77888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1217: 0.6070687770843506\n",
      "Seen so far: 77952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1218: 0.9493736028671265\n",
      "Seen so far: 78016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1219: 1.165813684463501\n",
      "Seen so far: 78080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1220: 0.6763854622840881\n",
      "Seen so far: 78144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1221: 0.6839635372161865\n",
      "Seen so far: 78208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1222: 0.6880375146865845\n",
      "Seen so far: 78272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1223: 0.8012049198150635\n",
      "Seen so far: 78336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1224: 0.5159436464309692\n",
      "Seen so far: 78400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1225: 1.1678051948547363\n",
      "Seen so far: 78464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1226: 0.8091055154800415\n",
      "Seen so far: 78528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1227: 0.7379597425460815\n",
      "Seen so far: 78592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1228: 0.8840649724006653\n",
      "Seen so far: 78656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1229: 0.9755092263221741\n",
      "Seen so far: 78720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1230: 1.005371332168579\n",
      "Seen so far: 78784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1231: 0.8342965245246887\n",
      "Seen so far: 78848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1232: 0.909722626209259\n",
      "Seen so far: 78912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1233: 0.5889761447906494\n",
      "Seen so far: 78976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1234: 0.9537701606750488\n",
      "Seen so far: 79040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1235: 0.6104427576065063\n",
      "Seen so far: 79104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1236: 0.7817292213439941\n",
      "Seen so far: 79168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1237: 0.6877781748771667\n",
      "Seen so far: 79232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1238: 1.0967334508895874\n",
      "Seen so far: 79296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1239: 0.7654541730880737\n",
      "Seen so far: 79360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1240: 0.873645544052124\n",
      "Seen so far: 79424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1241: 0.859930157661438\n",
      "Seen so far: 79488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1242: 0.7022280693054199\n",
      "Seen so far: 79552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1243: 0.9843119382858276\n",
      "Seen so far: 79616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1244: 0.6662439703941345\n",
      "Seen so far: 79680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1245: 0.848437488079071\n",
      "Seen so far: 79744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1246: 0.6379052996635437\n",
      "Seen so far: 79808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1247: 0.510388970375061\n",
      "Seen so far: 79872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1248: 0.677578330039978\n",
      "Seen so far: 79936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1249: 1.021680474281311\n",
      "Seen so far: 80000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1250: 0.7631381750106812\n",
      "Seen so far: 80064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1251: 0.3423769176006317\n",
      "Seen so far: 80128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1252: 0.9077191948890686\n",
      "Seen so far: 80192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1253: 0.5929337739944458\n",
      "Seen so far: 80256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1254: 0.7047705054283142\n",
      "Seen so far: 80320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1255: 0.5282547473907471\n",
      "Seen so far: 80384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1256: 1.1429502964019775\n",
      "Seen so far: 80448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1257: 0.8259738087654114\n",
      "Seen so far: 80512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1258: 0.5627776980400085\n",
      "Seen so far: 80576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1259: 0.6652851104736328\n",
      "Seen so far: 80640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1260: 0.5774945020675659\n",
      "Seen so far: 80704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1261: 0.5439978837966919\n",
      "Seen so far: 80768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1262: 0.6987384557723999\n",
      "Seen so far: 80832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1263: 0.5066843032836914\n",
      "Seen so far: 80896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1264: 0.9120191335678101\n",
      "Seen so far: 80960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1265: 0.7805012464523315\n",
      "Seen so far: 81024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1266: 0.5699450969696045\n",
      "Seen so far: 81088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1267: 0.6732252240180969\n",
      "Seen so far: 81152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1268: 0.5194652080535889\n",
      "Seen so far: 81216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1269: 0.8670088052749634\n",
      "Seen so far: 81280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1270: 1.2076326608657837\n",
      "Seen so far: 81344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1271: 0.5179440975189209\n",
      "Seen so far: 81408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1272: 0.9549860954284668\n",
      "Seen so far: 81472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1273: 0.8862011432647705\n",
      "Seen so far: 81536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1274: 0.43298766016960144\n",
      "Seen so far: 81600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1275: 0.8013683557510376\n",
      "Seen so far: 81664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1276: 0.46093088388442993\n",
      "Seen so far: 81728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1277: 0.7083303332328796\n",
      "Seen so far: 81792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1278: 0.9422860145568848\n",
      "Seen so far: 81856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1279: 0.8890224695205688\n",
      "Seen so far: 81920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1280: 0.9024480581283569\n",
      "Seen so far: 81984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1281: 0.628474771976471\n",
      "Seen so far: 82048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1282: 0.7347373962402344\n",
      "Seen so far: 82112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1283: 0.6757529377937317\n",
      "Seen so far: 82176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1284: 1.1385241746902466\n",
      "Seen so far: 82240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1285: 0.9829277396202087\n",
      "Seen so far: 82304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1286: 0.6007918119430542\n",
      "Seen so far: 82368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1287: 0.7710403800010681\n",
      "Seen so far: 82432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1288: 0.5044164657592773\n",
      "Seen so far: 82496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1289: 1.106770634651184\n",
      "Seen so far: 82560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1290: 0.43806740641593933\n",
      "Seen so far: 82624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1291: 0.8003491759300232\n",
      "Seen so far: 82688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1292: 0.24884521961212158\n",
      "Seen so far: 82752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1293: 0.7762928009033203\n",
      "Seen so far: 82816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1294: 0.7598891258239746\n",
      "Seen so far: 82880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1295: 0.7451215982437134\n",
      "Seen so far: 82944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1296: 0.4435659945011139\n",
      "Seen so far: 83008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1297: 0.6854504346847534\n",
      "Seen so far: 83072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1298: 0.5773037075996399\n",
      "Seen so far: 83136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1299: 0.6108944416046143\n",
      "Seen so far: 83200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1300: 0.8516823053359985\n",
      "Seen so far: 83264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1301: 0.7357043027877808\n",
      "Seen so far: 83328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1302: 0.8963262438774109\n",
      "Seen so far: 83392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1303: 0.9324182271957397\n",
      "Seen so far: 83456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1304: 0.4382641315460205\n",
      "Seen so far: 83520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1305: 0.5535006523132324\n",
      "Seen so far: 83584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1306: 0.7732823491096497\n",
      "Seen so far: 83648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1307: 0.639352023601532\n",
      "Seen so far: 83712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1308: 0.5654552578926086\n",
      "Seen so far: 83776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1309: 0.4692765772342682\n",
      "Seen so far: 83840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1310: 0.43986499309539795\n",
      "Seen so far: 83904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1311: 0.7049234509468079\n",
      "Seen so far: 83968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1312: 0.5964639186859131\n",
      "Seen so far: 84032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1313: 0.6344542503356934\n",
      "Seen so far: 84096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1314: 0.6096794605255127\n",
      "Seen so far: 84160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1315: 0.9264769554138184\n",
      "Seen so far: 84224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1316: 0.8228498101234436\n",
      "Seen so far: 84288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1317: 1.245441198348999\n",
      "Seen so far: 84352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1318: 0.621881902217865\n",
      "Seen so far: 84416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1319: 0.789125919342041\n",
      "Seen so far: 84480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1320: 0.8414859175682068\n",
      "Seen so far: 84544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1321: 1.16339111328125\n",
      "Seen so far: 84608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1322: 0.756920337677002\n",
      "Seen so far: 84672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1323: 0.6832549571990967\n",
      "Seen so far: 84736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1324: 0.6631247997283936\n",
      "Seen so far: 84800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1325: 0.8361062407493591\n",
      "Seen so far: 84864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1326: 0.8009507656097412\n",
      "Seen so far: 84928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1327: 0.7429949641227722\n",
      "Seen so far: 84992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1328: 0.8207091093063354\n",
      "Seen so far: 85056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1329: 0.7692018747329712\n",
      "Seen so far: 85120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1330: 0.6557719707489014\n",
      "Seen so far: 85184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1331: 0.8628206849098206\n",
      "Seen so far: 85248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1332: 0.7684515714645386\n",
      "Seen so far: 85312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1333: 0.9270937442779541\n",
      "Seen so far: 85376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1334: 0.8859775066375732\n",
      "Seen so far: 85440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1335: 0.7575434446334839\n",
      "Seen so far: 85504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1336: 0.7100032567977905\n",
      "Seen so far: 85568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1337: 0.6421177983283997\n",
      "Seen so far: 85632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1338: 1.1184473037719727\n",
      "Seen so far: 85696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1339: 0.838408887386322\n",
      "Seen so far: 85760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1340: 1.402084469795227\n",
      "Seen so far: 85824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1341: 0.9258444905281067\n",
      "Seen so far: 85888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1342: 0.5338157415390015\n",
      "Seen so far: 85952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1343: 0.6414732933044434\n",
      "Seen so far: 86016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1344: 1.1745870113372803\n",
      "Seen so far: 86080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1345: 0.5320696234703064\n",
      "Seen so far: 86144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1346: 0.8251848220825195\n",
      "Seen so far: 86208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1347: 0.649935245513916\n",
      "Seen so far: 86272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1348: 0.9403594732284546\n",
      "Seen so far: 86336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1349: 1.041178822517395\n",
      "Seen so far: 86400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1350: 0.8923453092575073\n",
      "Seen so far: 86464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1351: 0.5245434045791626\n",
      "Seen so far: 86528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1352: 1.2334632873535156\n",
      "Seen so far: 86592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1353: 0.5668576955795288\n",
      "Seen so far: 86656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1354: 1.087762475013733\n",
      "Seen so far: 86720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1355: 0.8699325323104858\n",
      "Seen so far: 86784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1356: 0.5443720817565918\n",
      "Seen so far: 86848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1357: 0.9023802280426025\n",
      "Seen so far: 86912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1358: 0.6517034769058228\n",
      "Seen so far: 86976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1359: 0.6950840950012207\n",
      "Seen so far: 87040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1360: 0.8372176885604858\n",
      "Seen so far: 87104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1361: 0.6102011203765869\n",
      "Seen so far: 87168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1362: 0.8466465473175049\n",
      "Seen so far: 87232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1363: 0.8018326759338379\n",
      "Seen so far: 87296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1364: 0.9052406549453735\n",
      "Seen so far: 87360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1365: 0.7344760894775391\n",
      "Seen so far: 87424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1366: 0.8821489810943604\n",
      "Seen so far: 87488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1367: 1.183509111404419\n",
      "Seen so far: 87552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1368: 0.8515348434448242\n",
      "Seen so far: 87616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1369: 0.4499131441116333\n",
      "Seen so far: 87680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1370: 0.6153819561004639\n",
      "Seen so far: 87744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1371: 0.6420032978057861\n",
      "Seen so far: 87808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1372: 0.9944745302200317\n",
      "Seen so far: 87872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1373: 0.6164665222167969\n",
      "Seen so far: 87936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1374: 0.8296135067939758\n",
      "Seen so far: 88000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1375: 0.8361859321594238\n",
      "Seen so far: 88064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1376: 0.9458972811698914\n",
      "Seen so far: 88128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1377: 0.8944204449653625\n",
      "Seen so far: 88192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1378: 0.9371870160102844\n",
      "Seen so far: 88256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1379: 0.9995038509368896\n",
      "Seen so far: 88320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1380: 0.9289906620979309\n",
      "Seen so far: 88384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1381: 0.6541903018951416\n",
      "Seen so far: 88448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1382: 0.57415771484375\n",
      "Seen so far: 88512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1383: 0.958335280418396\n",
      "Seen so far: 88576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1384: 0.446916401386261\n",
      "Seen so far: 88640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1385: 0.567569375038147\n",
      "Seen so far: 88704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1386: 0.6696608066558838\n",
      "Seen so far: 88768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1387: 0.7922461032867432\n",
      "Seen so far: 88832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1388: 0.961796760559082\n",
      "Seen so far: 88896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1389: 0.5635567903518677\n",
      "Seen so far: 88960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1390: 0.9021836519241333\n",
      "Seen so far: 89024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1391: 1.119544506072998\n",
      "Seen so far: 89088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1392: 0.8612544536590576\n",
      "Seen so far: 89152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1393: 1.1440225839614868\n",
      "Seen so far: 89216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1394: 0.646420419216156\n",
      "Seen so far: 89280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1395: 0.5384668111801147\n",
      "Seen so far: 89344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1396: 0.8570510149002075\n",
      "Seen so far: 89408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1397: 0.7434965372085571\n",
      "Seen so far: 89472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1398: 0.710960865020752\n",
      "Seen so far: 89536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1399: 0.957825779914856\n",
      "Seen so far: 89600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1400: 0.7661034464836121\n",
      "Seen so far: 89664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1401: 0.6682356595993042\n",
      "Seen so far: 89728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1402: 0.8118828535079956\n",
      "Seen so far: 89792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1403: 0.8205571174621582\n",
      "Seen so far: 89856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1404: 0.45203515887260437\n",
      "Seen so far: 89920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1405: 0.47685134410858154\n",
      "Seen so far: 89984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1406: 1.289607286453247\n",
      "Seen so far: 90048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1407: 0.5971350073814392\n",
      "Seen so far: 90112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1408: 0.5120145082473755\n",
      "Seen so far: 90176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1409: 0.7565186023712158\n",
      "Seen so far: 90240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1410: 0.7059301137924194\n",
      "Seen so far: 90304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1411: 0.7571515440940857\n",
      "Seen so far: 90368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1412: 0.9156820774078369\n",
      "Seen so far: 90432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1413: 0.7633118629455566\n",
      "Seen so far: 90496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1414: 0.5529499053955078\n",
      "Seen so far: 90560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1415: 0.5987584590911865\n",
      "Seen so far: 90624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1416: 0.7599632740020752\n",
      "Seen so far: 90688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1417: 0.6922669410705566\n",
      "Seen so far: 90752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1418: 0.629921555519104\n",
      "Seen so far: 90816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1419: 0.8473491668701172\n",
      "Seen so far: 90880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1420: 0.5719199776649475\n",
      "Seen so far: 90944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1421: 0.525918185710907\n",
      "Seen so far: 91008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1422: 0.7415101528167725\n",
      "Seen so far: 91072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1423: 0.937910258769989\n",
      "Seen so far: 91136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1424: 0.7507977485656738\n",
      "Seen so far: 91200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1425: 0.3908967971801758\n",
      "Seen so far: 91264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1426: 0.5112408399581909\n",
      "Seen so far: 91328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1427: 0.7703026533126831\n",
      "Seen so far: 91392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1428: 0.8661888241767883\n",
      "Seen so far: 91456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1429: 0.6058918237686157\n",
      "Seen so far: 91520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1430: 0.6890290379524231\n",
      "Seen so far: 91584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1431: 0.9077297449111938\n",
      "Seen so far: 91648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1432: 0.26461589336395264\n",
      "Seen so far: 91712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1433: 0.7277756929397583\n",
      "Seen so far: 91776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1434: 0.47174519300460815\n",
      "Seen so far: 91840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1435: 0.6597399711608887\n",
      "Seen so far: 91904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1436: 0.8381669521331787\n",
      "Seen so far: 91968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1437: 0.5559827089309692\n",
      "Seen so far: 92032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1438: 0.7923168540000916\n",
      "Seen so far: 92096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1439: 0.9783086180686951\n",
      "Seen so far: 92160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1440: 0.7843718528747559\n",
      "Seen so far: 92224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1441: 0.5120334625244141\n",
      "Seen so far: 92288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1442: 0.9887658357620239\n",
      "Seen so far: 92352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1443: 0.9012322425842285\n",
      "Seen so far: 92416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1444: 0.9343531131744385\n",
      "Seen so far: 92480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1445: 0.8529151678085327\n",
      "Seen so far: 92544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1446: 0.6433429718017578\n",
      "Seen so far: 92608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1447: 0.446065217256546\n",
      "Seen so far: 92672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1448: 0.5053266882896423\n",
      "Seen so far: 92736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1449: 1.2309738397598267\n",
      "Seen so far: 92800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1450: 0.41768282651901245\n",
      "Seen so far: 92864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1451: 0.9519085884094238\n",
      "Seen so far: 92928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1452: 0.4882020652294159\n",
      "Seen so far: 92992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1453: 1.0011347532272339\n",
      "Seen so far: 93056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1454: 0.743574321269989\n",
      "Seen so far: 93120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1455: 1.162053108215332\n",
      "Seen so far: 93184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1456: 0.746296763420105\n",
      "Seen so far: 93248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1457: 0.9731342792510986\n",
      "Seen so far: 93312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1458: 0.9032139778137207\n",
      "Seen so far: 93376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1459: 0.8840850591659546\n",
      "Seen so far: 93440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1460: 0.8715071082115173\n",
      "Seen so far: 93504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1461: 0.7519891262054443\n",
      "Seen so far: 93568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1462: 0.7241337895393372\n",
      "Seen so far: 93632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1463: 0.9600942134857178\n",
      "Seen so far: 93696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1464: 0.5339341759681702\n",
      "Seen so far: 93760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1465: 0.8765135407447815\n",
      "Seen so far: 93824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1466: 0.7506756782531738\n",
      "Seen so far: 93888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1467: 0.5198813080787659\n",
      "Seen so far: 93952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1468: 0.7445130348205566\n",
      "Seen so far: 94016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1469: 0.5423790216445923\n",
      "Seen so far: 94080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1470: 1.0627648830413818\n",
      "Seen so far: 94144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1471: 0.27988022565841675\n",
      "Seen so far: 94208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1472: 0.8015425801277161\n",
      "Seen so far: 94272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1473: 0.7747434377670288\n",
      "Seen so far: 94336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1474: 0.6286386251449585\n",
      "Seen so far: 94400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1475: 0.9594107866287231\n",
      "Seen so far: 94464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1476: 0.4539876878261566\n",
      "Seen so far: 94528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1477: 0.46354514360427856\n",
      "Seen so far: 94592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1478: 1.0933643579483032\n",
      "Seen so far: 94656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1479: 0.7475988864898682\n",
      "Seen so far: 94720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1480: 0.7347903251647949\n",
      "Seen so far: 94784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1481: 0.7813524007797241\n",
      "Seen so far: 94848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1482: 0.5485252737998962\n",
      "Seen so far: 94912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1483: 1.0645475387573242\n",
      "Seen so far: 94976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1484: 0.5637731552124023\n",
      "Seen so far: 95040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1485: 0.619702935218811\n",
      "Seen so far: 95104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1486: 0.5757426023483276\n",
      "Seen so far: 95168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1487: 0.37805861234664917\n",
      "Seen so far: 95232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1488: 0.7671653628349304\n",
      "Seen so far: 95296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1489: 0.6212579011917114\n",
      "Seen so far: 95360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1490: 0.6132372617721558\n",
      "Seen so far: 95424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1491: 0.40741652250289917\n",
      "Seen so far: 95488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1492: 0.801715612411499\n",
      "Seen so far: 95552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1493: 0.7369176149368286\n",
      "Seen so far: 95616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1494: 0.6308543682098389\n",
      "Seen so far: 95680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1495: 1.2823071479797363\n",
      "Seen so far: 95744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1496: 0.8025004863739014\n",
      "Seen so far: 95808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1497: 1.078798532485962\n",
      "Seen so far: 95872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1498: 0.6363308429718018\n",
      "Seen so far: 95936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1499: 0.7929539680480957\n",
      "Seen so far: 96000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1500: 0.6585425138473511\n",
      "Seen so far: 96064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1501: 1.0747357606887817\n",
      "Seen so far: 96128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1502: 0.8342156410217285\n",
      "Seen so far: 96192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1503: 0.3794899582862854\n",
      "Seen so far: 96256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1504: 0.681659460067749\n",
      "Seen so far: 96320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1505: 1.0386546850204468\n",
      "Seen so far: 96384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1506: 0.5336141586303711\n",
      "Seen so far: 96448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1507: 1.47747802734375\n",
      "Seen so far: 96512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1508: 0.5691503882408142\n",
      "Seen so far: 96576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1509: 1.1000837087631226\n",
      "Seen so far: 96640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1510: 1.3399627208709717\n",
      "Seen so far: 96704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1511: 0.6655117273330688\n",
      "Seen so far: 96768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1512: 0.7130552530288696\n",
      "Seen so far: 96832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1513: 0.6146839261054993\n",
      "Seen so far: 96896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1514: 0.8374899625778198\n",
      "Seen so far: 96960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1515: 1.2812401056289673\n",
      "Seen so far: 97024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1516: 0.785555362701416\n",
      "Seen so far: 97088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1517: 1.239741325378418\n",
      "Seen so far: 97152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1518: 0.9368662238121033\n",
      "Seen so far: 97216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1519: 0.6492162346839905\n",
      "Seen so far: 97280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1520: 0.7119531631469727\n",
      "Seen so far: 97344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1521: 0.8432531356811523\n",
      "Seen so far: 97408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1522: 1.01614248752594\n",
      "Seen so far: 97472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1523: 0.9588159322738647\n",
      "Seen so far: 97536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1524: 0.9168962240219116\n",
      "Seen so far: 97600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1525: 1.0958398580551147\n",
      "Seen so far: 97664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1526: 0.9240447282791138\n",
      "Seen so far: 97728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1527: 0.6591762900352478\n",
      "Seen so far: 97792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1528: 0.6229432821273804\n",
      "Seen so far: 97856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1529: 0.7245578169822693\n",
      "Seen so far: 97920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1530: 0.70159912109375\n",
      "Seen so far: 97984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1531: 0.37190502882003784\n",
      "Seen so far: 98048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1532: 0.8058842420578003\n",
      "Seen so far: 98112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1533: 0.6450084447860718\n",
      "Seen so far: 98176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1534: 0.9309242963790894\n",
      "Seen so far: 98240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1535: 0.46023085713386536\n",
      "Seen so far: 98304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1536: 0.6701472997665405\n",
      "Seen so far: 98368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1537: 0.7211730480194092\n",
      "Seen so far: 98432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1538: 0.8494549989700317\n",
      "Seen so far: 98496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1539: 0.4909004867076874\n",
      "Seen so far: 98560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1540: 0.5568904876708984\n",
      "Seen so far: 98624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1541: 0.5497816801071167\n",
      "Seen so far: 98688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1542: 0.6333078145980835\n",
      "Seen so far: 98752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1543: 0.9008951187133789\n",
      "Seen so far: 98816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1544: 0.6049176454544067\n",
      "Seen so far: 98880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1545: 0.47798919677734375\n",
      "Seen so far: 98944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1546: 0.8746939897537231\n",
      "Seen so far: 99008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1547: 0.875287652015686\n",
      "Seen so far: 99072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1548: 0.7014429569244385\n",
      "Seen so far: 99136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1549: 0.5843580961227417\n",
      "Seen so far: 99200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1550: 0.6970584988594055\n",
      "Seen so far: 99264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1551: 1.1673173904418945\n",
      "Seen so far: 99328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1552: 0.6392422318458557\n",
      "Seen so far: 99392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1553: 0.5854842662811279\n",
      "Seen so far: 99456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1554: 0.9876953363418579\n",
      "Seen so far: 99520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1555: 0.9991632103919983\n",
      "Seen so far: 99584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1556: 0.8142969012260437\n",
      "Seen so far: 99648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1557: 1.1996188163757324\n",
      "Seen so far: 99712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1558: 0.7567644715309143\n",
      "Seen so far: 99776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1559: 0.3615795373916626\n",
      "Seen so far: 99840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1560: 1.279564619064331\n",
      "Seen so far: 99904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1561: 0.6106425523757935\n",
      "Seen so far: 99968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1562: 0.7960699200630188\n",
      "Seen so far: 100032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1563: 0.8523552417755127\n",
      "Seen so far: 100096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1564: 0.9208344221115112\n",
      "Seen so far: 100160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1565: 1.0110681056976318\n",
      "Seen so far: 100224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1566: 0.8445096015930176\n",
      "Seen so far: 100288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1567: 0.5967288017272949\n",
      "Seen so far: 100352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1568: 0.730818510055542\n",
      "Seen so far: 100416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1569: 0.6157838702201843\n",
      "Seen so far: 100480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1570: 1.1738618612289429\n",
      "Seen so far: 100544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1571: 0.9911779165267944\n",
      "Seen so far: 100608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1572: 0.5541822910308838\n",
      "Seen so far: 100672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1573: 0.9755761623382568\n",
      "Seen so far: 100736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1574: 0.7814177870750427\n",
      "Seen so far: 100800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1575: 0.8775116205215454\n",
      "Seen so far: 100864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1576: 0.7434583902359009\n",
      "Seen so far: 100928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1577: 0.6428742408752441\n",
      "Seen so far: 100992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1578: 0.9788010716438293\n",
      "Seen so far: 101056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1579: 0.607225239276886\n",
      "Seen so far: 101120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1580: 0.9023813605308533\n",
      "Seen so far: 101184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1581: 0.7328354120254517\n",
      "Seen so far: 101248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1582: 0.8597356081008911\n",
      "Seen so far: 101312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1583: 0.7037365436553955\n",
      "Seen so far: 101376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1584: 0.8888034224510193\n",
      "Seen so far: 101440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1585: 1.4563995599746704\n",
      "Seen so far: 101504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1586: 0.6746267676353455\n",
      "Seen so far: 101568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1587: 0.5953339338302612\n",
      "Seen so far: 101632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1588: 0.5439216494560242\n",
      "Seen so far: 101696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1589: 0.7961382269859314\n",
      "Seen so far: 101760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1590: 0.8205894231796265\n",
      "Seen so far: 101824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1591: 0.8308459520339966\n",
      "Seen so far: 101888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1592: 0.646398663520813\n",
      "Seen so far: 101952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1593: 0.6024244427680969\n",
      "Seen so far: 102016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1594: 0.6594452857971191\n",
      "Seen so far: 102080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1595: 0.8735739588737488\n",
      "Seen so far: 102144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1596: 0.6799379587173462\n",
      "Seen so far: 102208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1597: 0.8793839812278748\n",
      "Seen so far: 102272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1598: 0.5873875021934509\n",
      "Seen so far: 102336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1599: 0.7983577251434326\n",
      "Seen so far: 102400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1600: 0.35866764187812805\n",
      "Seen so far: 102464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1601: 0.7802327871322632\n",
      "Seen so far: 102528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1602: 0.4555645287036896\n",
      "Seen so far: 102592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1603: 1.1453306674957275\n",
      "Seen so far: 102656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1604: 0.6527864336967468\n",
      "Seen so far: 102720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1605: 1.2175774574279785\n",
      "Seen so far: 102784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1606: 0.9579600691795349\n",
      "Seen so far: 102848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1607: 0.6779395341873169\n",
      "Seen so far: 102912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1608: 0.7819826602935791\n",
      "Seen so far: 102976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1609: 0.7533720135688782\n",
      "Seen so far: 103040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1610: 0.8574862480163574\n",
      "Seen so far: 103104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1611: 0.6396052837371826\n",
      "Seen so far: 103168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1612: 0.6316870450973511\n",
      "Seen so far: 103232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1613: 0.937688410282135\n",
      "Seen so far: 103296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1614: 0.6465854644775391\n",
      "Seen so far: 103360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1615: 0.648383378982544\n",
      "Seen so far: 103424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1616: 0.7452658414840698\n",
      "Seen so far: 103488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1617: 0.6229183077812195\n",
      "Seen so far: 103552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1618: 0.5528275370597839\n",
      "Seen so far: 103616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1619: 0.8038527369499207\n",
      "Seen so far: 103680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1620: 0.6681454181671143\n",
      "Seen so far: 103744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1621: 0.6012864708900452\n",
      "Seen so far: 103808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1622: 0.7365027666091919\n",
      "Seen so far: 103872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1623: 0.8519653081893921\n",
      "Seen so far: 103936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1624: 0.6199311017990112\n",
      "Seen so far: 104000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1625: 1.0050349235534668\n",
      "Seen so far: 104064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1626: 0.767553448677063\n",
      "Seen so far: 104128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1627: 0.66111820936203\n",
      "Seen so far: 104192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1628: 0.7611768841743469\n",
      "Seen so far: 104256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1629: 0.5613688826560974\n",
      "Seen so far: 104320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1630: 0.8569074869155884\n",
      "Seen so far: 104384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1631: 0.6930121183395386\n",
      "Seen so far: 104448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1632: 0.9721591472625732\n",
      "Seen so far: 104512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1633: 0.7505462169647217\n",
      "Seen so far: 104576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1634: 0.8376118540763855\n",
      "Seen so far: 104640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1635: 0.7283510565757751\n",
      "Seen so far: 104704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1636: 0.7202250957489014\n",
      "Seen so far: 104768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1637: 0.4420455992221832\n",
      "Seen so far: 104832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1638: 0.9020594954490662\n",
      "Seen so far: 104896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1639: 0.4959104359149933\n",
      "Seen so far: 104960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1640: 0.7873049974441528\n",
      "Seen so far: 105024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1641: 0.6643271446228027\n",
      "Seen so far: 105088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1642: 0.7249380350112915\n",
      "Seen so far: 105152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1643: 1.2083224058151245\n",
      "Seen so far: 105216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1644: 0.7457662224769592\n",
      "Seen so far: 105280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1645: 1.0921359062194824\n",
      "Seen so far: 105344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1646: 0.7029339075088501\n",
      "Seen so far: 105408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1647: 0.5220777988433838\n",
      "Seen so far: 105472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1648: 0.7440739274024963\n",
      "Seen so far: 105536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1649: 0.9924219250679016\n",
      "Seen so far: 105600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1650: 0.6248033046722412\n",
      "Seen so far: 105664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1651: 0.8946776986122131\n",
      "Seen so far: 105728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1652: 0.7168317437171936\n",
      "Seen so far: 105792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1653: 0.6255035400390625\n",
      "Seen so far: 105856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1654: 0.6386204361915588\n",
      "Seen so far: 105920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1655: 0.7628152966499329\n",
      "Seen so far: 105984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1656: 0.41647833585739136\n",
      "Seen so far: 106048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1657: 0.7151435017585754\n",
      "Seen so far: 106112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1658: 0.44447430968284607\n",
      "Seen so far: 106176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1659: 0.8194931149482727\n",
      "Seen so far: 106240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1660: 0.7793360948562622\n",
      "Seen so far: 106304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1661: 0.7020350694656372\n",
      "Seen so far: 106368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1662: 0.4077528715133667\n",
      "Seen so far: 106432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1663: 0.7012206315994263\n",
      "Seen so far: 106496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1664: 0.9002719521522522\n",
      "Seen so far: 106560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1665: 1.2368590831756592\n",
      "Seen so far: 106624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1666: 0.67193603515625\n",
      "Seen so far: 106688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1667: 0.5104517340660095\n",
      "Seen so far: 106752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1668: 0.8499829769134521\n",
      "Seen so far: 106816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1669: 0.417944997549057\n",
      "Seen so far: 106880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1670: 0.49443888664245605\n",
      "Seen so far: 106944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1671: 0.723878026008606\n",
      "Seen so far: 107008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1672: 0.8090510368347168\n",
      "Seen so far: 107072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1673: 0.4315544068813324\n",
      "Seen so far: 107136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1674: 0.681891679763794\n",
      "Seen so far: 107200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1675: 1.098890781402588\n",
      "Seen so far: 107264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1676: 0.5001004934310913\n",
      "Seen so far: 107328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1677: 0.6280698776245117\n",
      "Seen so far: 107392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1678: 0.7367961406707764\n",
      "Seen so far: 107456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1679: 0.6520699262619019\n",
      "Seen so far: 107520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1680: 0.8761659860610962\n",
      "Seen so far: 107584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1681: 1.2836880683898926\n",
      "Seen so far: 107648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1682: 0.6845579147338867\n",
      "Seen so far: 107712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1683: 1.1469134092330933\n",
      "Seen so far: 107776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1684: 1.000732183456421\n",
      "Seen so far: 107840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1685: 0.8525344133377075\n",
      "Seen so far: 107904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1686: 1.0753023624420166\n",
      "Seen so far: 107968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1687: 1.0036299228668213\n",
      "Seen so far: 108032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1688: 0.8972054719924927\n",
      "Seen so far: 108096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1689: 0.6692625880241394\n",
      "Seen so far: 108160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1690: 0.8951668739318848\n",
      "Seen so far: 108224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1691: 0.5290524959564209\n",
      "Seen so far: 108288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1692: 0.6317196488380432\n",
      "Seen so far: 108352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1693: 1.1357855796813965\n",
      "Seen so far: 108416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1694: 0.906253457069397\n",
      "Seen so far: 108480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1695: 0.8151195049285889\n",
      "Seen so far: 108544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1696: 1.0068544149398804\n",
      "Seen so far: 108608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1697: 0.9445894956588745\n",
      "Seen so far: 108672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1698: 0.4932958483695984\n",
      "Seen so far: 108736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1699: 0.452140212059021\n",
      "Seen so far: 108800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1700: 0.6265470385551453\n",
      "Seen so far: 108864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1701: 0.7424626350402832\n",
      "Seen so far: 108928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1702: 1.077760934829712\n",
      "Seen so far: 108992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1703: 0.5983076095581055\n",
      "Seen so far: 109056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1704: 1.0011377334594727\n",
      "Seen so far: 109120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1705: 1.0000519752502441\n",
      "Seen so far: 109184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1706: 0.8634200692176819\n",
      "Seen so far: 109248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1707: 0.6006515026092529\n",
      "Seen so far: 109312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1708: 0.8761722445487976\n",
      "Seen so far: 109376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1709: 1.2530776262283325\n",
      "Seen so far: 109440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1710: 0.7031176090240479\n",
      "Seen so far: 109504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1711: 0.3766622841358185\n",
      "Seen so far: 109568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1712: 0.6197930574417114\n",
      "Seen so far: 109632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1713: 0.488227903842926\n",
      "Seen so far: 109696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1714: 0.8164935111999512\n",
      "Seen so far: 109760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1715: 0.48280349373817444\n",
      "Seen so far: 109824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1716: 0.8724112510681152\n",
      "Seen so far: 109888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1717: 0.5260516405105591\n",
      "Seen so far: 109952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1718: 0.714821457862854\n",
      "Seen so far: 110016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1719: 0.5914430022239685\n",
      "Seen so far: 110080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1720: 0.8368269205093384\n",
      "Seen so far: 110144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1721: 0.9453142285346985\n",
      "Seen so far: 110208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1722: 0.7364735007286072\n",
      "Seen so far: 110272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1723: 0.6427831649780273\n",
      "Seen so far: 110336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1724: 0.9184857606887817\n",
      "Seen so far: 110400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1725: 0.8756616115570068\n",
      "Seen so far: 110464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1726: 1.2828845977783203\n",
      "Seen so far: 110528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1727: 0.7695062160491943\n",
      "Seen so far: 110592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1728: 0.6807535886764526\n",
      "Seen so far: 110656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1729: 0.9747893810272217\n",
      "Seen so far: 110720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1730: 0.7304995059967041\n",
      "Seen so far: 110784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1731: 0.6031048893928528\n",
      "Seen so far: 110848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1732: 1.0224721431732178\n",
      "Seen so far: 110912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1733: 0.9773114919662476\n",
      "Seen so far: 110976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1734: 0.6425130367279053\n",
      "Seen so far: 111040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1735: 0.7402907609939575\n",
      "Seen so far: 111104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1736: 0.6048420667648315\n",
      "Seen so far: 111168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1737: 0.862402617931366\n",
      "Seen so far: 111232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1738: 0.8267019987106323\n",
      "Seen so far: 111296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1739: 0.6560382843017578\n",
      "Seen so far: 111360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1740: 1.0089232921600342\n",
      "Seen so far: 111424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1741: 0.8467824459075928\n",
      "Seen so far: 111488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1742: 0.7124353647232056\n",
      "Seen so far: 111552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1743: 0.6418733596801758\n",
      "Seen so far: 111616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1744: 0.8041012287139893\n",
      "Seen so far: 111680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1745: 0.9588167667388916\n",
      "Seen so far: 111744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1746: 1.130028247833252\n",
      "Seen so far: 111808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1747: 1.186025619506836\n",
      "Seen so far: 111872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1748: 0.6112926006317139\n",
      "Seen so far: 111936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1749: 0.5520893335342407\n",
      "Seen so far: 112000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1750: 0.7316412329673767\n",
      "Seen so far: 112064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1751: 0.7918981909751892\n",
      "Seen so far: 112128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1752: 1.0093239545822144\n",
      "Seen so far: 112192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1753: 0.9621483683586121\n",
      "Seen so far: 112256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1754: 1.0558974742889404\n",
      "Seen so far: 112320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1755: 0.7663285136222839\n",
      "Seen so far: 112384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1756: 0.9894169569015503\n",
      "Seen so far: 112448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1757: 0.6355671882629395\n",
      "Seen so far: 112512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1758: 1.2464340925216675\n",
      "Seen so far: 112576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1759: 0.7134936451911926\n",
      "Seen so far: 112640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1760: 0.8138072490692139\n",
      "Seen so far: 112704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1761: 0.6572283506393433\n",
      "Seen so far: 112768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1762: 0.817758321762085\n",
      "Seen so far: 112832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1763: 0.8641899824142456\n",
      "Seen so far: 112896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1764: 0.8036500215530396\n",
      "Seen so far: 112960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1765: 0.4613015353679657\n",
      "Seen so far: 113024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1766: 0.7241542339324951\n",
      "Seen so far: 113088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1767: 0.7794033288955688\n",
      "Seen so far: 113152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1768: 0.9966623783111572\n",
      "Seen so far: 113216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1769: 1.066421627998352\n",
      "Seen so far: 113280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1770: 0.5553287863731384\n",
      "Seen so far: 113344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1771: 0.8779158592224121\n",
      "Seen so far: 113408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1772: 0.9043599367141724\n",
      "Seen so far: 113472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1773: 0.9295387268066406\n",
      "Seen so far: 113536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1774: 0.5824898481369019\n",
      "Seen so far: 113600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1775: 0.8520258069038391\n",
      "Seen so far: 113664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1776: 1.0542147159576416\n",
      "Seen so far: 113728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1777: 0.7872370481491089\n",
      "Seen so far: 113792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1778: 0.6923625469207764\n",
      "Seen so far: 113856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1779: 1.1095178127288818\n",
      "Seen so far: 113920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1780: 1.0577266216278076\n",
      "Seen so far: 113984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1781: 0.9035757184028625\n",
      "Seen so far: 114048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1782: 0.367524653673172\n",
      "Seen so far: 114112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1783: 1.0204370021820068\n",
      "Seen so far: 114176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1784: 0.9258313179016113\n",
      "Seen so far: 114240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1785: 0.7328869104385376\n",
      "Seen so far: 114304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1786: 0.8299481868743896\n",
      "Seen so far: 114368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1787: 0.6836727857589722\n",
      "Seen so far: 114432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1788: 0.6076279282569885\n",
      "Seen so far: 114496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1789: 0.6327400803565979\n",
      "Seen so far: 114560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1790: 0.7265658378601074\n",
      "Seen so far: 114624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1791: 0.6572939157485962\n",
      "Seen so far: 114688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1792: 0.48168301582336426\n",
      "Seen so far: 114752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1793: 0.9176238775253296\n",
      "Seen so far: 114816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1794: 0.4816407263278961\n",
      "Seen so far: 114880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1795: 0.6816516518592834\n",
      "Seen so far: 114944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1796: 0.735558271408081\n",
      "Seen so far: 115008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1797: 0.3940076231956482\n",
      "Seen so far: 115072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1798: 0.420143723487854\n",
      "Seen so far: 115136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1799: 0.6123626232147217\n",
      "Seen so far: 115200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1800: 0.8421099185943604\n",
      "Seen so far: 115264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1801: 0.7132741212844849\n",
      "Seen so far: 115328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1802: 0.34341758489608765\n",
      "Seen so far: 115392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1803: 0.9349274039268494\n",
      "Seen so far: 115456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1804: 0.4489520192146301\n",
      "Seen so far: 115520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1805: 0.5560555458068848\n",
      "Seen so far: 115584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1806: 0.7083264589309692\n",
      "Seen so far: 115648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1807: 0.7731160521507263\n",
      "Seen so far: 115712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1808: 0.9465911388397217\n",
      "Seen so far: 115776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1809: 0.6561364531517029\n",
      "Seen so far: 115840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1810: 0.6436627507209778\n",
      "Seen so far: 115904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1811: 0.8403155207633972\n",
      "Seen so far: 115968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1812: 0.5611739754676819\n",
      "Seen so far: 116032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1813: 0.9133603572845459\n",
      "Seen so far: 116096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1814: 0.913460373878479\n",
      "Seen so far: 116160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1815: 1.3374290466308594\n",
      "Seen so far: 116224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1816: 0.7388678789138794\n",
      "Seen so far: 116288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1817: 0.7846847176551819\n",
      "Seen so far: 116352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1818: 0.8488751649856567\n",
      "Seen so far: 116416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1819: 0.4047800898551941\n",
      "Seen so far: 116480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1820: 0.6634366512298584\n",
      "Seen so far: 116544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1821: 0.9518720507621765\n",
      "Seen so far: 116608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1822: 0.9347795248031616\n",
      "Seen so far: 116672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1823: 1.0936496257781982\n",
      "Seen so far: 116736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1824: 0.9866839647293091\n",
      "Seen so far: 116800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1825: 0.5753650665283203\n",
      "Seen so far: 116864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1826: 1.0254662036895752\n",
      "Seen so far: 116928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1827: 0.8194884061813354\n",
      "Seen so far: 116992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1828: 0.846298336982727\n",
      "Seen so far: 117056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1829: 0.819884717464447\n",
      "Seen so far: 117120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1830: 0.6235518455505371\n",
      "Seen so far: 117184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1831: 0.6568979024887085\n",
      "Seen so far: 117248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1832: 1.078730583190918\n",
      "Seen so far: 117312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1833: 0.8184834718704224\n",
      "Seen so far: 117376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1834: 1.0170564651489258\n",
      "Seen so far: 117440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1835: 0.6037329435348511\n",
      "Seen so far: 117504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1836: 0.6922988891601562\n",
      "Seen so far: 117568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1837: 0.5037431120872498\n",
      "Seen so far: 117632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1838: 0.8414091467857361\n",
      "Seen so far: 117696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1839: 0.62009197473526\n",
      "Seen so far: 117760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1840: 1.1571826934814453\n",
      "Seen so far: 117824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1841: 0.7215875387191772\n",
      "Seen so far: 117888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1842: 0.43814900517463684\n",
      "Seen so far: 117952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1843: 0.7972239255905151\n",
      "Seen so far: 118016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1844: 0.7066882252693176\n",
      "Seen so far: 118080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1845: 0.7731053233146667\n",
      "Seen so far: 118144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1846: 1.0038416385650635\n",
      "Seen so far: 118208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1847: 0.8031988739967346\n",
      "Seen so far: 118272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1848: 0.7101230025291443\n",
      "Seen so far: 118336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1849: 1.035405158996582\n",
      "Seen so far: 118400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1850: 0.6519806385040283\n",
      "Seen so far: 118464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1851: 1.133918046951294\n",
      "Seen so far: 118528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1852: 0.861216127872467\n",
      "Seen so far: 118592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1853: 0.6264221668243408\n",
      "Seen so far: 118656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1854: 1.0379340648651123\n",
      "Seen so far: 118720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1855: 1.0603080987930298\n",
      "Seen so far: 118784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1856: 0.7134501934051514\n",
      "Seen so far: 118848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1857: 0.524621844291687\n",
      "Seen so far: 118912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1858: 0.9263390302658081\n",
      "Seen so far: 118976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1859: 0.5658930540084839\n",
      "Seen so far: 119040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1860: 0.6014911532402039\n",
      "Seen so far: 119104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1861: 0.8352847099304199\n",
      "Seen so far: 119168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1862: 0.5884968042373657\n",
      "Seen so far: 119232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1863: 0.6262673139572144\n",
      "Seen so far: 119296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1864: 0.7079710960388184\n",
      "Seen so far: 119360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1865: 0.7664072513580322\n",
      "Seen so far: 119424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1866: 0.8542048931121826\n",
      "Seen so far: 119488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1867: 0.9592901468276978\n",
      "Seen so far: 119552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1868: 0.42383480072021484\n",
      "Seen so far: 119616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1869: 0.42298996448516846\n",
      "Seen so far: 119680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1870: 0.4116470217704773\n",
      "Seen so far: 119744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1871: 0.7565644979476929\n",
      "Seen so far: 119808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1872: 0.7359364628791809\n",
      "Seen so far: 119872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1873: 0.894517719745636\n",
      "Seen so far: 119936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1874: 0.7054958343505859\n",
      "Seen so far: 120000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1875: 0.5742084980010986\n",
      "Seen so far: 120064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1876: 0.6185016632080078\n",
      "Seen so far: 120128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1877: 0.5329821109771729\n",
      "Seen so far: 120192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1878: 0.6506383419036865\n",
      "Seen so far: 120256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1879: 0.538108766078949\n",
      "Seen so far: 120320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1880: 0.7387923002243042\n",
      "Seen so far: 120384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1881: 0.4287983775138855\n",
      "Seen so far: 120448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1882: 0.846361517906189\n",
      "Seen so far: 120512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1883: 0.5407668352127075\n",
      "Seen so far: 120576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1884: 0.772113561630249\n",
      "Seen so far: 120640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1885: 0.7517997622489929\n",
      "Seen so far: 120704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1886: 0.5202427506446838\n",
      "Seen so far: 120768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1887: 0.6213944554328918\n",
      "Seen so far: 120832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1888: 0.4032686948776245\n",
      "Seen so far: 120896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1889: 0.9451953768730164\n",
      "Seen so far: 120960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1890: 1.1598429679870605\n",
      "Seen so far: 121024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1891: 0.9285160303115845\n",
      "Seen so far: 121088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1892: 0.7881042957305908\n",
      "Seen so far: 121152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1893: 0.9367819428443909\n",
      "Seen so far: 121216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1894: 0.6488986015319824\n",
      "Seen so far: 121280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1895: 0.6271224617958069\n",
      "Seen so far: 121344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1896: 0.34991466999053955\n",
      "Seen so far: 121408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1897: 0.7773313522338867\n",
      "Seen so far: 121472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1898: 0.4993228316307068\n",
      "Seen so far: 121536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1899: 0.7025108337402344\n",
      "Seen so far: 121600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1900: 0.8086029887199402\n",
      "Seen so far: 121664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1901: 0.5444056391716003\n",
      "Seen so far: 121728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1902: 1.1070486307144165\n",
      "Seen so far: 121792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1903: 0.727890133857727\n",
      "Seen so far: 121856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1904: 0.7874532341957092\n",
      "Seen so far: 121920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1905: 0.74754399061203\n",
      "Seen so far: 121984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1906: 0.5906060934066772\n",
      "Seen so far: 122048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1907: 0.9077956676483154\n",
      "Seen so far: 122112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1908: 0.7178912162780762\n",
      "Seen so far: 122176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1909: 0.7786674499511719\n",
      "Seen so far: 122240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1910: 0.5990638732910156\n",
      "Seen so far: 122304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1911: 0.7127516269683838\n",
      "Seen so far: 122368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1912: 0.9623230695724487\n",
      "Seen so far: 122432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1913: 0.7420561909675598\n",
      "Seen so far: 122496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1914: 0.5673192739486694\n",
      "Seen so far: 122560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1915: 0.5821986198425293\n",
      "Seen so far: 122624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1916: 0.7032198309898376\n",
      "Seen so far: 122688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1917: 0.8734403848648071\n",
      "Seen so far: 122752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1918: 0.8899900317192078\n",
      "Seen so far: 122816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1919: 0.8010033369064331\n",
      "Seen so far: 122880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1920: 1.0338044166564941\n",
      "Seen so far: 122944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1921: 0.6849488019943237\n",
      "Seen so far: 123008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1922: 0.953336775302887\n",
      "Seen so far: 123072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1923: 0.8990483283996582\n",
      "Seen so far: 123136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1924: 0.9332700371742249\n",
      "Seen so far: 123200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1925: 0.7639886736869812\n",
      "Seen so far: 123264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1926: 0.7881888151168823\n",
      "Seen so far: 123328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1927: 0.6910082101821899\n",
      "Seen so far: 123392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1928: 0.5277563333511353\n",
      "Seen so far: 123456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1929: 0.6700410842895508\n",
      "Seen so far: 123520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1930: 1.081761121749878\n",
      "Seen so far: 123584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1931: 0.846651017665863\n",
      "Seen so far: 123648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1932: 1.1918301582336426\n",
      "Seen so far: 123712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1933: 0.7442468404769897\n",
      "Seen so far: 123776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1934: 0.7117328643798828\n",
      "Seen so far: 123840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1935: 0.9638499617576599\n",
      "Seen so far: 123904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1936: 1.0014456510543823\n",
      "Seen so far: 123968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1937: 0.851420521736145\n",
      "Seen so far: 124032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1938: 0.5589745044708252\n",
      "Seen so far: 124096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1939: 1.1924140453338623\n",
      "Seen so far: 124160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1940: 0.6588818430900574\n",
      "Seen so far: 124224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1941: 0.7414741516113281\n",
      "Seen so far: 124288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1942: 0.6051263809204102\n",
      "Seen so far: 124352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1943: 0.5871427059173584\n",
      "Seen so far: 124416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1944: 0.8733463883399963\n",
      "Seen so far: 124480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1945: 0.850428581237793\n",
      "Seen so far: 124544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1946: 0.8113618493080139\n",
      "Seen so far: 124608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1947: 0.5166725516319275\n",
      "Seen so far: 124672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1948: 0.9903671145439148\n",
      "Seen so far: 124736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1949: 0.8549824953079224\n",
      "Seen so far: 124800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1950: 0.9706722497940063\n",
      "Seen so far: 124864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1951: 0.5530452132225037\n",
      "Seen so far: 124928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1952: 0.2515036463737488\n",
      "Seen so far: 124992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1953: 0.5818332433700562\n",
      "Seen so far: 125056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1954: 0.5582119226455688\n",
      "Seen so far: 125120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1955: 0.8349728584289551\n",
      "Seen so far: 125184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1956: 0.6714485287666321\n",
      "Seen so far: 125248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1957: 0.7420941591262817\n",
      "Seen so far: 125312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1958: 0.5606350302696228\n",
      "Seen so far: 125376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1959: 0.6158900856971741\n",
      "Seen so far: 125440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1960: 0.9987953901290894\n",
      "Seen so far: 125504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1961: 0.5341012477874756\n",
      "Seen so far: 125568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1962: 0.6288110017776489\n",
      "Seen so far: 125632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1963: 0.7903084754943848\n",
      "Seen so far: 125696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1964: 0.6055712103843689\n",
      "Seen so far: 125760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1965: 1.1028118133544922\n",
      "Seen so far: 125824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1966: 0.6199718713760376\n",
      "Seen so far: 125888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1967: 0.6000168919563293\n",
      "Seen so far: 125952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1968: 0.507951021194458\n",
      "Seen so far: 126016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1969: 0.7898564338684082\n",
      "Seen so far: 126080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1970: 0.7577570080757141\n",
      "Seen so far: 126144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1971: 0.5522765517234802\n",
      "Seen so far: 126208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1972: 0.8159821629524231\n",
      "Seen so far: 126272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1973: 0.7359076738357544\n",
      "Seen so far: 126336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1974: 0.8304818868637085\n",
      "Seen so far: 126400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1975: 0.9398860931396484\n",
      "Seen so far: 126464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1976: 0.40094277262687683\n",
      "Seen so far: 126528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1977: 0.8173950910568237\n",
      "Seen so far: 126592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1978: 0.7838224768638611\n",
      "Seen so far: 126656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1979: 0.4328957200050354\n",
      "Seen so far: 126720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1980: 0.7708045244216919\n",
      "Seen so far: 126784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1981: 0.7750908136367798\n",
      "Seen so far: 126848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1982: 0.5229723453521729\n",
      "Seen so far: 126912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1983: 1.0476510524749756\n",
      "Seen so far: 126976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1984: 0.9350944757461548\n",
      "Seen so far: 127040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1985: 1.1135876178741455\n",
      "Seen so far: 127104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1986: 0.31349530816078186\n",
      "Seen so far: 127168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1987: 0.9232112169265747\n",
      "Seen so far: 127232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1988: 0.8093534111976624\n",
      "Seen so far: 127296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1989: 0.6236996650695801\n",
      "Seen so far: 127360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1990: 0.9412312507629395\n",
      "Seen so far: 127424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1991: 1.1932127475738525\n",
      "Seen so far: 127488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1992: 0.9116705656051636\n",
      "Seen so far: 127552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1993: 0.7457057237625122\n",
      "Seen so far: 127616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1994: 0.8735190629959106\n",
      "Seen so far: 127680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1995: 0.421960711479187\n",
      "Seen so far: 127744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1996: 0.8340140581130981\n",
      "Seen so far: 127808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1997: 0.8603811264038086\n",
      "Seen so far: 127872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1998: 0.7602726221084595\n",
      "Seen so far: 127936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 1999: 0.7613443732261658\n",
      "Seen so far: 128000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2000: 0.5955379009246826\n",
      "Seen so far: 128064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2001: 0.7170045375823975\n",
      "Seen so far: 128128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2002: 0.9252699613571167\n",
      "Seen so far: 128192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2003: 0.6121124625205994\n",
      "Seen so far: 128256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2004: 0.8228739500045776\n",
      "Seen so far: 128320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2005: 0.7091690301895142\n",
      "Seen so far: 128384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2006: 1.019902229309082\n",
      "Seen so far: 128448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2007: 0.6261035203933716\n",
      "Seen so far: 128512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2008: 0.6528565883636475\n",
      "Seen so far: 128576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2009: 0.9651398658752441\n",
      "Seen so far: 128640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2010: 1.1458513736724854\n",
      "Seen so far: 128704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2011: 0.799209713935852\n",
      "Seen so far: 128768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2012: 0.7412757873535156\n",
      "Seen so far: 128832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2013: 0.6843320727348328\n",
      "Seen so far: 128896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2014: 0.7442767024040222\n",
      "Seen so far: 128960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2015: 0.588260293006897\n",
      "Seen so far: 129024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2016: 0.44991838932037354\n",
      "Seen so far: 129088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2017: 0.8184297680854797\n",
      "Seen so far: 129152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2018: 0.5168696641921997\n",
      "Seen so far: 129216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2019: 0.8576611280441284\n",
      "Seen so far: 129280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2020: 0.3434809446334839\n",
      "Seen so far: 129344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2021: 0.8435401916503906\n",
      "Seen so far: 129408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2022: 0.9314199686050415\n",
      "Seen so far: 129472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2023: 0.7912693619728088\n",
      "Seen so far: 129536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2024: 0.6103118658065796\n",
      "Seen so far: 129600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2025: 0.6506733894348145\n",
      "Seen so far: 129664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2026: 0.6519918441772461\n",
      "Seen so far: 129728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2027: 1.0455831289291382\n",
      "Seen so far: 129792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2028: 0.7253037691116333\n",
      "Seen so far: 129856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2029: 0.6274069547653198\n",
      "Seen so far: 129920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2030: 0.9471766948699951\n",
      "Seen so far: 129984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2031: 1.0993375778198242\n",
      "Seen so far: 130048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2032: 0.9041767120361328\n",
      "Seen so far: 130112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2033: 1.1990485191345215\n",
      "Seen so far: 130176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2034: 1.0380656719207764\n",
      "Seen so far: 130240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2035: 0.6194742321968079\n",
      "Seen so far: 130304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2036: 0.5141233205795288\n",
      "Seen so far: 130368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2037: 0.5310506224632263\n",
      "Seen so far: 130432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2038: 0.9293237924575806\n",
      "Seen so far: 130496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2039: 0.7406889796257019\n",
      "Seen so far: 130560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2040: 0.522325873374939\n",
      "Seen so far: 130624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2041: 0.6409019827842712\n",
      "Seen so far: 130688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2042: 0.7332766056060791\n",
      "Seen so far: 130752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2043: 0.7230772972106934\n",
      "Seen so far: 130816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2044: 0.7233515977859497\n",
      "Seen so far: 130880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2045: 0.5569461584091187\n",
      "Seen so far: 130944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2046: 0.8388068079948425\n",
      "Seen so far: 131008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2047: 0.5289896726608276\n",
      "Seen so far: 131072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2048: 0.5575135946273804\n",
      "Seen so far: 131136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2049: 0.9998610019683838\n",
      "Seen so far: 131200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2050: 0.8643982410430908\n",
      "Seen so far: 131264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2051: 0.8599844574928284\n",
      "Seen so far: 131328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2052: 0.725093424320221\n",
      "Seen so far: 131392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2053: 0.7686147689819336\n",
      "Seen so far: 131456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2054: 0.6774953603744507\n",
      "Seen so far: 131520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2055: 0.25069019198417664\n",
      "Seen so far: 131584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2056: 0.573475182056427\n",
      "Seen so far: 131648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2057: 0.7509726285934448\n",
      "Seen so far: 131712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2058: 0.8441111445426941\n",
      "Seen so far: 131776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2059: 0.9164092540740967\n",
      "Seen so far: 131840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2060: 0.7644494771957397\n",
      "Seen so far: 131904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2061: 0.8850075006484985\n",
      "Seen so far: 131968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2062: 0.7450098991394043\n",
      "Seen so far: 132032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2063: 0.736537754535675\n",
      "Seen so far: 132096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2064: 0.7011680603027344\n",
      "Seen so far: 132160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2065: 0.7116520404815674\n",
      "Seen so far: 132224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2066: 0.8433763384819031\n",
      "Seen so far: 132288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2067: 0.6013925671577454\n",
      "Seen so far: 132352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2068: 1.0692766904830933\n",
      "Seen so far: 132416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2069: 0.9277311563491821\n",
      "Seen so far: 132480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2070: 0.510428786277771\n",
      "Seen so far: 132544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2071: 0.48802560567855835\n",
      "Seen so far: 132608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2072: 1.1010560989379883\n",
      "Seen so far: 132672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2073: 0.6738260984420776\n",
      "Seen so far: 132736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2074: 0.5998043417930603\n",
      "Seen so far: 132800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2075: 0.8309323191642761\n",
      "Seen so far: 132864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2076: 0.6789839267730713\n",
      "Seen so far: 132928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2077: 0.8622749447822571\n",
      "Seen so far: 132992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2078: 0.7105276584625244\n",
      "Seen so far: 133056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2079: 0.999866247177124\n",
      "Seen so far: 133120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2080: 0.3150733411312103\n",
      "Seen so far: 133184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2081: 1.023859977722168\n",
      "Seen so far: 133248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2082: 0.559985876083374\n",
      "Seen so far: 133312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2083: 0.5353472232818604\n",
      "Seen so far: 133376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2084: 0.6862050294876099\n",
      "Seen so far: 133440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2085: 0.3651987314224243\n",
      "Seen so far: 133504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2086: 0.3713908791542053\n",
      "Seen so far: 133568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2087: 0.8483477234840393\n",
      "Seen so far: 133632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2088: 0.6737450957298279\n",
      "Seen so far: 133696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2089: 1.1075310707092285\n",
      "Seen so far: 133760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2090: 0.5477429628372192\n",
      "Seen so far: 133824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2091: 0.46396204829216003\n",
      "Seen so far: 133888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2092: 0.6834819912910461\n",
      "Seen so far: 133952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2093: 0.6385172605514526\n",
      "Seen so far: 134016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2094: 0.6170670986175537\n",
      "Seen so far: 134080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2095: 0.9629231095314026\n",
      "Seen so far: 134144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2096: 0.7008249759674072\n",
      "Seen so far: 134208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2097: 0.6541944146156311\n",
      "Seen so far: 134272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2098: 0.6933678984642029\n",
      "Seen so far: 134336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2099: 0.6708101034164429\n",
      "Seen so far: 134400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2100: 0.7978565692901611\n",
      "Seen so far: 134464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2101: 0.48876476287841797\n",
      "Seen so far: 134528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2102: 0.8494786024093628\n",
      "Seen so far: 134592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2103: 0.6179152727127075\n",
      "Seen so far: 134656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2104: 0.49385637044906616\n",
      "Seen so far: 134720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2105: 0.5084041357040405\n",
      "Seen so far: 134784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2106: 0.7871867418289185\n",
      "Seen so far: 134848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2107: 0.7242222428321838\n",
      "Seen so far: 134912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2108: 0.3030954599380493\n",
      "Seen so far: 134976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2109: 0.5266357660293579\n",
      "Seen so far: 135040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2110: 0.7485238313674927\n",
      "Seen so far: 135104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2111: 0.5486845970153809\n",
      "Seen so far: 135168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2112: 0.38864919543266296\n",
      "Seen so far: 135232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2113: 0.7488323450088501\n",
      "Seen so far: 135296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2114: 0.7657939195632935\n",
      "Seen so far: 135360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2115: 0.8172391057014465\n",
      "Seen so far: 135424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2116: 0.5755830407142639\n",
      "Seen so far: 135488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2117: 0.443525493144989\n",
      "Seen so far: 135552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2118: 1.1699097156524658\n",
      "Seen so far: 135616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2119: 0.7811023592948914\n",
      "Seen so far: 135680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2120: 0.8711628317832947\n",
      "Seen so far: 135744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2121: 0.5561130046844482\n",
      "Seen so far: 135808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2122: 0.853380560874939\n",
      "Seen so far: 135872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2123: 0.8049466609954834\n",
      "Seen so far: 135936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2124: 0.6138752698898315\n",
      "Seen so far: 136000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2125: 1.1671552658081055\n",
      "Seen so far: 136064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2126: 0.7915818691253662\n",
      "Seen so far: 136128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2127: 1.0586539506912231\n",
      "Seen so far: 136192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2128: 0.8096596002578735\n",
      "Seen so far: 136256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2129: 0.8824728727340698\n",
      "Seen so far: 136320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2130: 0.6663640737533569\n",
      "Seen so far: 136384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2131: 0.999516487121582\n",
      "Seen so far: 136448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2132: 0.6365818381309509\n",
      "Seen so far: 136512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2133: 0.5361514091491699\n",
      "Seen so far: 136576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2134: 0.25706174969673157\n",
      "Seen so far: 136640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2135: 0.401065468788147\n",
      "Seen so far: 136704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2136: 0.5041295289993286\n",
      "Seen so far: 136768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2137: 0.6514068841934204\n",
      "Seen so far: 136832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2138: 0.9288983345031738\n",
      "Seen so far: 136896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2139: 0.8919622898101807\n",
      "Seen so far: 136960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2140: 0.8622820377349854\n",
      "Seen so far: 137024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2141: 1.306918740272522\n",
      "Seen so far: 137088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2142: 0.44399774074554443\n",
      "Seen so far: 137152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2143: 0.6527829170227051\n",
      "Seen so far: 137216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2144: 0.711432695388794\n",
      "Seen so far: 137280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2145: 0.8416496515274048\n",
      "Seen so far: 137344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2146: 1.2743653059005737\n",
      "Seen so far: 137408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2147: 0.5436674952507019\n",
      "Seen so far: 137472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2148: 0.7901561260223389\n",
      "Seen so far: 137536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2149: 0.9143275022506714\n",
      "Seen so far: 137600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2150: 0.6044363379478455\n",
      "Seen so far: 137664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2151: 0.5566658973693848\n",
      "Seen so far: 137728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2152: 1.0803258419036865\n",
      "Seen so far: 137792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2153: 0.5386292934417725\n",
      "Seen so far: 137856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2154: 0.8355171084403992\n",
      "Seen so far: 137920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2155: 0.7849699854850769\n",
      "Seen so far: 137984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2156: 0.8118282556533813\n",
      "Seen so far: 138048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2157: 0.4074190855026245\n",
      "Seen so far: 138112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2158: 0.5907779932022095\n",
      "Seen so far: 138176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2159: 0.42381641268730164\n",
      "Seen so far: 138240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2160: 0.955199658870697\n",
      "Seen so far: 138304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2161: 0.6759481430053711\n",
      "Seen so far: 138368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2162: 0.5029621124267578\n",
      "Seen so far: 138432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2163: 0.5669933557510376\n",
      "Seen so far: 138496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2164: 1.0972249507904053\n",
      "Seen so far: 138560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2165: 0.6987783908843994\n",
      "Seen so far: 138624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2166: 0.7165474891662598\n",
      "Seen so far: 138688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2167: 0.7153670787811279\n",
      "Seen so far: 138752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2168: 0.5157522559165955\n",
      "Seen so far: 138816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2169: 0.4151509404182434\n",
      "Seen so far: 138880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2170: 0.8793749809265137\n",
      "Seen so far: 138944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2171: 0.7679311037063599\n",
      "Seen so far: 139008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2172: 0.39393022656440735\n",
      "Seen so far: 139072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2173: 0.6303491592407227\n",
      "Seen so far: 139136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2174: 1.037645697593689\n",
      "Seen so far: 139200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2175: 0.6102532744407654\n",
      "Seen so far: 139264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2176: 0.7812091112136841\n",
      "Seen so far: 139328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2177: 0.717540979385376\n",
      "Seen so far: 139392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2178: 0.5025999546051025\n",
      "Seen so far: 139456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2179: 0.469751238822937\n",
      "Seen so far: 139520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2180: 0.7900210618972778\n",
      "Seen so far: 139584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2181: 0.731891393661499\n",
      "Seen so far: 139648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2182: 0.9677718877792358\n",
      "Seen so far: 139712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2183: 0.665216326713562\n",
      "Seen so far: 139776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2184: 0.8923481702804565\n",
      "Seen so far: 139840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2185: 0.6768480539321899\n",
      "Seen so far: 139904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2186: 0.7546133995056152\n",
      "Seen so far: 139968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2187: 0.6950909495353699\n",
      "Seen so far: 140032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2188: 0.3969098925590515\n",
      "Seen so far: 140096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2189: 0.8597819209098816\n",
      "Seen so far: 140160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2190: 0.7692990303039551\n",
      "Seen so far: 140224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2191: 0.6679016351699829\n",
      "Seen so far: 140288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2192: 0.5273861885070801\n",
      "Seen so far: 140352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2193: 0.7264527678489685\n",
      "Seen so far: 140416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2194: 0.37971487641334534\n",
      "Seen so far: 140480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2195: 0.9198859333992004\n",
      "Seen so far: 140544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2196: 0.46893274784088135\n",
      "Seen so far: 140608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2197: 0.5046353340148926\n",
      "Seen so far: 140672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2198: 0.9083656072616577\n",
      "Seen so far: 140736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2199: 0.7213490009307861\n",
      "Seen so far: 140800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2200: 0.8869853019714355\n",
      "Seen so far: 140864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2201: 0.6537876725196838\n",
      "Seen so far: 140928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2202: 0.6348994970321655\n",
      "Seen so far: 140992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2203: 1.0852696895599365\n",
      "Seen so far: 141056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2204: 0.42443907260894775\n",
      "Seen so far: 141120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2205: 0.5065057873725891\n",
      "Seen so far: 141184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2206: 1.1260356903076172\n",
      "Seen so far: 141248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2207: 0.7496837973594666\n",
      "Seen so far: 141312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2208: 1.7203259468078613\n",
      "Seen so far: 141376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2209: 0.6986422538757324\n",
      "Seen so far: 141440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2210: 0.73746258020401\n",
      "Seen so far: 141504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2211: 0.6753438115119934\n",
      "Seen so far: 141568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2212: 0.5417614579200745\n",
      "Seen so far: 141632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2213: 0.47461429238319397\n",
      "Seen so far: 141696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2214: 0.9769895076751709\n",
      "Seen so far: 141760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2215: 0.764639139175415\n",
      "Seen so far: 141824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2216: 0.5243172645568848\n",
      "Seen so far: 141888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2217: 0.6983351707458496\n",
      "Seen so far: 141952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2218: 0.7435952425003052\n",
      "Seen so far: 142016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2219: 0.9523996114730835\n",
      "Seen so far: 142080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2220: 0.9185327291488647\n",
      "Seen so far: 142144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2221: 0.8903437852859497\n",
      "Seen so far: 142208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2222: 0.9670388698577881\n",
      "Seen so far: 142272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2223: 0.4389411211013794\n",
      "Seen so far: 142336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2224: 0.8093846440315247\n",
      "Seen so far: 142400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2225: 0.9055692553520203\n",
      "Seen so far: 142464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2226: 0.7341631650924683\n",
      "Seen so far: 142528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2227: 0.6372332572937012\n",
      "Seen so far: 142592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2228: 0.8312289714813232\n",
      "Seen so far: 142656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2229: 0.8156594038009644\n",
      "Seen so far: 142720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2230: 0.7814090251922607\n",
      "Seen so far: 142784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2231: 0.954034686088562\n",
      "Seen so far: 142848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2232: 0.7832953333854675\n",
      "Seen so far: 142912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2233: 0.6279749870300293\n",
      "Seen so far: 142976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2234: 0.6055635809898376\n",
      "Seen so far: 143040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2235: 0.9381914138793945\n",
      "Seen so far: 143104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2236: 0.6247588396072388\n",
      "Seen so far: 143168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2237: 0.6959488391876221\n",
      "Seen so far: 143232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2238: 0.6144232749938965\n",
      "Seen so far: 143296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2239: 0.9467515349388123\n",
      "Seen so far: 143360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2240: 0.7127443552017212\n",
      "Seen so far: 143424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2241: 0.8709363341331482\n",
      "Seen so far: 143488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2242: 0.6761385202407837\n",
      "Seen so far: 143552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2243: 1.0151820182800293\n",
      "Seen so far: 143616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2244: 0.8696411848068237\n",
      "Seen so far: 143680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2245: 0.45183032751083374\n",
      "Seen so far: 143744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2246: 0.7150483727455139\n",
      "Seen so far: 143808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2247: 1.008802056312561\n",
      "Seen so far: 143872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2248: 0.39158952236175537\n",
      "Seen so far: 143936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2249: 0.9708868861198425\n",
      "Seen so far: 144000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2250: 0.7312875986099243\n",
      "Seen so far: 144064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2251: 0.6305316090583801\n",
      "Seen so far: 144128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2252: 0.7098079323768616\n",
      "Seen so far: 144192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2253: 0.972111165523529\n",
      "Seen so far: 144256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2254: 0.6593393087387085\n",
      "Seen so far: 144320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2255: 0.6856561899185181\n",
      "Seen so far: 144384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2256: 0.7172368764877319\n",
      "Seen so far: 144448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2257: 0.7988263368606567\n",
      "Seen so far: 144512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2258: 1.2127366065979004\n",
      "Seen so far: 144576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2259: 0.8430423140525818\n",
      "Seen so far: 144640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2260: 0.7841760516166687\n",
      "Seen so far: 144704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2261: 1.0363625288009644\n",
      "Seen so far: 144768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2262: 0.7701770663261414\n",
      "Seen so far: 144832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2263: 0.8959455490112305\n",
      "Seen so far: 144896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2264: 0.8569758534431458\n",
      "Seen so far: 144960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2265: 0.4521183371543884\n",
      "Seen so far: 145024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2266: 0.6026675701141357\n",
      "Seen so far: 145088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2267: 0.7390650510787964\n",
      "Seen so far: 145152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2268: 0.6242445707321167\n",
      "Seen so far: 145216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2269: 0.39784669876098633\n",
      "Seen so far: 145280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2270: 0.6668100357055664\n",
      "Seen so far: 145344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2271: 0.5567141771316528\n",
      "Seen so far: 145408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2272: 0.9270809888839722\n",
      "Seen so far: 145472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2273: 0.789962887763977\n",
      "Seen so far: 145536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2274: 0.819399356842041\n",
      "Seen so far: 145600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2275: 0.8733774423599243\n",
      "Seen so far: 145664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2276: 0.6995199918746948\n",
      "Seen so far: 145728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2277: 0.7100856304168701\n",
      "Seen so far: 145792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2278: 0.899071455001831\n",
      "Seen so far: 145856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2279: 0.4841436743736267\n",
      "Seen so far: 145920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2280: 0.9876550436019897\n",
      "Seen so far: 145984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2281: 0.6862378120422363\n",
      "Seen so far: 146048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2282: 0.9461028575897217\n",
      "Seen so far: 146112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2283: 0.7741121053695679\n",
      "Seen so far: 146176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2284: 0.7035773992538452\n",
      "Seen so far: 146240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2285: 0.7606037259101868\n",
      "Seen so far: 146304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2286: 0.9265568852424622\n",
      "Seen so far: 146368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2287: 0.5035784244537354\n",
      "Seen so far: 146432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2288: 0.5664765238761902\n",
      "Seen so far: 146496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2289: 0.8245890140533447\n",
      "Seen so far: 146560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2290: 0.7903244495391846\n",
      "Seen so far: 146624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2291: 0.603675365447998\n",
      "Seen so far: 146688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2292: 0.7695105075836182\n",
      "Seen so far: 146752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2293: 1.1973391771316528\n",
      "Seen so far: 146816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2294: 0.8940331935882568\n",
      "Seen so far: 146880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2295: 0.929884672164917\n",
      "Seen so far: 146944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2296: 0.6533352136611938\n",
      "Seen so far: 147008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2297: 1.1457586288452148\n",
      "Seen so far: 147072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2298: 0.8565829992294312\n",
      "Seen so far: 147136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2299: 0.44667232036590576\n",
      "Seen so far: 147200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2300: 0.8512845039367676\n",
      "Seen so far: 147264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2301: 0.7439978718757629\n",
      "Seen so far: 147328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2302: 0.5992562770843506\n",
      "Seen so far: 147392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2303: 0.8411945104598999\n",
      "Seen so far: 147456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2304: 0.46501249074935913\n",
      "Seen so far: 147520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2305: 0.9147580862045288\n",
      "Seen so far: 147584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2306: 0.6239372491836548\n",
      "Seen so far: 147648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2307: 0.6331539154052734\n",
      "Seen so far: 147712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2308: 0.7046142220497131\n",
      "Seen so far: 147776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2309: 0.8748891949653625\n",
      "Seen so far: 147840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2310: 0.6432966589927673\n",
      "Seen so far: 147904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2311: 0.5720453858375549\n",
      "Seen so far: 147968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2312: 0.40244659781455994\n",
      "Seen so far: 148032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2313: 0.683821439743042\n",
      "Seen so far: 148096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2314: 0.9595961570739746\n",
      "Seen so far: 148160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2315: 0.7673898935317993\n",
      "Seen so far: 148224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2316: 0.7593127489089966\n",
      "Seen so far: 148288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2317: 0.5042650103569031\n",
      "Seen so far: 148352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2318: 0.5223037600517273\n",
      "Seen so far: 148416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2319: 0.7378463745117188\n",
      "Seen so far: 148480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2320: 0.9276426434516907\n",
      "Seen so far: 148544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2321: 0.4930732548236847\n",
      "Seen so far: 148608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2322: 0.5548793077468872\n",
      "Seen so far: 148672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2323: 0.5460590720176697\n",
      "Seen so far: 148736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2324: 1.026902437210083\n",
      "Seen so far: 148800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2325: 0.4290551543235779\n",
      "Seen so far: 148864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2326: 0.701894998550415\n",
      "Seen so far: 148928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2327: 0.8586380481719971\n",
      "Seen so far: 148992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2328: 0.6100496053695679\n",
      "Seen so far: 149056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2329: 0.7349258661270142\n",
      "Seen so far: 149120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2330: 0.7637746334075928\n",
      "Seen so far: 149184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2331: 0.4342120289802551\n",
      "Seen so far: 149248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2332: 0.8807088732719421\n",
      "Seen so far: 149312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2333: 0.6929011344909668\n",
      "Seen so far: 149376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2334: 0.7642508745193481\n",
      "Seen so far: 149440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2335: 0.7006847858428955\n",
      "Seen so far: 149504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2336: 0.7341636419296265\n",
      "Seen so far: 149568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2337: 0.7455719113349915\n",
      "Seen so far: 149632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2338: 0.678081214427948\n",
      "Seen so far: 149696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2339: 0.9641921520233154\n",
      "Seen so far: 149760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2340: 0.9406329989433289\n",
      "Seen so far: 149824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2341: 1.0371884107589722\n",
      "Seen so far: 149888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2342: 0.45632970333099365\n",
      "Seen so far: 149952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2343: 0.5308816432952881\n",
      "Seen so far: 150016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2344: 0.8204985857009888\n",
      "Seen so far: 150080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2345: 0.8815101385116577\n",
      "Seen so far: 150144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2346: 0.7747122049331665\n",
      "Seen so far: 150208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2347: 0.5420123338699341\n",
      "Seen so far: 150272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2348: 0.91572505235672\n",
      "Seen so far: 150336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2349: 0.6858184337615967\n",
      "Seen so far: 150400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2350: 0.8610445857048035\n",
      "Seen so far: 150464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2351: 0.5910394191741943\n",
      "Seen so far: 150528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2352: 0.9258478879928589\n",
      "Seen so far: 150592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2353: 0.6566711664199829\n",
      "Seen so far: 150656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2354: 0.5973684787750244\n",
      "Seen so far: 150720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2355: 0.7172356843948364\n",
      "Seen so far: 150784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2356: 0.6595834493637085\n",
      "Seen so far: 150848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2357: 0.8195915222167969\n",
      "Seen so far: 150912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2358: 0.84389328956604\n",
      "Seen so far: 150976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2359: 0.9433618783950806\n",
      "Seen so far: 151040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2360: 0.8050870895385742\n",
      "Seen so far: 151104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2361: 0.691135048866272\n",
      "Seen so far: 151168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2362: 0.8363937735557556\n",
      "Seen so far: 151232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2363: 0.8379487991333008\n",
      "Seen so far: 151296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2364: 0.5305191278457642\n",
      "Seen so far: 151360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2365: 1.0993648767471313\n",
      "Seen so far: 151424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2366: 0.5800300240516663\n",
      "Seen so far: 151488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2367: 0.665202796459198\n",
      "Seen so far: 151552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2368: 1.0172970294952393\n",
      "Seen so far: 151616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2369: 1.0860308408737183\n",
      "Seen so far: 151680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2370: 0.8212095499038696\n",
      "Seen so far: 151744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2371: 0.7219477891921997\n",
      "Seen so far: 151808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2372: 0.7107207775115967\n",
      "Seen so far: 151872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2373: 0.8756840229034424\n",
      "Seen so far: 151936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2374: 0.5550442934036255\n",
      "Seen so far: 152000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2375: 0.7533630728721619\n",
      "Seen so far: 152064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2376: 1.3151172399520874\n",
      "Seen so far: 152128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2377: 0.6743806004524231\n",
      "Seen so far: 152192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2378: 0.5579919815063477\n",
      "Seen so far: 152256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2379: 0.8666948080062866\n",
      "Seen so far: 152320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2380: 0.5035953521728516\n",
      "Seen so far: 152384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2381: 0.4924570322036743\n",
      "Seen so far: 152448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2382: 0.4958738386631012\n",
      "Seen so far: 152512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2383: 0.6689780950546265\n",
      "Seen so far: 152576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2384: 0.9974822998046875\n",
      "Seen so far: 152640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2385: 0.8987499475479126\n",
      "Seen so far: 152704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2386: 0.7387012243270874\n",
      "Seen so far: 152768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2387: 0.6193211674690247\n",
      "Seen so far: 152832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2388: 0.5011669993400574\n",
      "Seen so far: 152896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2389: 0.6488489508628845\n",
      "Seen so far: 152960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2390: 1.1125867366790771\n",
      "Seen so far: 153024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2391: 0.7455335855484009\n",
      "Seen so far: 153088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2392: 0.5174049735069275\n",
      "Seen so far: 153152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2393: 0.847091794013977\n",
      "Seen so far: 153216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2394: 0.610684871673584\n",
      "Seen so far: 153280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2395: 0.9126294851303101\n",
      "Seen so far: 153344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2396: 0.5419024229049683\n",
      "Seen so far: 153408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2397: 0.7830212116241455\n",
      "Seen so far: 153472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2398: 0.6255481243133545\n",
      "Seen so far: 153536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2399: 0.49372750520706177\n",
      "Seen so far: 153600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2400: 0.5488113164901733\n",
      "Seen so far: 153664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2401: 0.6234849095344543\n",
      "Seen so far: 153728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2402: 0.8576552867889404\n",
      "Seen so far: 153792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2403: 0.9219115972518921\n",
      "Seen so far: 153856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2404: 0.663671612739563\n",
      "Seen so far: 153920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2405: 1.0330253839492798\n",
      "Seen so far: 153984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2406: 0.42480310797691345\n",
      "Seen so far: 154048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2407: 1.2229328155517578\n",
      "Seen so far: 154112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2408: 0.3996068835258484\n",
      "Seen so far: 154176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2409: 0.7627609968185425\n",
      "Seen so far: 154240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2410: 0.5070878267288208\n",
      "Seen so far: 154304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2411: 1.1335139274597168\n",
      "Seen so far: 154368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2412: 1.0669360160827637\n",
      "Seen so far: 154432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2413: 0.8351746201515198\n",
      "Seen so far: 154496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2414: 0.9483926296234131\n",
      "Seen so far: 154560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2415: 0.9160747528076172\n",
      "Seen so far: 154624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2416: 0.8386468887329102\n",
      "Seen so far: 154688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2417: 0.863889217376709\n",
      "Seen so far: 154752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2418: 0.8565884828567505\n",
      "Seen so far: 154816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2419: 0.7073676586151123\n",
      "Seen so far: 154880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2420: 0.8162890672683716\n",
      "Seen so far: 154944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2421: 0.7467511296272278\n",
      "Seen so far: 155008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2422: 0.6501951217651367\n",
      "Seen so far: 155072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2423: 0.6895871758460999\n",
      "Seen so far: 155136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2424: 0.7861069440841675\n",
      "Seen so far: 155200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2425: 1.0233769416809082\n",
      "Seen so far: 155264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2426: 0.7956610321998596\n",
      "Seen so far: 155328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2427: 1.0020959377288818\n",
      "Seen so far: 155392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2428: 0.9774829149246216\n",
      "Seen so far: 155456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2429: 0.7325475215911865\n",
      "Seen so far: 155520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2430: 0.8946569561958313\n",
      "Seen so far: 155584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2431: 1.1575367450714111\n",
      "Seen so far: 155648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2432: 0.7208067178726196\n",
      "Seen so far: 155712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2433: 0.7845578193664551\n",
      "Seen so far: 155776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2434: 0.7131380438804626\n",
      "Seen so far: 155840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2435: 1.1248283386230469\n",
      "Seen so far: 155904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2436: 0.9408688545227051\n",
      "Seen so far: 155968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2437: 0.524863600730896\n",
      "Seen so far: 156032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2438: 0.8883072137832642\n",
      "Seen so far: 156096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2439: 0.7210789918899536\n",
      "Seen so far: 156160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2440: 0.6729409098625183\n",
      "Seen so far: 156224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2441: 0.42770272493362427\n",
      "Seen so far: 156288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2442: 0.8682802319526672\n",
      "Seen so far: 156352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2443: 0.6987574100494385\n",
      "Seen so far: 156416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2444: 0.687740683555603\n",
      "Seen so far: 156480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2445: 0.6231880187988281\n",
      "Seen so far: 156544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2446: 0.9002208113670349\n",
      "Seen so far: 156608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2447: 0.43157172203063965\n",
      "Seen so far: 156672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2448: 1.1864778995513916\n",
      "Seen so far: 156736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2449: 0.7007733583450317\n",
      "Seen so far: 156800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2450: 0.9105812311172485\n",
      "Seen so far: 156864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2451: 0.8280232548713684\n",
      "Seen so far: 156928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2452: 0.7837048768997192\n",
      "Seen so far: 156992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2453: 0.5401872396469116\n",
      "Seen so far: 157056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2454: 0.8760384321212769\n",
      "Seen so far: 157120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2455: 0.636418342590332\n",
      "Seen so far: 157184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2456: 0.59270179271698\n",
      "Seen so far: 157248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2457: 0.9125896692276001\n",
      "Seen so far: 157312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2458: 0.5713561773300171\n",
      "Seen so far: 157376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2459: 0.6898105144500732\n",
      "Seen so far: 157440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2460: 0.7993865013122559\n",
      "Seen so far: 157504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2461: 0.6158435940742493\n",
      "Seen so far: 157568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2462: 0.9580230116844177\n",
      "Seen so far: 157632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2463: 0.46217507123947144\n",
      "Seen so far: 157696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2464: 0.6763184070587158\n",
      "Seen so far: 157760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2465: 0.9117178916931152\n",
      "Seen so far: 157824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2466: 1.023624300956726\n",
      "Seen so far: 157888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2467: 1.0018177032470703\n",
      "Seen so far: 157952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2468: 0.6891511082649231\n",
      "Seen so far: 158016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2469: 0.5858899354934692\n",
      "Seen so far: 158080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2470: 0.7537102699279785\n",
      "Seen so far: 158144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2471: 1.0776119232177734\n",
      "Seen so far: 158208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2472: 0.7987383008003235\n",
      "Seen so far: 158272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2473: 0.7249796986579895\n",
      "Seen so far: 158336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2474: 1.2519161701202393\n",
      "Seen so far: 158400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2475: 0.7466679215431213\n",
      "Seen so far: 158464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2476: 0.6885159611701965\n",
      "Seen so far: 158528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2477: 0.7194918394088745\n",
      "Seen so far: 158592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2478: 0.9101108312606812\n",
      "Seen so far: 158656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2479: 0.8613761067390442\n",
      "Seen so far: 158720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2480: 0.7815818190574646\n",
      "Seen so far: 158784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2481: 0.7256956696510315\n",
      "Seen so far: 158848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2482: 0.7220619916915894\n",
      "Seen so far: 158912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2483: 0.8157006502151489\n",
      "Seen so far: 158976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2484: 0.6836992502212524\n",
      "Seen so far: 159040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2485: 0.5800269842147827\n",
      "Seen so far: 159104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2486: 1.214963436126709\n",
      "Seen so far: 159168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2487: 0.7325935959815979\n",
      "Seen so far: 159232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2488: 0.9113750457763672\n",
      "Seen so far: 159296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2489: 0.5495191812515259\n",
      "Seen so far: 159360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2490: 0.7271245718002319\n",
      "Seen so far: 159424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2491: 0.8360167145729065\n",
      "Seen so far: 159488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2492: 0.6576673984527588\n",
      "Seen so far: 159552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2493: 0.45272451639175415\n",
      "Seen so far: 159616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2494: 0.5354245901107788\n",
      "Seen so far: 159680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2495: 0.5054050087928772\n",
      "Seen so far: 159744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2496: 0.4880407452583313\n",
      "Seen so far: 159808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2497: 0.6253604292869568\n",
      "Seen so far: 159872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2498: 0.5607457756996155\n",
      "Seen so far: 159936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2499: 0.9575406312942505\n",
      "Seen so far: 160000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2500: 0.811508297920227\n",
      "Seen so far: 160064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2501: 0.7331510782241821\n",
      "Seen so far: 160128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2502: 0.6881077289581299\n",
      "Seen so far: 160192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2503: 0.6757053732872009\n",
      "Seen so far: 160256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2504: 0.9125747680664062\n",
      "Seen so far: 160320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2505: 1.1344413757324219\n",
      "Seen so far: 160384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2506: 0.6897050142288208\n",
      "Seen so far: 160448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2507: 0.8190199732780457\n",
      "Seen so far: 160512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2508: 0.7860379219055176\n",
      "Seen so far: 160576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2509: 0.5830762386322021\n",
      "Seen so far: 160640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2510: 0.9677832722663879\n",
      "Seen so far: 160704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2511: 0.9934214353561401\n",
      "Seen so far: 160768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2512: 0.6041147708892822\n",
      "Seen so far: 160832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2513: 0.766993522644043\n",
      "Seen so far: 160896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2514: 0.7118741869926453\n",
      "Seen so far: 160960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2515: 0.5367884635925293\n",
      "Seen so far: 161024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2516: 0.6185973882675171\n",
      "Seen so far: 161088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2517: 0.8947091102600098\n",
      "Seen so far: 161152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2518: 0.8713668584823608\n",
      "Seen so far: 161216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2519: 0.9062014222145081\n",
      "Seen so far: 161280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2520: 0.5240124464035034\n",
      "Seen so far: 161344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2521: 0.6935558319091797\n",
      "Seen so far: 161408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2522: 0.6033551692962646\n",
      "Seen so far: 161472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2523: 0.8934051394462585\n",
      "Seen so far: 161536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2524: 0.7456190586090088\n",
      "Seen so far: 161600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2525: 0.7421740293502808\n",
      "Seen so far: 161664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2526: 0.6788138151168823\n",
      "Seen so far: 161728 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2527: 0.7321615219116211\n",
      "Seen so far: 161792 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2528: 1.1211721897125244\n",
      "Seen so far: 161856 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2529: 0.9506386518478394\n",
      "Seen so far: 161920 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2530: 0.5641064047813416\n",
      "Seen so far: 161984 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2531: 0.7624117136001587\n",
      "Seen so far: 162048 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2532: 0.5429983139038086\n",
      "Seen so far: 162112 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2533: 1.0801281929016113\n",
      "Seen so far: 162176 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2534: 0.7944344878196716\n",
      "Seen so far: 162240 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2535: 0.5921732187271118\n",
      "Seen so far: 162304 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2536: 0.7449357509613037\n",
      "Seen so far: 162368 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2537: 0.9376028776168823\n",
      "Seen so far: 162432 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2538: 0.5162985920906067\n",
      "Seen so far: 162496 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2539: 0.8858254551887512\n",
      "Seen so far: 162560 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2540: 1.2994401454925537\n",
      "Seen so far: 162624 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2541: 1.8056045770645142\n",
      "Seen so far: 162688 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2542: 0.6668163537979126\n",
      "Seen so far: 162752 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2543: 0.7977941632270813\n",
      "Seen so far: 162816 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2544: 0.8016476035118103\n",
      "Seen so far: 162880 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2545: 1.291059970855713\n",
      "Seen so far: 162944 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2546: 0.5569954514503479\n",
      "Seen so far: 163008 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2547: 0.9285387396812439\n",
      "Seen so far: 163072 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2548: 0.894974946975708\n",
      "Seen so far: 163136 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2549: 1.1412842273712158\n",
      "Seen so far: 163200 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2550: 1.2256035804748535\n",
      "Seen so far: 163264 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2551: 0.8069571256637573\n",
      "Seen so far: 163328 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2552: 0.40996161103248596\n",
      "Seen so far: 163392 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2553: 0.9729177951812744\n",
      "Seen so far: 163456 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2554: 0.697850227355957\n",
      "Seen so far: 163520 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2555: 0.5678637027740479\n",
      "Seen so far: 163584 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2556: 1.0473614931106567\n",
      "Seen so far: 163648 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2557: 0.6443241834640503\n",
      "Seen so far: 163712 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2558: 0.6968451142311096\n",
      "Seen so far: 163776 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2559: 0.9052937030792236\n",
      "Seen so far: 163840 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2560: 0.9735062122344971\n",
      "Seen so far: 163904 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2561: 0.8583896160125732\n",
      "Seen so far: 163968 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2562: 0.5380806922912598\n",
      "Seen so far: 164032 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2563: 0.8524205088615417\n",
      "Seen so far: 164096 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2564: 0.8090004920959473\n",
      "Seen so far: 164160 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2565: 0.41708940267562866\n",
      "Seen so far: 164224 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2566: 0.8998972177505493\n",
      "Seen so far: 164288 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2567: 0.8225044012069702\n",
      "Seen so far: 164352 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2568: 1.1081522703170776\n",
      "Seen so far: 164416 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2569: 0.9051612615585327\n",
      "Seen so far: 164480 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2570: 0.7608582973480225\n",
      "Seen so far: 164544 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2571: 0.44372427463531494\n",
      "Seen so far: 164608 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2572: 1.2032859325408936\n",
      "Seen so far: 164672 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2573: 0.577800989151001\n",
      "Seen so far: 164736 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2574: 0.8035671710968018\n",
      "Seen so far: 164800 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2575: 0.5449447631835938\n",
      "Seen so far: 164864 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2576: 0.6770800948143005\n",
      "Seen so far: 164928 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2577: 0.6815313696861267\n",
      "Seen so far: 164992 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2578: 0.5727106332778931\n",
      "Seen so far: 165056 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2579: 0.7293912172317505\n",
      "Seen so far: 165120 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2580: 1.2162208557128906\n",
      "Seen so far: 165184 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2581: 0.693000853061676\n",
      "Seen so far: 165248 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2582: 1.0750856399536133\n",
      "Seen so far: 165312 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2583: 0.6318504810333252\n",
      "Seen so far: 165376 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2584: 0.38621556758880615\n",
      "Seen so far: 165440 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2585: 0.6147443056106567\n",
      "Seen so far: 165504 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2586: 0.7743792533874512\n",
      "Seen so far: 165568 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2587: 0.5453093647956848\n",
      "Seen so far: 165632 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2588: 0.6611341238021851\n",
      "Seen so far: 165696 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2589: 0.7328314185142517\n",
      "Seen so far: 165760 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2590: 0.8374402523040771\n",
      "Seen so far: 165824 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2591: 0.7567524909973145\n",
      "Seen so far: 165888 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2592: 0.743138313293457\n",
      "Seen so far: 165952 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2593: 0.7574847340583801\n",
      "Seen so far: 166016 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2594: 0.850256085395813\n",
      "Seen so far: 166080 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2595: 0.5980223417282104\n",
      "Seen so far: 166144 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2596: 0.5397794246673584\n",
      "Seen so far: 166208 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2597: 0.487663209438324\n",
      "Seen so far: 166272 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2598: 0.9138559103012085\n",
      "Seen so far: 166336 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2599: 0.6495373249053955\n",
      "Seen so far: 166400 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2600: 0.8441929817199707\n",
      "Seen so far: 166464 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2601: 0.5190722942352295\n",
      "Seen so far: 166528 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2602: 0.6544926166534424\n",
      "Seen so far: 166592 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2603: 0.5934077501296997\n",
      "Seen so far: 166656 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2604: 0.8542381525039673\n",
      "Seen so far: 166720 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2605: 0.5800009965896606\n",
      "Seen so far: 166784 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2606: 0.8844735026359558\n",
      "Seen so far: 166848 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2607: 1.340315580368042\n",
      "Seen so far: 166912 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2608: 0.528564989566803\n",
      "Seen so far: 166976 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2609: 0.6050295233726501\n",
      "Seen so far: 167040 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2610: 0.862319827079773\n",
      "Seen so far: 167104 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2611: 0.7218636274337769\n",
      "Seen so far: 167168 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2612: 0.9118359684944153\n",
      "Seen so far: 167232 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2613: 0.6672726273536682\n",
      "Seen so far: 167296 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2614: 0.8090730905532837\n",
      "Seen so far: 167360 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2615: 0.5670891404151917\n",
      "Seen so far: 167424 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2616: 0.5816675424575806\n",
      "Seen so far: 167488 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2617: 0.6602616310119629\n",
      "Seen so far: 167552 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2618: 0.6781325936317444\n",
      "Seen so far: 167616 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2619: 1.188417673110962\n",
      "Seen so far: 167680 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2620: 0.5756697058677673\n",
      "Seen so far: 167744 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2621: 0.6209867000579834\n",
      "Seen so far: 167808 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2622: 0.8477692604064941\n",
      "Seen so far: 167872 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2623: 0.9206311106681824\n",
      "Seen so far: 167936 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2624: 0.9124621152877808\n",
      "Seen so far: 168000 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2625: 0.5988819599151611\n",
      "Seen so far: 168064 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2626: 0.6076408624649048\n",
      "Seen so far: 168128 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2627: 0.843326985836029\n",
      "Seen so far: 168192 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2628: 0.39220213890075684\n",
      "Seen so far: 168256 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2629: 0.8934805393218994\n",
      "Seen so far: 168320 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2630: 1.0135371685028076\n",
      "Seen so far: 168384 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2631: 0.6978247165679932\n",
      "Seen so far: 168448 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2632: 0.554174542427063\n",
      "Seen so far: 168512 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2633: 0.7579230070114136\n",
      "Seen so far: 168576 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2634: 0.8618937730789185\n",
      "Seen so far: 168640 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2635: 0.8849472999572754\n",
      "Seen so far: 168704 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2636: 0.7964468002319336\n",
      "Seen so far: 168768 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2637: 0.7470080256462097\n",
      "Seen so far: 168832 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2638: 1.4881503582000732\n",
      "Seen so far: 168896 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2639: 0.987934947013855\n",
      "Seen so far: 168960 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2640: 0.6325676441192627\n",
      "Seen so far: 169024 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2641: 0.4907398521900177\n",
      "Seen so far: 169088 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2642: 0.7785078287124634\n",
      "Seen so far: 169152 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2643: 0.9079344272613525\n",
      "Seen so far: 169216 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2644: 0.7030302286148071\n",
      "Seen so far: 169280 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2645: 0.7352396249771118\n",
      "Seen so far: 169344 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2646: 0.7375605702400208\n",
      "Seen so far: 169408 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2647: 0.5897791385650635\n",
      "Seen so far: 169472 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2648: 0.6939277648925781\n",
      "Seen so far: 169536 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2649: 0.8758656978607178\n",
      "Seen so far: 169600 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2650: 0.7615271806716919\n",
      "Seen so far: 169664 samples\n",
      "inside the tape\n",
      "Training loss (for one batch) at step 2651: 0.9115432500839233\n",
      "Seen so far: 169728 samples\n",
      "Training acc over epoch: 0.7507631778717041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n    # Run a validation loop at the end of each epoch.\\n    for x_batch_val, y_batch_val in val_dataset:\\n        val_logits = model(x_batch_val)\\n        # Update val metrics\\n        val_acc_metric(y_batch_val, val_logits)\\n\\n    val_acc = val_acc_metric.result()\\n    val_acc_metric.reset_states()\\n    print('Validation acc: %s' % (float(val_acc),))\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Try manual learining \n",
    "\n",
    "# Instantiate an optimizer.\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
    "# Instantiate a loss function.\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "# Prepare the metrics.\n",
    "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "# Iterate over epochs.\n",
    "for epoch in range(10):\n",
    "    print('Start of epoch %d' % (epoch,))\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "\n",
    "        # Open a GradientTape to record the operations run\n",
    "        # during the forward pass, which enables autodifferentiation.\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            # Run the forward pass of the layer.\n",
    "            # The operations that the layer applies\n",
    "            # to its inputs are going to be recorded\n",
    "            # on the GradientTape.\n",
    "            logits = model(x_batch_train)  # Logits for this minibatch\n",
    "\n",
    "            # Compute the loss value for this minibatch.\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "            \n",
    "            print(\"inside the tape\")\n",
    "\n",
    "        # Use the gradient tape to automatically retrieve\n",
    "        # the gradients of the trainable variables with respect to the loss.\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "\n",
    "        # Run one step of gradient descent by updating\n",
    "        # the value of the variables to minimize the loss.\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        \n",
    "        # Update training metric.\n",
    "        train_acc_metric(y_batch_train, logits)\n",
    "\n",
    "        print('Training loss (for one batch) at step %s: %s' % (step, float(loss_value)))\n",
    "        print('Seen so far: %s samples' % ((step + 1) * 64))\n",
    "        \n",
    "    # Display metrics at the end of each epoch.\n",
    "    train_acc = train_acc_metric.result()\n",
    "    print('Training acc over epoch: %s' % (float(train_acc),))\n",
    "    # Reset training metrics at the end of each epoch\n",
    "    train_acc_metric.reset_states()\n",
    "\"\"\" Questa parte si puo scommentare dovebbe usare il validation set e basta \n",
    "    # Run a validation loop at the end of each epoch.\n",
    "    for x_batch_val, y_batch_val in val_dataset:\n",
    "        val_logits = model(x_batch_val)\n",
    "        # Update val metrics\n",
    "        val_acc_metric(y_batch_val, val_logits)\n",
    "\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    print('Validation acc: %s' % (float(val_acc),))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model (ho aggiornato il modello, se vuoi salvare cambia il numero)\n",
    "model.save('Model/my_model_using-tf-lowlevel-api-2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11005/11005 [==============================] - 356s 32ms/step - loss: 0.9338 - sparse_categorical_accuracy: 0.7042\n"
     ]
    }
   ],
   "source": [
    "test_dataset = create_dataset(dataset_dir, test, testWAVlabels, batch_size = 1, shuffle = False, cache_file = 'test_cache')\n",
    "\n",
    "model.compile(optimizer = adam,\n",
    "              loss = tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics = ['sparse_categorical_accuracy'])\n",
    "\n",
    "testEval = model.evaluate(test_dataset, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" CApire se con eager execution attiva funziona il fit normale, che sarebbe molto meglio\n",
    "adam = tf.train.AdamOptimizer(learning_rate=0.001,  \n",
    "                                beta1=0.9,\n",
    "                                beta2=0.999,\n",
    "                                epsilon=1e-07,\n",
    "                                use_locking=False,\n",
    "                                name='Adam')\n",
    "\n",
    "model.compile(optimizer = adam,\n",
    "              loss = tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics = ['sparse_categorical_accuracy'])\n",
    "\n",
    "num_epochs = 10\n",
    "history = model.fit(train_dataset, \n",
    "                    epochs = num_epochs, \n",
    "                    #steps_per_epoch = train_steps,\n",
    "                    validation_data = val_dataset, \n",
    "                    validation_steps = val_steps)\n",
    "\n",
    "# Save the model\n",
    "model.save('Model/my_model_using-tf.h5')\n",
    "\n",
    "print(history.history.keys())\n",
    "\n",
    "# Plot loss\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Train loss')\n",
    "plt.plot(history.history['val_loss'], label='Val loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "# Plot accuracy\n",
    "plt.figure()\n",
    "plt.plot(history.history['categorical_accuracy'], label='Train acc')\n",
    "plt.plot(history.history['val_categorical_accuracy'], label='Val acc')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" DA capire come usare questa cosa che pu essere molto utile\n",
    "import math\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    drop = 0.4\n",
    "    epochs_drop = 3.0\n",
    "    lrate = initial_lrate * math.pow(drop,  \n",
    "            math.floor((1+epoch)/epochs_drop))\n",
    "    \n",
    "    if (lrate < 4e-5):\n",
    "        lrate = 4e-5\n",
    "      \n",
    "    print('Changing learning rate to {}'.format(lrate))\n",
    "    return lrate\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "\n",
    "earlystopper = EarlyStopping(monitor='val_categorical_accuracy', patience=10, verbose=1)\n",
    "checkpointer = ModelCheckpoint('Model/my_model_loss_dropout-0_05-yes_reg-0.h5', \n",
    "                               monitor='val_categorical_accuracy', \n",
    "                               verbose=1, save_best_only = True, save_weights_only = True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 99, 39, 1)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# I don't now why i need to reshape in this way but it works \n",
    "x = \"tree/022cd682_nohash_1.wav.npy\"\n",
    "x = load_and_preprocess_data(x, dataset_dir).reshape((1, 99, 39, 1))\n",
    "print(x.shape)\n",
    "res = model.predict(x) \n",
    "print(res.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
