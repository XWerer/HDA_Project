{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta0\n"
     ]
    }
   ],
   "source": [
    "import Model\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import re\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "from extractMFCC import computeFeatures, computeFeatures1\n",
    "from addNoise import addNoise\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "testWAVs = pd.read_csv('Dataset/testing_list.txt', sep=\" \", header=None)[0].tolist()\n",
    "valWAVs  = pd.read_csv('Dataset/validation_list.txt', sep=\" \", header=None)[0].tolist()\n",
    "\n",
    "for idx, item in enumerate(testWAVs):\n",
    "    testWAVs[idx] = \"Dataset/\" + testWAVs[idx]\n",
    "\n",
    "for idx, item in enumerate(valWAVs):\n",
    "    valWAVs[idx] = \"Dataset/\" + valWAVs[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DictCategs = {'nine' : 1, 'yes' : 2, \n",
    "                         'no' : 3, 'up' : 4, 'down' : 5, 'left' : 6, 'right' : 7, 'on' : 8, 'off' : 9, 'stop' : 10, 'go' : 11,\n",
    "                         'zero' : 12, 'one' : 13, 'two' : 14, 'three' : 15, 'four' : 16, 'five' : 17, 'six' : 18, \n",
    "                         'seven' : 19,  'eight' : 20, 'backward':0, 'bed':0, 'bird':0, 'cat':0, 'dog':0,\n",
    "                         'follow':0, 'forward':0, 'happy':0, 'house':0, 'learn':0, 'marvin':0, 'sheila':0, 'tree':0,\n",
    "                         'visual':0, 'wow':0}\n",
    "nCategs = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "allWAVs  = []\n",
    "for root, dirs, files in os.walk('Dataset/'):\n",
    "    if root != \"Dataset/_background_noise_\":\n",
    "        allWAVs += [root+'/'+ f for f in files if f.endswith('.wav')]\n",
    "trainWAVs = list( set(allWAVs)-set(valWAVs)-set(testWAVs) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84843\n",
      "9981\n",
      "11005\n"
     ]
    }
   ],
   "source": [
    "print(len(trainWAVs))\n",
    "print(len(valWAVs))\n",
    "print(len(testWAVs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _getFileCategory(file, catDict):\n",
    "    \"\"\"\n",
    "    Receives a file with name Dataset/<cat>/<filename> and returns an integer that is catDict[cat]\n",
    "    \"\"\"\n",
    "    categ = os.path.basename(os.path.dirname(file))\n",
    "    return catDict.get(categ,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get categories\n",
    "testWAVlabels = [_getFileCategory(f, DictCategs) for f in testWAVs]\n",
    "valWAVlabels = [_getFileCategory(f, DictCategs) for f in valWAVs]\n",
    "trainWAVlabels = [_getFileCategory(f, DictCategs) for f in trainWAVs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84843\n",
      "9981\n",
      "11005\n"
     ]
    }
   ],
   "source": [
    "print(len(trainWAVlabels))\n",
    "print(len(valWAVlabels))\n",
    "print(len(testWAVlabels))\n",
    "#print(trainWAVs[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfeats = load_and_preprocess_data(trainWAVs[25])\\nfeats = np.transpose(feats)\\n\\nplt.figure(figsize=(17,6))\\nplt.pcolormesh(feats)\\n\\nplt.title('Spectrogram visualization')\\nplt.ylabel('Frequency')\\nplt.xlabel('Time')\\n\\nplt.show()\\nprint(trainWAVlabels[25])\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_and_preprocess_data(file_name):\n",
    "    # Required by tensorflow (strings are passed as bytes)\n",
    "    # tf.strings.as_string(...)\n",
    "    file_name = file_name.numpy()\n",
    "    file_name = file_name.decode(\"utf-8\") \n",
    "    #print(file_name)\n",
    "    #print(type(file_name))\n",
    "\n",
    "    # Load data\n",
    "    feats = computeFeatures(file_name)\n",
    "    # Normalize\n",
    "    mean = np.mean(feats, axis = 0)\n",
    "    stv = np.std(feats, axis = 0)\n",
    "    diff = np.subtract(feats, mean)\n",
    "    feats = np.divide(diff, stv)\n",
    "\n",
    "    return feats.astype(np.float32)\n",
    "\n",
    "# example:\n",
    "\"\"\"\n",
    "feats = load_and_preprocess_data(trainWAVs[25])\n",
    "feats = np.transpose(feats)\n",
    "\n",
    "plt.figure(figsize=(17,6))\n",
    "plt.pcolormesh(feats)\n",
    "\n",
    "plt.title('Spectrogram visualization')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Time')\n",
    "\n",
    "plt.show()\n",
    "print(trainWAVlabels[25])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(file_names, labels, batch_size, shuffle, cache_file=None):\n",
    "    \n",
    "    # Create a Dataset object\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((file_names, labels))\n",
    "    \n",
    "    # Map the load_and_preprocess_data function\n",
    "    py_func = lambda file_name, label: (tf.py_function(load_and_preprocess_data, [file_name], Tout=tf.float32), label)\n",
    "    dataset = dataset.map(py_func, num_parallel_calls=os.cpu_count())\n",
    "    \n",
    "    # Cache dataset\n",
    "    if cache_file:\n",
    "        dataset = dataset.cache(cache_file)\n",
    "    \n",
    "    # Shuffle    \n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(len(file_names))\n",
    "        \n",
    "    # Repeat the dataset indefinitely\n",
    "    dataset = dataset.repeat()\n",
    "    \n",
    "    # Correct input shape for the network\n",
    "    dataset = dataset.map(lambda data, label: (tf.expand_dims(data, 1), label))\n",
    "    \n",
    "    # Batch\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "    \n",
    "    # Prefetch\n",
    "    dataset = dataset.prefetch(buffer_size=1)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataset = create_dataset(trainWAVs, \n",
    "                               trainWAVlabels, \n",
    "                               batch_size=batch_size, \n",
    "                               shuffle=True,\n",
    "                               cache_file='train_cache')\n",
    "\n",
    "val_dataset = create_dataset(valWAVs, \n",
    "                             valWAVlabels,\n",
    "                             batch_size=batch_size, \n",
    "                             shuffle=False,\n",
    "                             cache_file='val_cache')\n",
    "\n",
    "train_steps = int(np.ceil(len(trainWAVs)/batch_size))\n",
    "val_steps = int(np.ceil(len(valWAVs)/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model.AttentionModel(21, 99, 39, use_GRU = True)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0621 12:00:08.520006 140281944991488 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n",
      "W0621 12:00:08.521326 140281936598784 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n",
      "W0621 12:00:08.582413 140281944991488 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n",
      "W0621 12:00:08.630427 140281936598784 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n",
      "/home/jupyter/HDA_Project/extractMFCC.py:30: RuntimeWarning: invalid value encountered in log10\n",
      "  log_E_s = np.log10(E_s)\n",
      "W0621 12:00:08.635338 140281944991488 backprop.py:842] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/scipy/io/wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "history = model.fit(train_dataset, epochs=num_epochs, steps_per_epoch=train_steps, validation_data=val_dataset, validation_steps=val_steps)\n",
    "\n",
    "# Save the model\n",
    "model.save('my_model.h5')\n",
    "\n",
    "# Plot loss\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Train loss')\n",
    "plt.plot(history.history['val_loss'], label='Val loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "# Plot accuracy\n",
    "plt.figure()\n",
    "plt.plot(history.history['acc'], label='Train loss')\n",
    "plt.plot(history.history['val_acc'], label='Val loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
